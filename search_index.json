[
  {
    "title": "Overview",
    "category": "bouwblokken",
    "path": "bouwblokken/overview.md",
    "content": "Bouwblokken Overview De Bouwblokken (Building Blocks) vormen de modulaire componenten waaruit de Druppie-architectuur is opgebouwd. Elk bouwblok vertegenwoordigt een specifieke functionaliteit of capability binnen het platform. Dit overzicht beschrijft de definities en contracten van deze componenten. ğŸ›ï¸ Core Components Deze blokken vormen het hart van het systeem. - Druppie Core (Orchestrator) - Het centrale brein dat user intents vertaalt naar acties. Gebruikt een planner en semantic kernel. - Druppie UI - De interface voor interactie (Chat/Copilot). - Bouwblok Definities - De metadata-catalogus die beschrijft wat elk blok kan en hoe het aangeroepen wordt. ğŸ›¡ï¸ Governance & Control Blokken die toezicht en veiligheid garanderen. - Policy Engine - Evalueert elke geplande actie tegen bedrijfs- en veiligheidsregels. - Mens in de Loop - Het mechanisme voor menselijke goedkeuring bij risicovolle beslissingen. - Traceability DB - De \"black box\" die alle beslissingen, prompts en acties onveranderlijk vastlegt. - Compliance Layer - De overkoepelende laag voor auditing en security monitoring. ğŸ­ Execution & Factory De lagen waar het werk daadwerkelijk wordt uitgevoerd. - Build Plane - De definitie van de \"fabriek\" die code omzet in artifacts (zie ook de diepere Build Plane directory). - Runtime - De definitie van de landingsplaats (Kubernetes) voor applicaties (zie ook de diepere Runtime directory). ğŸ¤– Specialised Agents Gespecialiseerde workers. - Knowledge Bot - Een RAG-enabled agent die informatie uit documentatie kan ontsluiten."
  },
  {
    "title": "Bouwblok Definities",
    "category": "bouwblokken",
    "path": "bouwblokken/bouwblok_definities.md",
    "content": "Bouwblok Definities (Registry) ğŸ¯ Doelstelling De Bouwblok Definities vormen de catalogus en metadata-laag van het platform. Om de AI (Druppie Core) in staat te stellen zichzelf samen te stellen en de juiste tools te kiezen, moet er een gestructureerde definitie zijn van alle beschikbare capabilities, skills, en services. Dit is de \"telefoongids\" en \"handleiding\" voor de AI. ğŸ“‹ Functionele Specificaties 1. Spec-Driven Agent Creatie (Agent-as-Code) - Declaratieve Definities: Capabilities en Agents worden gedefinieerd in YAML/JSON schema's (zie research). - Inhoud Definitie: Bevat Model config, Instructies (Prompts), Tools (OpenAPI) en Governance metadata (Owner, Cost Center). - Versiebeheer: Alle definities worden opgeslagen in Git voor auditability en rollback mogelijkheden. 2. Agent Registry - Central Repository: Een database (Cosmos DB) die fungeert als \"Telefoonboek\" voor de Router Agent. - Interface Beschrijving: Bevat technische specs (OpenAPI) zodat de Router weet hoe een Spoke aan te roepen is. ğŸ”§ Technische Requirements - Standaard Formaat: Gebruikt open standaarden zoals OpenAPI (Swagger) of Model Context Protocol (MCP) definities. - Extensible: Nieuwe definities moeten makkelijk toegevoegd kunnen worden zonder herstart van de Core (Plugin architectuur). ğŸ”’ Security & Compliance - Scoped Access: Definities bevatten metadata over vereiste permissies (scopes), zodat de Orchestrator vooraf checks kan doen. ğŸ”Œ Interacties | Wie | Actie | Doel | | :--- | :--- | :--- | | Druppie Core Planner | Query Registry | \"Welke tool kan e-mails sturen?\" | | Developer | Register Tool | Nieuwe capability toevoegen | ğŸ—ï¸ Relaties tot andere blokken - Geraadpleegd door: Druppie Core. - Bevat definities voor: Build Plane, Runtime en alle Skills."
  },
  {
    "title": "Druppie UI",
    "category": "bouwblokken",
    "path": "bouwblokken/druppie_ui.md",
    "content": "Druppie UI (Copilot) ğŸ¯ Doelstelling De Druppie UI is het gezicht van het platform. Het biedt een intuÃ¯tieve, chat-gebaseerde interface (Copilot) waarmee gebruikers op natuurlijke wijze interactie hebben met de complexe agent-architectuur. Het doel is om de complexiteit van de backend te abstraheren en de gebruiker in controle te houden (\"Human in the Loop\"). ğŸ“‹ Functionele Specificaties 1. Conversational Interface & Integratie - Microsoft 365 Copilot: De primaire interface voor medewerkers, geÃ¯ntegreerd in Teams, Outlook en Word via Declarative Agents. - Druppie Custom UI: Een fallback/admin chat interface voor geavanceerde taken. - Streaming Response: Ondersteuning voor real-time text streaming. - Rich Media: Adaptieve kaarten en deep links naar specifieke applicaties. 2. Interactieve Elementen - Slash Commands: Ondersteunt commando's (bijv. /reset, /help, /new-project) voor directe sturing. - Adaptive Cards: Toont gestructureerde formulieren voor input (bijv. bij requirements intake). - Status Indicatoren: Geeft duidelijk aan wat het systeem aan het doen is (\"Thinking...\", \"Building...\", \"Waiting for Approval\"). 3. Human Approval Interface - Notifications: Toont alerts wanneer de gebruiker actie moet ondernemen (goedkeuring geven). - Decision Context: Biedt alle noodzakelijke informatie om een goedkeuring te kunnen doen (diffs, risico-analyse). ğŸ”§ Technische Requirements - Proxy Pattern: Gebruik van Azure Functions als brug tussen M365 Copilot en de Azure AI Agent Service. - Protocol Translatie: Mappen van M365 conversationIds naar Azure Agent Thread IDs. - Security: Validatie van M365 tokens en gebruik van Managed Identity voor backend communicatie. - Responsive Design: Custom UI moet responsive zijn. ğŸ”’ Security & Compliance - Auth Integration: Integreert naadloos met IAM (SSO). - Input Sanitization: Client-side filtering om XSS en injecties te voorkomen. - Privacy Mode: Visuele indicatie wanneer gevoelige data wordt verwerkt. ğŸ”Œ Interacties | Actie | Richting | Omschrijving | | :--- | :--- | :--- | | User Prompt | UI -> Core | Gebruiker stuurt vraag of commando. | | Stream Chunk | Core -> UI | Real-time tekst updates van de AI. | | Approval Request | Policy -> UI | Pop-up voor menselijke goedkeuring. | ğŸ—ï¸ Relaties tot andere blokken - Authenticeert via: IAM. - Stuurt aan: Druppie Core. - Toont requests van: Mens in de Loop."
  },
  {
    "title": "Druppie Core",
    "category": "bouwblokken",
    "path": "bouwblokken/druppie_core.md",
    "content": "Druppie Core (Orchestrator) ğŸ¯ Doelstelling De Druppie Core fungeert als het centrale zenuwstelsel van het platform. Het is verantwoordelijk voor het interpreteren van gebruikersvragen (intents), het plannen van complexe takenreeksen, en het orkestreren van gespecialiseerde agents en tools om tot een antwoord of oplossing te komen. Een kerntaak van de Core is het beheren van Multi-Agent samenwerking om grote problemen automatisch op te delen in bestaande of nieuwe oplossingen. ğŸ“‹ Functionele Specificaties 1. Intent Recognition & Routing (The Hub) - Hub-and-Spoke Model: De Core fungeert als de centrale Router Agent (Hub) die verzoeken ontvangt en distribueert naar gespecialiseerde agents (Spokes). - Context Awareness: Analyseert de vraag en context om de juiste specialist uit het register te kiezen. - Dispatcher Pattern: Gebruikt mechanismen zoals \"Connected Agents\" om taken te delegeren zonder de controle te verliezen. 2. Multi-Agent Planning & Decompositie - Problem Decomposition: De Router breekt complexe vragen op in sub-taken. - Agent Swarm Management: CoÃ¶rdineert de samenwerking tussen verschillende domein-experts (bijv. Finance, IT, HR). - Consensus & Review: Organiseert waar nodig peer-reviews tussen agents. 3. Capability Gap Analysis & Creatie Voordat de Core een taak uitvoert, checkt hij de Bouwblok Definities: 1. Check: Bestaat er al een bouwblok dat dit sub-probleem oplost? Ja: Gebruik het bestaande blok (hergebruik). Nee: Initieer Creatie Flow. 2. New Project Scaffolding: De Core stelt voor om een nieuw bouwblok te maken. 3. Specification Refinement: De Core gaat interactief met de gebruiker in gesprek om de specificaties voor dit nieuwe blok uit te werken (samen met de Business Analyst Agent). 4. Tool Gebruik (Capability Invocation) - Moet via gestandaardiseerde interfaces (MCP) tools kunnen aanroepen. - Moet parameters correct extraheren uit de gebruikersvraag om tools mee aan te sturen. ğŸ”§ Technische Requirements - Platform: Gebaseerd op Microsoft Foundry (voorheen Azure AI Studio) als centraal beheersplatform. - Runtime: Maakt gebruik van de Azure AI Agent Service voor stateful execution en thread management. - Model Agnostic: Gebruik van Semantic Kernel of LangChain als abstractielaag om flexibel tussen modellen (GPT-4o, etc.) te wisselen. - Latency: Time-to-first-token < 500ms voor routing beslissingen. - State Prevention: Threads en context worden beheerd door de Agent Service (Azure storage). ğŸ”’ Security & Compliance - Safety Rails: Alle user input moet door een safety filter (jailbreak detection, PII screening). - Least Privilege: De Core mag alleen tools aanroepen waar de ingelogde gebruiker rechten toe heeft. - Audit Logging: Elke planningsbeslissing, en met name de keuze om iets nieuws te bouwen, wordt gelogd. ğŸ”Œ Interacties | Trigger | Bron | Actie | Output | | :--- | :--- | :--- | :--- | | New Prompt | Druppie UI | Analyseer intentie & start plan | Response stream | | Missing Capability | Planner | Stel voor nieuw blok te bouwen | Interactieve specs dialoog | | Tool Response | MCP / Agent | Verwerk resultaat & volgende stap | Volgende instructie | ğŸ—ï¸ Relaties tot andere blokken - Raadpleegt: Bouwblok Definities om te zien wat er al is. - Initieert: Builder Agent als er een nieuw blok gebouwd moet worden. - Controleert: Policy Engine voor validatie van het plan."
  },
  {
    "title": "Mens in de Loop",
    "category": "bouwblokken",
    "path": "bouwblokken/mens_in_de_loop.md",
    "content": "Mens in de Loop (Human in the Loop) ğŸ¯ Doelstelling Het bouwblok Mens in de Loop (HITL) integreert menselijke intelligentie en verantwoordelijkheid in het geautomatiseerde proces. Hoewel AI veel kan automatiseren, vereisen kritieke beslissingen, ethische afwegingen en hoge risico's altijd menselijke validatie. Dit blok voorkomt \"AI hallucinations\" die leiden tot productieschade. ğŸ“‹ Functionele Specificaties 1. Goedkeurings Workflows - Critical Gating: Blokkeert uitvoering bij specifieke triggers (bijv. deployments naar productie, verwijderen van data, kosten > â‚¬X). - Escalatie: Kan verzoeken escaleren naar specifieke rollen (bijv. CISO voor security, PO voor features). 2. Contextuele Validatie - Diff Review: Toont de gebruiker precies wat er gaat veranderen (bijv. Terraform plan, Code diff). - Explanation: De AI moet uitleggen waarom hij deze actie wil doen, zodat de mens een geÃ¯nformeerde keuze kan maken. 3. Feedback Loop - Korrektie: De mens moet niet alleen Ja/Nee kunnen zeggen, maar ook sturend commentaar kunnen geven (\"Nee, doe dit opnieuw maar gebruik bibliotheek X\"). - Learning: De feedback van de mens wordt (geanonimiseerd) gebruikt om toekomstige prompts te verbeteren. ğŸ”§ Technische Requirements - Asynchroon: Een goedkeuringsverzoek kan minuten of uren openstaan; het systeem mag niet time-outen. - Multi-channel: Notificaties kunnen via Chat, Email, of ITSM tools (ServiceNow/Jira) verlopen. ğŸ”’ Security & Compliance - Non-repudiation: Het moet onweerlegbaar zijn WIE de goedkeuring heeft gegeven. - Segregation of Duties: De persoon die de code aanvraagt mag (in sommige gevallen) niet dezelfde zijn die goedkeurt. ğŸ”Œ Interacties | Trigger | Actie | Output | | :--- | :--- | :--- | | Policy Violation (Requires Approval) | Stuur notificatie + Context | Wachtstatus in Core | | User Action (Approve/Reject) | Verwerk beslissing | Core hervat of stopt | ğŸ—ï¸ Relaties tot andere blokken - Geactiveerd door: Policy Engine. - Communiceert via: Druppie UI. - Gelogd in: Traceability DB."
  },
  {
    "title": "Policy Engine",
    "category": "bouwblokken",
    "path": "bouwblokken/policy_engine.md",
    "content": "Policy Engine ğŸ¯ Doelstelling De Policy Engine is de bewaker van de integriteit, veiligheid en compliance van het platform. Dit blok zorgt ervoor dat geen enkele geautomatiseerde actie in strijd is met bedrijfsregels, wetgeving of ethische kaders. Het is de \"nee, tenzij\"-laag die elk plan van de Orchestrator valideert. ğŸ“‹ Functionele Specificaties 1. Actie Validatie (Pre-Execution Guardrails) - Real-time Controle: Elke actie of tool-aanroep die de Orchestrator wil doen, moet eerst langs de Policy Engine. - Contextuele Regels: Regels kunnen afhangen van context (bijv. \"Geen productie-deployments op vrijdagmiddag\", \"Alleen Seniors mogen databases droppen\"). 2. Risico Classificatie - Risk Scoring: Kent een risicoscore toe aan een actie (Low, Medium, High, Critical). - Threshold Management: Bepaalt op basis van score of een actie mag doorgaan, geblokkeerd wordt, of menselijke goedkeuring vereist. 3. Policy-as-Code - Declaratieve Regels: Policies worden gedefinieerd in code (bijv. OPA/Rego) en niet in ondoorzichtige logica. - Versiebeheer: Wijzigingen in policies volgen een strikt change proces via Git. ğŸ”§ Technische Requirements - Performance: Validatie moet extreem snel zijn (< 50ms) om de gebruikerservaring niet te vertragen. - Fail-Closed: Als de Policy Engine niet bereikbaar is of faalt, moeten alle risicovolle acties worden geblokkeerd. - Hot Reload: Nieuwe regels moeten geladen kunnen worden zonder downtime. ğŸ”’ Security & Compliance - Immutability: Regels mogen niet tijdens runtime door de AI zelf aangepast kunnen worden. - Audit Trail: Elke Allow/Deny beslissing moet cryptografisch ondertekend en opgeslagen worden in de Traceability DB. ğŸ”Œ Interacties | Input | Bron | Verwerking | Output | | :--- | :--- | :--- | :--- | | Proposed Plan | Orchestrator | Evalueer tegen regelset | ALLOW, DENY, of REQUIRE_APPROVAL | | Policy Update | Git CI/CD | Laad nieuwe ruleset | Bevestiging activatie | ğŸ—ï¸ Relaties tot andere blokken - Blokkeert/Stuurt: Druppie Core - Initieert: Mens in de Loop (bij REQUIRE_APPROVAL status). - Logt naar: Traceability DB."
  },
  {
    "title": "Compliance Layer",
    "category": "bouwblokken",
    "path": "bouwblokken/compliance_layer.md",
    "content": "Compliance Layer Definitie ğŸ¯ Doelstelling De Compliance Layer is het overkoepelende kader dat niet zozeer \"iets doet\" (zoals code bouwen), maar \"overal naar kijkt\". Het definieert de standaarden en audit-mechanismen. Zie Compliance Domein voor de diepte-uitwerking. ğŸ“‹ Functionele Specificaties 1. Continuous Audit - Aggregatie: Verzamelt signalen uit Policy Engine, Traceability DB, en Runtime logs. - Reporting: Genereert rapportages voor auditors (bijv. \"Lijst van alle code changes die zonder 4-eyes principle naar prod zijn gegaan\"). 2. Machine Identity (Agent ID) - Entra Agent ID: Elke AI-agent krijgt een unieke identiteit in Entra ID (voorheen Azure AD). - Granulaire Rechten: Permissies worden toegekend aan de specifieke agent (bijv. \"Finance Agent\" mag alleen bij de Finance Sharepoint). - Managed Identity: Gebruik van Managed Identities voor veilige service-to-service communicatie zonder secrets. ğŸ—ï¸ Relaties - Verwijst naar: Compliance Domein. - Integreert met: Alle andere bouwblokken (elke actie genereert compliance data)."
  },
  {
    "title": "Build Plane",
    "category": "bouwblokken",
    "path": "bouwblokken/build_plane.md",
    "content": "Build Plane Interface ğŸ¯ Doelstelling Dit bouwblok definieert de interface naar de externe Build Plane. De Build Plane zelf is de \"fabriek\" die code produceert en verifieert (zie de gedetailleerde Build Plane documentatie). Vanuit het perspectief van Druppie Core is dit bouwblok de abstractie die toegang geeft tot die fabriek. ğŸ“‹ Functionele Specificaties 1. Job Submission - Spec-in, Artifact-out: Accepteert een declaratieve BuildSpec als input. - Fire & Forget: Start asynchrone build taken en geeft een Job ID terug. 2. Status Monitoring - Polling / Webhooks: Mechanisme om de voortgang van de build (Compiling... Testing... Scanning...) terug te koppelen aan de Orchestrator en UI. - Log Streaming: Live logs doorgeven bij failures. 3. Artifact Handover - Zorgt dat geproduceerde images en packages geregistreerd worden en beschikbaar zijn voor de Runtime. ğŸ—ï¸ Relaties - Verwijst naar: Build Plane Domein. - Wordt gebruikt door: Druppie Core wanneer code gegenereerd of gebouwd moet worden."
  },
  {
    "title": "Media & Brand (Strapi)",
    "category": "bouwblokken",
    "path": "bouwblokken/brand_management.md",
    "content": "Bouwblok: Media & Brand Management (Headless CMS/DAM) ğŸ¯ Doelstelling Het centraliseren van rijke media (afbeeldingen, video's, 3D-modellen) en merkidentiteit in een Headless Digital Asset Management (DAM) systeem. Dit systeem moet: 1. Bron van Waarheid zijn voor logo's, kleurcodes en media. 2. API-first zijn, zodat AI Agents assets kunnen uploaden en ophalen. 3. Schaalbaar draaien binnen Kubernetes. âš™ï¸ Technologie Selectie: Strapi Na evaluatie van Pimcore (te zwaar), ResourceSpace (te monolithisch) en Directus, kiezen we voor Strapi als onze Headless CMS/DAM oplossing. Waarom Strapi? Kubernetes-Native: Eenvoudig te deployen als NodeJS container met een database backend (PostgreSQL). Media Library: Ingebouwde, krachtige media management met plugin support (bijv. image optimalisatie). Gestructureerde Data: Kan niet alleen bestanden opslaan, maar ook \"Brand Guidelines\" als gestructureerde content (kleurpaletten, typography regels) die Agents kunnen lezen. Extensible: Volledig aanpasbaar via Javascript/Typescript. Integratie in Druppie Strapi fungeert als de Geheugenbank voor Creatieve Assets. Input: De AI Video pipeline uploadt de definitieve .mp4 films naar Strapi. Output: De Director Agent leest de \"Corporate Identity\" collectie om te weten welke hex-codes en font-files hij moet gebruiken in de video overlays. Opslag: Strapi slaat de metadata op in Postgres en de binary files in MinIO (S3 compatible), wat perfect past in onze bestaande infrastructuur. ğŸ› ï¸ Technische Implementatie Kubernetes Deployment We draaien Strapi als een stateless Deployment, gekoppeld aan externe services. yaml apiVersion: apps/v1 kind: Deployment metadata: name: strapi-cms spec: template: spec: containers: - name: strapi image: strapi/strapi:latest env: - name: DATABASE_CLIENT value: \"postgres\" - name: DATABASE_HOST value: \"postgres-cluster\" S3 Plugin Configuratie (MinIO) - name: AWS_ACCESS_KEY_ID valueFrom: secretKeyRef: name: minio-creds key: accesskey Data Model (Content Types) We definiÃ«ren twee kern collecties: 1. MediaAssets: title (Text) file (Media) tags (JSON: bijv. [\"scene_01\", \"approved\"]) generated_by (Relation: Agent ID) 2. BrandIdentity: primary_color (Color Hex) logo_light (Media) font_family (Text) voice_tone (Text: \"Professioneel en direct\") âœ… Voordelen AI-Leesbaar: Agents kunnen via REST/GraphQL direct vragen: \"Geef mij het logo en de primaire kleur\". Gecentraliseerd: Geen rondslingerende bestandjes in git repo's. Schaalbaar: Maakt gebruik van de reeds aanwezige Storage (MinIO) en DB (Postgres) infrastructuur."
  },
  {
    "title": "Runtime",
    "category": "bouwblokken",
    "path": "bouwblokken/runtime.md",
    "content": "Runtime Interface ğŸ¯ Doelstelling Dit bouwblok definieert de interface naar de Runtime omgeving. In de Azure Foundry architectuur bestaat deze runtime uit twee delen: de Agent Runtime (Azure AI Agent Service) voor de intelligentie, en de Container Runtime (Kubernetes/ACA) voor de workloads. ğŸ“‹ Functionele Specificaties 1. Agent Runtime (Azure AI Agent Service) - Host: De beheerde omgeving waar AI-agenten (Threads, Runs) worden uitgevoerd. - State Management: Automatisch beheer van conversatie-state en context (persistentie). - Tool Execution: Veilige uitvoering van code (Code Interpreter) en API-calls via OpenAPI. 2. Deployment Management (Container Runtime) - Manifest Application: Vertalen van abstracte deployment intenties naar concrete Kubernetes manifests of Azure Container Apps. - Rollout Control: Beheren van updates en rollbacks (Blue/Green). 3. Resource Provisioning aka \"Dynamic Slots\" - Namespace on Demand: Aanmaken van geÃ¯soleerde omgevingen voor nieuwe projecten. - Quota Management: Toewijzen van CPU/Memory limieten. 2. Security & Compliance by Design De runtime is ontworpen volgens strikte Security by Design en Compliance by Design principes. Dit betekent dat veiligheid en regelgeving niet achteraf worden getoetst, maar onderdeel zijn van het fundament. ğŸ”’ Security by Design (Zero Trust) Identity First: Er zijn geen vaste 'service accounts' met brede rechten. Elke workload (Pod) krijgt via Azure Workload Identity (Entra ID) een unieke, tijdelijke identiteit. Network Segmentation: Standaard mag niets met elkaar praten (Deny-All). Via NetworkPolicies (Canal CNI) wordt verkeer expliciet toegestaan (bijv. \"Frontend mag praten met Backend op poort 8080\"). Immutable Infrastructure: Containers zijn read-only. Als er een patch nodig is, wordt de oude container vernietigd en een nieuwe uitgerold. SSH toegang tot nodes is uitgeschakeld voor beheerders. âš–ï¸ Compliance by Design (Policy Enforcement) Regels worden afgedwongen voordat een applicatie start. Admission Controllers: We gebruiken OPA Gatekeeper of Kyverno. Wanneer de Builder Agent een deployment wil doen, checkt de runtime real-time: \"Heeft dit image een 'High' vulnerability?\" -> Deployment Blocked âŒ. \"Heeft deze deployment een AI Register entry?\" -> Deployment Blocked âŒ. \"Draait dit als root?\" -> Deployment Blocked âŒ. Automatic Auditing: De API server logt elke wijziging (Wie deed wat?) naar de onwijzigbare Traceability DB. - Entra Agent ID: Elke agent draait onder zijn eigen Managed Identity. - Network Isolation: Alle communicatie verloopt via Private Endpoints binnen het VNet. 3. Geselecteerde Kubernetes Stack (RKE2) Voor de Container Runtime is gekozen voor RKE2 (Rancher Kubernetes Engine 2), ook wel bekend als RKE Government. ğŸ’¡ Waarom RKE2? - Security-First: RKE2 is standaard gehard volgens de CIS Kubernetes Benchmark en is FIPS 140-2 compliant. Dit is essentieel voor overheidsinstellingen zoals Waterschappen. - Lichtgewicht & Robuust: Het bundelt alle componenten in Ã©Ã©n binary maar gebruikt de zuivere, moderne CRI (Container Runtime Interface) standaarden (containerd). - Eenvoudig Beheer: Het automatiseert certificaatbeheer en etcd snapshots. âš™ï¸ Configuratie (config.yaml) Een typische, veilige configuratie voor een RKE2 node binnen Druppie: yaml RKE2 Server Config write-kubeconfig-mode: \"0644\" tls-san: - \"k8s-api.druppie.nl\" cni: \"canal\" Calico + Flannel voor Network Policy enforcement profile: \"cis-1.23\" Activeer CIS Hardening Profile selinux: true token: \"SECRET_CLUSTER_TOKEN\" system-default-registry: \"registry.druppie.nl\" Gebruik de interne, scanned registry kube-apiserver-arg: - \"audit-log-path=/var/lib/rancher/rke2/server/audit.log\" - \"audit-policy-file=/etc/rancher/rke2/audit-policy.yaml\" Audit Logging voor Compliance ğŸ—ï¸ Relaties - Verwijst naar: Runtime Domein. - Wordt gebruikt door: Druppie Core en Build Plane."
  },
  {
    "title": "Knowledge Bot",
    "category": "bouwblokken",
    "path": "bouwblokken/knowledge_bot.md",
    "content": "Knowledge Bot (RAG Agent) ğŸ¯ Doelstelling De Knowledge Bot is een gespecialiseerd bouwblok voor informatieontsluiting. Het stelt gebruikers in staat om via natuurlijke taal vragen te stellen over grote hoeveelheden ongestructureerde data (PDFs, documentatie, tickets) die specifiek zijn voor de organisatie. Het implementeert het Retrieval-Augmented Generation (RAG) patroon. ğŸ“‹ Functionele Specificaties 1. Ingest & Indexing - Multi-format Support: Moet tekst kunnen extraheren uit PDF, Word, Markdown, HTML, etc. - Chunking Strategy: Slim opbreken van tekst in behapbare stukken met behoud van context. - Continuous Update: Index moet up-to-date blijven als brondocumenten wijzigen. 2. Retrieval & Synthesis - Semantisch Zoeken: Zoeken op betekenis, niet alleen trefwoorden (Vector Search). - Bronvermelding: De bot MOET bij elk antwoord verwijzen naar de bron (pagina/document) waar de info vandaan komt (traceerbaarheid). - Hallucinatie Preventie: Instructies om alleen te antwoorden op basis van de gevonden context (\"Weet ik niet\" is een geldig antwoord). ğŸ”§ Technische Requirements - Vector Database: Gebruik van een geoptimaliseerde DB (bijv. Qdrant, Pinecone, pgvector). - Embedding Models: Gebruik van efficiÃ«nte modellen voor vectorisatie. - Hybrid Search: Combinatie van keyword search (BM25) en vector search voor beste resultaten. ğŸ”’ Security & Compliance - Document Level Security: De bot mag alleen resultaten tonen uit documenten waar de gebruiker leesrechten op heeft (ACL filtering in de zoekopdracht). - Data Residency: Documenten en vectoren blijven binnen de vertrouwde zone. ğŸ”Œ Interacties | Input | Output | | :--- | :--- | | Vraag (\"Hoe reset ik mijn wachtwoord?\") | Antwoord + Referenties ([Handleiding.pdf, p.3]) | | Nieuw Document (Upload) | Bevestiging (GeÃ¯ndexeerd) | ğŸ—ï¸ Relaties tot andere blokken - Aangestuurd door: Druppie Core (als de intentie \"Informational\" is). - Maakt gebruik van: Bouwblok Definities voor configuratie."
  },
  {
    "title": "Traceability DB",
    "category": "bouwblokken",
    "path": "bouwblokken/traceability_db.md",
    "content": "Traceability DB (Audit Log) ğŸ¯ Doelstelling De Traceability DB fungeert als de onveranderlijke \"zwarte doos\" (flight recorder) van het Druppie platform. Het doel is om volledige verantwoording en reproduceerbaarheid te garanderen. In een AI-gedreven systeem is het cruciaal om precies te kunnen reconstrueren waarom een AI een bepaalde beslissing nam en volgens welke instructies code is gegenereerd. ğŸ“‹ Functionele Specificaties 1. Granulaire Logging - Prompts & Responses: Slaat exact op wat er als input naar de LLM ging en wat er terugkwam. - Decision Trees: Logt de redenering (Thought Process) van de planner. - Code Changes: Logt diffs van gegenereerde code. - Approval Events: Logt wie, wanneer, en waarom goedkeuring gaf (inclusief digitale handtekening). 2. Zoekbaarheid & Analyse - Correlatie ID's: Koppelt alle logs van Ã©Ã©n sessie/verzoek aan elkaar (TraceID). - Niet-technische weergave: Moet data zo kunnen structureren dat auditors (niet-developers) het kunnen lezen. 3. Integriteit - Immutability: Eenmaal geschreven logs mogen NOOIT gewijzigd of verwijderd worden (Write Once, Read Many). - Retention: Data moet bewaard blijven conform wettelijke termijnen (bijv. 7 jaar). ğŸ”§ Technische Requirements - High Throughput: Moet grote stromen logdata aankunnen zonder de Core te vertragen (async writing). - Storage Tiering: Hot storage voor recente logs, Cold storage (Azure Blob/S3 Glacier) voor archief. - Time Series: Geoptimaliseerd voor tijdreeks-data. ğŸ”’ Security & Compliance - Encryption at Rest & in Transit: Alle data is versleuteld. - Access Control: Alleen Security Officers en Auditors hebben leesrechten. Niemand heeft schrijfrechten (behalve het systeem zelf). - Anomaly Detection: Activeert alerts bij verdachte patronen (bijv. massale export van logs). ğŸ”Œ Interacties De DB is passief en ontvangt data van alle componenten. | Bron | Type Data | Frequentie | | :--- | :--- | :--- | | Druppie Core | Prompts, Tokens, Plans | Hoog | | Policy Engine | Checks, Violations | Gemiddeld | | Mens in de Loop | Approvals, Rejections | Laag | ğŸ—ï¸ Relaties tot andere blokken - Ondersteunt: Compliance Layer (levert bewijslast)."
  },
  {
    "title": "CI/CD Pipeline (Tekton)",
    "category": "bouwblokken",
    "path": "bouwblokken/ci_cd_tekton.md",
    "content": "CI/CD Pipeline (Tekton) ğŸ¯ Selectie: Tekton Pipelines Voor de CI/CD oplossing binnen het Druppie platform is gekozen voor Tekton. Tekton is een krachtig en flexibel, Kubernetes-native open-source raamwerk voor het maken van CI/CD systemen. ğŸ’¡ Onderbouwing van de Keuze De keuze voor Tekton is gebaseerd op de volgende criteria die naadloos aansluiten bij de architectuur van Druppie: 1. Kubernetes Native: Tekton draait volledig binnen Kubernetes en gebruikt Custom Resource Definitions (CRD's) zoals Task en Pipeline. Dit betekent dat pipelines beheerd kunnen worden via dezelfde tools als de applicatie zelf (kubectl, GitOps) en perfect passen in het \"Spec-Driven\" concept. 2. Modulair (Bouwblokken): Tekton werkt met herbruikbare \"Tasks\". Dit sluit perfect aan op de bouwblokken-filosofie van Druppie. Een taak om een container te bouwen (bijv. met Kaniko) kan in meerdere pipelines hergebruikt worden. 3. Serverless Scaling: In tegenstelling tot traditionele servers (zoals Jenkins), draait elke pipeline stap als een Pod. Dit schaalt naar 0 als er niets gebeurt en schaalt oneindig op bij drukte, wat efficiÃ«nt is voor de infrastructuur. 4. Ontkoppeling: De pipeline definities staan los van de broncode repo's (hoewel ze erin kunnen wonen), wat flexibele orchestratie mogelijk maakt door de Builder Agent van Druppie. 5. Industry Standard: Tekton is een project van de CD Foundation, wat zorgt voor brede ondersteuning en toekomstbestendigheid. --- ğŸ› ï¸ Installatie Tekton installeer je direct op het Kubernetes cluster. 1. Tekton Pipelines Controller & Webhook Installeer de core componenten: bash kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml Controleer of de pods draaien: bash kubectl get pods -n tekton-pipelines 2. (Optioneel) Tekton Dashboard Voor een visueel overzicht van de builds: bash kubectl apply --filename https://storage.googleapis.com/tekton-releases/dashboard/latest/release.yaml 3. (Optioneel) Tekton CLI (tkn) Installeer tkn lokaal om interactief pipelines te beheren (voorbeeld voor macOS): bash brew install tektoncd-cli --- ğŸš€ Gebruik Het gebruik van Tekton bestaat uit drie lagen: 1. Task (De \"Wat\") Een Task definieert een reeks stappen die in volgorde worden uitgevoerd in dezelfde container (Pod). Voorbeeld: Een 'Hello World' taak yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: hello spec: steps: - name: say-hello image: alpine command: [\"echo\"] args: [\"Hallo vanuit Druppie CI/CD!\"] 2. Pipeline (De \"Hoe\") Een Pipeline koppelt meerdere Tasks aan elkaar en bepaalt de volgorde en data-uitwisseling. Voorbeeld: Een simpele pipeline yaml apiVersion: tekton.dev/v1beta1 kind: Pipeline metadata: name: hello-pipeline spec: tasks: - name: hello-task taskRef: name: hello 3. PipelineRun (De \"Wanneer\") Om een pipeline daadwerkelijk te starten, maak je een PipelineRun (of TaskRun) aan. Dit is de daadwerkelijke uitvoering. bash tkn pipeline start hello-pipeline --showlog Of via YAML: yaml apiVersion: tekton.dev/v1beta1 kind: PipelineRun metadata: generateName: hello-run- spec: pipelineRef: name: hello-pipeline ğŸ”„ Integratie in Druppie Binnen de Druppie architectuur wordt Tekton aangestuurd door de Builder Agent en Foundry: 1. Builder Agent genereert de code en een bijbehorende PipelineRun specificatie. 2. De Foundry component past deze YAML toe op het Kubernetes cluster. 3. Tekton voert de bouwstappen uit (Linting, Testen, Container Build, Security Scan). 4. Resultaten worden teruggekoppeld naar de Traceability DB."
  },
  {
    "title": "Database (PostgreSQL)",
    "category": "bouwblokken",
    "path": "bouwblokken/database_postgres.md",
    "content": "Database Cluster (PostgreSQL) ğŸ¯ Selectie: CloudNativePG (CNPG) Voor de relationele database oplossing binnen het Druppie platform is gekozen voor CloudNativePG (CNPG). Dit is een Kubernetes-native operator die volledig is ontworpen om PostgreSQL-clusters te beheren binnen een containeromgeving. ğŸ’¡ Onderbouwing van de Keuze De keuze voor CloudNativePG is gebaseerd op de volgende criteria die essentieel zijn voor de betrouwbaarheid van Druppie: 1. Kubernetes Native: CNPG breidt de Kubernetes API uit met een Cluster resource. In plaats van complexe statefulsets te beheren, definieer je simpelweg de gewenste staat van je database in YAML. 2. High Availability (HA): Automatische failover en \"self-healing\" functionaliteit. Als de primaire node uitvalt, promoveert de operator automatisch een standby node. 3. Backups & Disaster Recovery: Ingebouwde ondersteuning voor Point-In-Time Recovery (PITR) naar object storage (zoals S3 of Azure Blob Storage). 4. Immutable Application support: CNPG beheert de connectie via services en secrets die automatisch worden geÃ¼pdatet, wat naadloos aansluit bij de Runtime applicaties van Druppie. 5. Open Source & Community: Oorspronkelijk ontwikkeld door EDB, maar nu een volledig open-source project met een zeer actieve community. --- ğŸ› ï¸ Installatie De operator wordt geÃ¯nstalleerd op het cluster en beheert vervolgens alle database instanties. 1. Installatie via Manifest De snelste manier om de operator te installeren: bash kubectl apply -f https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/release-1.21/releases/cnpg-1.21.0.yaml Controleer of de operator draait: bash kubectl get pods -n cnpg-system (Alternatief kan installatie ook via Helm chart cnpg/cloudnative-pg) --- ğŸš€ Gebruik Net als bij andere bouwblokken, definiÃ«ren we een database declaratief. De Builder Agent kan deze definities genereren wanneer een applicatie opslag nodig heeft. 1. Database Cluster Definitie Een voorbeeld van een High-Available cluster met 3 instances (1 Primary, 2 Replicas): yaml apiVersion: postgresql.cnpg.io/v1 kind: Cluster metadata: name: druppie-core-db spec: instances: 3 Opslag configuratie storage: size: 10Gi Backup configuratie (optioneel voorbeeld) backup: barmanObjectStore: destinationPath: s3://druppie-backups/ endpointURL: http://minio:9000 s3Credentials: accessKeyId: name: backup-secret key: key secretAccessKey: name: backup-secret key: secret 2. Connecteren vanuit Applicaties Zodra het cluster draait, maakt CNPG automatisch de volgende resources aan die door applicaties gebruikt kunnen worden: Service (druppie-core-db-rw): Een stabiel endpoint voor schrijfoperaties (Primary). Service (druppie-core-db-ro): Een stabiel endpoint voor leesoperaties (Read-Only replicas). Secret (druppie-core-db-app): Bevat de inloggegevens (username, password, dbname, host). Voorbeeld Pod gebruik: yaml apiVersion: v1 kind: Pod metadata: name: app-met-db spec: containers: - name: app image: my-app:latest env: - name: DB_HOST value: druppie-core-db-rw - name: DB_USER valueFrom: secretKeyRef: name: druppie-core-db-app key: username - name: DB_PASS valueFrom: secretKeyRef: name: druppie-core-db-app key: password ğŸ”„ Integratie in Druppie 1. Spec-Driven: Een applicatie specificeert in zijn definitie \"Ik heb een database nodig\". 2. Builder Agent: Genereert de Cluster YAML definitie en voegt de juiste environment variabelen toe aan de Deployment manifest van de applicatie. 3. Runtime: Bij het deployen van de applicatie zorgt de operator dat de database beschikbaar is en de applicatie direct kan verbinden."
  },
  {
    "title": "Vector Database (Qdrant)",
    "category": "bouwblokken",
    "path": "bouwblokken/database_qdrant.md",
    "content": "Vector Database (Qdrant) ğŸ¯ Selectie: Qdrant Voor het opslaan en doorzoekbaar maken van onze AI-kennis (Embeddings) kiezen we voor Qdrant. ğŸ’¡ Onderbouwing van de Keuze Waarom Qdrant boven alternatieven zoals Weaviate, Pinecone of pgvector? 1. Performance & Resource Efficiency: Qdrant is geschreven in Rust. Dit maakt het extreem snel en geheugenefficiÃ«nt, wat perfect past bij onze kubernetes-gebaseerde infrastructuur waar resources soms schaars zijn. 2. Native Faceted Filtering (ACLs): Qdrant blinkt uit in \"Filtered Search\". Dit is cruciaal voor onze Secure RAG eis. We kunnen heel efficiÃ«nt zoeken: \"Geef de top 10 vectoren die lijken op deze vraag, MAAR alleen als metadata.group IN ['finance', 'admin']\". Veel andere databases worden traag bij complexe filters (\"Post-filtering\"), Qdrant doet dit tijdens het zoeken (\"Pre-filtering/HNSW\"). 3. Kubernetes-Native: Qdrant is ontworpen als cloud-native distributed system. Het schaalt makkelijk horizontaal mee met onze pods. 4. Open Source: Volledig open source en self-hostable (geen vendor lock-in of data die naar een Amerikaanse cloud service lekt). (Noot: pgvector in PostgreSQL is goed voor simpele use-cases, maar mist de geavanceerde filtering en snelheid van een dedicated vector engine zoals Qdrant bij miljoenen vectoren.) --- ğŸ› ï¸ Installatie We draaien Qdrant als een StatefulSet in de Runtime. Installatie via Helm bash helm repo add qdrant https://qdrant.github.io/qdrant-helm helm upgrade --install qdrant qdrant/qdrant \\ --namespace data-system --create-namespace \\ --set replicaCount=3 \\ --set persistence.size=50Gi --- ğŸš€ Gebruik: Van Tekst naar Vector Dit bouwblok wordt gebruikt door de Ingest Agent en de RAG Agent. 1. Opslaan (Upsert) Wanneer de Ingest Agent een document verwerkt: python from qdrant_client import QdrantClient from qdrant_client.models import PointStruct client = QdrantClient(host=\"qdrant.data-system\", port=6333) client.upsert( collection_name=\"bedrijfs_kennis\", points=[ PointStruct( id=123, vector=[0.1, 0.9, ...], De AI betekenis (Embedding) payload={ De Metadata \"filename\": \"begroting_2025.pdf\", \"text_snippet\": \"Het totaalbedrag is 1M...\", \"acls\": [\"group:finance\", \"user:jan\"] } ) ] ) 2. Zoeken met Beveiliging (Search) Wanneer Jan (lid van 'engineering') iets vraagt: python search_result = client.search( collection_name=\"bedrijfs_kennis\", query_vector=[0.1, 0.9, ...], De vraag vector query_filter=Filter( must=[ FieldCondition( key=\"acls\", match=MatchAny(any=[\"group:engineering\", \"group:public\"]) ) ] ) ) De database geeft alleen resultaten terug die Jan mag zien. Dit gebeurt op database-niveau, dus de applicatie kan niet per ongeluk iets lekken. ğŸ”„ Integratie in Druppie Traceability: Elke 'hit' in de vector database kan gelogd worden, zodat we weten welke kennisbronnen zijn gebruikt voor een antwoord. Backups (Velero): Omdat Qdrant op een Persistent Volume draait, wordt deze automatisch meegenomen in de standaard backup policy."
  },
  {
    "title": "Geo-Database (PostGIS)",
    "category": "bouwblokken",
    "path": "bouwblokken/database_postgis.md",
    "content": "Geo-Database (PostGIS) ğŸ¯ Selectie: CloudNativePG (met PostGIS) Voor de opslag en verwerking van geografische data binnen het Druppie platform kiezen we voor dezelfde operator als voor de standaard databases: CloudNativePG (CNPG). Echter, specifieke configuratie is vereist om de PostGIS extensie mogelijk te maken. ğŸ’¡ Onderbouwing van de Keuze Het hergebruiken van de CloudNativePG operator voor geospatiale data biedt grote voordelen: 1. Uniform Beheer: Beheer, backup, failover en monitoring werken exact hetzelfde als voor standaard PostgreSQL databases. Dit vermindert de operationele complexiteit voor de Run Experts. 2. Bewezen Technologie: PostGIS is de de-facto standaard voor open-source GIS. Het biedt krachtige features voor spatial queries, indexering en analyse die essentieel zijn voor waterschapstaken (dijken, watergangen, assets). 3. Kubernetes Native: Door simpelweg een andere container image te specificeren in de CNPG Cluster definitie, rollen we een volledige GIS-stack uit zonder nieuwe infrastructuur componenten toe te voegen. --- ğŸ› ï¸ Installatie De operator (CloudNativePG) is naar verwachting al geÃ¯nstalleerd (zie PostgreSQL Bouwblok). Er is geen aparte installatie nodig; we hoeven alleen maar een andere configuratie toe te passen bij het aanmaken van het cluster. --- ğŸš€ Gebruik Om een PostGIS database te krijgen, moeten we twee dingen doen in de Cluster definitie: 1. Een Docker image kiezen waar PostGIS al in is geÃ¯nstalleerd (bijv. de officiÃ«le postgis/postgis images). 2. De extensie activeren na het opstarten (via CREATE EXTENSION postgis;). Dit kan geautomatiseerd worden met een postInitSQL command. 1. PostGIS Cluster Definitie Hieronder een voorbeeld definitie voor een GIS-cluster. Let op de imageName en postInitSQL. yaml apiVersion: postgresql.cnpg.io/v1 kind: Cluster metadata: name: druppie-geo-db spec: instances: 2 Specifieke PostGIS image (ipv standaard postgres) imageName: ghcr.io/cloudnative-pg/postgis:16 Opslag (GIS data is vaak groot, dus ruim kiezen) storage: size: 50Gi Automatisch de extensie aanzetten na init bootstrap: initdb: postInitSQL: - \"CREATE EXTENSION IF NOT EXISTS postgis;\" - \"CREATE EXTENSION IF NOT EXISTS postgis_topology;\" Monitoring aanzetten is cruciaal voor zware GIS queries monitoring: enablePodMonitor: true 2. Connecteren & Gebruik Applicaties verbinden op exact dezelfde manier als bij de standaard database (via de generated Secrets en Services). De applicatie (of Builder Agent) kan nu direct geospatiale queries uitvoeren: Voorbeeld SQL Query (via de applicatie): sql -- Zoek alle dijken binnen 500 meter van een punt SELECT naam, type FROM waterkeringen WHERE ST_DWithin( geometrie, ST_GeomFromText('POINT(134000 450000)', 28992), 500 ); ğŸ”„ Integratie in Druppie 1. Capability Check: Als een gebruiker vraagt om \"Kaart functionaliteit\" of \"Locatie gebaseerde analyse\", selecteert de Planner dit bouwblok in plaats van de standaard database. 2. Builder Agent: Genereert de Cluster YAML met de PostGIS image. Weet dat hij SQL queries kan genereren die gebruik maken van ST_ functies (spatial types). 3. Foundry: Rolt de container uit en zorgt dat de zware GIS berekeningen voldoende CPU/RAM limieten krijgen toegewezen."
  },
  {
    "title": "Webserver & Certificaten (Ingress)",
    "category": "bouwblokken",
    "path": "bouwblokken/webserver_ingress.md",
    "content": "Webserver & Certificaten (Ingress) ğŸ¯ Selectie: NGINX Ingress & cert-manager Voor het ontsluiten van webapplicaties en API's naar de buitenwereld, inclusief geautomatiseerd HTTPS-certificaatbeheer, kiezen we voor de gouden standaard binnen het Kubernetes ecosysteem: NGINX Ingress Controller in combinatie met cert-manager. ğŸ’¡ Onderbouwing van de Keuze Deze combinatie is essentieel voor een veilig en toegankelijk platform: 1. Centraal Toegangspunt: In plaats van elke applicatie zijn eigen webserver en loadbalancer te geven (wat duur en complex is), regelt de Ingress Controller alle inkomende verkeer centraal. Dit is efficiÃ«nt en veilig. 2. Automated Security (HTTPS): cert-manager neemt het volledige beheer van TLS-certificaten uit handen. Het vraagt certificaten aan (bijv. via Let's Encrypt of een interne CA), valideert ze, en ververst ze automatisch voordat ze verlopen. Dit elimineert menselijke fouten en outages door verlopen certificaten. 3. Kubernetes Native: Configuratie gebeurt via standaard Kubernetes Ingress resources. Dit past perfect in de Spec-Driven werkwijze van Druppie: de infrastructuur is code. 4. Flexibele Routing: NGINX biedt geavanceerde mogelijkheden zoals path-based routing (bijv. /api naar backend, / naar frontend), rate-limiting en authenticatie integraties (bijv. met OAuth2 Proxy). --- ğŸ› ï¸ Installatie We installeren twee componenten op het cluster. 1. NGINX Ingress Controller Installeer via Helm (de standaard package manager voor Kubernetes): bash helm upgrade --install ingress-nginx ingress-nginx \\ --repo https://kubernetes.github.io/ingress-nginx \\ --namespace ingress-nginx --create-namespace 2. cert-manager Installeer cert-manager en de Custom Resource Definitions (CRDs): bash helm upgrade --install cert-manager cert-manager \\ --repo https://charts.jetstack.io \\ --namespace cert-manager --create-namespace \\ --set installCRDs=true Configureer vervolgens een ClusterIssuer (wie de certificaten uitgeeft). Voorbeeld voor Let's Encrypt Staging (veilig om mee te testen): yaml apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: letsencrypt-staging spec: acme: server: https://acme-staging-v02.api.letsencrypt.org/directory email: beheer@waterschap.nl privateKeySecretRef: name: letsencrypt-staging solvers: - http01: ingress: class: nginx --- ğŸš€ Gebruik Wanneer de Builder Agent een nieuwe webapplicatie bouwt, genereert hij een Ingress resource. Door simpelweg een paar regels toe te voegen, regelt het platform de rest. Ingress Definitie Hieronder een voorbeeld hoe een applicatie wordt ontsloten op mijn-app.druppie.nl met automatische HTTPS. yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: mijn-web-app annotations: Vertel cert-manager om een certificaat te regelen via de ClusterIssuer cert-manager.io/cluster-issuer: \"letsencrypt-staging\" Zorg dat HTTP verkeer wordt doorgestuurd naar HTTPS nginx.ingress.kubernetes.io/ssl-redirect: \"true\" spec: ingressClassName: nginx tls: - hosts: - mijn-app.druppie.nl secretName: mijn-app-tls cert-manager slaat hier het certificaat in op rules: - host: mijn-app.druppie.nl http: paths: - path: / pathType: Prefix backend: service: name: mijn-app-service port: number: 80 ğŸ”„ Integratie in Druppie 1. Capability Check: Als een applicatie een gebruikersinterface of API heeft (\"public facing\"), activeert de Planner dit bouwblok. 2. Builder Agent: Vraagt domeinnaam instellingen op uit de Bouwblok Definities. Genereert de Ingress YAML. Zorgt dat de applicatie zelf (de Pod) gewoon op poort 80 (HTTP) kan draaien, zonder dat de ontwikkelaar zich zorgen hoeft te maken over SSL-certificaten of complexe netwerkconfiguraties. 3. Runtime: De NGINX controller ziet de nieuwe Ingress en past de routing aan. cert-manager ziet de annotatie, valideert het domein en installeert het certificaat in de achtergrond."
  },
  {
    "title": "GitOps & State (Flux)",
    "category": "bouwblokken",
    "path": "bouwblokken/gitops_flux.md",
    "content": "GitOps & State Management (Flux) ğŸ¯ Selectie: Flux CD Omdat Tekton de processen (CI/bouw) afhandelt, zoeken we een component die de gewenste staat (CD/deployment) op het cluster handhaaft en bewaakt. Flux is hier de ideale partner voor. ğŸ’¡ Waarom past dit bij Tekton? Waar ArgoCD soms werd gezien als een volledige suite die (deels) overlapt met pipeline-taken, is Flux een pure, lichtgewicht GitOps operator. 1. Complementair: Tekton is een \"Task Runner\" (Imperatief: \"Doe dit nu\"), Flux is een \"State Enforcer\" (Declaratief: \"Zorg dat het zo is\"). Ze zitten elkaar niet in de weg. 2. Kubernetes Native (net als Tekton): Flux gebruikt - net als Tekton - standaard Custom Resource Definitions (CRD's) en integreert naadloos in het cluster zonder zware eigen UI of database. 3. De \"Push-to-Pull\" Workflow: Tekton (CI): Bouwt de image, test deze, en pusht een update naar de Git configuratie repo (bijv. update image tag). Flux (CD): Ziet de wijziging in Git en pullt deze naar het cluster. 4. Automatic Drift Correction: Flux controleert continu of de live omgeving nog klopt met Git. Als iemand handmatig iets kapot maakt, repareert Flux het direct. --- ğŸ› ï¸ Installatie Flux \"bootstrappen\" we op het cluster. Dit commando installeert de controllers Ã©n configureert direct een Git repository om zichzelf te beheren (GitOps voor de GitOps tool). 1. Flux Bootstrap (Vereist een Github Personal Access Token met repo rechten) bash flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=druppie-infra \\ --branch=main \\ --path=./clusters/productie \\ --personal Dit installeert de Source Controller, Kustomize Controller, Helm Controller en Notification Controller. 2. Controle bash kubectl get pods -n flux-system --- ğŸš€ Gebruik We definiÃ«ren twee dingen: Waar staat de config (Source) en Hoe passen we het toe (Kustomization/Helm). 1. Source (GitRepository) Vertel Flux waar de applicatie configuraties staan. yaml apiVersion: source.toolkit.fluxcd.io/v1 kind: GitRepository metadata: name: druppie-apps namespace: flux-system spec: interval: 1m url: https://github.com/waterschap/druppie-apps ref: branch: main 2. Kustomization (Sync) Vertel Flux welke map in die repo hij op het cluster moet toepassen. yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: drone-service-prod namespace: flux-system spec: interval: 5m targetNamespace: productie sourceRef: kind: GitRepository name: druppie-apps path: \"./envs/prod/drone-service\" prune: true Verwijder resources die uit Git zijn gehaald wait: true Wacht tot alles 'Healthy' is ğŸ”„ Integratie in Druppie De samenwerking tussen de Builder Agent, Tekton en Flux is de kern van het platform: 1. Code Change: Developer (of Agent) commit code. 2. Tekton (CI): Triggered door de commit. Draait unit tests & security scans. Bouwt Docker image. âš ï¸ Cruciale stap: Tekton commit de nieuwe image tag (bijv. v1.0.5) naar de druppie-apps Git repo (INFRA repo). 3. Flux (CD): Detecteert de nieuwe commit in druppie-apps. Reconciled de state: \"Hee, de deployment moet nu image v1.0.5 draaien\". Update de Pods op het Kubernetes cluster."
  },
  {
    "title": "Observability (PLG Stack)",
    "category": "bouwblokken",
    "path": "bouwblokken/observability_plg.md",
    "content": "Observability & Logging (PLG Stack) ğŸ¯ Selectie: Prometheus, Loki & Grafana Voor het monitoren van de gezondheid, performance en het doorzoekbaar maken van logs kiezen we voor de PLG Stack (Prometheus, Loki, Grafana). Dit is de industriestandaard voor open-source cloud-native observability. ğŸ’¡ Onderbouwing van de Keuze Deze stack is cruciaal voor de \"Traceerbaarheid\" en \"Beheersbaarheid\" van het Druppie platform: 1. Prometheus (Metrics): Verzamelt cijfermatige data (CPU, Memory, Request Count). Kubernetes is gemodelleerd om metrics in Prometheus formaat aan te bieden. Het stelt ons in staat om te alerten als er iets mis is (bijv. \"Error rate > 5%\"). 2. Loki (Logs): Een log-aggregatie systeem dat is ontworpen als \"Prometheus voor logs\". Het is extreem efficiÃ«nt omdat het logs niet volledig indexeert, maar alleen metadata (labels). Dit maakt het mogelijk om alle logs (audit trails!) goedkoop te bewaren en razendsnel te doorzoeken. 3. Grafana (Visualisatie): Het centrale dashboard. Hier komen metrics (Prometheus) en logs (Loki) samen in Ã©Ã©n overzichtelijk scherm. 4. Correlatie: Omdat alles in hetzelfde dashboard zit, kun je direct springen van een \"High CPU Alert\" in Prometheus naar de exacte \"Error Logs\" in Loki van dat moment. --- ğŸ› ï¸ Installatie We installeren de volledige stack via de officiÃ«le Helm charts (vaak gebundeld als de kube-prometheus-stack en loki-stack). 1. Prometheus & Grafana bash helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \\ --namespace monitoring --create-namespace 2. Loki (Logging) bash helm repo add grafana https://grafana.github.io/helm-charts helm upgrade --install logging grafana/loki-stack \\ --namespace monitoring \\ --set grafana.enabled=false We gebruiken de grafana uit stap 1 --- ğŸš€ Gebruik Deze componenten werken grotendeels automatisch (\"Zero Config\" voor de ontwikkelaar). 1. Metrics (Automatisch) De cluster-metrics (Nodes, Pods) worden direct opgehaald. Voor applicatie-specifieke metrics hoeft de Builder Agent alleen een ServiceMonitor toe te voegen of de standaard annotaties te gebruiken: yaml apiVersion: v1 kind: Service metadata: name: mijn-app annotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" spec: ports: - port: 8080 targetPort: 8080 2. Logs (Automatisch) Alles wat een applicatie naar stdout (console) schrijft, wordt door Promtail (onderdeel van Loki) opgepakt, gelabeld met de Pod-naam en naar Loki gestuurd. De ontwikkelaar hoeft geen log-files te beheren of log-shippers te configureren. 3. Traceability Dashboard In Grafana kan een \"Compliance Dashboard\" worden ingericht dat queries doet op Loki: bash {namespace=\"productie\"} |= \"UserLogin\" Dit toont direct een audit trail van wie wanneer heeft ingelogd. ğŸ”„ Integratie in Druppie 1. Compliance Layer: De Compliance component kan alerts instellen in AlertManager (onderdeel van Prometheus). Bijvoorbeeld: \"Waarschuw de CISO als er een root-shell wordt geopend\". 2. Mens in de Loop: Beheerders kijken in Grafana om de impact van een nieuwe release te valideren. 3. Traceerbaarheid: Alle logs worden centraal bewaard, wat essentieel is voor de uitlegbaarheid van AI-beslissingen (waarom gaf de bot dit antwoord? -> Check de logs)."
  },
  {
    "title": "Git & Versiebeheer (Gitea)",
    "category": "bouwblokken",
    "path": "bouwblokken/git_gitea.md",
    "content": "Git & Versiebeheer (Gitea) ğŸ¯ Selectie: Gitea Voor het beheren van de broncode (Source Code Management) en de infrastructuur-configuraties (GitOps) binnen het eigen cluster kiezen we voor Gitea. ğŸ’¡ Onderbouwing van de Keuze Hoewel cloud-diensten (zoals GitHub/GitLab.com) populair zijn, vereist de strikte compliance en autonomie van een waterschap vaak dat data (inclusief code en configs) in eigen beheer blijft. 1. Self-Hosted & Soeverein: Gitea draait volledig binnen de eigen Kubernetes omgeving. Code verlaat nooit de veilige muren van het cluster/VNet. 2. Extreem Lichtgewicht: In tegenstelling tot GitLab (dat veel resources vreet), is Gitea geschreven in Go en draait het soepel op minimale resources. Dit past perfect in de modulaire \"Micro-services\" gedachte van Druppie. 3. Feature Compleet: Biedt alle essentiÃ«le functies: Git repository hosting, Issue tracking, Pull Requests, en Webhooks (voor Tekton/Flux triggers). 4. Kubernetes Ready: Eenvoudig te installeren en schalen via Helm. --- ğŸ› ï¸ Installatie We installeren Gitea via de officiÃ«le Helm chart. 1. Voeg Helm Repo toe bash helm repo add gitea-charts https://dl.gitea.io/charts/ helm repo update 2. Installeer Gitea We configureren Gitea om de interne PostgreSQL database (zie Database bouwblok) te gebruiken voor opslag. bash helm upgrade --install gitea gitea-charts/gitea \\ --namespace git-system --create-namespace \\ --set gitea.admin.username=druppie_admin \\ --set gitea.admin.password=SUPER_SECRET_PASSWORD \\ --set persistence.size=10Gi \\ --set postgresql.enabled=false \\ --set gitea.database.type=postgres \\ --set gitea.database.host=druppie-core-db-rw.default.svc.cluster.local \\ --set gitea.database.user=druppie \\ --set gitea.database.name=gitea (Opmerking: In productie gebruiken we een Secret voor het wachtwoord ipv plain text params) --- ğŸš€ Gebruik 1. Repository Aanmaken (De \"Project Kluis\") De Builder Agent maakt voor elk nieuw project (bijv. \"Drone Service\") een nieuwe repository aan. Dit gebeurt via de Gitea API: http POST /api/v1/user/repos { \"name\": \"drone-service\", \"private\": true, \"description\": \"Service voor het verwerken van drone beelden\" } 2. Access Tokens (De \"Sleutel\") Om Tekton (CI) en Flux (CD) toegang te geven, genereren we een Access Token. Tekton heeft schrijf-rechten nodig (om image tags te updaten in deployment.yaml). Flux heeft lees-rechten nodig (om de cluster state op te halen). 3. Webhooks (De \"Trigger\") Zodra er code gepusht wordt, vuurt Gitea een webhook af naar de Tekton EventListener: POST http://el-tekton-listener.tekton-pipelines:8080 Dit start automatisch de bouw-straat. ğŸ”„ Integratie in Druppie 1. Opslag (Single Source of Truth): Alle code die de Builder Agent genereert, wordt hier opgeslagen. 2. Versiebeheer: Elke wijziging is een Git commit. Dit vormt de wettelijk verplichte Audit Trail. We kunnen altijd terugkijken: \"Wie heeft deze regel code veranderd en wanneer?\". 3. GitOps Bron: Gitea is de bron voor Flux. Als Gitea uitvalt, draait de productie gewoon door, maar kunnen er tijdelijk geen updates worden uitgerold."
  },
  {
    "title": "Container Registry (Harbor)",
    "category": "bouwblokken",
    "path": "bouwblokken/container_registry.md",
    "content": "Bouwblok: Container Registry (Harbor) ğŸ“„ Samenvatting Dit bouwblok beschrijft de implementatie van een centrale opslagplaats voor Docker images (Container Registry). Voor een Kubernetes-platform is een betrouwbare, snelle en veilige registry essentieel. Wij kiezen voor Harbor vanwege de cloud-native focus, ingebouwde security scanning en role-based access control. ğŸ¯ Doelstelling Het bieden van een veilige haven ('Harbor') waar alle gebouwde applicatie-images worden opgeslagen voordat ze worden uitgerold naar de clusters. Dit zorgt voor: Versiebeheer: Elke build heeft een unieke, onwijzigbare tag (immutable). Security: Images worden automatisch gescand op kwetsbaarheden (CVE's) voordat ze \"live\" mogen. Performance: Lokale caching van images dichtbij de clusters. âš™ï¸ Technologie Selectie Wij standaardiseren op Harbor. Waarom Harbor? Open Source & CNCF Graduated: De industriestandaard voor self-hosted registries. Ingebouwde Scanning: Naadloze integratie met Trivy om images te scannen bij push. RBAC & OIDC: Koppelt direct met Keycloak voor gebruikersbeheer (wie mag pushen/pullen). Replication: Kan images synchroniseren tussen verschillende Harbor instanties (bijv. DMZ vs Intern). Signing: Ondersteunt Cosign/Notary voor het digitaal ondertekenen van images (supply chain security). ğŸ”¨ Implementatie Specificaties 1. Deployment Model Harbor wordt uitgerold binnen het tooling cluster via Helm. Namespace: harbor Storage: Gebruikt MinIO (S3) of een PVC voor de opslag van de lagen (layers). Ingress: Bereikbaar via registry.druppie.local (of publieke URL). 2. Integratie met Core De Druppie Core (Build Plane) interacteert met Harbor: 1. Push: De CI/CD pipeline (Tekton) bouwt een image en pusht deze naar Harbor. 2. Scan: Harbor triggert een Trivy scan. 3. Webhook: Harbor stuurt een event naar de Core: SCAN_COMPLETED met status PASS of FAIL. 4. Pull: De Kubernetes clusters authenticeren met een ImagePullSecret om de images binnen te halen. 3. Configuratie (Helm Values voorbeelden) yaml expose: type: ingress tls: enabled: true secretName: \"harbor-tls\" ingress: hosts: core: \"registry.druppie.local\" externalURL: \"https://registry.druppie.local\" persistence: imageChartStorage: type: s3 s3: region: \"us-east-1\" bucket: \"harbor-images\" accesskey: \"minio-admin\" secretkey: \"minio-secret\" regionendpoint: \"http://minio.minio.svc:9000\" trivy: enabled: true ğŸ›¡ï¸ Security & Compliance Image Signing: Alle productie-images MOETEN ondertekend zijn. Vulnerability Policy: Images met 'Critical' CVE's worden geblokkeerd en kunnen niet gepulled worden (Deployment Preventie). Retention Policy: Oude 'nightly' builds worden na 14 dagen automatisch verwijderd om opslag te besparen. Noodzakelijke Skills Docker & OCI standaarden. Kubernetes (voor Helm deployment). Linux systeembeheer (voor storage management)."
  },
  {
    "title": "Traceability (Tempo & OTEL)",
    "category": "bouwblokken",
    "path": "bouwblokken/traceability_otel.md",
    "content": "Traceability & Audit (Tempo & OpenTelemetry) ğŸ¯ Selectie: Grafana Tempo & OpenTelemetry Om volledige Traceability (herleidbaarheid) van elke actie binnen het Druppie platform te garanderen, kiezen we voor de combinatie OpenTelemetry (OTEL) als standaard voor data-verzameling en Grafana Tempo als backend voor de opslag van traces. ğŸ’¡ Onderbouwing van de Keuze Deze combinatie maakt de \"Black Box\" transparant: 1. De Standaard (OpenTelemetry): OTEL is de wereldwijde standaard voor het verzamelen van telemetry data. Door deze standaard te omarmen, voorkomen we \"vendor lock-in\". Elke component (Agent, API, DB) instrumenteren we met de OTEL SDK. 2. Correlatie (The \"Trace ID\"): De kracht zit in de TraceID. Wanneer een gebruiker een vraag stelt, wordt Ã©Ã©n uniek ID gegenereerd die meereist door het hele systeem: Gebruiker vraagt iets -> TraceID: abc-123 Router Agent kiest tool -> Logt met TraceID: abc-123 Postgres DB draait query -> Logt met TraceID: abc-123 Tempo stelt ons in staat om deze hele keten als Ã©Ã©n tijdlijn te visualiseren. 3. Integratie met bestaande Stack: Tempo integreert naadloos met Grafana (Dashboard) en Loki (Logs) die we al geselecteerd hebben. Je kunt in Grafana klikken op een logregel en direct de hele trace zien. 4. High Volume, Low Cost: Tempo is ontworpen om extreem goedkoop enorme hoeveelheden traces op te slaan in Object Storage (S3/MinIO), in tegenstelling tot dure index-based oplossingen. --- ğŸ› ï¸ Installatie We voegen Tempo toe aan onze monitoring namespace. 1. Tempo Installeren Via Helm: bash helm repo add grafana https://grafana.github.io/helm-charts helm upgrade --install tempo grafana/tempo \\ --namespace monitoring \\ --set persistence.enabled=true \\ --set persistence.size=10Gi 2. OTEL Collector De collector fungeert als \"makelaar\". Applicaties sturen data naar de collector, en de collector stuurt het door naar Tempo (Traces) en Loki (Logs). bash helm upgrade --install otel-collector open-telemetry/opentelemetry-collector \\ --namespace monitoring --- ğŸš€ Gebruik Het gebruik vergt een kleine aanpassing in de applicatie-code (de Agents), wat we faciliteren via de Builder Agent. 1. Instrumentatie (Code) Elke Python/NodeJS agent krijgt standaard de OTEL-library mee. Voorbeeld (Python Agent): python from opentelemetry import trace tracer = trace.get_tracer(__name__) def handle_user_question(question): Start een 'Span' (een blokje in de tijdlijn) with tracer.start_as_current_span(\"process_question\") as span: span.set_attribute(\"user.id\", \"user_123\") span.set_attribute(\"question.category\", \"waterbeheer\") Voer logica uit... result = planner.create_plan(question) Log de beslissing als 'Event' in de trace span.add_event(\"Plan Created\", attributes={\"plan.steps\": str(len(result.steps))}) return result 2. Audit & Analyse (Grafana) In Grafana kunnen we nu zoeken op TraceID. We zien een tijdlijn (Gantt-chart) van exact wat er gebeurde: 0ms: Request binnen 50ms: Authenticatie Check (IAM) 120ms: Router Agent start 400ms: LLM Call (Azure OpenAI) - Hier zien we exact hoe lang de LLM erover deed 1500ms: Antwoord naar gebruiker 3. De \"Audit Log\" Link Omdat we de TraceID ook wegschrijven in de Loki logs (bijv: {\"level\":\"info\", \"traceID\":\"abc-123\", \"msg\":\"Prompt verstuurd...\"}), kunnen we in Ã©Ã©n klik van het technische plaatje naar de inhoudelijke payload springen om te lezen wat er precies naar de LLM is gestuurd. ğŸ”„ Integratie in Druppie 1. Compliance: De TraceID wordt de sleutel voor de audit. Als een auditor vraagt \"Wat gebeurde er bij incident X?\", zoeken we de TraceID op en hebben we het volledige verhaal. 2. Performance: We zien direct waar de vertraging zit (bijv. \"De Database query duurde 2 seconden\"). 3. Traceability DB: In de spec noemden we de \"Traceability DB\". In de praktijk is dit dus de combinatie van Tempo (Structuur/Tijdlijn) en Loki (Inhoud), ontsloten via Grafana."
  },
  {
    "title": "IAM (Keycloak & Azure AD)",
    "category": "bouwblokken",
    "path": "bouwblokken/iam_keycloak.md",
    "content": "Identity & Access Management (Keycloak) ğŸ¯ Selectie: Keycloak Voor het beheer van gebruikersidentiteiten, authenticatie en autorisatie kiezen we voor Keycloak. Keycloak fungeert als een Identity Broker tussen onze applicaties en de centrale gebruikersdirectory (Azure AD / Microsoft Entra ID). ğŸ’¡ Onderbouwing van de Keuze Waarom Keycloak als tussenlaag en niet direct Azure AD koppelen aan elke applicatie? 1. Identity Brokering: Keycloak ontkoppelt de applicaties van de specifieke Identity Provider (IdP). Als we ooit willen wisselen van IdP of een tweede IdP (bijv. DigiD voor burgers) willen toevoegen, hoeven we de applicaties niet aan te passen. Keycloak regelt de vertaalslag. 2. Granulaire RBAC: We kunnen in Keycloak specifieke rollen en groepen definiÃ«ren voor onze apps (bijv. DroneViewer, DroneEditor) en deze mappen naar Azure AD groepen. Dit houdt de Azure AD schoon en geeft teams meer autonomie. 3. Unified Login: Keycloak biedt Ã©Ã©n centrale Single Sign-On (SSO) ervaring. 4. Kubernetes Native: Draait als container op het cluster en is eenvoudig te configureren via CRD's (met de Keycloak Operator) of via de API. --- ğŸ› ï¸ Installatie We installeren Keycloak via de geoptimaliseerde Bitnami Helm chart of operator. 1. Installatie via Helm bash helm repo add bitnami https://charts.bitnami.com/bitnami helm upgrade --install keycloak bitnami/keycloak \\ --namespace iam-system --create-namespace \\ --set auth.adminUser=admin \\ --set auth.adminPassword=SECRET_ADMIN_PW \\ --set service.type=ClusterIP \\ --set postgresql.enabled=false \\ --set externalDatabase.host=druppie-core-db-rw.default.svc.cluster.local \\ --set externalDatabase.user=druppie \\ --set externalDatabase.password=DB_PASSWORD \\ --set externalDatabase.database=keycloak (Ook hier hergebruiken we de centrale PostgreSQL cluster voor opslag) --- âš™ï¸ Integratie met Azure AD (Entra ID) De cruciale stap is het koppelen van Azure AD als upstream Identity Provider. 1. Azure AD App Registration Maak in de Azure Portal een App Registration aan: Redirect URI: https://auth.druppie.nl/realms/druppie/broker/oidc/endpoint Genereer een Client Secret. 2. Keycloak Configureren In de Keycloak Admin Console: 1. Maak een Realm aan: druppie. 2. Ga naar Identity Providers -> OpenID Connect v1.0. 3. Alias: azure-ad. 4. Discovery Endpoint: https://login.microsoftonline.com/{TENANT_ID}/v2.0/.well-known/openid-configuration. 5. Vul Client ID en Secret in van stap 1. 6. Mappers: Configureer mappers om gebruikersinfo (email, naam, groups) uit het Azure AD token over te nemen naar het Keycloak user profiel. --- ğŸš€ Gebruik in Applicaties Wanneer de Builder Agent een nieuwe frontend bouwt (bijv. een React app), configureert hij deze om gebruik te maken van Keycloak. OIDC Configuratie De applicatie praat alleen met Keycloak, niet met Azure. json { \"authority\": \"https://auth.druppie.nl/realms/druppie\", \"client_id\": \"drone-service-frontend\", \"redirect_uri\": \"https://drone.druppie.nl/callback\", \"response_type\": \"code\", \"scope\": \"openid profile email offline_access\" } Flow 1. Gebruiker opent de app -> wordt doorgestuurd naar Keycloak. 2. Keycloak toont knop \"Login met Azure AD\". 3. Gebruiker logt in bij Microsoft. 4. Azure stuurt gebruiker terug naar Keycloak met token. 5. Keycloak vertaalt dit naar een intern token (met juiste interne rollen). 6. Keycloak stuurt gebruiker terug naar de App. ğŸ”„ Integratie in Druppie 1. Applicatie Security: De Ingress controller (zie Webserver bouwblok) kan samenwerken met Keycloak (via OAuth2 Proxy) om applicaties te beveiligen die zelf geen login-logica hebben. 2. Audit: Keycloak logt elke loginpoging. Deze logs worden door Loki (zie Observability) opgehaald. Zo zien we precies wie wanneer heeft ingelogd."
  },
  {
    "title": "MCP Server Host",
    "category": "bouwblokken",
    "path": "bouwblokken/mcp_server.md",
    "content": "MCP Server Host (Model Context Protocol) ğŸ¯ Selectie: Standardized MCP Container Voor het ontsluiten van tools en data naar de AI-modellen gebruiken we het Model Context Protocol (MCP). We implementeren dit als een gestandaardiseerde container-architectuur (de \"MCP Host\") op basis van de officiÃ«le TypeScript of Python SDK's. ğŸ’¡ Onderbouwing van de Keuze Waarom kiezen we voor losse MCP Servers in plaats van alle tools in de Core te bakken? 1. Isolatie & Security: Elke set van tools draait in zijn eigen Pod (bijv. mcp-database-tools of mcp-weather-tools). We kunnen per server exact instellen waar hij bij mag. De mcp-weather pod mag wel naar internet (api.weather.com), maar niet naar de interne database. De mcp-database pod mag wel naar de DB, maar niet naar internet. Dit is Security by Design. 2. Taal Agnostisch: Een data-scientist kan een tool schrijven in Python (met Pandas/Numpy), terwijl een web-developer een tool schrijft in TypeScript. MCP abstraheert dit weg; voor de AI is het protocol identiek. 3. Schaalbaarheid: Als de \"Video Processing Tool\" veel CPU nodig heeft, schalen we alleen die specifieke container op, zonder de rest van het platform te belasten. 4. Standaardisatie: Door het MCP protocol te volgen, kunnen we in de toekomst ook externe agents of lokale clients (zoals Claude Desktop) laten verbinden met onze tools. --- ğŸ› ï¸ Installatie Een MCP server is een eenvoudige webserver (meestal via Server-Sent Events - SSE). We rollen deze uit met een standaard Kubernetes Deployment. 1. Base Image Druppie biedt standaard base frames voor developers: ghcr.io/waterschap/druppie-mcp-node:latest ghcr.io/waterschap/druppie-mcp-python:latest 2. Deployment Manifest Een voorbeeld deployment voor een \"Weer Service\". yaml apiVersion: apps/v1 kind: Deployment metadata: name: mcp-weather spec: replicas: 2 selector: matchLabels: app: mcp-weather template: metadata: labels: app: mcp-weather spec: containers: - name: server image: my-registry/mcp-weather:v1 env: - name: API_KEY valueFrom: secretKeyRef: name: weather-api-key key: key ports: - containerPort: 3000 Standaard SSE poort We ontsluiten dit intern via een Service: yaml apiVersion: v1 kind: Service metadata: name: mcp-weather-svc spec: selector: app: mcp-weather ports: - port: 80 targetPort: 3000 --- ğŸš€ Gebruik (Implementatie) De Builder Agent kan de code genereren om een tool te maken. Hier is een voorbeeld in TypeScript. 1. Code (index.ts) typescript import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\"; import { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\"; import { SSEServerTransport } from \"@modelcontextprotocol/sdk/server/sse.js\"; // Maak de server const server = new McpServer({ name: \"weather-server\", version: \"1.0.0\", }); // Definieer een Tool server.tool( \"get_forecast\", { city: z.string(), days: z.number().max(5) }, async ({ city, days }) => { // Voer de logica uit (API call naar externe weerdienst) const forecast = await fetchWeather(city, days); return { content: [{ type: \"text\", text: JSON.stringify(forecast) }], }; } ); // Start de server (SSE mode voor Kubernetes) const transport = new SSEServerTransport(\"/sse\", \"/messages\"); server.connect(transport); 2. Registratie Om de tool beschikbaar te maken, voegen we hem toe aan de Bouwblok Definities (Registry). json { \"name\": \"Weer Tools\", \"type\": \"mcp\", \"endpoint\": \"http://mcp-weather-svc.default.svc.cluster.local/sse\" } ğŸ”„ Integratie in Druppie 1. Discovery: Bij het opstarten (of runtime) scant Druppie Core de registry. 2. Connection: De Core maakt een SSE verbinding met http://mcp-weather-svc.... 3. Tool Listing: De MCP server stuurt een lijst terug: [\"get_forecast\"]. 4. Execution: Gebruiker vraagt: \"Gaat het morgen regenen in Zwolle?\" Planner kiest tool get_forecast. Core stuurt JSON commando naar de MCP pod. MCP pod voert code uit en stuurt antwoord terug."
  },
  {
    "title": "Data Lake (MinIO)",
    "category": "bouwblokken",
    "path": "bouwblokken/data_lake_minio.md",
    "content": "Data Lake & Object Storage (MinIO) ğŸ¯ Selectie: MinIO Voor de opslag van grootschalige ongestructureerde data, specifiek drone-beelden, satelliet-data en AI-modellen, kiezen we voor MinIO. MinIO is een High-Performance Object Storage oplossing die volledig compatible is met de Amazon S3 API. ğŸ’¡ Onderbouwing van de Keuze Relationele databases (zoals Postgres) zijn niet geschikt voor het opslaan van Terabytes aan ruwe pixel-data (Raster files). MinIO vult dit gat: 1. De facto Standaard (S3 API): Vrijwel elke moderne data-tool spreekt \"S3\". GIS Tools: GDAL, QGIS, GeoServer kunnen direct lezen/schrijven naar S3. AI/ML Frameworks: PyTorch, TensorFlow en MLflow laden datasets direct uit S3. Pipeline Tools: OpenDroneMap (voor stichting) en Tekton kunnen S3 als input/output gebruiken. 2. Versioning & Immutability: MinIO ondersteunt S3 Bucket Versioning. Als je een bestand overschrijft, bewaart MinIO de oude versie. Dit is cruciaal voor reproduceerbare AI: \"Op welke versie van de dataset is dit model getraind?\". 3. Performance: MinIO is geoptimaliseerd voor snelheid (gebruikt SIMD instructies) en kan de enorme doorvoer aan die nodig is voor het trainen van modellen op GPU's. 4. Kubernetes Native: Integreert naadloos met de rest van het platform. --- ğŸ› ï¸ Installatie We installeren een stand-alone MinIO cluster (of een Distributed cluster voor productie). 1. Installatie via Helm bash helm repo add minio https://charts.min.io/ helm upgrade --install data-lake minio/minio \\ --namespace data-systems --create-namespace \\ --set rootUser=admin \\ --set rootPassword=VERY_SECRET_KEY \\ --set persistence.size=1Ti \\ --set buckets[0].name=drone-raw \\ --set buckets[0].policy=public \\ --set buckets[0].versioning=true \\ --set buckets[1].name=drone-ortho \\ --set buckets[2].name=ai-models --- ğŸš€ Gebruik: De Drone Workflow Dit bouwblok vormt de fundering voor de geavanceerde verwerking van beelden. Hieronder schetsen we hoe de \"Drone Pipeline\" gebruik maakt van MinIO. Stap 1: Ingestie & Versiebeheer De ruwe beelden (van de drone of satelliet provider) worden geupload naar de drone-raw bucket. Bestand: projects/dijk-a/flight-2025/image_001.tiff Versie: Dankzij bucket versioning krijgt elk bestand een uniek VersionID. Stap 2: Verwerking (Stitching) Een Tekton pipeline start een container met OpenDroneMap (ODM) of GDAL. Input: Leest de raw images direct uit s3://drone-raw. Process: \"Stitcht\" de losse foto's aan elkaar tot Ã©Ã©n grote kaart (Orthophoto). Output: Schrijft het resultaat naar s3://drone-ortho/dijk-a-merged.geotiff. Stap 3: Object Herkenning (AI) Zodra de nieuwe Orthophoto beschikbaar is, start de AI-job (bijvoorbeeld een YOLOv8 model in een Python container). Input: Leest de merged.geotiff uit MinIO. Inference: Het model scant de foto op specifieke objecten (bijv. \"Muskusrat klem\" of \"Beschadiging oever\"). Output: De gevonden locaties (coÃ¶rdinaten) worden opgeslagen in PostGIS (zie Database bouwblok). Annotated images (met bounding boxes) gaan terug naar MinIO s3://ai-results/. MetadataCatalogus (STAC) Om overzicht te houden in deze miljoenen bestanden, gebruiken we de SpatioTemporal Asset Catalog (STAC) standaard. De metadata (waar is de foto gemaakt? wanneer? welke cloud-cover?) slaan we op in PostGIS (of een dedicated STAC server), maar de link wijst altijd naar de binary in MinIO (href: s3://drone-raw/...). ğŸ”„ Integratie in Druppie 1. MCP Server: We kunnen een MCP tool maken (list_drone_images) die de inhoud van de buckets aan de AI toont. 2. Model Training: Data Scientists koppelen hun Jupyter notebooks direct aan MinIO om nieuwe modellen te trainen. 3. Governance: Via MinIO Policies (IAM) regelen we dat de \"Stagiair\" alleen mag lezen, en alleen de \"Pipeline Service Account\" mag schrijven in de drone-ortho bucket."
  },
  {
    "title": "Infrastructure as Code (Terraform)",
    "category": "bouwblokken",
    "path": "bouwblokken/iaas_terraform.md",
    "content": "Bouwblok: Infrastructure as Code (Terraform/OpenTofu) ğŸ¯ Selectie: OpenTofu (Terraform) Voor het provisioneren van infrastructuur binnen het Druppie platform is gekozen voor OpenTofu (de open-source fork van Terraform). Dit stelt ons in staat om infrastructuur declaratief te definiÃ«ren en te beheren als code. ğŸ’¡ Onderbouwing van de Keuze De keuze voor OpenTofu/Terraform is gebaseerd op de volgende kernwaarden: 1. Declaratief Model: Definieer wat je wilt (bijv. een Kubernetes cluster, een S3 bucket), niet hoe het gemaakt moet worden. Dit sluit 1-op-1 aan bij de Spec-Driven Architecture van Druppie. 2. Cloud Agnostisch: Hoewel providers specifiek zijn, is de workflow (init, plan, apply) identiek voor Azure, AWS, Google Cloud en on-premise (VMware/Proxmox). Dit ondersteunt de hybride runtime strategie. 3. State Management: Terraform houdt de staat van de infrastructuur bij. Dit is cruciaal voor de Builder Agent om te weten wat er al bestaat en wat er gewijzigd moet worden (drift detection). 4. Enorme Ecosystem: Er zijn providers voor bijna alles (Azure, Kubernetes, Helm, Keycloak, Grafana), waardoor we de hele stack met Ã©Ã©n tool kunnen beheren. âš™ï¸ Implementatie in Druppie Binnen de architectuur vervult Terraform een specifieke rol in de Build Plane: Gegenereerd door AI: De Builder Agent schrijft Terraform configuraties (.tf files) op basis van de functionele specificaties. Execution in Foundry: De Tekton pipelines draaien tofu plan en tofu apply in een gecontroleerde omgeving. Integratie met Compliance: Terraform plannen worden vÃ³Ã³r uitvoering gevalideerd door tools zoals Trivy (IaC scanning) om te garanderen dat er geen onveilige infrastructuur wordt uitgerold (bijv. open storage buckets). ğŸ› ï¸ Voorbeeld Spec Een voorbeeld van hoe een Terraform definitie eruit ziet die door de Agent gegenereerd kan worden: hcl resource \"azurerm_kubernetes_cluster\" \"druppie_cluster\" { name = \"druppie-prod\" location = \"West Europe\" resource_group_name = azurerm_resource_group.rg.name dns_prefix = \"druppie-k8s\" default_node_pool { name = \"default\" node_count = 3 vm_size = \"Standard_D2_v2\" } identity { type = \"SystemAssigned\" } tags = { Environment = \"Production\" ManagedBy = \"DruppieAgent\" } }"
  },
  {
    "title": "AI Dataset Versioning (DVC)",
    "category": "bouwblokken",
    "path": "bouwblokken/data_versioning_dvc.md",
    "content": "AI Dataset Versioning (DVC) ğŸ¯ Selectie: DVC (Data Version Control) Voor het semantisch beheren van versies van datasets (\"Trainingsset V1\", \"Validatieset V2.3\") bovenop onze ruwe opslag kiezen we voor DVC. DVC brengt de kracht van Git naar grote data-bestanden, zonder dat die bestanden daadwerkelijk in Git worden opgeslagen. ğŸ’¡ Onderbouwing van de Keuze MinIO heeft Object Versioning (technisch), maar DVC biedt Dataset Versioning (logisch). 1. Git voor Data: DVC werkt exact zoals Git. Data Scientists gebruiken commando's die ze al kennen (dvc checkout, dvc commit). 2. Meta-data in Git, Data in MinIO: De grote bestanden (GB's aan Tiff's) blijven in MinIO. DVC maakt kleine pointer-files (dataset.dvc) aan. Deze pointer-files slaan we op in Gitea. Hierdoor is de relatie tussen Code (het model) en Data (de trainingsset) onlosmakelijk verbonden in Ã©Ã©n Git commit hash. Dit garandeert volledige reproduceerbaarheid. 3. CI/CD Integratie: Omdat de dataset-definities in Git staan, kan Tekton automatisch een training pipeline starten zodra er een nieuwe dataset-versie wordt gepusht. --- ğŸ› ï¸ Installatie DVC is een command-line tool en Python library. Er hoeft geen server geÃ¯nstalleerd te worden op het cluster; het maakt gebruik van de infrastructuur die er al is (Gitea + MinIO). Wel kunnen we een (optionele) DVC Studio of een visualisatie-tool hosten, maar de kern werkt client-side. 1. Configuratie in Project Een Data Scientist initialiseert DVC in zijn project repo (op zijn laptop of in een DevContainer): bash In de git repo dvc init Stel MinIO in als 'remote' storage dvc remote add -d my-minio s3://ai-datasets dvc remote modify my-minio endpointurl https://minio.druppie.nl dvc remote modify my-minio access_key_id AR_IS_EEN_KEY dvc remote modify my-minio secret_access_key SUPER_GEHEIM --- ğŸš€ Gebruik: Een Gecontroleerde Dataset Maken Stel we hebben een map data/raw_images met 10.000 drone foto's. Stap 1: Tracken van Data bash dvc add data/raw_images Dit doet 2 dingen: 1. Uploadt de bestanden naar MinIO. 2. Maakt data/raw_images.dvc aan (bevat MD5 hashes van de data). Stap 2: Versie Vastleggen (Git) We committen de pointer naar Gitea. bash git add data/raw_images.dvc .gitignore git commit -m \"Dataset V1: InitiÃ«le drone set\" git push Stap 3: Werken met Versies Stel een collega (of de Builder Agent) wil het model trainen op deze specifieke versie. bash git clone https://gitea.druppie.nl/projecten/drone-ai.git dvc pull DVC ziet de hash in het .dvc bestand, haalt exact die versie van de bestanden uit MinIO, en plaatst ze in de werkmap. Zelfs als de dataset inmiddels is aangepast naar V2, haalt deze commit altijd V1 op. ğŸ”„ Integratie in Druppie (MLOps) 1. Reproduceerbaarheid (Compliance): Als een auditor vraagt \"Op welke data is dit model getraind?\", wijzen we naar de Git commit hash. Via DVC kunnen we bewijzen welke bestanden dat waren. 2. Pipeline Triggering: De Builder Agent ziet een update in de dataset (nieuwe .dvc file). Triggert een Tekton pipeline. Tekton doet dvc pull -> python train.py -> dvc metrics log. Het resultaat is een nieuw AI model."
  },
  {
    "title": "Drone Mapping (WebODM)",
    "category": "bouwblokken",
    "path": "bouwblokken/drone_pipeline_odm.md",
    "content": "Drone Mapping & 3D Processing (OpenDroneMap) ğŸ¯ Selectie: WebODM (OpenDroneMap) Voor het totale proces van fotogrammetrie â€” het omzetten van losse 2D dronefoto's naar georeferenced orthofoto's en 3D-modellen â€” kiezen we voor WebODM. Dit is de gebruiksvriendelijke, web-based interface bovenop de krachtige OpenDroneMap (ODM) engine. ğŸ’¡ Onderbouwing van de Keuze Deze toolset is de open-source standaard in de GIS-wereld en sluit naadloos aan op onze infrastructuur: 1. Alles-in-Ã©Ã©n Pipeline: Preprocessing: Herkent GPS data in foto's. Stitching: Plakt foto's aan elkaar (Orthofoto). 3D Modelling: Genereert Point Clouds (.laz) en Textured 3D Models (.obj/gltf). Analyses: Kan ook vegetatie-indices (zoals NDVI voor landbouw/natuur) berekenen. 2. Kubernetes Ready: WebODM is ontworpen als een set microservices (NodeODMICM) die schalen op ons cluster. \"Zware\" taken worden verdeeld over meerdere Processing Nodes. 3. Integratie: Kan resultaten direct wegschrijven naar onze PostGIS database of als tiles serveren. 4. Vluchtplanning (QGroundControl): WebODM werkt perfect samen met open standaarden voor vluchtplannen. Hoewel de drone zelf vliegt, slaan we het Vluchtplan op als onderdeel van het project. --- ğŸ› ï¸ Installatie We installeren WebODM op het Kubernetes cluster, met toegang tot de GPU-nodes (indien beschikbaar) voor snellere 3D verwerking. 1. Installatie via Helm Er is geen officiÃ«le Helm repository, maar we gebruiken vaak een community chart of de docker-compose conversie. Een typische deployment in Druppie ziet er zo uit: bash Clone de deployment configuratie uit onze GIT repo flux create kustomization webodm \\ --source=druppie-infra \\ --path=./apps/webodm \\ --prune=true Dit start: WebApp: De interface voor gebruikers. NodeODM: De worker(s) die het rekenwerk doen. Database: Interne Postgres (of onze centrale Postgres Cluster). --- ğŸš€ Gebruik: Van Vlucht tot 3D Model Het proces bestaat uit drie fasen, die door Druppie worden gefaciliteerd. Stap 1: Vluchtplanning & Uitvoering Tool: QGroundControl (Client-side) Om een vast interval (bijv. \"elke 2 meter een foto\") en overlap te garanderen, maakt de piloot een vluchtplan. 1. Teken gebied in QGroundControl. 2. Stel parameters in: Front Overlap: 70% (Cruciaal voor 3D). Side Overlap: 60%. GSD (Ground Sampling Distance): 2cm/pixel. 3. Sla het plan op (mission.plan) en upload dit naar Gitea bij het project. Dit garandeert reproduceerbaarheid (\"Vlieg volgende maand exact dezelfde route\"). Stap 2: Upload & Verwerking (WebODM) De foto's komen van de SD-kaart. 1. Upload: Gebruiker (of script) uploadt de map met 500 foto's naar een WebODM Taak. 2. Opties: Selecteer \"High Resolution\" voor dijkinspectie of \"Fast\" voor een snelle check. 3. Processing: WebODM draait de Structure from Motion (SfM) algoritmes. Feature Matching: Zoekt dezelfde boom/struik in foto A en foto B. Point Cloud: Berekent de 3D positie van elk punt. Texturing: Plakt de foto-pixels op het 3D model. Stap 3: Resultaat & Analyse De output wordt automatisch beschikbaar gemaakt: Orthofoto (2D): Een meetbare kaart. Te openen in QGIS of via de WebODM interface. 3D Model: Een interactief model. De gebruiker kan in de browser ronddraaien, afstanden meten en volumes berekenen (bijv. \"Hoeveel kuub zand ligt hier?\"). ğŸ”„ Integratie in Druppie 1. Data Lake: WebODM gebruikt ons MinIO cluster (s3://drone-ortho) om de gigabytes aan resultaten op te slaan. 2. MCP Server: We bouwen een MCP tool (get_3d_snapshot) waarmee de AI een screenshot kan maken van het 3D model vanuit een bepaalde hoek, om daar vervolgens vragen over te beantwoorden. 3. Traceability: Het vluchtplan (mission.plan in Git) + de ruwe foto's (in DVC) + de WebODM instellingen = 100% Reproduceerbaar resultaat."
  },
  {
    "title": "AI Anonymizer (YOLOv8)",
    "category": "bouwblokken",
    "path": "bouwblokken/ai_anonymizer_yolo.md",
    "content": "AI Anonymizer (YOLOv8) ğŸ¯ Selectie: YOLOv8 Voor het automatisch detecteren en anonimiseren van privacy-gevoelige objecten (gezichten, personen, kentekenplaten) in beeldmateriaal kiezen we voor YOLOv8 (You Only Look Once, versie 8) van Ultralytics. ğŸ’¡ Onderbouwing van de Keuze Waarom een generiek AI-model en geen specifieke \"Blur Tool\"? 1. SOTA (State of the Art): YOLOv8 is momenteel de industriestandaard voor real-time objectdetectie. Het is extreem snel en nauwkeurig. 2. Trainbaar: Standaard tools (zoals FaceDetect) werken vaak niet goed op drone-beelden (bovenaanzicht, kleine pixels). YOLOv8 kunnen we specifiek hertrainen (Fine-Tuning) op onze eigen \"Drone Dataset\" met behulp van gelabelde data uit DVC. 3. Flexibiliteit: Vandaag: Gezichten en Kentekens anonimiseren. Morgen: Muskusratten of Kadebreuken detecteren. De infrastructuur blijft hetzelfde, alleen het modelbestand (.pt) verandert. 4. Performance: Geoptimaliseerd voor GPU. Dit is essentieel als we TB's aan data moeten verwerken in onze pipeline. --- ğŸ› ï¸ Installatie We verpakken YOLOv8 in een container die fungeert als een \"Filter Service\". Docker Image We gebruiken de officiÃ«le base image en voegen een klein Python script toe dat de blurring doet. dockerfile FROM ultralytics/ultralytics:latest-cpu (Of 'latest-gpu' voor de nodes met NVIDIA kaarten) RUN pip install opencv-python-headless COPY anonymize.py /app/ ENTRYPOINT [\"python\", \"/app/anonymize.py\"] Het Script (anonymize.py) In pseudocode: 1. Laad Model: model = YOLO('yolov8n-face.pt') 2. Open Info: img = cv2.imread(input_path) 3. Detecteer: results = model(img) 4. Voor elke detectie (Box): Pas een Gaussian Blur toe op de regio binnen de box. (Tip: Gebruik geen zwart vlak, dat verstoort de fotogrammetrie/stitching in WebODM. Blurring behoudt de kleur-structuur). 5. Sla op: cv2.imwrite(output_path, img) --- ğŸš€ Gebruik: De \"Scrubbing Pipeline\" Dit bouwblok wordt aangeroepen door Tekton in de Data Lifecycle. Configuratie (ConfigMap) We kunnen de agressiviteit van het model instellen: yaml confidence_threshold: 0.25 Bij twijfel: blurren (Better safe than sorry) classes_to_blur: - 0 Person - 1 Bicycle (Optioneel) - 2 Car (Kentekens) Validatie (Human-in-the-Loop) Hoewel YOLOv8 >99% kan scoren, is bij High Risk data (dichtbij bebouwing) een menselijke check nodig. De pipeline kan een \"Heatmap\" genereren van geblurde locaties. De operator ziet in Ã©Ã©n oogopslag waar anonimisering heeft plaatsgevonden en kan steekproeven doen. ğŸ”„ Integratie in Druppie 1. DVC: Het getrainde model zelf (drone-face-v1.pt) wordt beheerd in DVC net als de data. 2. WebODM: De output van deze anonimizer is de input voor WebODM. Doordat we \"zacht\" blurren, kan WebODM de foto's nog steeds aan elkaar stitchen op basis van de omgeving (gras, bomen), terwijl de personen onherkenbaar zijn. 3. Governance: In de metadata van de foto (EXIF) schrijven we: Processed-By: Druppie-Anonymizer-V1."
  },
  {
    "title": "Workflow Engine (Argo)",
    "category": "bouwblokken",
    "path": "bouwblokken/workflow_argo.md",
    "content": "Workflow Orchestration (Argo Workflows) ğŸ¯ Selectie: Argo Workflows Voor het orkestreren van complexe werkprocessen en data-pipelines kiezen we voor Argo Workflows. Dit is de Kubernetes-native workflow engine waarmee je processen definieert als een reeks stappen (DAG - Directed Acyclic Graph). ğŸ’¡ Onderbouwing van de Keuze Waarom is dit ideaal voor een \"door AI gegenereerde\" workflow? 1. Declaratief (YAML): Een workflow is \"gewoon\" een Kubernetes resource (kind: Workflow). LLM's (zoals GPT-4) zijn uitstekend getraind in het genereren van gestructureerde YAML. De AI hoeft geen complexe, proprietary code te schrijven, maar alleen een logische lijst van stappen te definiÃ«ren. 2. Visueel: Argo biedt een prachtige UI. De Mens in de Loop ziet precies het schema dat de AI heeft bedacht (A -> B -> C) en kan dit valideren. 3. Container Native: Elke stap in de workflow is een container. Dit betekent dat we al onze bestaande bouwblokken (Python scripts, WebODM commando's, DVC acties) direct als stap kunnen hergebruiken. \"Lijm code\" is minimaal. 4. Schaalbaar: In tegenstelling tot monolithische tools (zoals n8n of Airflow op Ã©Ã©n VM), draait elke stap als een Pod. Voor onze drone-data kunnen we dus duizenden stappen parallel draaien. --- ğŸ› ï¸ Installatie Argo Workflows staat los van ArgoCD en bijt elkaar niet. 1. Installatie via Helm bash helm repo add argo https://argoproj.github.io/argo-helm helm upgrade --install argo-workflows argo/argo-workflows \\ --namespace workflow-system --create-namespace \\ --set server.serviceType=ClusterIP 2. (Optioneel) Argo Events Om workflows te starten op basis van \"Events\" (bijv. een bestand in MinIO, een webhook, of een tijdstip): bash helm upgrade --install argo-events argo/argo-events \\ --namespace workflow-system --- ğŸš€ Gebruik: AI-Driven Workflow Creatie Het concept is: De gebruiker beschrijft het proces, de Builder Agent genereert de YAML. Scenario: \"Verwerk Drone Foto's\" Gebruiker: \"Maak een flow die alle foto's uit de raw bucket haalt, ze verwerkt met WebODM, en mij een email stuurt als het klaar is.\" De Generatie (door AI) De Builder Agent genereert de volgende YAML (simpel weergegeven): yaml apiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: drone-process- spec: entrypoint: drone-dag templates: - name: drone-dag dag: tasks: Stap 1: Check Data - name: fetch-data template: dvc-pull arguments: parameters: [{name: repo, value: \"flight-2025\"}] Stap 2: Verwerking (Start pas als Stap 1 klaar is) - name: process-odm dependencies: [fetch-data] template: odm-stitch arguments: parameters: [{name: resolution, value: \"high\"}] Stap 3: Notificatie - name: send-email dependencies: [process-odm] template: send-notification arguments: parameters: [{name: msg, value: \"Verwerking gereed!\"}] Herbruikbare Templates (De \"Bouwstenen\") - name: dvc-pull container: image: my-registry/dvc-worker:latest command: [dvc, pull] ... De Uitvoering 1. Submit: De Agent (of Foundry) past deze YAML toe (kubectl create -f flow.yaml). 2. Visualisatie: De gebruiker opent de Argo UI en ziet drie blokjes. fetch-data wordt groen âœ… (Klaar). process-odm wordt blauw ğŸ”µ (Bezig). 3. Governance: Omdat alles via Kubernetes loopt, geldt automatisch ons beveiligingsbeleid (Network Policies, IAM). ğŸ”„ Integratie in Druppie 1. Business Logica: Voor bedrijfsprocessen (\"Nieuwe medewerker onboarden\") werkt dit exact hetzelfde. De AI koppelt de ad-create-user en email-send-welcome stappen aan elkaar. 2. Samenwerking met Tekton: Tekton gebruiken we voor CI/CD (het bouwen van de containers). Argo Workflows gebruiken we voor de Processen (het uitvoeren van de containers in een logische volgorde)."
  },
  {
    "title": "API Gateway (Kong)",
    "category": "bouwblokken",
    "path": "bouwblokken/api_gateway_kong.md",
    "content": "API Gateway (Kong) ğŸ¯ Selectie: Kong Gateway Voor het geavanceerd beheren, beveiligen en monitoren van API-verkeer kiezen we voor Kong Gateway (DB-less mode). Kong fungeert als de voordeur voor alle microservices en AI-agenten. ğŸ’¡ Onderbouwing van de Keuze Hoewel we al een Ingress Controller (NGINX) hebben voor basis routing, voegt een API Gateway een abstractielaag toe die essentieel is voor een volwassen platform: 1. Decoupling: De afnemer van de data praat met api.druppie.nl/v1/drone-data, terwijl de backend misschien drone-service-v3.internal:8080/export heet. De Gateway vertaalt dit. 2. Policy Enforcement (CRD): Met Kong beheren we \"Traffic Policies\" als Kubernetes objecten (KongPlugin). De Policy Engine (zie Architecture) kan zo afdwingen dat elke externe API een Rate Limit heeft, zonder de applicatiecode aan te passen. 3. Centrale Authenticatie: Kong valideert API Keys of JWT tokens (van Keycloak) voordat het verzoek de service bereikt. Dit ontlast de ontwikkelaars. 4. Transformation: Kong kan on-the-fly requests aanpassen (bijv. een oude XML response omzetten naar JSON) om legacy systemen te ontsluiten voor moderne AI agents. 5. Performance: Kong is gebouwd op NGINX en is extreem snel en lichtgewicht. --- ğŸ› ï¸ Installatie We installeren Kong als Ingress Controller (of als Gateway achter NGINX). In DB-less mode is hij stateless en makkelijk te schalen. 1. Installatie via Helm bash helm repo add kong https://charts.konghq.com helm upgrade --install kong kong/kong \\ --namespace api-gateway --create-namespace \\ --set ingressController.installCRDs=false \\ --set dblessConfig.configMap=kong-config (We installeren CRDs meestal apart om race-conditions te voorkomen) --- ğŸš€ Gebruik: Policies als Code De kracht van Kong binnen Druppie is dat de Builder Agent policies kan genereren op basis van functionele eisen. Scenario: \"Bescherm de Drone API tegen overbelasting\" Gebruiker: \"De drone data API mag maximaal 100 requests per minuut ontvangen.\" De Builder Agent genereert een KongPlugin manifest: yaml apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: rate-limit-100 namespace: productie config: minute: 100 policy: local plugin: rate-limiting En koppelt deze aan de Service of Ingress: yaml apiVersion: filtering.presidio.com/v1 Fictief voorbeeld kind: Ingress metadata: name: drone-api annotations: konghq.com/plugins: rate-limit-100 konghq.com/strip-path: \"true\" spec: ingressClassName: kong rules: - host: api.druppie.nl http: paths: - path: /v1/drone-data pathType: ImplementationSpecific backend: service: name: drone-service port: number: 80 Andere veelgebruikte Plugins Key Auth: konghq.com/plugins: api-key-auth (Voor M2M communicatie). Prometheus: Exposeert metrics over API gebruik direct naar onze PLG stack. Correlation ID: Voegt een Trace-ID toe aan de header voor Traceability. ğŸ”„ Integratie in Druppie 1. Compliance: De Gateway logt elk request. De logs gaan naar Loki. Als er misbruik wordt gemaakt van een API, zien we dat direct. 2. Versiebeheer: API changes (v1 -> v2) worden beheerd in de Ingress definities in Git. 3. Verbinding met MCP: Als we externe tools (MCP Servers) ontsluiten, zetten we die achter Kong. Zo kunnen we precies meten hoeveel tokens/calls een specifieke AI-agent verbruikt."
  },
  {
    "title": "Architectuur (Archi)",
    "category": "bouwblokken",
    "path": "bouwblokken/architecture_archi.md",
    "content": "Architectuur Modellering (Archi) ğŸ¯ Selectie: Archi & Model Repository (coArchi) Voor het vastleggen en beheren van de Enterprise Architectuur conform de ArchiMate 3.2 standaard kiezen we voor Archi. Om samenwerking en versiebeheer mogelijk te maken, gebruiken we de coArchi plugin in combinatie met onze Gitea Git-server. ğŸ’¡ Onderbouwing van de Keuze Waarom Archi in een DevOps omgeving? 1. De Open Source Standaard: Archi is de referentie-implementatie voor ArchiMate. Het is gratis, open-source en wordt breed gedragen. 2. Git-Based (coArchi): Dankzij de coArchi plugin wordt het model niet als Ã©Ã©n monolithisch bestand opgeslagen, maar als losse objecten/files in Git. Dit maakt Merge Conflicts beheersbaar. Het integreert naadloos met onze \"Alles is Code\" filosofie. Wijzigingen in de architectuur zijn commits in Gitea. 3. Automatisering (CLI): Archi heeft een Command Line Interface. We kunnen hiermee automatisch (via Tekton) rapporten en plaatjes genereren zodra een architect iets commit. 4. Machine Readable: Het .archimate (XML) bestandsformaat is leesbaar voor onze Builder Agent. De AI kan de architectuur lezen om te \"begrijpen\" hoe componenten samenhangen voordat hij code gaat schrijven. --- ğŸ› ï¸ Installatie De tool bestaat uit een Client (voor de architect) en een Pipeline (voor publicatie). 1. Client Setup (Op laptop van Architect) Download Archi 5.x+. Installeer de coArchi Plugin. Verbind met Gitea: URL: https://gitea.druppie.nl/architectuur/enterprise-model.git Auth: Gebruikersnaam + Token. 2. CI/CD Setup (In het Cluster) We gebruiken een Docker container met de Archi CLI om rapporten te genereren in onze bouwstraat. Docker Image: ghcr.io/archi-contrib/docker-archi:latest Implementatie in een Tekton Task: yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: generate-archi-report spec: steps: - name: export-html image: ghcr.io/archi-contrib/docker-archi:latest command: - /opt/Archi/Archi - -application - com.archimatetool.commandline.app - -consoleLog - -nosplash - --html.createReport - /workspace/output - --modelrepository.loadModel - /workspace/source --- ğŸš€ Gebruik: Van Model naar Publicatie Workflow 1. Modelleren: De architect past het model aan in Archi (b.v. \"Nieuwe applicatie toevoegen aan landschap\"). 2. Commit & Push: Via de coArchi plugin \"Publish Changes\". Dit stuurt de wijzigingen naar Gitea. 3. Pipeline Trigger: Gitea stuurt een webhook naar Tekton. 4. Generatie: Tekton start de docker-archi container. Genereert een interactief HTML rapport. Genereert losse PNG's van alle views. 5. Publicatie: De HTML wordt geÃ¼pload naar een webserver (bijv. via Nginx Ingress) op https://architectuur.druppie.nl. AI Integratie (Builder Agent) De Builder Agent kan het model analyseren: Vraag: \"Welke applicaties gebruiken de 'Klant Database'?\" Actie: Agent leest de XML export (via MCP tool read_repo). Analyse: Zoekt relaties Serving of Access richting het object Klant Database. Resultaat: \"Volgens het model gebruiken 'MijnOmgeving' en 'Facturatie' deze database.\" ğŸ”„ Integratie in Druppie 1. Levende Documentatie: Het architectuurmodel is geen statisch PDF in een lade, maar een levende website die altijd up-to-date is met de laatste commit. 2. Compliance: Wijzigingen in de architectuur (bijv. toevoegen van een externe koppeling) zijn traceerbaar in Git (Wie? Wanneer? Waarom?). Dit ondersteunt de BIO/ISO audits. 3. Ontwerp Validatie: Voordat een team begint met bouwen, checkt de Builder Agent of de voorgenomen oplossing past binnen de kaders van het ArchiMate model."
  },
  {
    "title": "GIS Desktop (QGIS)",
    "category": "bouwblokken",
    "path": "bouwblokken/gis_qgis.md",
    "content": "GIS Desktop & Server (QGIS) ğŸ¯ Selectie: QGIS (Quantum GIS) Voor geavanceerde ruimtelijke analyses, kaarten maken en data-bewerking kiezen we voor QGIS. Dit is de absolute marktleider in open-source GIS software. We zetten QGIS in op twee manieren: 1. QGIS Desktop: De applicatie voor de GIS-specialist en Data Scientist. 2. QGIS Server: Een OGC-compliant server die .qgs projectbestanden direct publiceert als WMS/WFS services. ğŸ’¡ Onderbouwing van de Keuze 1. Gebruikersgemak: Biedt een rijke interface die vergelijkbaar is met ArcGIS, maar dan zonder licentiekosten. 2. Integratie: Werkt native samen met onze PostGIS database en MinIO (via VSI S3 of plugins). 3. Project-as-a-Service (QGIS Server): Een unieke krachtige feature. Je maakt een mooie kaart op in Desktop (styling, labels, kleuren), slaat het project op, en de Server serveert het exact zo als web-kaart. Geen gedoe met SLD's (Styled Layer Descriptors) schrijven in XML. 4. Extensible: Enorm ecosysteem van plugins (Python-based), wat automatisering door onze Builder Agent makkelijk maakt. --- ğŸ› ï¸ Installatie 1. QGIS Desktop (Client) Wordt geÃ¯nstalleerd op de werkplekken (Windows/Mac/Linux) of aangeboden via een VDI (Virtual Desktop) oplossing (bijv. KasmWeb of Apache Guacamole) binnen de browser. 2. QGIS Server (Kubernetes) We draaien QGIS Server als container in het cluster om de projecten te ontsluiten. Docker Image: camptocamp/qgis-server:latest Deployment snippet: yaml apiVersion: apps/v1 kind: Deployment metadata: name: qgis-server spec: template: spec: containers: - name: qgis-server image: camptocamp/qgis-server:3.34 env: - name: QGIS_PROJECT_FILE value: \"/data/projects/dijk_analyse.qgs\" volumeMounts: - name: project-data mountPath: /data --- ğŸš€ Gebruik Workflow: \"Van Analyse naar Webkaart\" 1. Data Laden: De GIS-specialist opent QGIS Desktop en verbindt met PostGIS (vector data) en MinIO (drone foto's). 2. Opmaak: Hij stelt de symbologie in (bijv. dijken rood kleuren als conditie < 6). 3. Opslaan: Slaat het project op als inspectie_kaart.qgs in Gitea. 4. Publish: De CI/CD pipeline ziet de commit. Pusht het bestand naar de QGIS Server volume. Resultaat: Een WMS link (https://maps.druppie.nl/wms/inspectie) die exact toont wat de specialist zag. ğŸ”„ Integratie in Druppie 1. WebODM: Resultaten uit de drone-pipeline (Orthofoto's) worden vaak in QGIS gevalideerd voordat ze definitief worden. 2. Frontend: Onze web-apps (React + Leaflet/OpenLayers) gebruiken de WMS/WFS feeds van QGIS Server als ondergrondlaag."
  },
  {
    "title": "GIS Server (GeoServer)",
    "category": "bouwblokken",
    "path": "bouwblokken/gis_geoserver.md",
    "content": "GIS Data Server (GeoServer) ğŸ¯ Selectie: GeoServer Voor het robuust en gestandaardiseerd ontsluiten van onze ruimtelijke data kiezen we voor GeoServer. Waar QGIS Server goed is in visualisatie (Maps), is GeoServer de koning van de data-distributie en standaarden (WFS, WCS, WPS). ğŸ’¡ Onderbouwing van de Keuze 1. De Standaard: GeoServer is de referentie-implementatie voor veel OGC standaarden. Als een externe partij (bijv. Kadaster of Provincie) data bij ons wil ophalen, is een GeoServer WFS-endpoint de universele taal. 2. Fine-grained Security: GeoServer heeft een ingebouwd beveiligingsmodel. We kunnen instellen dat gebruiker \"Stagiair\" alleen de attributen ID en Type mag zien van een laag, maar niet het attribuut Eigenaar. 3. Caching (GeoWebCache): Ingebouwde tiling en caching zorgt voor razendsnelle kaarten, zelfs bij terabytes aan data. 4. Data Formats: Kan output leveren in KML, GeoJSON, GML, Shapefile, Excel, PDF, etc. --- ğŸ› ï¸ Installatie We gebruiken de officiele Kartoza Docker image of een Helm chart. Installatie via Docker/Helm bash helm repo add oscarfonts https://oscarfonts.github.io/helm-charts helm upgrade --install geoserver oscarfonts/geoserver \\ --namespace gis-system --create-namespace \\ --set persistence.enabled=true \\ --set persistence.size=20Gi \\ --set tomcat.extras.javaOpts=\"-Xms2G -Xmx4G\" Configuratie: We koppelen GeoServer aan onze PostGIS store en MinIO store (via de S3 plugin). --- ğŸš€ Gebruik Scenario: \"Publieke Dienst WFS\" Stel we willen partner-waterschappen toegang geven tot onze \"Waterlopen\" dataset. 1. Store Aanmaken: Koppel de PostGIS tabel waterlopen. 2. Layer Publiceren: Publiceer de tabel als Layer druppie:waterlopen. 3. Styling (SLD/CSS): Definieer een standaard blauwe lijn stijl (optioneel, vooral voor WMS). 4. Security: Zet de layer op \"Read-Only\" voor groep Anonymous of vereis een API Key. Resultaat: Een URL: https://geodata.druppie.nl/geoserver/wfs?request=GetFeature&typeName=druppie:waterlopen&outputFormat=application/json ğŸ”„ Integratie in Druppie 1. GeoNode: GeoServer is vaak de \"engine\" onder de motorkap van GeoNode (zie GeoNode bouwblok). GeoNode beheert dan de config. 2. Performance: Voor high-performance tile serving van onze Drone orthofoto's (WMS-T) is GeoServer (met GeoWebCache) zeer geschikt."
  },
  {
    "title": "GIS Portal (GeoNode)",
    "category": "bouwblokken",
    "path": "bouwblokken/gis_geonode.md",
    "content": "Spatial Data Infrastructure (GeoNode) ğŸ¯ Selectie: GeoNode Als centraal portaal voor het vinden en delen van geografische data kiezen we GeoNode. GeoNode is een Open Source Geospatial Content Management System (GeoCMS). ğŸ’¡ Onderbouwing van de Keuze Waarom hebben we GeoNode nodig naast GeoServer en QGIS? 1. De \"Catalogus\" (Metadata): Met duizenden drone-vluchten en GIS-lagen raak je het overzicht kwijt. GeoNode biedt een zoekbalk, previews, en metadata (CSW) ondersteuning. Het is de \"Google\" voor je interne data. 2. Self-Service: Een medewerker kan zelf een Excel met coÃ¶rdinaten of een Shapefile uploaden. GeoNode regelt op de achtergrond automatisch de opslag in PostGIS en publicatie in GeoServer. 3. Social: Gebruikers kunnen comments plaatsen, kaarten raten, en kaarten combineren tot \"Map Stories\" om inzichten te delen met het management. 4. Backend Integratie: Onder water gebruikt GeoNode gewoon GeoServer (voor OGC services) en PostGIS (voor data). Het vervangt deze niet, maar management ze. --- ğŸ› ï¸ Installatie GeoNode is een complexe stack (Django + Celery + GeoServer + DB + RabbitMQ). Het installeren via Docker Compose (of een Helm chart wrapper) is de standaard. Componenten in de Stack Django App: De web interface. GeoServer: De map engine (beheerd door Django). PostGIS: Data opslag. RabbitMQ: Voor asynchrone taken (bijv. upload processing). (In Druppie configureren we GeoNode zo dat hij onze bestaande centrale PostGIS en MinIO clusters gebruikt in plaats van eigen containers te starten.) --- ğŸš€ Gebruik Workflow: \"Data Delen met de Organisatie\" De Drone Operator heeft net een nieuwe kaart gemaakt. 1. Upload: Gaat naar geoportal.druppie.nl en sleept de GeoTIFF erin. 2. Processing: GeoNode valideert het bestand en registreert het in GeoServer. 3. Verrijken: De operator vult metadata in: \"Vlucht 2025, locatie XYZ, vlieger Jan\". 4. Delen: Hij zet de rechten op \"Zichtbaar voor Team Ecologie\". 5. Ontdekken: Een ecoloog zoekt op \"Vegetatie 2025\", vindt de kaart, en opent hem direct in de browser of laadt hem in QGIS via de geboden WMS link. ğŸ”„ Integratie in Druppie 1. Single Source of Truth: GeoNode fungeert als de catalogus. Als de AI Knowledge Bot een vraag krijgt (\"Hebben we kaarten van gebied X?\"), zoekt hij via de GeoNode API (CSW/API v2). 2. Samenhang: GeoServer doet het zware werk, GeoNode maakt het mens-vriendelijk."
  },
  {
    "title": "Policy Enforcement (Kyverno)",
    "category": "bouwblokken",
    "path": "bouwblokken/policy_kyverno.md",
    "content": "Policy Enforcement (Kyverno) ğŸ¯ Selectie: Kyverno Voor het technisch afdwingen en rapporteren van Security by Design en Compliance by Design regels binnen de Kubernetes runtime kiezen we voor Kyverno. Kyverno is een Kubernetes-native Policy Engine. ğŸ’¡ Onderbouwing van de Keuze Waar traditionele tools zoals OPA Gatekeeper een complexe, losstaande taal (Rego) vereisen, gebruikt Kyverno gewoon YAML voor zijn policies. Dit past perfect in onze \"Alles is YAML\" strategie met de Builder Agent. 1. Simpel & Declaratief: Policies zien eruit als Kubernetes resources. De AI (en de mens) kan ze makkelijk lezen en schrijven. 2. Validate, Mutate, Generate: Validate: Blokkeer een Pod als hij als root draait. Mutate: Voeg automatisch een cost-center label toe aan elke Namespace. Generate: Maak automatisch een NetworkPolicy (Deny-All) aan bij elk nieuw project. 3. Reporting: Kyverno genereert PolicyReport objecten in het cluster. Deze zijn direct uitleesbaar door tools als Grafana of een compliance dashboard. --- ğŸ› ï¸ Installatie Kyverno draait als Admission Controller in het cluster. Installatie via Helm bash helm repo add kyverno https://kyverno.github.io/kyverno/ helm upgrade --install kyverno kyverno/kyverno \\ --namespace policy-system --create-namespace \\ --set replicaCount=3 \\ --set admissionController.replicas=3 --- ğŸš€ Gebruik: Van Regel naar Handhaving Scenario: \"Verplicht AI Register\" Vanuit de compliance regels (zie AI Register) is de eis: Geen deployment zonder verwijzing naar een algoritme ID. De Policy (YAML) We definiÃ«ren een ClusterPolicy die dit controleert: yaml apiVersion: kyverno.io/v1 kind: ClusterPolicy metadata: name: require-algorithm-id spec: validationFailureAction: Enforce Blokkeer deployment! (Of 'Audit' voor alleen loggen) rules: - name: check-label match: resources: kinds: - Deployment validate: message: \"Deze deployment moet een 'algorithm-id' label hebben conform de AI Act.\" pattern: metadata: labels: algorithm-id: \"?\" Moet minimaal 1 karakter zijn De Rapportage Kyverno maakt continu rapporten aan: kubectl get policyreports. In Grafana Dashboard: We bouwen een Compliance Dashboard dat deze rapporten uitleest. âœ… Green: 95% van de workloads voldoet aan de eisen. ğŸ”´ Red: Project \"Drone-V1\" faalt op \"Non-Root\" check. Hierdoor heeft de CISO (Chief Information Security Officer) real-time inzicht: \"Zijn we NU compliant?\", in plaats van een jaarlijkse papieren audit. ğŸ”„ Integratie in Druppie 1. CISO Component: De Mens-in-de-Loop kan via Kyverno \"Exceptions\" goedkeuren (bijv. voor een tijdelijke test). 2. Builder Agent: Voordat de agent probeert te deployen, kan hij de YAML valideren tegen de Kyverno CLI (kyverno apply policy.yaml --resource deploy.yaml) om \"afwijzing aan de poort\" te voorkomen."
  },
  {
    "title": "Scanning & Compliance (Trivy)",
    "category": "bouwblokken",
    "path": "bouwblokken/security_scanning_trivy.md",
    "content": "Security & Compliance Scanning (Trivy) ğŸ¯ Selectie: Trivy Voor het scannen van onze containers, bestandssystemen en Infrastructuur-als-Code (IaC) kiezen we voor Trivy (van Aqua Security). Trivy is de meest veelzijdige, uitgebreide en gebruiksvriendelijke open-source security scanner. ğŸ’¡ Onderbouwing van de Keuze Waarom Trivy boven alternatieven (zoals Clair, SonarQube of Anchore)? 1. Alles-in-Ã©Ã©n Scanner: Trivy scant niet alleen container images op CVE's (Common Vulnerabilities), maar scant ook: Filesystem: Source code dependencies (npm, pip, maven). IaC: Kubernetes manifests, Helm charts en Terraform bestanden op misconfiguraties (bijv. \"Container draait als root\"). SBOM: Genereert automatisch een Software Bill of Materials (vereist voor Cyber Resilience Act / NIS2). 2. CI/CD Native: Trivy is ontworpen als CLI tool die perfect past in een Tekton pipeline. Het geeft een harde Exit Code 1 als er een kritiek lek wordt gevonden, wat de build laat falen. 3. Stand-alone & Operator: Kan als CLI draaien tijdens de build, maar ook als Trivy Operator in het cluster om draaiende workloads continu te scannen op nieuwe exploits (Day-2 Operations). 4. Database: De vulnerability database is extreem up-to-date en wordt dagelijks ververst. (Noot: SonarQube is sterker in Code Quality/Bugs, maar voor Security & Compliance van de infrastructuurketen is Trivy de primaire tool.) --- ğŸ› ï¸ Installatie We implementeren Trivy op twee plekken: in de Build Plane (Pipeline) en in de Runtime (Operator). 1. In de Pipeline (Tekton Task) We voegen een herbruikbare Tekton Task toe die door de Builder Agent kan worden aangeroepen. yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: trivy-scan spec: params: - name: IMAGE_URL description: The image to scan steps: - name: scan-image image: aquasec/trivy:latest command: [\"trivy\"] args: - \"image\" - \"--exit-code\" - \"1\" Fail pipeline on Critical - \"--severity\" - \"CRITICAL,HIGH\" - \"--format\" - \"json\" - \"--output\" - \"scan_results.json\" - \"$(params.IMAGE_URL)\" 2. In het Cluster (Trivy Operator) Voor continue monitoring van productie. bash helm repo add aqua https://aquasecurity.github.io/helm-charts/ helm upgrade --install trivy-operator aqua/trivy-operator \\ --namespace security-system --create-namespace \\ --set compliance.cron=\"0 /6 \" Scan elke 6 uur --- ğŸš€ Gebruik: De \"Secure Supply Chain\" Scenario: Vulnerability Gevonden 1. Build Fase: De Builder Agent commit nieuwe code. Tekton bouwt de container. 2. Scan: De trivy-scan taak draait en vindt CVE-2024-1234 (Critical) in de base image python:3.9. 3. Actie: De pipeline faalt âŒ. De image wordt niet gepusht naar de registry. De Agent krijgt feedback: \"Critical Vulnerability in base image. Update naar python:3.9-slim of patch de dependency.\" Scenario: SBOM Generatie (Compliance) Voor elk release genereren we een SBOM (Software Bill of Materials). bash trivy image --format cylonedx --output sbom.json my-app:v1 Dit bestand slaan we op in de Traceability DB. Als over 6 maanden blijkt dat \"Log4j\" lek is, kunnen we met Ã©Ã©n query zien: \"Welke applicaties gebruikten versie X?\". ğŸ”„ Integratie in Druppie 1. Kyverno: Trivy scant, Kyverno handhaaft. De Trivy Operator schrijft rapporten (VulnerabilityReport) naar de Kubernetes API. Kyverno kan een policy hebben die zegt: \"Als een pod een rapport heeft met >0 Criticals, kill de pod.\" 2. Visualisatie: De resultaten van de Trivy Operator worden geÃ«xporteerd naar Grafana. De CISO ziet een dashboard met \"Security Posture: 98% Safe\"."
  },
  {
    "title": "Code Quality (SonarQube)",
    "category": "bouwblokken",
    "path": "bouwblokken/code_quality_sonarqube.md",
    "content": "Code Quality & Static Analysis (SonarQube) ğŸ¯ Selectie: SonarQube Voor het bewaken van de technische kwaliteit, onderhoudbaarheid en code coverage kiezen we voor SonarQube. Waar Trivy focust op beveiligingslekken in containers (CVE's), focust SonarQube op de broncode zelf (SAST - Static Application Security Testing). ğŸ’¡ Onderbouwing van de Keuze SonarQube is de logische aanvulling op Trivy in onze \"Quality Gate\". 1. Clean Code: De Builder Agent genereert veel code. SonarQube fungeert als de automatische \"Senior Developer\" die de kwaliteit reviewt: Complexiteit: \"Deze functie is te ingewikkeld (Deep nesting).\" Bugs: \"Mogelijke NullPointer Exception op regel 40.\" Duplicatie: \"Stuk code is 3x gekopieerd.\" 2. Code Coverage: Visualizeert welke regels code zijn geraakt door de Unit Tests (uitgevoerd door PyTest/Jest in Tekton). We eisen bijvoorbeeld minimaal 80% coverage. 3. Security Hotspots: Vindt hardcoded secrets of zwakke encryptie in de code voordat het gecompileerd wordt. 4. Quality Gate: Blokkeert de pipeline als de kwaliteit zakt (bijv. \"Technical Debt ratio > 5%\"). --- ğŸ› ï¸ Installatie We draaien SonarQube als een stateful service in de Build Plane. Installatie via Helm bash helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube helm upgrade --install sonarqube sonarqube/sonarqube \\ --namespace build-system --create-namespace \\ --set edition=community \\ --set persistence.enabled=true --- ğŸš€ Gebruik: De \"Quality Gate\" 1. In de Pipeline (Tekton) Na de unit-tests draait de scan. yaml Tekton Task Snippet - name: sonar-scan image: sonarsource/sonar-scanner-cli command: [\"sonar-scanner\"] args: - \"-Dsonar.projectKey=drone-service\" - \"-Dsonar.sources=.\" - \"-Dsonar.host.url=http://sonarqube.build-system:9000\" - \"-Dsonar.qualitygate.wait=true\" Wacht op uitslag en faal indien nodig 2. Functional & Technical Testing SonarQube zelf voert geen functionele testen uit (dat doen tools als PyTest, Jest, of Cypress), maar het rapporteert er wel over. Technisch Testen (Unit): De Builder Agent schrijft unit tests. Tekton voert ze uit. SonarQube toont: \"95% Coverage\". Functioneel Testen (E2E): Voor UI tests (bijv. met Playwright) kunnen de resultaten ook ingelezen worden als \"Generic Test Data\" om te zien welke features gedekt zijn. Scenario: \"De Agent maakt rommelige code\" De Builder Agent is soms lui en kopieert code. 1. Commit: Agent pusht code naar Gitea. 2. Scan: SonarQube detecteert 15% Code Duplication. 3. Feedback: De Quality Gate faalt âŒ. 4. Loop: De pipeline stuurt de error log terug naar de Agent. De Agent leest: \"Refactor required: Extract duplicate logic to helper function\". De Agent past de code aan en pusht opnieuw. ğŸ”„ Integratie in Druppie Trivy vs SonarQube: Trivy: Kijkt naar de Container en Dependencies (Is log4j lek?). -> Security. SonarQube: Kijkt naar de Eigen Code (Heb ik een wachtwoord hardcoded?). -> Kwaliteit. Samen: Ze vormen samen de verdedigingslinie in de Build Plane."
  },
  {
    "title": "AI Video (ComfyUI)",
    "category": "bouwblokken",
    "path": "bouwblokken/ai_video.md",
    "content": "Bouwblok: Headless ComfyUI (High-Performance Rendering) ğŸ¯ Alternatief voor Pinokio Waar Pinokio een gebruiksvriendelijke \"Desktop Wrapper\" is, is Headless ComfyUI de industriestandaard voor schaalbare, geautomatiseerde AI-productie zonder overhead. ğŸ’¡ Het Concept Pinokio draait een volledige browser + filesysteem management layer. Dit kost CPU/RAM en is moeilijk te schalen in een cluster. Door ComfyUI direct in API-Only Mode te draaien binnen een geoptimaliseerde Docker container, strippen we alle overhead weg. Geen GUI: De server luistert alleen naar API verzoeken via WebSocket/HTTP. Geen \"Install Scripts\": De environment zit 'fixed' gebakken in een Docker image (Immutable Infrastructure). ğŸš€ Architectuur: The Rendering Farm In deze opzet fungeert het Kubernetes cluster als een \"Rendering Farm\". 1. Designer (Lokaal): De creatief ontwikkelaar gebruikt lokaal ComfyUI (met GUI) om de workflow te bouwen. Hij slaat dit op als API Format (workflow.json). 2. Manager (Druppie Core): De Agent pakt de JSON en injecteert variabelen (bijv. \"text\": \"A cyberpunk city\"). Hij stuurt de payload naar het cluster. 3. Worker (K8s Pod): Een ComfyUI pod (met GPU) pikt de taak op. Rendert de video. Uploadt het resultaat naar MinIO. âš™ï¸ Spec-Driven Containers: Cog Binnen Druppie kiezen we voor Cog (van Replicate) als de standaard voor het bouwen van AI containers. Waarom Cog? Standaard Dockerfiles zijn krachtig maar imperatief (\"doe dit, doe dat\"). Voor AI workloads leidt dit vaak tot \"CUDA Hell\": het oneindig pielen met nvidia-drivers, python versies en torch builds die niet matchen. Cog is Declaratief (Spec-Driven): Je definieert wat je nodig hebt in cog.yaml, en Cog genereert de perfecte Docker image voor je. Automatic CUDA: Cog kiest automatisch de juiste base-images voor jouw GPU hardware. Immutable: De output is een production-ready container die overal werkt. API-First: Cog genereert automatisch een HTTP server rondom je model. De Spec (cog.yaml): yaml build: De \"Spec\" van de runtime gpu: true python_version: \"3.10\" system_packages: - \"ffmpeg\" - \"libgl1-mesa-glx\" python_packages: - \"torch==2.1.2\" Specifieke versies! - \"comfy-cli==1.0.0\" De \"Interface\" naar de buitenwereld predict: \"predict.py:Predictor\" In onze CI/CD pipeline (Tekton) draait simpelweg cog build om van deze spec een container te maken. ğŸ› ï¸ Technische Implementatie (K8s Deployment) yaml apiVersion: apps/v1 kind: Deployment metadata: name: comfyui-worker spec: replicas: 1 Schaalbaar via KEDA template: spec: containers: - name: comfyui image: ghcr.io/my-org/comfyui-hunyuan:sha-123456 Built by Cog ports: - containerPort: 5000 Standaard Cog poort resources: limits: nvidia.com/gpu: 1 ğŸ“¼ Implementatie: HunyuanVideo in Headless ComfyUI Om het HunyuanVideo model (state-of-the-art open source video) te draaien in deze headless setup, moeten we de Docker image \"pre-baken\" met de juiste modellen en custom nodes. 1. Directory Structuur (in de Container) De Dockerfile moet de volgende bestanden op de juiste plek zetten: Custom Nodes: custom_nodes/ComfyUI-HunyuanVideoWrapper: Clone van Kijai's wrapper. Modellen: /models/diffusion_models/: hunyuan_video_t2v_720p_bf16.safetensors /models/vae/: hunyuan_video_vae_bf16.safetensors /models/text_encoders/: clip_l.safetensors, llava_llama3_fp8_scaled.safetensors 2. Dockerfile Specificatie (Cog) yaml build: gpu: true python_version: \"3.10\" system_packages: - \"git\" - \"wget\" python_packages: - \"torch==2.1.0\" run: 1. Install Custom Nodes - \"git clone https://github.com/kijai/ComfyUI-HunyuanVideoWrapper custom_nodes/ComfyUI-HunyuanVideoWrapper\" - \"pip install -r custom_nodes/ComfyUI-HunyuanVideoWrapper/requirements.txt\" 2. Download Weights (Coded in Image for Speed) Let op: In productie mounten we dit vaak via een Volume (PVC) om image size clean te houden. - \"wget -O models/diffusion_models/hunyuan_video_720p.safetensors https://huggingface.co/Tencent-Hunyuan/HunyuanVideo/resolve/main/hunyuan_video_t2v_720p_bf16.safetensors\" âœ… Vergelijking | Feature | Pinokio | Headless ComfyUI | | :--- | :--- | :--- | | Gebruiksgemak | Hoog (One-click) | Gemiddeld (API knowledge) | | Overhead | Hoog (GUI, Node.js wrapper) | Minimaal (Pure Python) | | Schaalbaarheid | Laag (1 instantie) | Hoog (Kubernetes HPA) | | Startup Tijd | Traag (Install at runtime) | Instant (Pre-baked image) | | Doelgroep | Hobbyist / Single User | Enterprise / Automatisering |"
  },
  {
    "title": "AI Audio (TTS)",
    "category": "bouwblokken",
    "path": "bouwblokken/ai_audio.md",
    "content": "Bouwblok: AI Audio Service (TTS & Voice) ğŸ¯ Doelstelling Een dedicated, zelfstandige service voor het genereren van hoge kwaliteit spraak (Text-to-Speech) en audio-effecten. Hoewel audio vaak onderdeel is van video, rechtvaardigt de complexiteit en herbruikbaarheid (bijv. voor podcasts, accessibility, chatbots) een eigen bouwblok. ğŸ—ï¸ Architectuur We draaien dit als een Headless API Service op Kubernetes, vergelijkbaar met de AI Video setup. API-First: Input is tekst + stem-ID, output is .wav. Low-Latency: Geoptimaliseerd voor snelle generatie (sneller dan realtime). Stateful: Caching van gegenereerde stemmen in MinIO. âš™ï¸ Technologie Selectie: XTTSv2 / Parakeet We standaardiseren op Coqui XTTSv2 (via de coqui-ai/TTS library) vanwege: 1. Multilingual: Uitstekende ondersteuning voor Nederlands. 2. Voice Cloning: Kan met een 6-seconden sample een nieuwe stem klonen (ideaal voor consistente karakters). 3. Expressie: Ondersteunt emoties (blij, boos, fluisterend). Altenatief voor _ultra-realistisch_ Nederlands: Parakeet (Open Source model van NDI). ğŸ› ï¸ Technische Implementatie (Cog Spec) We gebruiken ook hier Cog voor de container definitie. yaml build: gpu: true python_version: \"3.10\" python_packages: - \"tts==0.22.0\" Coqui TTS - \"fastapi\" - \"uvicorn\" predict: \"predict.py:Predictor\" API Interface De service luistert naar POST requests: json { \"text\": \"Dit is een test voor de Druppie spraak service.\", \"language\": \"nl\", \"speaker_wav\": \"speakers/detective.wav\" // Reference audio voor Voice Cloning } âœ… Integratie Dit bouwblok wordt gebruikt door: 1. AI Video Pipeline: Voor de voice-overs. 2. Knowledge Bot: Voor spraak-terugkoppeling in de chat. 3. Accessibility: Voor het voorlezen van documentatie."
  },
  {
    "title": "Overview",
    "category": "skills",
    "path": "skills/overview.md",
    "content": "Skills Overview This directory contains the Skill Definitions for the Druppie platform. Skills are specialized capabilities that Agents possess. Each skill file defines the operational contract, standards, and processing logic (state machine) that an Agent must follow when performing tasks related to that domain. By formalizing skills as specifications, we ensure: - Consistency: All agents follow the same patterns (e.g., Mermaid-driven logic). - Quality: Best practices (testing, security, compliance) are embedded in the skill definition. - Traceability: Decisions and outputs can be mapped back to the skill's requirements. --- ğŸ—ï¸ Role-Based Skills These skills simulate specific human roles within a project team, focusing on process and methodology. - Architect (ArchiMate) - Focus: Enterprise and Solution Architecture, ArchiMate modeling. - Key Outputs: Architecture packages, ArchiMate diagrams, ADRs (Architecture Decision Records), Roadmaps. - Logic: From Intake to Motivation Modeling, Baseline/Target analysis, and Governance. - Business Analyst - Focus: Requirements gathering, stakeholder analysis, and user story definition. - Key Outputs: User stories, Acceptance Criteria, Process flows, Requirement specs. - Logic: Translates vague intent into structured, testable requirements. - Test / QA - Focus: Validation, verification, and quality assurance. - Key Outputs: Test plans, Test cases, Defect reports, Quality assessments. - Logic: Ensures requirements are met through rigorous testing cycles (from Unit to E2E). --- ğŸ’» Tech Stack Skills These skills provide deep technical expertise in specific programming languages and runtime environments. - Node.js - Focus: Backend development, APIs, CLI tools, and web services. - Standards: TypeScript-first, ESM, strict linting/testing. - Key Outputs: Production-ready code, Dockerfiles, CI workflows, Kubernetes manifests. - Python (Data Science) - Focus: Data Science, Machine Learning, Data Engineering, and Analysis. - Standards: Reproducible environments (poetry/uv), Data validation, Notebook-to-Production pipelines. - Key Outputs: Python packages, Analysis notebooks, Trained models, Validation reports. - Kubernetes Ops - Focus: Runtime operations, deployment configuration, and cluster management. - Key Outputs: Manifests (Deployment, Service, Ingress), Helm charts, Kustomize configurations. - Logic: Manages the deployment lifecycle and runtime stability. --- ğŸ§  Core Capabilities Foundational skills that support the logic or communication of other agents. - Mermaid Diagrams - Focus: Visualizing logic, workflows, and state machines. - Usage: Used by all other skills to visualize their internal state machine and decision logic. - Key Outputs: Flowcharts, Sequence diagrams, State diagrams. --- ğŸš€ How to use a Skill When an Agent adopts a skill (e.g., \"Act as a Node.js Developer\"), it loads the corresponding .md file and adheres to the Operational Contract defined therein: 1. Check Inputs: Does the request match the Input scope? 2. Follow State Machine: Execute the steps defined in the Processing Logic (often visualized with Mermaid). 3. Enforce Standards: Apply the Required Standards (coding style, testing, patterns). 4. Produce Outputs: Generate the artifacts listed in the Output section."
  },
  {
    "title": "Architect Skill",
    "category": "skills",
    "path": "skills/architect.md",
    "content": "Your primary function is to design, document, and govern enterprise and solution architectures using ArchiMate by translating business goals, stakeholder concerns, and technical constraints into consistent, layered, and traceable ArchiMate models and architecture documentation. You operate as a spec-driven architecture agent that: - applies ArchiMate concepts and viewpoints correctly, - documents architecture decisions and trade-offs, - maintains alignment between models and narrative documentation, - interacts with ArchiMate-capable MCP servers to create, query, validate, and evolve architecture models programmatically. You must always favor: - conceptual clarity over tool-specific tricks - ArchiMate semantics over informal diagrams - traceability over visual density - consistency across layers and viewpoints --- Scope You support architecture work using ArchiMate 3.x concepts, including: - Strategy, Business, Application, Technology, Physical, and Motivation layers - Cross-layer relationships and viewpoints - Architecture principles and requirements - Solution and enterprise architecture documentation - Architecture Decision Records (ADRs) - Governance and compliance reviews You are tool-agnostic by default, but capable of interacting with modeling tools via ArchiMate MCP servers. --- Operating Model You operate as an ArchiMate-driven architecture lifecycle: - Establish motivation and drivers - Model baseline (as-is) architecture - Model target (to-be) architecture - Analyze gaps and impacts - Govern decisions and roadmap All narrative documentation must be derived from and consistent with ArchiMate models. --- Operational Contract Inputs You accept: - Business context - goals, drivers, outcomes - value streams and capabilities - Architecture concerns - quality attributes (security, availability, cost, compliance) - regulatory and policy constraints - Current-state assets - existing ArchiMate models (if any) - inventories of applications, data, platforms - Governance inputs - architecture principles - reference architectures and standards - Delivery constraints - timelines, budgets, organizational boundaries --- Outputs You produce an ArchiMate-based Architecture Package, consisting of: - ArchiMate models (layers, viewpoints) - Viewpoint-specific diagrams - Architecture principles and requirements - ADRs with traceability to model elements - Gap analysis and migration roadmap - Governance and compliance notes - Glossary and model legend All outputs must be: - ArchiMate-semantic correct - traceable across layers - suitable for review, tooling, and automation --- ArchiMate Modeling Principles (Required) You must enforce the following: - Layer integrity: do not mix semantics improperly (e.g., business behavior in application layer) - Explicit realization chains: strategy â†’ business â†’ application â†’ technology - Clear ownership: actors, roles, and responsibilities are explicit - Minimalism: model what is relevant for the decision - Viewpoint-driven modeling: every diagram has a purpose and audience - Traceability: requirements, principles, and decisions link to model elements --- ArchiMate Layers & Core Elements You must correctly apply (non-exhaustive): Motivation Layer - Stakeholder, Driver, Goal, Requirement, Constraint, Principle Strategy Layer - Capability, Resource, Course of Action Business Layer - Business Actor, Role, Process, Function, Service, Object Application Layer - Application Component, Interface, Function, Service, Data Object Technology Layer - Node, Device, System Software, Technology Service, Network --- Processing Logic (State Machine) States - Intake - MotivationModeling - BaselineModeling - TargetModeling - ViewpointDerivation - PrinciplesAndConsistencyCheck - DecisionRecording - RoadmapAndGaps - DocumentationAssembly - ReviewAndGovernance - Iteration - Completion --- 1) Intake Purpose: define scope and modeling intent. Actions: - identify stakeholders and concerns - define modeling scope and depth - identify required viewpoints - confirm ArchiMate usage level (enterprise vs solution) Decision gates: - scope and audience clear? Transitions: - clear â†’ MotivationModeling - unclear â†’ Intake --- 2) Motivation Modeling Purpose: capture the â€œwhyâ€. Actions: - model drivers, goals, outcomes - derive requirements and constraints - map principles to goals Outputs: - Motivation viewpoint Transitions: - complete â†’ BaselineModeling --- 3) Baseline Modeling (As-Is) Purpose: model current state. Actions: - model existing capabilities and services - model current applications and technologies - identify pain points and risks Outputs: - Baseline viewpoints per layer Transitions: - complete â†’ TargetModeling --- 4) Target Modeling (To-Be) Purpose: model desired future state. Actions: - model target capabilities and services - define realization chains across layers - introduce new components and platforms - ensure alignment with principles Outputs: - Target viewpoints per layer Transitions: - complete â†’ V"
  },
  {
    "title": "Business Analyst Skill",
    "category": "skills",
    "path": "skills/business_analyst.md",
    "content": "Your primary function is to elicit, structure, validate, and evolve requirements by working with stakeholders to transform initial ideas, problems, or user stories into wellâ€‘defined epics, features, and requirements that are clear, testable, and implementationâ€‘ready. You operate as a researchâ€‘ and analysisâ€‘driven agent that bridges business intent and delivery, ensuring that requirements are: - complete but not bloated - structured and prioritized - traceable to business value - understandable for both business and technical teams You do not design solutions or write code. You focus on what and why, not how. --- Scope You support work typically performed by: - Business Analysts - Product Owners (analysis side) - Researchers / Discovery specialists Including: - Problem exploration and clarification - Stakeholder and user research - Requirement structuring - Epic & user story refinement - Acceptance criteria definition - Dependency and risk identification - Traceability and documentation --- Operating Principles You must always favor: - clarity over assumptions - questions over guesses - business value over feature lists - outcomes over outputs - shared understanding over speed You continuously validate understanding with the user. --- Operational Contract Inputs You accept: - Initial ideas - rough user stories - feature requests - problem statements - stakeholder wishes - Context - business goals - users / personas - existing processes or systems - Constraints - regulatory, legal, compliance - time, budget, scope - organizational policies - Existing artifacts - epics, backlogs, roadmaps - documentation or research notes --- Outputs You produce structured requirement artifacts, such as: - Refined problem statement - Clearly scoped epics - Wellâ€‘formed user stories - Acceptance criteria (Gherkin or equivalent) - Assumptions and open questions - Nonâ€‘functional requirements (where relevant) - Dependencies and risks - Traceability to business goals All outputs must be: - unambiguous - reviewable - prioritizable - suitable for backlog management tools --- Core Artifacts & Definitions Problem Statement You ensure the problem is expressed as: - who is affected - what problem they experience - why it matters - what success looks like --- Epic An Epic represents: - a significant business capability or outcome - composed of multiple related user stories - valueâ€‘oriented, not solutionâ€‘oriented Epic structure: - Name - Business goal - Inâ€‘scope / outâ€‘ofâ€‘scope - Success metrics - Risks and assumptions --- User Story User stories must follow: > As a [user], I want [capability], so that [benefit]. Each user story must include: - acceptance criteria - clear scope boundaries - dependencies (if any) - testable outcomes --- Acceptance Criteria Standard You should prefer Given / When / Then style: text Given <context> When <action> Then <expected outcome> Acceptance criteria must be: - objective - testable - directly linked to the story goal --- Processing Logic (State Machine) Your logic is modeled as a state machine, suitable for Mermaid visualization. States - Intake - ProblemExploration - StakeholderUnderstanding - RequirementStructuring - EpicDefinition - UserStoryRefinement - Validation - Review - Iteration - Completion --- 1) Intake Purpose: understand the request at a high level. Actions: - capture the initial idea or story - identify stakeholders and users - clarify urgency and context Decision gates: - is the problem statement clear? Transitions: - clear â†’ ProblemExploration - unclear â†’ Intake --- 2) Problem Exploration Purpose: uncover the real problem. Actions: - ask â€œwhyâ€ repeatedly - identify pain points and goals - separate symptoms from root causes Outputs: - refined problem statement Transitions: - complete â†’ StakeholderUnderstanding --- 3) Stakeholder Understanding Purpose: understand perspectives and needs. Actions: - identify primary and secondary users - capture stakeholder concerns - note conflicting goals Outputs: - stakeholder map - assumptions list Transitions: - complete â†’ RequirementStructuring --- 4) Requirement Structuring Purpose: organize requirements logically. Actions: - group needs into themes - identify functional vs nonâ€‘functional requirements - detect duplicates or conflicts Outputs: - requirement catalog (structured) Transitions: - complete â†’ EpicDefinition --- 5) Epic Definition Purpose: define epics that deliver value. Actions: - define epics based on outcomes - define scope and success criteria - link epics to business goals Decision gates: - epics valueâ€‘oriented and scoped? Transitions: - yes â†’ UserStoryRefinement - no â†’ Iteration --- 6) User Story Refinement Purpose: create highâ€‘quality user stories. Actions: - split epics into user stories - refine story wording - define acceptance criteria - identify dependencies Decision gates: - stories INVESTâ€‘compliant? - acceptance criteria testable? Transitions: - yes â†’ Validation - no â†’ Iteration --- 7) Validation Purpose: ensure correctness and c"
  },
  {
    "title": "Kubernetes Ops",
    "category": "skills",
    "path": "skills/kubernets.md",
    "content": "Your primary function is to autonomously manage the operational lifecycle of a Kubernetes cluster by transforming declarative intent, runtime signals, and policy constraints into safe, observable, and reversible actions across the full Kubernetes lifecycle. You operate as a continuous control-loop agent that governs: Deployment â†’ Monitoring â†’ Maintenance â†’ Incident Response â†’ Monitoring Your behavior must be deterministic, decision-driven, and aligned with standard Kubernetes APIs and conventions. --- Core Responsibilities You are responsible for: - Safely deploying workload changes using progressive delivery strategies - Continuously monitoring cluster and workload health - Executing maintenance actions within defined change windows - Detecting, diagnosing, and mitigating incidents - Returning the system to a stable, observable state You must always favor rollback, containment, and blast-radius reduction over forward progress when system health is uncertain. --- Operational Contract Inputs You accept the following inputs: - Declarative intent - Kubernetes manifests - Helm charts or rendered resources - Runtime signals - Metrics (CPU, memory, latency, error rates) - Logs (container and node-level) - Events (Kubernetes events stream) - Policy constraints - Change windows - Safety rules (e.g., rollback thresholds) - SLO definitions - Current cluster state - Pod status - Node health - Replica availability --- Processing Logic You execute logic as a state machine, where each state maps directly to a Mermaid diagram node or subgraph. 1. Deployment State Purpose: Introduce change safely. Actions: - Validate manifests - Verify cluster capacity - Select deployment strategy (rolling, canary, blue/green) - Apply resources - Observe rollout progress Decision Gates: - Rollout successful? - Health checks passing? Transitions: - Success â†’ Monitoring - Failure â†’ Incident Response --- 2. Monitoring State Purpose: Detect deviations from desired or healthy behavior. Actions: - Continuously collect metrics, logs, and events - Evaluate SLOs - Detect anomalies and error budget burn Decision Gates: - Anomaly detected? - Maintenance due? Transitions: - Healthy â†’ Monitoring (self-loop) - Anomaly â†’ Incident Response - Maintenance due â†’ Maintenance --- 3. Maintenance State Purpose: Preserve long-term cluster health. Actions: - Validate change window - Upgrade Kubernetes version - Upgrade node operating systems - Tune autoscaling behavior - Drain and uncordon nodes as required Decision Gates: - Maintenance successful? Transitions: - Success â†’ Monitoring - Failure â†’ Incident Response --- 4. Incident Response State Purpose: Restore system stability. Actions: - Classify incident (crashloop, saturation, node failure, network) - Diagnose root cause using logs, events, and metrics - Execute mitigation (rollback, scale, reconfigure, replace nodes) - Verify recovery Decision Gates: - System stable and SLOs restored? Transitions: - Stable â†’ Monitoring - Unstable â†’ Incident Response (loop) --- Outputs You produce: - Actions - Deployments - Rollbacks - Scaling events - Node maintenance actions - Evidence - Metrics snapshots - Logs references - Event traces - Reports - Deployment summaries - Incident reports - Maintenance summaries All actions must be observable, auditable, and reproducible. --- Behavioral Principles You must adhere to the following principles: - Kubernetes-native first (no platform assumptions) - Declarative intent over imperative drift - Rollback-first safety model - Decisions must be signal-driven - Every failure produces learning artifacts"
  },
  {
    "title": "Mermaid Diagrams",
    "category": "skills",
    "path": "skills/mermaid.md",
    "content": "Your primary function is to transform ANY textual diagram idea, natural language description, malformed/incomplete Mermaid code, or embedded Mermaid blocks within Markdown into production-ready, syntactically pristine, visually compelling, and interactive Mermaid diagrams. You will also provide micro-documentation via a concise changelog and embedded tooltips. Your core operational logic is derived from the comprehensive Mermaid syntax and feature compendium detailed herein. --- I. OPERATIONAL PHASES (Your Refinement Lifecycle) --- Phase 1: Input Ingestion & Contextual Analysis 1. Isolate Mermaid Content: If input is Markdown, extract content from mermaid ... blocks. For other inputs, identify the core diagram-related text. 2. Pre-sanitize: Normalize basic whitespace; identify explicit user flags (theme:, type:, layout:). 3. Diagram Type & Layout Inference (See Section II: Inference Matrix): Determine the most appropriate Mermaid diagram type and initial layout direction (e.g., TD, LR) based on explicit flags or content analysis. If ambiguous, default to flowchart TD and note this assumption. Phase 2: Syntactic & Structural Perfection (Guided by Section III) 1. Strict Syntax Enforcement: Apply the specific syntax rules detailed in Section III for the inferred diagram type. This includes, but is not limited to: - Correct diagram type declaration and direction. - Proper quoting of identifiers, labels, and text. - Accurate connection/arrow syntax. - Valid statement termination and block structuring. - Correct use of keywords and directives. 2. Code Formatting: Apply consistent indentation (spaces) and spacing for optimal readability. Phase 3: Visual Styling & Clarity Enhancement (Guided by Section III) 1. Theme & Color Application: - Default: Apply a WCAG-compliant, clear, professional base theme. - User Theme: Honor theme: dark | corporate | {JSON_object_for_themeVariables}. - Specific Styling: Apply type-specific styling directives (e.g., style, classDef, radius, UpdateRelStyle) as detailed in Section III for the inferred diagram type. 2. Layout Optimization: Refine layout for balance and legibility, respecting the inferred/specified direction and type-specific layout rules (e.g., columns in block-beta). Phase 4: Interactivity & Documentation Augmentation (Guided by Section III) 1. Click Actions & Links: Implement click, link, links directives according to the syntax in Section III for the diagram type. 2. Tooltips: Generate tooltips from %% comments %% or for complex elements. 3. Changelog: Prepare a concise list of key refinements. Phase 5: Output Assembly 1. Compile the final, validated Mermaid code block. 2. Assemble the changelog. --- II. DIAGRAM TYPE INFERENCE MATRIX & KEYWORD ASSOCIATIONS --- Use these cues to determine the most probable diagram type. Prioritize explicit type: flags. | Primary keywords / structural cues | Likely Mermaid diagram type | |---|---| | -->, ---, node shapes [] () (()) {} {{}} >] [/] [\\], subgraph, click, classDef | flowchart | | participant, actor, ->>, -->>, activate/deactivate, alt/opt/loop | sequenceDiagram | | class, interface, visibility + - ~, inheritance <|--, composition -- | classDiagram | | state, [] -->, <<choice>>, <<fork>>, <<join>> | stateDiagram-v2 | | Entity { attributes }, PK, FK, crowâ€™s foot connectors ||--o{ | erDiagram | | journey, title User Journey, section, Task: score: 3 | journey | | gantt, dateFormat, axisFormat, section, done, active | gantt | | pie, title, 'Label' : 42 | pie | | quadrantChart, x-axis, y-axis, quadrant-1, points like A: [0.2, 0.8] | quadrantChart | | requirementDiagram, requirement, functionalRequirement, risk, verifyMethod | requirementDiagram | | gitGraph, commit, branch, checkout, merge | gitGraph | | C4Context / C4Container / C4Component / C4Dynamic | C4 diagrams | | mindmap, indentation-based hierarchy | mindmap | | timeline, section, YYYY: event | timeline | | zenuml, @Actor, @Module, method calls A->B.method() | zenuml | | kanban, column headers with indented tasks | kanban | | sankey-beta, CSV-like Source,Target,Value | sankey-beta (may be disabled) | | xychart-beta, x-axis, y-axis, bar, line | xychart-beta (may be disabled) | | block-beta, columns, blocks with widths | block-beta (may be disabled) | | packet-beta, bit ranges like 0-7: \"Label\" | packet-beta (may be disabled) | | architecture-beta, group, service, junction | architecture-beta (may be disabled) | | radar-beta, axis, curve, graticule | radar-beta (may be disabled) | --- III. THE GRAND MERMAID COMPENDIUM: SYNTAX & FEATURES (Your Core Knowledge) --- This section is your exhaustive internal reference guide. You must apply these rules and patterns with precision. 1. Flowcharts (flowchart) - Declaration: flowchart <direction> - Directions: TB or TD (Top to Bottom/Top Down), BT (Bottom to Top), LR (Left to Right), RL (Right to Left). - Example: flowchart LR - Nodes: - Syntax: id[Text Label], id(\"Text Label\"), id([\"Text Label\"]), id[[\"Text Label\"]], id>\"Text Label\"]"
  },
  {
    "title": "Test Skill",
    "category": "skills",
    "path": "skills/test.md",
    "content": "Your primary function is to validate that a product, system, or solution meets its requirements, quality standards, and user expectations by designing, executing, and maintaining effective testing strategies. You operate as a spec-driven testing agent that ensures: - requirements are testable and verified - defects are detected as early as possible - quality risks are made explicit - feedback is actionable for delivery teams You focus on proving fitness for purpose, not on building the solution itself. --- Scope You support testing activities across the full lifecycle, including: - Requirement and acceptance testing - Functional and non-functional testing - Manual and automated testing - Test strategy and test planning - Defect analysis and reporting - Quality gates in CI/CD pipelines - Risk-based testing You work closely with: - Business Analysts / Researchers - Developers and Coding Agents - Architects and Platform teams - Product Owners and Stakeholders --- Operating Principles You must always favor: - prevention over detection - clarity over volume of tests - risk coverage over test count - early feedback over late assurance - evidence over opinion You are independent but collaborative. --- Operational Contract Inputs You accept: - Requirements - epics, user stories, acceptance criteria - non-functional requirements (NFRs) - Specifications - functional specs - API contracts - architecture constraints - Artifacts - code builds or services - test environments - logs and metrics - Quality policies - definition of done - coverage thresholds - compliance requirements --- Outputs You produce verifiable quality artifacts, including: - Test strategy and test plan - Test cases and scenarios - Automated test suites - Test execution reports - Defect reports with reproduction steps - Quality risk assessment - Go / No-Go recommendations All outputs must be: - objective - reproducible - traceable to requirements - understandable by technical and non-technical stakeholders --- Core Testing Artifacts Test Strategy Defines: - test levels and types - scope in / out - environments - tools and automation approach - risks and mitigations --- Test Case / Scenario Each test must define: - preconditions - steps - expected results - traceability to requirements You prefer scenario-based testing over isolated steps. --- Defect Report A defect must include: - clear title - steps to reproduce - expected vs actual result - severity and impact - evidence (logs, screenshots) --- Testing Levels & Types You must apply the test pyramid appropriately: - Unit tests (mostly by developers) - Integration tests - System / API tests - End-to-End tests - Exploratory tests Non-functional testing includes: - performance & load - security - usability - reliability & resilience - compliance --- Processing Logic (State Machine) Your logic is modeled as a state machine, suitable for Mermaid visualization. States - Intake - RequirementAnalysis - TestDesign - TestPreparation - TestExecution - DefectAnalysis - Reporting - Review - Iteration - Completion --- 1) Intake Purpose: understand what needs to be tested. Actions: - receive requirements and scope - identify stakeholders - understand timelines and constraints Decision gates: - scope and quality goals clear? Transitions: - clear â†’ RequirementAnalysis - unclear â†’ Intake --- 2) Requirement Analysis Purpose: ensure requirements are testable. Actions: - review requirements and acceptance criteria - identify ambiguities and gaps - derive test conditions Decision gates: - requirements testable? Transitions: - yes â†’ TestDesign - no â†’ Iteration --- 3) Test Design Purpose: design effective tests. Actions: - define test scenarios and cases - map tests to requirements - prioritize tests based on risk Decision gates: - sufficient risk coverage? Transitions: - yes â†’ TestPreparation - no â†’ Iteration --- 4) Test Preparation Purpose: prepare environments and data. Actions: - prepare test data - configure environments - set up automation frameworks Decision gates: - environment ready? Transitions: - yes â†’ TestExecution - no â†’ Iteration --- 5) Test Execution Purpose: execute tests and collect evidence. Actions: - run manual and automated tests - capture results and evidence - log defects Decision gates: - blocking defects found? Transitions: - yes â†’ DefectAnalysis - no â†’ Reporting --- 6) Defect Analysis Purpose: analyze and qualify defects. Actions: - reproduce defects - determine severity and priority - collaborate with developers Transitions: - resolved â†’ TestExecution - deferred â†’ Reporting --- 7) Reporting Purpose: provide transparent quality status. Actions: - summarize test results - report defect trends - assess quality risks Decision gates: - quality acceptable? Transitions: - yes â†’ Review - no â†’ Iteration --- 8) Review Purpose: support release decisions. Actions: - present quality findings - recommend Go / No-Go - confirm acceptance criteria Decision gates: - release approved? Transitions: - yes â†’ Completion"
  },
  {
    "title": "Node.js Skill",
    "category": "skills",
    "path": "skills/nodejs.md",
    "content": "Your primary function is to design, implement, test, package, and ship Node.js applications by transforming human intent, structured specifications, and existing codebases into production-ready, maintainable Node.js deliverables. You operate as a spec-driven, agentic coding agent. You refine requirements, propose architecture, implement code, run tests, build artifacts (Docker), and produce deployment-ready outputs (CI + Kubernetes manifests), using well-defined skills and guardrails. Your operational logic follows the Mermaid skill pattern: explicit states, decision gates, transitions, feedback loops, and embedded tooltips (when diagrams are produced). You must always favor: - correctness over speed - clarity over cleverness - safety, testability, and maintainability over premature optimization --- Scope You support: - Node.js (LTS) with TypeScript-first defaults (JS allowed) - REST APIs, background workers, CLIs, and simple web frontends - Build/test/deploy workflows suitable for CI/CD and Kubernetes - Local developer experience (DX): npm run dev, .env, Docker Compose --- Operational Contract Inputs You accept: - Intent - user requirements and constraints - target environments (local, test, prod) - non-functional requirements (SLOs, latency, security) - Specification - functional spec + acceptance criteria - API contracts (OpenAPI optional) - data contracts (JSON Schema optional) - Context - repo contents, existing conventions, dependencies - build system constraints (CI provider, container registry, k8s) - Policies - coding standards - security constraints and dependency allow/deny lists - quality thresholds (tests, lint, coverage) Outputs You produce: - application code (TS/JS) - tests (unit/integration/e2e as appropriate) - build artifacts: - Dockerfile - .dockerignore - optional docker-compose.yml for local/dev - operational files: - README.md (run/build/test instructions) - environment templates (.env.example) - CI workflow templates (generic YAML + provider example if requested) - deployment files (if Kubernetes target): - k8s/ manifests or Helm chart skeleton - health probes, resource requests/limits, autoscaling template All outputs must be: - incremental (small diffs) - reproducible (pinned deps, deterministic builds) - reviewable and reversible (clear commit boundaries) --- Required Standards (Coding, Structure, Testing) 1) Code Style & Conventions Default conventions unless repo dictates otherwise: - TypeScript strict mode enabled (new projects) - ESM preferred for new projects (Node LTS supports it); CJS only when required - Use async/await consistently; avoid mixed promise styles - Never ignore errors silently; all caught errors must be logged or returned - Prefer pure functions and small modules; avoid large â€œgod filesâ€ - Use explicit types at module boundaries: - request/response DTOs - external integration adapters - public service interfaces - Logging: - structured logs (JSON) in production - avoid logging secrets/PII - Configuration: - read from environment variables (12-factor) - validate config at startup (fail fast) - Security: - no secrets in code - sanitize/validate external input - dependency hygiene (no unmaintained or vulnerable deps when avoidable) Suggested file naming - kebab-case for files, PascalCase for classes, camelCase for functions/vars --- 2) Project Organization Patterns You must choose and enforce one pattern based on project type. Pattern A â€” Simple Service (REST API) src/ app.ts express/fastify app wiring server.ts startup + graceful shutdown routes/ controllers/ services/ repositories/ integrations/ external APIs, queues middlewares/ utils/ config/ tests/ unit/ integration/ Pattern B â€” Hexagonal (Ports & Adapters) for Medium/Large Services src/ domain/ entities/ value-objects/ services/ application/ use-cases/ dto/ ports/ inbound/ outbound/ adapters/ inbound/ http/cli/queue handlers outbound/ db/external apis infrastructure/ config/ observability/ tests/ Pattern C â€” CLI Tool src/ cli.ts commands/ core/ utils/ tests/ Rule: Follow existing repo conventions. Only introduce a new structure when starting a new project or when explicitly requested. --- 3) Testing Standards (What to test, and how) You must implement a testing strategy that matches risk and scope. Unit tests (required) - test pure logic: parsing, validation, transformations, domain rules - run fast, no network, no real DB Integration tests (recommended for services) - test HTTP handlers with in-memory server (supertest) - test DB adapters with ephemeral DB (Testcontainers) when feasible E2E tests (optional) - validate critical user journeys - run less frequently (nightly or pre-release) Test tooling defaults - Vitest (fast TS support) or Jest (common) - ts-node/tsx for dev, tsc or esbuild for build Coverage (default targets) - Unit coverage â‰¥ 80% for new code (configurable) - Focus on meaningful coverage, not 100% vanity metrics --- Build, Package, and Run Deliverables Node.js scripts you should provide I"
  },
  {
    "title": "Golang Expert Skill",
    "category": "skills",
    "path": "skills/golang.md",
    "content": "Skill: Senior Go (Golang) Expert Role Description You are an expert Go (Golang) software engineer with deep experience in building scalable, cloud-native microservices and Kubernetes controllers. You prioritize simplicity, readability, and performance. You strictly follow \"Idiomatic Go\" principles and avoid over-engineering. --- 1. Core Philosophy & Style Simple is better than clever: Write code that is easy to read and maintain. Avoid magic. Explicit Error Handling: NEVER ignore errors. Always handle them or wrap them with context using fmt.Errorf(\"doing something: %w\", err). Bad: func() { _ = doSomething() } Good: if err := doSomething(); err != nil { return fmt.Errorf(\"failed to do something: %w\", err) } Structs & Interfaces: Accept Interfaces, Return Structs: Functions should accept interfaces to allow mocking, but strictly return concrete types. Small Interfaces: Define interfaces where they are used, not where they are implemented. Concurrency: \"Share memory by communicating, don't communicate by sharing memory.\" Use Channels (chan) for orchestration and data flow. Use WaitGroup or ErrGroup for synchronization. ALWAYS use context.Context to manage cancellation and timeouts. 2. Project Structure (Standard Layout) Follow the Standard Go Project Layout: /cmd: Main application entry points (e.g., /cmd/server/main.go). /internal: Private application and business logic. Not importable by other modules. /pkg: Library code that is safe to be imported by external projects. /api: OpenAPI/Swagger specs, Protocol Buffer definitions. /deploy: Helm charts, Dockerfiles, K8s manifests. 3. Recommended Libraries (The Stack) Web Framework: github.com/go-chi/chi/v5 (preferred for simplicity and standard lib compatibility) or gin-gonic/gin (if high perfs/features needed). Kubernetes Client: k8s.io/client-go. NEVER use generic REST clients for K8s API; use the typed client. Logging: go.uber.org/zap (Structured logging is mandatory). Configuration: github.com/spf13/viper or github.com/kelseyhightower/envconfig. CLI: github.com/spf13/cobra. 4. Coding Standards 4.1 Dependency Injection Avoid global state. Pass dependencies explicitly via struct constructors. go // Bad var db Database func Init() { db = Connect() } // Good type Server struct { db Database } func NewServer(db Database) Server { return &Server{db: db} } 4.2 Testing Use Table-Driven Tests for all logic. Use the testing package (standard lib) + github.com/stretchr/testify/assert for ergonomics. Separate integration tests with build tags: //go:build integration. 4.3 Context Propagation Every blocking function (I/O, Database, API calls) MUST accept context.Context as the first argument to ensure the application allows graceful shutdown. go func (s Service) GetData(ctx context.Context, id string) (Data, error) { req, _ := http.NewRequestWithContext(ctx, \"GET\", ...) // ... } 5. Build & Deployment Docker: Use Multi-Stage builds. Build stage: golang:1.23-alpine Run stage: gcr.io/distroless/static-debian12:nonroot Linting: Strict adherence to golangci-lint. Modules: Always use go mod. Vendor dependencies only if strictly required by air-gapped constraints. 6. Implementation Checklist When writing code for the user, check against this list: - [ ] Are all errors handled? - [ ] Is context.Context passed down the stack? - [ ] Are logs structured (JSON)? - [ ] Are hardcoded values moved to Config/Env vars? - [ ] Is there a Dockerfile utilizing multi-stage builds? - [ ] Is there a go.mod and go.sum?"
  },
  {
    "title": "Python Skill",
    "category": "skills",
    "path": "skills/python.md",
    "content": "Your primary function is to design, implement, validate, and operationalize Python-based data science solutions by transforming human intent, structured specifications, and existing codebases/data assets into reproducible, testable, and production-ready data science artifacts. You operate as a spec-driven, agentic Python data science coding agent. You refine requirements, propose data/ML approaches, implement code, run analyses and tests, package deliverables (libraries, notebooks, pipelines), and prepare deployment-ready outputs (batch jobs, APIs, scheduled workflows), using well-defined skills and guardrails. Your operational logic follows the Mermaid skill pattern: explicit states, decision gates, transitions, and feedback loops, making the workflow diagrammable, auditable, and extendable. You must always favor: - correctness and reproducibility over speed - clarity and interpretability over cleverness - sound validation over â€œit looks goodâ€ - privacy and safety over convenience --- Scope You support: - Python (3.12+ preferred; align to repo constraints) - Data science workflows: EDA, feature engineering, statistical analysis, forecasting, classical ML, evaluation - Core libraries: NumPy, pandas, SciPy, scikit-learn - Visualization: matplotlib (default), plotly (optional) - Experiment tracking (optional): MLflow-like patterns - Packaging & environments: venv/conda, pip/poetry/uv - Notebooks (Jupyter) and script-first pipelines - Model serving (optional): FastAPI, batch scoring jobs - MLOps-lite: data validation, model validation, artifact versioning --- Operational Contract Inputs You accept: - Intent - business question / decision to support - constraints (latency, cost, interpretability, privacy) - stakeholders and acceptance criteria - Specification - problem framing (prediction vs inference vs reporting) - evaluation metrics (e.g., RMSE, AUC, F1, calibration) - data sources and schemas - constraints (train/test split rules, leakage rules) - Context - repository contents and conventions - available datasets, sample extracts, or data contracts - target runtime (local, notebook, CI, batch, API) - Policies - coding standards - data governance rules (PII handling, retention) - quality thresholds (tests, coverage, metric baselines) Outputs You produce: - Python source code (modules/packages) and/or notebooks - Data pipelines (scripts, DAG-ready steps) where relevant - Tests (unit + data/contract tests) - Documentation: - README: setup, run, reproduce results - methodology notes (assumptions, limitations) - Artifacts (as applicable): - trained model (pickle/joblib/onnx) + metadata - feature definitions - evaluation report - plots/tables - data validation reports All outputs must be: - reproducible (pinned deps, deterministic seeds where possible) - reviewable and incremental - traceable (inputs â†’ code â†’ outputs) --- Required Standards (Python, DS, Structure, Testing) 1) Code Style & Conventions Default conventions unless repo dictates otherwise: - Follow PEP 8 naming and layout - Use type hints for public interfaces and core transforms - Prefer pure functions for transforms; isolate side effects (I/O) - No hidden global state; pass configuration explicitly - Use deterministic randomness: - set seeds (numpy/random, sklearn) when applicable - Logging: - use logging module; structured logging optional - never log secrets/PII - Configuration: - env vars + config files (.env, yaml, toml) as appropriate - validate config at startup (fail fast) - Dependencies: - pin versions via lockfile (poetry.lock / requirements.txt with hashes) - avoid unnecessary heavy deps 2) Project Organization Patterns Choose one pattern and be consistent. Pattern A â€” Notebook + Library (best for exploratory + reusable code) notebooks/ 01_eda.ipynb 02_modeling.ipynb src/ project/ __init__.py data/ features/ models/ evaluation/ viz/ tests/ Pattern B â€” Pipeline-first (best for repeatable runs and CI) src/ project/ pipelines/ train.py score.py evaluate.py data/ ingest.py validate.py features/ build.py models/ train.py predict.py evaluation/ metrics.py report.py tests/ configs/ Pattern C â€” Service (batch + API) src/ project/ core/ data/ features/ models/ api/ FastAPI jobs/ batch scripts tests/ docker/ k8s/ optional Rule: Preserve existing repo conventions; introduce new structure only with intent and documentation. --- 3) Data Science Validation Standards You must implement validation beyond â€œit runsâ€: Data validation (required when using real datasets) - schema checks (columns, types, ranges) - missingness thresholds - categorical cardinality sanity checks - distribution drift checks (optional) Experiment hygiene - explicit train/validation/test split - leakage checks: - target leakage - time leakage (for time series) - baseline model required (simple benchmark) Evaluation - choose metrics aligned with the business goal - report confidence/uncertainty where relevant - error analysis: - segment performance - confusion matrix for classificatio"
  },
  {
    "title": "Overview",
    "category": "build_plane",
    "path": "build_plane/overview.md",
    "content": "Build Plane â€“ Spec-driven AI voor Bouwen & Testen via CI/CD Inleiding De Build Plane is het deel van je platform dat verantwoordelijk is voor het bouwen, testen en verpakken van software op een herhaalbare, auditeerbare en policy-gedreven manier. In een moderne platform-architectuur is de Build Plane vaak de â€œfabriekâ€ die van broncode + specificaties een release-artifact maakt (bijv. container image + SBOM + testresultaten). In dit document beschrijven we een spec-driven AI aanpak: > Een AI-agent (of meerdere) voert Build Plane-taken uit op basis van specificaties (specs), niet op basis van losse instructies. Hierdoor wordt het proces: - Consistent (zelfde regels, zelfde output) - Beheersbaar (policies, approvals, gates) - Schaalbaar (veel teams, veel services) - Traceerbaar (wie/wat/waarom via spec + logs) Dit document is gelaagd: - ğŸ”° Beginner: wat is de Build Plane en hoe loopt â€œcode â†’ build â†’ testâ€ - ğŸ§  Expert: architectuur, spec-schemaâ€™s, decision logic, supply chain security, caching, hermetic builds --- 1. Wat is de Build Plane? (Beginner) De Build Plane is alles wat gebeurt voordat je applicatie draait in Kubernetes (of productie): 1. Code ophalen uit Git 2. Build uitvoeren (compile, package) 3. Tests draaien (unit/integration/e2e) 4. Artifact maken (bijv. container image) 5. Artifact publiceren (registry) 6. Resultaten opslaan (logs, reports, SBOM) 7. Eventueel: promotie en release metadata genereren mermaid flowchart TD A[Git commit / PR] --> B[CI/CD pipeline start] B --> C[Build] C --> D[Test] D --> E[Package artifact] E --> F[Publish] F --> G[Reports & metadata] --- 2. Spec-driven AI: het kernidee Waarom â€œspec-drivenâ€? In plaats van â€œde pipeline doet X omdat iemand dat ooit zo schreefâ€, definieer je wat je wil in een spec: - welke taal/runtime - welke build tool - welke test suites - welke kwaliteitsgates - welke outputs vereist zijn (image, SBOM, attestations) - welke policies gelden (geen kritieke kwetsbaarheden, coverage threshold, etc.) De AI-agent gebruikt deze spec om: - de pipeline te genereren of aan te sturen - beslissingen te nemen (gates) - fouten te diagnostiseren en fixes voor te stellen - resultaten te formatteren en te publiceren mermaid flowchart LR Spec[Build Spec<br/>desired process] --> AI[Spec-driven AI Orchestrator] AI --> CI[CI/CD Runner] CI --> Tools[Build + Test Tools] Tools --> Outputs[Artifacts + Reports] Outputs --> AI Gerelateerde Ontwerpen Component Interactie: Hoe de Build Plane praat met de Runtime. Automated Rebuild: Hoe de Build Plane reageert op security patches. Automated Testing: De teststrategie die hier wordt uitgevoerd. --- 3. De Build Plane bouwblokken 3.1 Git & Triggering Triggers die de Build Plane activeren: - Pull Request (validatie) - Merge naar main (release candidate) - Tag (release) - Manual (hotfix / backfill) 3.2 CI/CD Framework Een CI/CD framework is de â€œexecute layerâ€: - voert jobs uit in containers/VMs - beheert secrets - geeft logs en artifacts door - ondersteunt concurrency en caching Voorbeelden (vendor-neutraal): GitHub Actions, GitLab CI, Jenkins, Tekton, Buildkite. 3.3 Build System Afhankelijk van je stack: - Node: npm/pnpm/yarn + bundlers - Java: Maven/Gradle - Python: uv/poetry/pip + build backends - Go: go build + modules - .NET: dotnet build/test/publish 3.4 Test Framework Tests worden uitgevoerd door: - Unit tests (bijv. JUnit, pytest, Jest) - Integration tests (bijv. Testcontainers) - Contract tests (bijv. Pact) - E2E tests (bijv. Playwright/Cypress) - Security tests (SAST/DAST) & dependency scans 3.5 Artifact & Registry De output is meestal: - Container image (OCI) - Helm chart / manifests bundle - SBOM (CycloneDX/SPDX) - Attestations (provenance) --- 4. Het Spec Model (Beginner â†’ Intermediate) Een Build Spec beschrijft het proces declaratief. Voorbeeld: yaml apiVersion: platform.build/v1 kind: BuildSpec metadata: name: checkout-service spec: language: nodejs runtimeVersion: \"20\" build: command: \"pnpm build\" artifact: type: oci-image imageName: \"registry.example.com/checkout\" tests: - name: unit command: \"pnpm test\" required: true - name: integration command: \"pnpm test:integration\" required: true qualityGates: coverageMinPct: 80 vulnMaxSeverity: high publish: tags: - \"{git.sha}\" - \"{semver}\" caching: enabled: true keys: - \"pnpm-lock.yaml\" Wat levert dit op? - De AI kan op basis hiervan: - een pipeline genereren - build/test uitvoeren - gates evalueren - outputs publiceren --- 5. Build Plane workflow (met gates) mermaid flowchart TD T[Trigger: PR / merge / tag] --> S[Load BuildSpec] S --> V[Validate spec + policies] V -->|OK| B[Build] V -->|Fail| X[Stop + feedback] B --> U[Unit tests] U --> G1{Unit OK?} G1 -->|No| X G1 -->|Yes| I[Integration/E2E tests] I --> G2{Tests OK?} G2 -->|No| X G2 -->|Yes| Q[Quality gates<br/>coverage + vuln] Q --> G3{Gates OK?} G3 -->|No| X G3 -->|Yes| P[Package & Publish artifact] P --> R[Reports: logs, junit, coverage, SBOM, attestations] R --> Done([Ready for Deploy Plane]) --- 6. Testen: van simpel naa"
  },
  {
    "title": "Builder Agent",
    "category": "build_plane",
    "path": "build_plane/builder_agent.md",
    "content": "AIâ€‘Builder Agent Inleiding Een AIâ€‘Builder Agent is een interactieve software-agent die samen met de gebruiker een specificatie (spec) opstelt en verfijnt, en vervolgens Ã©Ã©n of meerdere LLMâ€™s inzet om op basis van die specificatie en beschikbare skills (tools/capabilities) code te schrijven, te testen en iteratief te verbeteren. Het doel is: van idee â†’ heldere spec â†’ werkende implementatie, met controle, auditability en herhaalbaarheid. Dit document is gelaagd opgebouwd: - ğŸ”° Beginner: wat is een AIâ€‘Builder en hoe werkt het in simpele termen? - ğŸ§  Expert: architectuur, state machine, guardrails, skill contracts en agentic workflow patterns Mermaid-diagrammen worden gebruikt voor uitleg en voorbeelden. --- 1. Wat is een AIâ€‘Builder Agent? (Beginner) Een AIâ€‘Builder Agent is: > Een â€œbouwassistentâ€ die samen met jou uitzoekt wat je precies wil, en daarna software bouwt op basis van die afspraken. In plaats van dat je Ã©Ã©n prompt geeft (â€œmaak een appâ€), werkt de AIâ€‘Builder zo: 1. Vraagt door tot de spec duidelijk is 2. Vat samen wat er gebouwd moet worden 3. Laat een codeâ€‘LLM code genereren volgens de spec 4. Runt tests en checkt kwaliteit 5. Itereert totdat het klopt --- 2. Waarom spec-driven? (Beginner) Zonder spec-driven aanpak: - onduidelijke requirements - wisselende output - lastig te testen - moeilijk te onderhouden Met een spec: - iedereen is het eens over de scope - je krijgt consistente code - je kunt gates en tests toevoegen - je kunt later makkelijk uitbreiden --- 3. Hoofdrollen in het systeem Een AIâ€‘Builder omgeving bestaat meestal uit: - User: levert requirements, feedback, domeinkennis - AIâ€‘Builder Agent: spec + planning + besluitvorming - Code LLM: schrijft code op basis van spec + context - Skill Layer: tools (repo lezen, build uitvoeren, tests draaien, linten, deployen) - Artifact Store: code, testresultaten, logs, releases mermaid flowchart LR U[Gebruiker] <--> A[AIâ€‘Builder Agent] A --> L[Code LLM] A --> S[Skills / Tools] S --> R[Repo / Artifacts] L --> R R --> A --- 4. Kernverantwoordelijkheden van de AIâ€‘Builder Agent Voor beginners - Doorvragen en de spec duidelijk maken - Taken opdelen in stappen - Code laten genereren - Testen laten draaien - Feedback verwerken Voor experts - Spec governance (versioning, approvals) - Risk management (scope creep, security) - Orchestratie van multi-agent flows - Deterministische output via structured prompting - Evaluatie en kwaliteitsgates (tests, lint, policies) --- 5. De â€œSpec Refinement Loopâ€ (Beginner) De agent refineâ€™t de spec in korte iteraties: mermaid flowchart TD Idea[Idee] --> Q[Agent stelt vragen] Q --> Spec[Spec v0.1] Spec --> Review[Gebruiker reviewt] Review --> Update[Agent past spec aan] Update --> Spec2[Spec v0.2] Spec2 --> Ready{Spec klaar?} Ready -->|Nee| Q Ready -->|Ja| Build[Start build] Belangrijk: - De agent stelt vragen om ambiguÃ¯teit weg te nemen - De spec wordt steeds concreter - Elke stap is traceerbaar (versies) --- 6. Van spec naar code (Agentic AI) Wanneer de spec â€œreadyâ€ is, schakelt de AIâ€‘Builder naar implementatie: mermaid flowchart TD Spec[Final Spec] --> Plan[Plan / Tasks] Plan --> Gen[Code laten genereren door LLM] Gen --> Apply[Code toepassen in repo] Apply --> Test[Test suite] Test --> Gate{Alles groen?} Gate -->|Ja| Deliver[Opleveren] Gate -->|Nee| Fix[Debug + patch] Fix --> Gen De agent werkt hier â€œagenticâ€: - maakt een plan - voert acties uit via tools/skills - evalueert resultaten - past aan - herhaalt --- 7. Skill Contracts (Expert) De AIâ€‘Builder Agent gebruikt skills als gestandaardiseerde capabilities. Een skill heeft een contract: - Inputs (parameters) - Processing logic (wat doet de skill) - Outputs (resultaten, status, artifacts) - Failure modes (wat kan misgaan) - Safety constraints (wat mag niet) Voorbeeld (conceptueel): yaml skill: name: run_tests inputs: command: string outputs: status: pass|fail report_path: string constraints: timeout_seconds: 900 no_network: true Door skills te gebruiken kan de agent: - betrouwbaar acties uitvoeren - output structureren - beslissingen nemen op basis van resultaten --- 8. Guardrails & kwaliteitsgates (Expert) Een AIâ€‘Builder Agent hoort niet zomaar code te â€œspuwenâ€. Het moet kwaliteit borgen. Typische gates - Unit tests (must pass) - Linting (must pass) - Type checks (must pass) - Security scan (no critical) - Coverage threshold (bijv. â‰¥ 80%) mermaid flowchart LR Code --> Lint{Lint OK?} Lint -->|No| Fix Lint -->|Yes| Tests{Tests OK?} Tests -->|No| Fix Tests -->|Yes| Sec{Security OK?} Sec -->|No| Fix Sec -->|Yes| Ship[Ready] --- 9. Multi-model routing (Expert) Een AIâ€‘Builder kan meerdere modellen gebruiken: - Reasoning model: spec refinement, planning, debugging - Coding model: code generation - Review model: code review, style, security checks - Eval model: test failure classification, flaky detection mermaid flowchart TD Agent[AIâ€‘Builder] --> R[Reasoning LLM] Agent --> C[Coding LLM] Agent --> V[Verifier LLM] Agent --> E[Eval/Classifier] --- 10. Output van de AIâ€‘Builder Agen"
  },
  {
    "title": "Foundry",
    "category": "build_plane",
    "path": "build_plane/foundry.md",
    "content": "Foundry ğŸ¯ Doelstelling Microsoft Foundry (voorheen Azure AI Studio) fungeert als de centrale \"Agent Factory\" en \"Control Plane\" voor het Druppie platform. Het consolideert de creatie, het beheer en de beveiliging van AI-agenten in Ã©Ã©n omgeving. Waar de Build Plane het conceptuele domein is, is Foundry het concrete platform waarop dit domein draait. ğŸ“‹ Functionele Specificaties 1. Spec-Driven Agent Creatie (Agent-as-Code) - Repo-based: Agenten worden niet handmatig in een portal geklikt, maar gedefinieerd in code (YAML). - Automated Pipeline: Een CI/CD proces (Agent Factory Pipeline) vertaalt deze YAML-definities naar API-calls naar de Azure AI Agent Service. - Validatie: De pipeline valideert specs tegen beleidsregels (bijv. \"Mag deze afdeling GPT-4o gebruiken?\"). 2. Agent Management & Runtime - Hosting: Faciliteert de runtime omgeving voor agenten via de Azure AI Agent Service. - Model Hub: Biedt centrale toegang tot modellen (OpenAI, Phi, Llama) via een eenduidige API. - Tooling: Beheert de integratie met tools via OpenAPI definities en Python functies. 3. Evaluatie & Monitoring - Evaluation Flows: Automatisch testen van agent-responses tegen ground-truth datasets om kwaliteit/hallucinaties te meten. - Tracing: Volledige traceerbaarheid van elke stap (Prompt -> LLM -> Tool -> Response) via integratie met Azure Monitor/Purview. ğŸ”§ Technische Requirements - API-First: Alle interactie met Foundry verloopt via de Foundry SDK of REST API voor automatisering. - Private Networking: Foundry resources (Hubs, Projects) zijn verbonden via Private Endpoints en afgeschermd van het publieke internet. - Identity: Diepe integratie met Entra ID voor RBAC op project- en agent-niveau. ğŸ”’ Security & Compliance - Data Exfiltration Protection: Policy-regels voorkomen dat data naar niet-goedgekeurde URL's wordt gestuurd. - Model Safety: Standaard content filters (Hate, Self-harm, Violence) zijn actief op alle endpoints. ğŸ”Œ Interacties (Factory Process) | Stap | Actie | Component | | :--- | :--- | :--- | | Commit | Dev pusht agent.yaml | Git | | Validate | Pipeline checkt beleid | Build Agent | | Deploy | Pipeline roept API aan | Foundry API | | Register | Agent ID opgeslagen | Agent Registry | ğŸ—ï¸ Relaties tot andere blokken - Host voor: Build Plane Domein. - Levert Runtime aan: Runtime Domein. - Beveiligd door: Compliance Layer."
  },
  {
    "title": "Overview",
    "category": "runtime",
    "path": "runtime/overview.md",
    "content": "Runtime Overview De Runtime is de \"motor\" van het Druppie platform. Hier draaien de AI agents, de microservices, de databases en de data-pipelines. ğŸ—ï¸ De Infrastructuur Kubernetes (RKE2) De fundering. Een gehard, secure Kubernetes cluster dat voldoet aan overheidsstandaarden. Policy Enforcement (Kyverno) De \"douanier\". Zorgt ervoor dat alles wat op het cluster draait voldoet aan de veiligheids- en compliance-eisen. Automatische validatie, mutatie en rapportage. ğŸ“¦ Workloads Op deze runtime draaien de volgende type applicaties, gedefinieerd als Bouwblokken: AI Models & Agents GIS Applicaties (GeoServer, QGIS) Data Pipelines (Argo) Web Apps (React frontends)"
  },
  {
    "title": "Runtime Info",
    "category": "runtime",
    "path": "runtime/runtime.md",
    "content": "Kubernetes Runtime Inleiding Dit document beschrijft de Kubernetes runtime: de infrastructuurlaag waarop applicaties (bouwblokken) geautomatiseerd, veilig en schaalbaar worden uitgevoerd. Het document is bewust opgebouwd in lagen, zodat zowel beginners als experts / platform engineers waardevolle inzichten krijgen. - Beginners krijgen begrip van wat Kubernetes is en doet - Experts krijgen architectuur, control-loops en ontwerpprincipes --- 1. Wat is een Kubernetes Runtime? (Beginner) Een Kubernetes runtime is: > Een geautomatiseerde omgeving waarin containers worden gestart, bewaakt, geschaald en hersteld zonder menselijke tussenkomst. Je hoeft als gebruiker niet te weten: - Op welke server je applicatie draait - Wanneer een container opnieuw start - Hoe verkeer wordt gerouteerd Dat regelt Kubernetes voor je. --- 2. Hoofdcomponenten van een Kubernetes Cluster Overzicht (conceptueel) mermaid flowchart LR User[Gebruiker / CI-CD] --> API[Kubernetes API] API --> Scheduler API --> Controller[Controllers] Scheduler --> Node1[Node] Scheduler --> Node2[Node] Controller --> Node1 Controller --> Node2 Componenten uitgelegd Kubernetes API (Control Plane) - Het centrale aansturingspunt - Alle acties lopen via de API (kubectl, CI/CD, operators) - Bewaakt de desired state Scheduler - Bepaalt waar een Pod wordt geplaatst - Houdt rekening met: - CPU / Memory - Affiniteit / anti-affiniteit - Taints & tolerations Controllers - Controleren continu: > â€œIs de werkelijkheid gelijk aan wat gewenst is?â€ - Voorbeelden: - Deployment controller - ReplicaSet controller - Node controller --- 3. Nodes en Pods Nodes - Machines (VM of bare-metal) - Draaien: - container runtime (containerd) - kubelet - networking (CNI) Pods - Kleinste deploybare eenheid - Bevat: - EÃ©n of meerdere containers - Shared netwerk - Shared storage (volumes) mermaid graph TD Pod --> Container1 Pod --> Container2 Pod --> Volume --- 4. Netwerk en Verkeer Service Discovery (Beginner) mermaid flowchart LR PodA --> Service Service --> PodB Service --> PodC - Services zorgen voor: - Stabiel IP/DNS - Load balancing Network Policies (Expert) - Zero-trust binnen het cluster - Verkeer is expliciet toegestaan - Zonder policy: alles open mermaid flowchart LR Frontend -->|Allowed| Backend Backend -.->|Blocked| Database --- 5. Deployments en Scaling Deployment Lifecycle mermaid stateDiagram-v2 [] --> Created Created --> Running Running --> Scaling Scaling --> Running Running --> Failed Failed --> Restarting Restarting --> Running Scaling - Horizontal Pod Autoscaler (HPA) - Triggers: - CPU - Memory - Custom metrics --- 6. Failover en Self-Healing Kubernetes is self-healing: - Pod crasht â†’ nieuwe pod - Node valt weg â†’ pods opnieuw gepland - Healthcheck faalt â†’ container restart mermaid flowchart TD Pod -->|Crash| Controller Controller -->|New Pod| Node --- 7. Runtime als Control Loop (Expert) De kern van Kubernetes is een control loop: mermaid flowchart LR Desired[Desired State] --> Observe Observe --> Compare Compare --> Act Act --> Observe - Declaratief model - Geen scripts, maar intentie - Altijd convergent naar gewenst gedrag --- 8. Security & Compliance (Expert) Basisprincipes - Least privilege (RBAC) - Network isolation - Immutable containers Componenten - RBAC - NetworkPolicy - PodSecurity - Secrets management --- 9. Samenvatting Voor beginners - Kubernetes regelt alles rondom draaien van containers - Jij beschrijft wat je wilt, niet hoe Voor experts - Kubernetes is een gedistribueerde control-plane - Alles draait om: - Desired state - Control loops - Idempotente acties"
  },
  {
    "title": "Role Based Access Control (RBAC)",
    "category": "runtime",
    "path": "runtime/rbac.md",
    "content": "Kubernetes Role Based Access Control (RBAC) Inleiding RBAC (Role-Based Access Control) is het autorisatiemechanisme van Kubernetes. Het bepaalt wie (subject) wat (actie) mag doen op welke resources binnen het cluster. Dit document is gelaagd opgebouwd: - ğŸ”° Beginners leren wat RBAC is en waarom het nodig is - ğŸ§  Experts krijgen inzicht in het autorisatiemodel, evaluatielogica en ontwerpkeuzes --- 1. Wat is RBAC? (Beginner) RBAC beantwoordt Ã©Ã©n simpele vraag: > â€œMag deze gebruiker dit doen?â€ Voorbeelden: - Mag Alice pods bekijken? - Mag een CI/CD pipeline deployments aanpassen? - Mag een applicatie secrets lezen? Zonder RBAC: - Iedereen kan alles - Grote security-risicoâ€™s Met RBAC: - Rechten zijn expliciet - Toegang is beperkt en controleerbaar --- 2. De Basisbegrippen van RBAC (Beginner) RBAC bestaat uit vier kernobjecten: mermaid flowchart LR Subject --> Role Role --> Rule Subject --> Binding 1. Subject â€“ Wie? Een subject is een identiteit: - Gebruiker - Groep - ServiceAccount (meest gebruikt door applicaties) 2. Role / ClusterRole â€“ Wat mag je doen? Een role bevat regels: - Welke resources (pods, services, secrets) - Welke acties (get, list, create, update, delete) - Role â†’ namespace-specifiek - ClusterRole â†’ cluster-breed 3. RoleBinding / ClusterRoleBinding â€“ Waar geldt dit? Een binding koppelt: - Een subject - Aan een role - In een scope (namespace of cluster) --- 3. Eenvoudig Voorbeeld (Beginner) > Een applicatie mag alleen pods lezen in namespace app. yaml apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: pod-reader namespace: app rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\"] yaml apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: bind-pod-reader namespace: app subjects: - kind: ServiceAccount name: app-sa roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io --- 4. Hoe Kubernetes RBAC Beslissingen Neemt (Expert) RBAC werkt als een autorisation pipeline: mermaid flowchart TD Request[API Request] --> AuthN[Authentication] AuthN --> AuthZ[RBAC Authorization] AuthZ -->|Allowed| API AuthZ -->|Denied| Reject Stap-voor-stap: 1. Authenticatie: Wie ben je? 2. Autorisatie (RBAC): - Zoek alle bindings voor het subject - Verzamel alle bijbehorende roles - Combineer alle regels - EÃ©n allow is voldoende â†’ toegestaan 3. Geen expliciete deny bestaat in RBAC --- 5. Evaluatielogica (Expert) RBAC is: - Additief - Stateless - Order-onafhankelijk Belangrijke gevolgen: - Meer bindings = meer rechten - Rechten worden nooit â€œontzegdâ€, alleen niet toegekend - Least privilege vereist discipline mermaid flowchart LR RoleA --> Rights RoleB --> Rights RoleC --> Rights --- 6. ClusterRole vs Role (Expert) | Aspect | Role | ClusterRole | |------|------|-------------| | Scope | Namespace | Cluster | | Use-case | App-specifiek | Infra / platform | | Resources | Namespaced | Namespaced + cluster-wide | Let op: Een ClusterRole kan via een RoleBinding alsnog namespace-beperkt worden toegepast. --- 7. ServiceAccounts en Workloads (Expert) Best practices: - Elke workload krijgt eigen ServiceAccount - Nooit default gebruiken - Tokens alleen waar nodig - Combineer met NetworkPolicy mermaid flowchart LR Pod --> ServiceAccount ServiceAccount --> RoleBinding RoleBinding --> Role --- 8. Security Best Practices Voor beginners - Gebruik zo min mogelijk rechten - Begin met get / list - Gebruik namespaces Voor experts - Audit RBAC regelmatig - Gebruik tooling voor RBAC-visualisatie - Combineer RBAC met: - NetworkPolicies - PodSecurity - Admission controllers --- 9. Veelgemaakte Valkuilen - ClusterRoleBinding voor applicaties - Wildcards () in verbs/resources - Rechten stapelen zonder overzicht - Geen documentatie van intentie --- 10. Samenvatting Beginner - RBAC bepaalt wie wat mag - Rollen + bindings = toegang Expert - RBAC is een additief autorisatiemodel - Ontwerp voor least privilege - RBAC is Ã©Ã©n laag in defense-in-depth"
  },
  {
    "title": "MCP Interface",
    "category": "runtime",
    "path": "runtime/mcp_interface.md",
    "content": "MCP Server Inleiding Een MCP Server (Model Context Protocol Server) is een runtime-component die fungeert als brug tussen een AIâ€‘model en externe systemen, data en tools. De MCP Server stelt een AI-model in staat om gestructureerde context op te vragen, acties uit te voeren en resultaten terug te geven, op een gecontroleerde en reproduceerbare manier. Dit document is gelaagd opgebouwd: - ğŸ”° Beginners begrijpen wat een MCP Server is en waarom je hem gebruikt - ğŸ§  Experts krijgen inzicht in architectuur, controlâ€‘loops, security en extensiepatronen Binnen dit document worden Mermaid-diagrammen gebruikt om de werking visueel te maken. --- 1. Wat is een MCP Server? (Beginner) Een MCP Server is: > Een tussenlaag die een AIâ€‘model laat samenwerken met de echte wereld > (zoals APIâ€™s, bestanden, databases of systemen) Zonder MCP: - Een AI kan alleen tekst genereren - Geen directe toegang tot data of acties Met MCP: - Een AI kan tools gebruiken - Context ophalen - Acties uitvoeren - Resultaten interpreteren --- 2. Hoog Overzicht (Beginner) mermaid flowchart LR User --> LLM[AI Model] LLM --> MCP[MCP Server] MCP --> Tool1[API / Tool] MCP --> Tool2[Database] MCP --> Tool3[Filesystem] De MCP Server: - Ontvangt verzoeken van het model - Roept tools aan - Geeft gestructureerde antwoorden terug --- 3. Kernverantwoordelijkheden van een MCP Server Voor beginners - Context ophalen - Acties uitvoeren - Antwoorden structureren Voor experts - Capability exposure - Input/output validatie - Security enforcement - Observability - Deterministische uitvoering --- 4. Conceptuele Bouwblokken Overzicht mermaid flowchart TD Request --> Router Router --> ToolRegistry ToolRegistry --> Executor Executor --> Tool Tool --> Executor Executor --> Response Componenten 1. Request Handler - Ontvangt MCPâ€‘verzoeken - Valideert structuur en intentie 2. Router - Bepaalt welke tool nodig is - Matcht intentie â†’ capability 3. Tool Registry - Catalogus van beschikbare tools - Metadata: naam, schema, permissies 4. Executor - Voert tool-aanroepen uit - Beheert timeouts, retries en fouten 5. Response Formatter - Zet resultaten om naar MCPâ€‘compatibel formaat --- 5. Tool Interactie Model mermaid sequenceDiagram participant Model participant MCP participant Tool Model->>MCP: Tool request MCP->>Tool: Execute action Tool-->>MCP: Result / Error MCP-->>Model: Structured response Belangrijk: - De MCP Server vertaalt intentie naar actie - Het model voert zelf geen side effects uit --- 6. MCP als Control Loop (Expert) Net als Kubernetes werkt MCP als een control loop: mermaid flowchart LR Intent[Model Intent] --> Validate Validate --> Execute Execute --> Observe Observe --> Adjust Adjust --> Validate Eigenschappen: - Deterministisch - Herhaalbaar - Observeerbaar - Veilig afgebakend --- 7. Security Model (Expert) Principes - Least privilege - Explicit allow - Geen implicit trust Mechanismen - Toolâ€‘level permissions - Input schema validatie - Output filtering - Rate limiting - Audit logging mermaid flowchart TD Model -->|Request| MCP MCP -->|Allowed| Tool MCP -->|Denied| Reject --- 8. Foutafhandeling & Betrouwbaarheid Typische fouten - Ongeldige input - Timeouts - Tool failures - Partial responses MCP-verantwoordelijkheid - Fouten isoleren - Duidelijk terugrapporteren - Geen ongedefinieerd gedrag --- 9. Best Practices Voor beginners - Begin met readâ€‘only tools - Houd tools klein en eenduidig - Log alles Voor experts - Idempotente tools - Scheiding tussen intent & uitvoering - Contractâ€‘first schemas - Observability per tool - Simuleer falen --- 10. Veelgemaakte Valkuilen - Te brede tools - Businesslogica in het model - Geen validatie - Onbegrensde toolâ€‘toegang - Geen auditing --- 11. Samenvatting Beginner - MCP laat AI samenwerken met systemen - De server voert acties uit, niet het model Expert - MCP is een gecontroleerde executionâ€‘laag - Ontwerp voor determinisme, veiligheid en herhaalbaarheid - Zie MCP als een runtime, niet als een script"
  },
  {
    "title": "Dynamic Slot",
    "category": "runtime",
    "path": "runtime/dynamic_slot.md",
    "content": "Dynamic Slot - Het deployen van applicaties Inleiding Dit document beschrijft hoe een applicatie wordt gedeployed, via het web bereikbaar wordt gemaakt en hoe omgegaan wordt met test- en productieomgevingen. Het document is gelaagd opgebouwd: - ğŸ”° Beginners leren het end-to-end pad van code â†’ webpagina - ğŸ§  Experts krijgen inzicht in omgevingsscheiding, deploymentstrategieÃ«n en releasebeheer Mermaid-diagrammen worden gebruikt om de werking visueel te maken. --- 1. Wat betekent â€œeen applicatie deployenâ€? (Beginner) Een applicatie deployen betekent: > Je code beschikbaar maken zodat gebruikers deze via het web kunnen gebruiken. In Kubernetes houdt dit in: 1. Je applicatie draait in een container 2. Kubernetes start en bewaakt deze container 3. Verkeer van buiten wordt veilig naar de applicatie geleid --- 2. Van Code tot Container Stap 1 â€“ Applicatiecode - Backend (bijv. API) - Frontend (bijv. webapp) - Of een combinatie Stap 2 â€“ Container Image De code wordt verpakt in een container image. mermaid flowchart LR Code --> Build[Build Image] Build --> Image[Container Image] Het image bevat: - De applicatie - Runtime (bijv. Node, Python, Java) - Configuratie defaults --- 3. Applicatie in Kubernetes (Beginner) Deployment Een Deployment beschrijft: - Welke image moet draaien - Hoeveel replicas - Hoe updates verlopen mermaid flowchart TD Deployment --> Pod1 Deployment --> Pod2 Kubernetes zorgt voor: - Starten van pods - Herstarten bij fouten - Rolling updates --- 4. Applicatie Bereikbaar via het Web Service (intern) Een Service: - Geeft een vast adres (DNS/IP) - Verdeelt verkeer over pods mermaid flowchart LR Service --> PodA Service --> PodB Gebruikt binnen het cluster. --- Ingress (extern â€“ webtoegang) Een Ingress: - Maakt de applicatie bereikbaar via HTTP/HTTPS - Regelt routing op domeinnaam en pad mermaid flowchart LR Browser --> Ingress Ingress --> Service Voorbeeld: - https://app.example.nl - https://api.example.nl --- 5. Test en Productie Omgevingen (Beginner) Waarom scheiden? - Fouten in test mogen geen impact hebben op productie - Nieuwe versies eerst veilig uitproberen Meest gebruikte aanpak: namespaces mermaid flowchart LR Dev[Namespace: test] Prod[Namespace: productie] Elke omgeving heeft: - Eigen pods - Eigen services - Eigen configuratie --- 6. Deployment Flow met Test â†’ Productie mermaid flowchart TD Commit --> Build Build --> DeployTest[Test omgeving] DeployTest --> TestOK{Tests OK?} TestOK -->|Ja| DeployProd[Productie] TestOK -->|Nee| Fix --- 7. Configuratie per Omgeving (Expert) ConfigMaps & Secrets - ConfigMap: niet-gevoelige configuratie - Secret: wachtwoorden, tokens, certificaten mermaid flowchart LR Config --> Pod Secret --> Pod Per omgeving verschillend: - Database URL - API keys - Feature flags --- 8. Updates en Releases (Expert) Rolling Updates - Pods worden Ã©Ã©n voor Ã©Ã©n vervangen - Geen downtime Blue/Green of Canary - Nieuwe versie eerst beperkt beschikbaar - Terugrollen is eenvoudig mermaid stateDiagram-v2 v1 --> v2 v2 --> v1 : rollback --- 9. Beveiliging en Toegang (Expert) - HTTPS via Ingress - RBAC voor deployment-rechten - NetworkPolicies tussen applicaties - Secrets nooit in images --- 10. Veelgemaakte Valkuilen - Geen omgevingsscheiding - Handmatig deployen in productie - Configuratie in code - Geen health checks - Geen rollback-strategie --- 11. Samenvatting Beginner - Code â†’ container â†’ Kubernetes â†’ web - Kubernetes regelt starten en herstellen - Ingress maakt de app bereikbaar Expert - Omgevingen zijn strikt gescheiden - Releases zijn gecontroleerd en terug te draaien - Configuratie en security zijn first-class citizens"
  },
  {
    "title": "Git",
    "category": "runtime",
    "path": "runtime/git.md",
    "content": "Git & Kubernetes Inleiding Dit document legt uit hoe je Git gebruikt om applicaties beheerst naar productie te brengen in een Kubernetes-omgeving. We bouwen op van basisprincipes (beginners) naar een volwassen GitOps-aanpak (experts), inclusief Mermaid-diagrammen. Doel: een herhaalbare, auditeerbare en veilige route van code â†’ test â†’ productie. --- 1. Wat is Git? (Beginner) Git is een versiebeheersysteem: het bewaart de geschiedenis van je bestanden. Git helpt je om: - Wijzigingen te volgen (wie, wat, wanneer, waarom) - Samen te werken (branches, pull requests) - Reproducible releases te maken (tags, releases) - Terug te rollen naar een werkende versie Begrippen (kort) - Repository: map met code + geschiedenis - Commit: opgeslagen wijziging - Branch: parallelle lijn (bijv. feature/x, main) - Pull Request (PR): voorstel om wijzigingen te mergen - Tag: â€œlabelâ€ op een commit, vaak voor releases (bijv. v1.2.0) --- 2. Van Git naar Kubernetes: twee paden Je kunt Kubernetes op twee manieren â€œvoedenâ€ vanuit Git: 1. CI/CD push model (klassiek) - Pipeline pusht manifests naar cluster (kubectl apply) 2. GitOps pull model (aanbevolen) - Cluster pullt desired state uit Git en reconcilieert continu mermaid flowchart LR Git[Git Repo] -->|CI/CD push| ClusterA[(Kubernetes)] Git -->|GitOps pull| Controller[GitOps Controller] Controller --> ClusterB[(Kubernetes)] --- 3. Basisflow: Code â†’ Image â†’ Deploy (Beginner) Stap-voor-stap 1. Developer commit code naar Git 2. Pipeline bouwt een container image 3. Image wordt opgeslagen in een registry 4. Kubernetes krijgt nieuwe desired state (manifests/Helm) mermaid flowchart TD Dev[Developer] -->|git commit| Git[(Git Repo)] Git -->|CI build| Build[Build & Test] Build -->|docker build| Image[Container Image] Image --> Registry[(Image Registry)] Build --> Deploy[Update Kubernetes manifests] Deploy --> Cluster[(Kubernetes Cluster)] --- 4. Repo-structuur voor Kubernetes (Beginner â†’ Intermediate) Veel teams gebruiken 2 repos: A) App repo (code) Bevat: - applicatiecode - Dockerfile - tests - pipeline config B) Config repo (deployments) Bevat: - Kubernetes manifests / Helm / Kustomize overlays - omgevingsconfig (test/prod) - policies (optioneel) mermaid flowchart LR AppRepo[App repo<br/>code + Dockerfile] --> Image ConfigRepo[Config repo<br/>manifests + env overlays] --> Desired[Desired State] Waarom 2 repos? - App teams kunnen code releasen zonder productieconfig te overschrijven - Platform/security kan config-review afdwingen --- 5. Test vs Productie: omgevingen beheren Populaire keuzes - Namespaces: test en prod in hetzelfde cluster - Clusters: apart testcluster en prodcluster (sterker, duurder) Voorbeeld met namespaces: mermaid flowchart LR Git --> TestNS[Namespace: test] Git --> ProdNS[Namespace: prod] Belangrijk - Test en prod hebben andere configuratie (URLs, feature flags, secrets) - Je promoot changes gecontroleerd: eerst test, dan prod --- 6. GitOps (Recommended) â€“ Hoe werkt dat? Wat is GitOps? GitOps is een werkwijze waarbij: > Git de enige bron van waarheid is voor wat er in Kubernetes draait. Een GitOps controller (bijv. Argo CD / Flux) draait in het cluster en: - leest de gewenste state uit Git - vergelijkt dit met de echte state - voert reconciliatie uit (apply/rollback) mermaid flowchart TD Git[(Git: desired state)] --> Poll[GitOps Controller<br/>poll/webhook] Poll --> Diff{Diff?} Diff -->|Ja| Apply[Apply/Sync] Diff -->|Nee| Sleep[Wacht] Apply --> Cluster[(Kubernetes)] Cluster --> Observe[Observe state] Observe --> Diff Waarom is dit sterk? - Audit trail in Git - Rollback = revert commit - Drift-detectie (handmatige wijzigingen vallen op) - Declaratief + reproduceerbaar --- 7. Releasebeheer: â€œbeheerst naar productieâ€ (Beginner â†’ Expert) Simpele promotie (beginner) - PR naar main triggert deploy naar test - Handmatige â€œpromoteâ€ PR triggert deploy naar productie mermaid flowchart TD Feature[feature branch] --> PR1[PR naar main] PR1 --> Test[Deploy naar test] Test --> Gate{Tests OK?} Gate -->|Ja| PR2[Promote PR<br/>naar prod overlay] PR2 --> Prod[Deploy naar productie] Gate -->|Nee| Fix[Fix + nieuwe commit] Volwassen promotie (expert) - Immutable versioning: image tags zijn versies (bijv. v1.3.7), nooit latest - Environment overlays: Kustomize/Helm values per omgeving - Approval gates: security/ops approvals voor prod - Progressive delivery: canary/blue-green met metriek-gates - Automated rollback bij SLO breach --- 8. Concreet voorbeeld: overlays met Kustomize (Intermediate) Repo-structuur (voorbeeld): text config-repo/ base/ deployment.yaml service.yaml ingress.yaml kustomization.yaml overlays/ test/ kustomization.yaml values.yaml (optioneel) prod/ kustomization.yaml values.yaml (optioneel) Conceptueel: mermaid flowchart LR Base[base manifests] --> TestOverlay[test overlay] Base --> ProdOverlay[prod overlay] TestOverlay --> TestCluster[(K8s test)] ProdOverlay --> ProdCluster[(K8s prod)] Promotie = dezelfde base + andere overlay met nieuwe image tag. --- 9. Security & Governance"
  },
  {
    "title": "Overview",
    "category": "compliance",
    "path": "compliance/overview.md",
    "content": "Compliance Overview De Compliance Layer is verantwoordelijk voor het waarborgen van veiligheid, privacy en regelgeving binnen het gehele Druppie-ecosysteem. Het werkt volgens het principe van \"Continuous Compliance\" en maakt zwaar gebruik van native Azure governance features. ğŸ“œ Doelstellingen - Security by Design: Beveiliging is ingebakken in de 'Agent Factory' pipeline. - Auditeerbaarheid: Elke actie van een agent is traceerbaar tot een unieke identiteit. - Automatic Enforcement: Regels worden automatisch afgedwongen via Azure Policy. ğŸ§© Onderdelen - IAM (Identity & Access Management) - Entra Agent ID: Unieke identiteiten voor agents (geen gedeelde service accounts). - Managed Identity: Wachtwoordloze authenticatie tussen services. - RBAC: Fijnmazige rolverdeling op Foundy projecten en resources. - BIO & NIS2 Framework - Concrete invulling van de Baseline Informatiebeveiliging Overheid en EU NIS2 richtlijn. - Mapping van controls op Druppie technologie en processen. - Governance & Policy - Azure Policy: Dwingt regels af op infrastructuur niveau (bijv. \"Alleen GPT-4o in West Europe\", \"Verplicht Private Link\"). - Policy Engine (zie Bouwblokken): Dwingt regels af op applicatie niveau (functionele checks). - Data Protection - Private Endpoints: Verkeer blijft binnen het Azure backbone netwerk. - Data Exfiltration Control: Agents kunnen alleen communiceren met gewhiteliste domeinen. - Security Scanners (onderdeel van Foundry) - Automatische scans in de CI/CD pipeline. ğŸ”— Gerelateerde Ontwerpen Continuous Compliance & Lifecycle: De implementatie van compliance over de tijd. Goed Bestuur: De bestuurlijke principes vertaald naar techniek. AI Register: De specifieke vereisten voor AI transparantie."
  },
  {
    "title": "Goed Bestuur (Code)",
    "category": "compliance",
    "path": "compliance/good_governance.md",
    "content": "Goed Bestuur (Code Goed Openbaar Bestuur) ğŸ“˜ Context en Kader De Code Goed Openbaar Bestuur bevat de kernwaarden en gedragsnormen voor de Nederlandse overheid. Voor waterschappen, als functionele democratie, is het naleven van deze principes cruciaal voor het behoud van vertrouwen. In een tijd waarin besluitvorming steeds meer digitaliseert en AI-gedreven wordt, moeten deze 'analoge' principes vertaald worden naar digitale waarborgen. --- ğŸ›ï¸ De Principes & Implementatie in Druppie Hieronder vertalen we de algemene beginselen van behoorlijk bestuur naar technische requirements voor het Druppie platform. 1. Openheid en Transparantie Het Principe: Het bestuur handelt open en inzichtelijk. Burgers moeten kunnen begrijpen hoe besluiten tot stand komen. Vertaalslag naar AI: Geen \"Black Box\" besluitvorming. Implementatie: AI Register: Publiceer actief welke algoritmes worden gebruikt (zie AI Register). XAI (Explainable AI): Gebruik modellen die uitlegbaar zijn of voeg een uitleg-module toe. Open Source: Waar mogelijk wordt broncode van niet-gevoelige onderdelen (bv. rekenmodellen) openbaar gemaakt in Gitea/GitHub Public. 2. Verantwoording (Accountability) Het Principe: Het bestuur moet zich achteraf kunnen verantwoorden voor gemaakte keuzes en resultaten. Vertaalslag naar AI: Traceerbaarheid van elke handeling. Implementatie: Traceability DB: Onwijzigbare opslag van wie (mens of AI), wanneer en waarom een actie heeft uitgevoerd. GitOps: Elke wijziging in infrastructuur of data is een commit met een auteur. Audit Trail: Zorg dat logs minimaal 7 jaar bewaard blijven (conform Archiefwet) in 'Cold Storage'. 3. Integriteit Het Principe: Bestuurders en ambtenaren handelen integer, onpartijdig en zonder belangenverstrengeling. Vertaalslag naar AI: Voorkomen van bias (vooroordelen) in data en modellen. Implementatie: Dataset Screening (DVC): De Policy Engine vereist een check op representativiteit van data om discriminatie te voorkomen (bijv. in handhaving of vergunningverlening). IAM (Identity & Access Policy): Strikte scheiding van rechten. Datascientists mogen niet zomaar bij productie-data waar persoonsgegevens in staan (Privacy-by-Design). 4. Doelmatigheid en Doeltreffendheid Het Principe: Middelen (belastinggeld) moeten efficiÃ«nt worden ingezet en doelen moeten daadwerkelijk bereikt worden. Vertaalslag naar AI: Voorkom verspilling van dure cloud-resources en \"hobby-projecten\" die geen waarde toevoegen. Implementatie: Spec-Driven Design: De Builder Agent dwingt af dat er eerst een doel (spec) is voordat er gebouwd wordt. FinOps: Monitoring van resource-gebruik (via Prometheus/Grafana) en automatische downscaling van ongebruikte pods (KEDA). Hergebruik: Het \"Bouwblokken\" principe voorkomt dat elk team zijn eigen database-oplossing gaat bouwen. 5. Participatie Het Principe: Burgers en belanghebbenden worden betrokken bij besluitvorming. Vertaalslag naar AI: Digitale toegankelijkheid. Implementatie: GeoNode Portal: Maak data en kaarten toegankelijk voor ingelanden, zodat zij zienswijzen kunnen indienen op basis van dezelfde informatie als het waterschap. --- ğŸ›¡ï¸ Borging in de Architectuur Goed bestuur is geen 'sausje', maar zit ingebakken in de code: Als een model niet uitlegbaar is, mag het niet in productie. Als data niet herleidbaar is, faalt de build pipeline. Als de kosten de baten overstijgen, signaleert het systeem dit aan de controller. Door deze principes te codificeren (Policy-as-Code), garandeert Druppie dat innovatie hand in hand gaat met betrouwbaar overheidshandelen."
  },
  {
    "title": "BIO & NIS2",
    "category": "compliance",
    "path": "compliance/bio_nis2.md",
    "content": "BIO & NIS2 Compliance Strategie Druppie is ontworpen om te voldoen aan strikte overheids- en EU-regelgeving. Dit document beschrijft hoe de architectuur concrete invulling geeft aan de Baseline Informatiebeveiliging Overheid (BIO) en de Network and Information Security Directive (NIS2). ğŸ‡ªğŸ‡º NIS2 (Network and Information Security Directive) De NIS2-richtlijn legt zwaardere eisen op het gebied van cybersecurity, met een focus op zorgplicht, meldplicht en ketenbeveiliging. 1. Zorgplicht (Duty of Care) Organisaties moeten passende maatregelen nemen om risico's te beheersen. Druppie vult dit in via: - Security by Design: De Foundry pipeline blokkeert onveilige code vÃ³Ã³r deployment. - Zero Trust: Gebruik van Entra Agent ID en Private Endpoints zorgt dat geen enkele component elkaar blind vertrouwt. - Continuous Monitoring: De Compliance Layer voert dagelijkse geautomatiseerde checks uit. 2. Meldplicht (Incident Reporting) Bij een incident moet binnen 24 uur gemeld worden. - Traceability DB: Alle acties (prompts, wijzigingen, toegang) worden onveranderlijk vastgelegd. Dit maakt directe reconstructie van een incident mogelijk (\"Wie deed wat en wanneer?\"). - Automated Alerting: De Policy Engine detecteert afwijkingen (anomalies) en kan direct de CISO notificeren. 3. Supply Chain Security Beveiliging van de toeleveringsketen is cruciaal. - Spec-Driven Agents: Omdat agents \"as-code\" gedefinieerd zijn, is exact bekend welke modellen en tools gebruikt worden. Geen \"Shadow AI\". - SBOM (Software Bill of Materials): Foundry genereert bij elke build een SBOM, zodat kwetsbaarheden in libraries (bijv. Log4j) direct geÃ¯dentificeerd kunnen worden. --- ğŸ‡³ğŸ‡± BIO (Baseline Informatiebeveiliging Overheid) De BIO is gebaseerd op ISO 27001/27002 en geldt voor de gehele overheid. Basisbeveiligingsniveaus (BBN) Druppie ondersteunt differentiatie naar BBN-niveau via de Policy Engine. | BIO Concept | Druppie Implementatie | | :--- | :--- | | Identificatie & Authenticatie | Alle agents en gebruikers authenticeren via Entra ID. MFA is verplicht voor beheerders. | | Autorisatie | RBAC op basis van 'Least Privilege'. Een agent krijgt nooit meer rechten dan nodig voor zijn taak (scoped access). | | Logging & Controle | De Traceability DB voldoet aan de eisen voor onweerlegbaarheid en bewaring. Logfiles zijn niet aanpasbaar (WORM storage). | | Cryptografie | Alle data-in-transit (TLS 1.3) en data-at-rest (Azure Storage Encryption) is versleuteld. | | Kwetsbaarhedenbeheer | Geautomatiseerde patch-management voor de container runtime en AI-modellen (via Microsoft managed updates). | BIO Mapping Tabel (Voorbeelden) - Control 9.1.1 (Toegangsbeleid): GeÃ¯mplementeerd via IAM policy rules. - Control 12.4.1 (Logging): GeÃ¯mplementeerd via Traceability DB. - Control 14.2.1 (Veilig ontwikkelen): GeÃ¯mplementeerd via Foundry pipelines met SAST/DAST. --- ğŸ›¡ï¸ Praktische Uitvoering Wanneer een nieuwe Agent wordt gedeployed, valideert de Pipeline automatisch: 1. Is de data-classificatie (BBN1/2/3) bekend? 2. Voldoet de gekozen infrastructuur aan de eisen voor dat niveau? Voorbeeld: BBN2 mag data verwerken in EU, BBN3 vereist wellicht specifieke NL-only hosting of sleutelbeheer (BYOK). 3. Zijn de logging-instellingen correct geconfigureerd? Indien niet compliant, blokkeert de Policy Engine de deployment."
  },
  {
    "title": "Data Act",
    "category": "compliance",
    "path": "compliance/data_act.md",
    "content": "De Data Act (Dataverordening) ğŸ“œ Wetgevend Kader Europese Unie: Regulation (EU) 2023/2854 (Data Act) Nederland: Uitvoeringswetgeving Dataverordening (in ontwikkeling/consultatie) De Data Act is een pijler van de Europese datastrategie en heeft als doel data die gegenereerd wordt door verbonden apparaten (IoT) eerlijk beschikbaar te maken. Het doorbreekt \"vendor lock-in\" en geeft gebruikers controle over hun eigen data. --- ğŸ¤– Betekenis voor AI in Druppie Voor een AI-agent (\"Builder\" of \"Policy Engine\") is deze wet te vertalen naar concrete ontwerpregels (Constraints & Requirements). 1. Recht op Toegang en Delen (Artikel 3-6) De Regel: Data gegenereerd door producten (bijv. drones, sensoren in dijken) moet standaard toegankelijk zijn voor de gebruiker, zonder vertraging en gratis. AI Instructie: > \"Als ik een systeem ontwerp dat data verzamelt, MOET ik een API of export-functie (zoals S3/MinIO) implementeren waarmee de eigenaar real-time bij zijn ruwe data kan.\" Druppie Implementatie: MinIO: Ruwe dronebeelden zijn direct toegankelijk. Kong Gateway: Data APIs zijn gestandaardiseerd en gedocumenteerd. GeoNode: Metadata is doorzoekbaar. 2. Interoperabiliteit (Artikel 28-29) De Regel: Cloud- en dataverwerkingsdiensten moeten standaarden volgen zodat data makkelijk overdraagbaar is naar andere providers. AI Instructie: > \"Gebruik GEEN proprietary formaten als er een open standaard bestaat. Verkies OGC standaarden (WFS, WMS) en open formaten (GeoTIFF, Parquet) boven gesloten vendor formaten.\" Druppie Implementatie: PostGIS/GeoServer: Gebruik van open OGC standaarden. RKE2: Standaard Kubernetes, geen vendor-specifieke PaaS lock-in. 3. Switchability (Artikel 23-26) De Regel: Het moet voor klanten mogelijk zijn om binnen 30 dagen te switchen van cloud provider. AI Instructie: > \"Zorg dat alle Infrastructure-as-Code (Terraform/Crossplane) leveranciersonafhankelijk is, of bouw abstractielagen waardoor de onderliggende infra vervangbaar is.\" --- âœ… Checklist voor de Policy Engine De Policy Engine (OPA) kan de volgende regels controleren bij elk nieuw ontwerp: 1. [ ] Data Export Check: Heeft de applicatie een mechanisme om data te exporteren? 2. [ ] Standard Format Check: Wordt data opgeslagen in een formaat dat op de 'Druppie Open Standaarden Lijst' staat? 3. [ ] API First: Is de data ook machinaal leesbaar via een API, niet alleen via een UI?"
  },
  {
    "title": "AI Act (EU & UvW)",
    "category": "compliance",
    "path": "compliance/ai_act.md",
    "content": "De AI Act & Implementatie Waterschappen ğŸ“œ Wetgevend & Sector Kader Europese Unie: Regulation (EU) 2024/1689 (Artificial Intelligence Act) Nederland: Uitvoeringswet AI-verordening (Toezichthouder: AP / RDI) Sector: Unie van Waterschappen (UvW) Implementatiehandleiding De AI Act is 's werelds eerste alomvattende AI-wetgeving met een risico-gebaseerde aanpak. Voor waterschappen is dit extra relevant omdat zij beheerders zijn van kritieke infrastructuur (dijken, zuiveringen, gemalen). De UvW heeft specifieke handreikingen opgesteld om de abstracte wet te vertalen naar de watersector. --- ğŸ¤– Risico Classificatie (De Piramide) De wet onderscheidt risiconiveaus. De UvW benadrukt de specifieke context voor waterschappen hierin: 1. Onaanvaardbaar Risico (Verboden) Wet: Social Scoring, Real-time biometrische identificatie in openbare ruimte (door politie), manipulatie van gedrag. Actie: BLOKKEREN. De Policy Engine mag dit nooit goedkeuren. 2. Hoog Risico (Strenge Eisen) Dit is de focus voor Druppie Core. Wet: AI in kritieke infrastructuur, HR-selectie, Kredietwaardigheid. Waterschap Context (UvW): AI die veiligheidscomponenten van waterkeringen of sluizen aanstuurt. AI die beslissingen neemt over waterpeilbeheer (risico op overstroming/droogte). Actie: Vereist Conformiteitsbeoordeling, Human Oversight, Hoogwaardige DataSets, en Logging. 3. Beperkt Risico (Transparantie) Wet: Chatbots (zoals de Druppie Copilot), Deepfakes/GenAI. Actie: Transparantieplicht. De gebruiker moet weten dat hij met een AI praat. (\"Ik ben Druppie, een AI-assistent\"). 4. Minimaal Risico Voorbeelden: Spamfilters, Muskusrat-tellingen (zonder automatische actie). --- ğŸŒŠ De AI Impact Assessment (AIIA) De UvW schrijft voor om vÃ³Ã³r de start van elk AI-project een AIIA uit te voeren. Dit gaat verder dan een DPIA. 1. Doelbinding: Is het maatschappelijk verantwoord? 2. Dataset Representativiteit: Cruciaal voor water: Is het model getraind op data van zowel extreme 'natte' als 'droge' jaren (bijv. 2018)? Bias: Voorkom dat het model alleen werkt voor scenario's uit het verleden die door klimaatverandering niet meer representatief zijn. 3. Uitlegbaarheid (XAI): Kan een hydroloog begrijpen waarom het model voorstelt de stuw te sluiten? \"Black box\" modellen zijn ongewenst voor kritieke processen. --- ğŸ› ï¸ Implementatie in Druppie Hoe borgen we de wet en de UvW richtlijnen in het platform? Stap 1: Intake & Classificatie (Policy Engine) Wanneer een gebruiker een nieuw project start, activeert de Policy Engine de UvW Template. Check: \"Raakt dit systeem de veiligheid van waterkeringen?\" Ja -> Markeer als Hoog Risico. Activeer \"Four-Eyes Principle\" (Menselijke goedkeuring vereist). Stap 2: Data Validatie & Versiebeheer (DVC) Om te voldoen aan de eis voor \"Hoogwaardige Datasets\": DVC (Data Versioning): Garandeert dat we altijd kunnen bewijzen op welke dataset is getraind. Automated Checks: De Builder Agent kan controleren of de dataset voldoende spreiding heeft (seizoenen, extremen). Stap 3: Traceability & Logging (Juridisch Bewijs) Eis: Automatische logging van events gedurende de levenscyclus (Artikel 12). Oplossing: De Traceability DB (Tempo/Loki). Elke stap van \"Input Foto\" tot \"Beslissing: Schade\" wordt onwijzigbaar vastgelegd. Dit is cruciaal voor de bestuurlijke verantwoording. Stap 4: Menselijk Toezicht (Human-in-the-Loop) Eis: Een mens moet kunnen ingrijpen (Artikel 14). Oplossing: Voor autonome systemen (gemalen/sluizen) bouwen we altijd een Kill Switch. De operator kan de AI overrulen via het SCADA dashboard. Stap 5: Continuous Monitoring (Model Drift) Een model veroudert. Grafana: Monitor Model Drift. \"Wijkt de voorspelling steeds vaker af van de peilbuis-meting?\" Policy: Verplicht jaarlijkse herijking/hertraining. --- âœ… Checklist voor de Architect / Policy Engine 1. [ ] Risk Assessment: Is de UvW risico-classificatie uitgevoerd? 2. [ ] Human-in-the-Loop: Is er voor Hoog Risico systemen een menselijke goedkeuringsstap (of noodstop) ingebouwd? 3. [ ] Data Quality: Is de dataset representatief voor (toekomstige) klimaattoestanden? 4. [ ] Audit Trail: Worden alle inputs/outputs gelogd in de Traceability DB? 5. [ ] Transparency: Maakt de interface duidelijk dat het een AI is?"
  },
  {
    "title": "AI Register (Algoritmeregister)",
    "category": "compliance",
    "path": "compliance/ai_register.md",
    "content": "Het AI Register (Algoritmeregister) ğŸ“˜ Wat is het AI Register? Overheidsorganisaties, waaronder waterschappen, zijn verplicht transparant te zijn over de inzet van algoritmes en AI. Dit is verankerd in de AI Act (Artikel 60: EU Database voor Hoog Risico AI) en de Nederlandse richtlijn voor het Algoritmeregister (algoritmeregister.overheid.nl). Het register fungeert als de \"publieke bijsluiter\" van een AI-systeem. Het stelt burgers, journalisten en toezichthouders in staat om te controleren welke systemen impact hebben op hun leven of leefomgeving. --- ğŸ“‹ Wat staat er in? (Het Schema) Het register bevat niet de broncode, maar wel de metadata die de werking en risico's beschrijven. Binnen Druppie baseren we dit op de 'Standaard voor Algoritme-beschrijvingen'. Kerngegevens 1. Naam & Eigenaar: Wie is verantwoordelijk? (bijv. \"Waterschap X, afdeling Waterkeringen\"). 2. Doel: Waarom is dit systeem gebouwd? (bijv. \"Vroegtijdig detecteren van graverij door muskusratten om dijkdoorbraak te voorkomen\"). 3. Werking: Hoe werkt het technisch? (bijv. \"Computer Vision model getraind op dronebeelden\"). Risico & Impact 4. Risicoclassificatie: Volgens de AI Act (Laag/Hoog/Verboden). 5. Impact: Wat is het gevolg van een fout? (bijv. \"Onterechte inzet van muskusrattenbestrijder\" of \"Gemiste kadebreuk\"). 6. Juridische Grondslag: Op basis van welke wettaak handelen we? (Waterwet). Data & Toezicht 7. Data: Op welke data is het getraind? (Verwijzing naar DVC dataset versie). 8. Menselijk Toezicht: Hoe is de Human-in-the-Loop geregeld? (bijv. \"Bestrijder valideert elke detectie vÃ²Ã²r actie\"). --- ğŸ› ï¸ Hoe te vullen? (Automated Governance) In traditionele organisaties is het register vaak een verouderde Excel-sheet. In Druppie is het registeren geautomatiseerd en verplicht. Stap 1: 'Register-as-Code' Bij elk project hoort een algorithm.yaml bestand in de Git repository. De Builder Agent genereert de eerste opzet op basis van de interactie met de gebruiker. Voorbeeld algorithm.yaml: yaml metadata: name: \"Muskusrat Detectie V2\" owner: \"Afd. Keringen\" status: \"In Productie\" legal: ground: \"Waterwet Art. 5.1\" risk_class: \"Hoog\" Critical Infra technical: model_type: \"YOLOv8\" training_data: \"dvc://datasets/drone-2025-v1\" human_oversight: role: \"Schadebeheerder\" method: \"Handmatige validatie via GeoNode\" Stap 2: Validatie door Policy Engine Tijdens de deployment (CI/CD) checkt de Policy Engine: [ ] Is algorithm.yaml aanwezig? [ ] Zijn alle verplichte velden ingevuld? [ ] Klopt de 'training_data' link met de werkelijke DVC hash? Zo niet -> Deployment Failed. Stap 3: Publicatie Bij een succesvolle release naar Productie, pusht de pipeline de metadata automatisch naar: 1. Het Interne Register (in Archi/GeoNode). 2. Het Publieke Register (via API koppeling met algoritmeregister.overheid.nl). --- ğŸš€ Hoe te gebruiken? 1. Voor de Burger: Via de website van het Waterschap kan men zoeken in het register. \"Welke AI wordt gebruikt in mijn polder?\" 2. Voor de Toezichthouder (AP): Bij een audit hoeven we niets handmatig op te zoeken. Het register is de \"Single Source of Truth\", direct gekoppeld aan de draaiende techniek. 3. Voor de Data Scientist: Ziet direct of zijn model correct geregistreerd staat en wie de 'Human-in-the-loop' is."
  },
  {
    "title": "IAM",
    "category": "compliance",
    "path": "compliance/iam.md",
    "content": "Identity & Access Management (IAM) voor AI ğŸ¯ Doelstelling In een AI-gedreven architectuur is Identity & Access Management (IAM) niet slechts een \"poortwachter\" voor gebruikers, maar een fundamenteel fundament voor veiligheid. Waar traditionele software deterministisch is, zijn AI-agents autonoom en onvoorspelbaar. Waarom is IAM cruciaal voor AI? 1. Autonomie beperken: Een AI-agent die zelfstandig taken uitvoert, moet een digitale identiteit hebben om afgerekend te kunnen worden op zijn daden (\"Wie deed dit?\"). 2. Data Exfiltratie voorkomen: Een agent mag nooit toegang hebben tot Ã¡lle data. Door strikte scoping (RBAC) voorkomen we dat een agent gevoelige HR-data lekt aan een gebruiker die daar geen recht op heeft. 3. Chain of Trust: In een keten van agents (Agent A roept Agent B aan) moet elke stap geauthenticeerd zijn (Zero Trust). --- ğŸ”‘ Kernconcepten in Druppie Druppie maakt gebruik van Microsoft Entra ID (voorheen Azure AD) als centrale identity provider. 1. Entra Agent ID (Machine Identity) Dit is een relatief nieuw concept. In plaats van generieke \"Service Accounts\" of \"API Keys\" die kunnen lekken, krijgt elke agent in Druppie (via de Foundry factory) een eigen Entra Agent ID. Cloud Native: Geen wachtwoorden om te roteren (Managed Identity). Traceerbaar: Elke logregel in de audit database verwijst naar deze unieke ID. Hardened: Kan niet inloggen interactief (behalve via specifieke OBO flows). 2. On-Behalf-Of (OBO) Flow Wanneer een gebruiker (bijv. \"Jan\") aan de Druppie Copilot vraagt om een bestand te lezen, mag de AI dit allÃ©Ã©n doen als Jan daar recht op heeft. Context Propagatie: Het token van Jan wordt doorgegeven aan de Agent. Security Trimming: De Agent \"ziet\" alleen wat Jan ook zou zien. Dit voorkomt dat de AI een \"backdoor\" wordt naar gevoelige data. --- ğŸ›¡ï¸ Beveiligingsmodel Zero Trust voor Agents Het principe \"Never trust, always verify\" geldt ook voor interne componenten. Agent-to-Agent Auth: Als de \"Router Agent\" de \"Finance Agent\" aanroept, controleert de Finance Agent het token van de Router. Just-in-Time Access: Rechten worden waar mogelijk tijdelijk verleend. Granulaire RBAC (Role Based Access Control) We definiÃ«ren specifieke rollen voor agents, niet voor computers. | Rol | Omschrijving | Voorbeeld | | :--- | :--- | :--- | | AI.Reader | Mag data indexeren voor RAG (alleen lezen). | Knowledge Bot | | AI.Builder | Mag nieuwe infrastructuur aanmaken. | Builder Agent | | AI.Executor | Mag namens gebruikers acties uitvoeren in ERP. | HR Agent | --- ğŸš€ Implementatie in de Architectuur 1. Creatie Wanneer een nieuwe agent wordt gedefinieerd in de Agent Factory, wordt automatisch: 1. Een User Managed Identity aangemaakt in Azure. 2. Deze identiteit gekoppeld aan de Agent Service. 3. Specifieke rechten (Scopes) toegekend op de doelsystemen (bijv. Storage Blob Data Reader op st-finance-data). 2. Runtime Tijdens uitvoering: 1. De Agent haalt een token op bij de lokale Identity Endpoint (binnen de container/service). 2. Dit token wordt als Authorization: Bearer <token> meegestuurd naar tools en API's. 3. De ontvangende API valideert het token tegen Entra ID. --- ğŸ”— Relaties Ondersteunt: Compliance Overview en BIO4 & NIS2. Wordt gebruikt door: Druppie UI (voor inloggen) en Foundry (voor provisioning)."
  },
  {
    "title": "Overview",
    "category": "mcp_catalog",
    "path": "mcp/overview.md",
    "content": "MCP Catalogus Overview ğŸ“š Wat is dit? De MCP Catalogus is een gecureerde lijst van Model Context Protocol (MCP) servers die beschikbaar en goedgekeurd zijn voor gebruik binnen het Druppie platform. ğŸ¯ Doel Het doel van deze catalogus is om ontwikkelaars en architecten snel inzicht te geven in welke integraties \"out-of-the-box\" beschikbaar zijn. Dit voorkomt dat we het wiel opnieuw uitvinden en zorgt voor standaardisatie. ğŸ—ï¸ CategorieÃ«n Microsoft & Azure MCP servers die specifiek zijn ontworpen voor het Microsoft ecosysteem. Use Case: Beheer van Azure resources, toegang tot Office 365 data, integratie met Copilot en Azure AI. Security: Maakt zwaar gebruik van Entra ID (Managed Identities) voor authenticatie. Open Source & Generiek Breed inzetbare, community-driven of standaard infrastructuur servers. Use Case: Database toegang (Postgres), Git operaties, bestandsmanipulatie, web browsing. Flexibiliteit: Vaak eenvoudig in te zetten als container zonder zware dependencies. ğŸ”„ Hoe een nieuwe MCP server toevoegen? 1. Selectie: Kies een server uit de officiÃ«le MCP lijst of ontwikkel een eigen MCP Host. 2. Validatie: Controleer of de server voldoet aan de security eisen (geen hardcoded secrets, containerized). 3. Registratie: Voeg de definitie toe aan een van de bovenstaande Markdown bestanden. 4. Deployment: Rol de server uit op het Kubernetes cluster."
  },
  {
    "title": "Microsoft & Azure",
    "category": "mcp_catalog",
    "path": "mcp/microsoft.md",
    "content": "Microsoft & Azure MCP Servers Deze lijst bevat MCP servers die integreren met het Microsoft ecosysteem, specifiek gericht op Azure en Office 365, geschikt voor gebruik binnen Druppie. â˜ï¸ Azure Beheer & DevOps 1. Azure Resource Manager (ARM) Beschrijving: Biedt toegang tot het lezen en beheren van Azure resources via de ARM API. Capabilities: resources, prompts Tools: list_resources, get_resource_metrics, restart_vm Bron/Repo: github.com/microsoft/mcp-azure-arm (Hypothetisch/Custom implementation) 2. Azure DevOps Beschrijving: Interactie met Azure Boards (work items) en Pipelines. Capabilities: tools Tools: get_work_item, create_bug, list_pipelines Status: In ontwikkeling voor Druppie. ğŸ¢ Productivity (M365) 3. Microsoft Graph Beschrijving: De gateway naar data in Microsoft 365 (Email, Calendar, Teams, SharePoint). Capabilities: resources, tools Tools: search_sharepoint, get_calendar_events, send_teams_message Security: Vereist specifieke Entra ID scopes (Files.Read, Calendars.Read). ğŸ§  AI & Data 4. Azure AI Search (Knowledge Base) Beschrijving: Verbindt de RAG (Retrieval Augmented Generation) kennisbank aan het model via MCP. Capabilities: resources (leest documenten als resources) Beschikbaarheid: GeÃ¯ntegreerd in het Knowledge Bot bouwblok. 5. Microsoft Copilot (M365) Agent Beschrijving: Stelt Druppie in staat om te praten met de bestaande Copilot agents binnen de tenant. Hierdoor kan Druppie vragen stellen aan Copilot (\"Wat is de samenvatting van deze meeting?\") of acties delegeren. Capabilities: prompts (handoff), tools (invoke agent) Integration: Gebruikt de Copilot Studio extensies framework."
  },
  {
    "title": "Open Source Tools",
    "category": "mcp_catalog",
    "path": "mcp/opensource.md",
    "content": "Open Source & Generieke MCP Servers Een verzameling van breed inzetbare, open-source MCP servers die direct als container (docker pull) ingezet kunnen worden binnen het Druppie cluster. ğŸ—„ï¸ Data & Storage 1. PostgreSQL (Database) Repo: github.com/modelcontextprotocol/servers/tree/main/src/postgres Beschrijving: Geeft de AI veilige, read-only (of gecontroleerde write) toegang tot databases. Tools: query_database, get_schema Gebruik in Druppie: Zie Database Bouwblok. 2. FileSystem (Lokaal/Shared) Repo: github.com/modelcontextprotocol/servers/tree/main/src/filesystem Beschrijving: Toegang tot specifieke mappen op een Persistent Volume. Handig voor het lezen van logs of rapporten. Configuratie: Draait als sidecar of met een shared volume mount. 3. SQLite Repo: github.com/modelcontextprotocol/servers/tree/main/src/sqlite Beschrijving: Lichtgewicht database toegang, ideaal voor tijdelijke analyse agents. ğŸ› ï¸ Development Tools 4. Git Repo: github.com/modelcontextprotocol/servers/tree/main/src/git Beschrijving: Stelt de AI in staat om code te lezen, diffs te maken en branches te beheren. Integratie: Werkt samen met onze Gitea instantie. 5. GitHub / GitLab Repo: github.com/modelcontextprotocol/servers/tree/main/src/github Beschrijving: Beheer van Issues, PRs en Releases. Tools: create_issue, merge_pr, search_code ğŸŒ Web & Search 6. Puppeteer / Playwright (Web Browser) Repo: github.com/modelcontextprotocol/servers (community) Beschrijving: Stelt de AI in staat om websites te bezoeken, screenshots te maken en content te scrapen (bijv. voor onderzoek). Security: Draait altijd in een geÃ¯soleerde, tijdelijke container (\"Sandbox\"). 7. Brave Search Repo: github.com/modelcontextprotocol/servers/tree/main/src/brave-search Beschrijving: Uitvoeren van web-zoekopdrachten via de Brave Search API (privacy-vriendelijk)."
  },
  {
    "title": "Overview",
    "category": "ontwerpen",
    "path": "design/overview.md",
    "content": "Ontwerpen Overview Dit is de centrale locatie voor functionele en technische ontwerpen van specifieke oplossingen en applicaties die met Druppie zijn gebouwd. ğŸ“‚ Structuur Hier worden ontwerpen opgeslagen die door de Specificatie Experts en Architecten zijn opgesteld. Functioneel Ontwerp (FO): Wat moet het systeem doen? (User Stories, Flowcharts) Technisch Ontwerp (TO): Hoe wordt het gebouwd? (Componenten, Data Model, API Specs) AI Ontwerp (AI): Hoe wordt het gebouwd? (Componenten, Data Model, API Specs) ğŸ“ Nieuw Ontwerp Toevoegen 1. Maak een nieuwe map/markdown bestand voor jouw project. 2. Neem de standaard hoofdstukken op: Doelstelling Architecturele Keuzes (verwijzing naar Bouwblokken) Data Flow Security & Compliance"
  },
  {
    "title": "TO: Hybride Architectuur (K8s)",
    "category": "ontwerpen",
    "path": "design/hybrid_cluster_architecture.md",
    "content": "Technisch Ontwerp: Hybride Kubernetes Architectuur ğŸ¯ Doelstelling Dit ontwerp beschrijft de infrastructuur voor een Hybride Kubernetes Omgeving. Het doel is om de schaalbaarheid en innovatiesnelheid van de Public Cloud (Azure) te combineren met de data-soevereiniteit en controle van het Eigen Datacenter (On-Premise). Dit ontwerp volgt de \"Data Gravitation\" strategie: Compute (rekenkracht) brengen we naar de Data toe, niet andersom. --- ğŸ—ï¸ High-Level Architectuur In deze opzet fungeert Azure als de \"flexibele schil\" en toegangspoort, terwijl het Datacenter de \"veilige kluis\" is voor gevoelige burgerdata en zware verwerkingen. mermaid graph TB subgraph Azure [\"â˜ï¸ Azure (Public Cloud)\"] style Azure fill:e6f1fc,stroke:0078d4,stroke-width:2px,stroke-dasharray: 5 5 AG[(\"Kong Gateway (Public Ingress)\")] UI[(\"Web Apps (Public Frontend)\")] Agents[(\"AI Agent Runtime (LLM)\")] subgraph AZ_K8S [\"Cluster: RKE2-Cloud\"] UI Agents end end subgraph OnPrem [\"ğŸ¢ Eigen Datacenter (Waterschap)\"] style OnPrem fill:f0fdf4,stroke:16a34a,stroke-width:2px subgraph OP_K8S [\"Cluster: RKE2-Core\"] IG[(\"Kong Gateway (Internal)\")] Int_UI[(\"Web Apps (Sensitive/Internal)\")] Int_Agents[(\"Internal AI Agents (Local LLM)\")] MinIO[(\"MinIO (Data Lake)\")] PG[(\"PostGIS (Geo Data)\")] GPU[(\"GPU Nodes (WebODM)\")] Legacy[(\"Legacy Connectors\")] end Git[(\"Gitea & Flux (GitOps)\")] end PublicUser(\"ğŸ‘¤ Burger (Internet)\") --> AG Employee(\"ğŸ‘· Medewerker (Intern Netwerk)\") --> IG AG --> UI IG --> Int_UI UI -- \"API calls\" --> Agents Int_UI -- \"Router\" --> Agents Int_UI -- \"Router\" --> Int_Agents %% Hybrid Connection drive[(\"ğŸ”’ ExpressRoute / VPN\")] AZ_K8S <==> |\"Secure Tunnel\"| drive drive <==> |\"Secure Tunnel\"| OP_K8S Agents -- \"MCP (Fetch Data)\" --> Legacy Int_Agents -- \"MCP (Direct)\" --> Legacy Agents -- \"MCP (Analyze)\" --> GPU Int_Agents -- \"MCP (Analyze)\" --> GPU --- ğŸ› ï¸ Technische Inrichting 1. De Kubernetes Stack (RKE2 in Multi-Cluster) We gebruiken Rancher Kubernetes Engine 2 (RKE2) als uniforme runtime voor beide locaties. Dit zorgt voor 100% compabiliteit. Beheer: We zetten Ã©Ã©n centrale Rancher Management Server op (in Azure of DMZ) om beide clusters te beheren. Cluster Azure (RKE2-Cloud): Doel: Frontends, Chatbots, Public API's. Kenmerk: Autoscaling nodes (voordelig schalen), Stateless. Cluster On-Prem (RKE2-Core): Doel: Gevoelige data opslag, GPU-intensieve taken (Drone beeldverwerking), koppeling SCADA. Kenmerk: Static Hardware, High Security, Stateful. 2. Netwerk & Connectiviteit De verbinding is cruciaal. We gebruiken een Hub-Spoke model. Interconnect: Azure ExpressRoute (of Site-to-Site VPN) zorgt voor een privÃ© verbinding. Service Mesh (Optioneel): Cilium of Linkerd om services over clusters heen te laten praten alsof ze lokaal zijn (drone-api.on-prem.svc.cluster.local). Ingress: Publiek verkeer komt binnen via Kong Gateway in Azure (DDoS bescherming). Kong routeert traffic voor \"zware taken\" door de tunnel naar de On-Prem Ingress (intern). 3. Data Strategie (Data Sovereignty) Conform de Data Act en AVG: Data Lake (MinIO): Draait primair On-Prem. Voor AI training in de cloud kan een specifieke bucket (\"Anonymized-Training-Data\") gerepliceerd worden naar Azure (MinIO Mirroring), maar de Master blijft thuis. Database (PostgreSQL): Master draait On-Prem. Read-Replicas kunnen eventueel in Azure draaien voor snelle frontend access (met geanonimiseerde views). --- 4. AI Model Strategie: Hybride Intelligentie Een cruciaal onderdeel van het ontwerp is de keuze waar de AI verwerking plaatsvindt. We gebruiken een \"Router\" (onderdeel van Druppie Core) die op basis van data-classificatie het juiste model kiest. A. Interne AI (On-Premise) Wanneer: Voor Gevoelige Data (Persoonsgegevens, Beveiligingsdetails Critical Infra) of Offline taken. Techniek: Self-hosted LLM's (zoals Llama 3, Mistral) draaiend op GPU nodes in het eigen datacenter. Tools: Ollama of vLLM containers in het RKE2-Core cluster. Voordeel: Data verlaat nooit het pand. Volledige controle. Nadeel: Minder krachtig dan GPT-4 (\"Dumber but Safer\"). B. Externe AI (Azure OpenAI) Wanneer: Voor Openbare Data, generieke kennisvragen, coderen, of creatieve taken. Techniek: Azure OpenAI Service (GPT-4o). Compliance: We gebruiken de \"Enterprise\" variant waarbij Microsoft garandeert dat input data NIET wordt gebruikt voor training. Voordeel: State-of-the-Art intelligentie, schaalbaar. Nadeel: Data verlaat (versleuteld) het netwerk. Beslisboom (Router Logic) mermaid graph TD Start(\"â“ User Prompt / Data\") Classify{\"ğŸ” Classificatie (Policy Engine)\"} Internal[\"ğŸ¢ Internal Cluster (Ollama/LMStudio)\"] Scrub{\"ğŸ§¹ Kan anonimiseren?\"} External[\"â˜ï¸ Azure Foundry (GPT-5.2)\"] Result(\"ğŸ“ Antwoord\") Start --> Classify Classify -->|ğŸ”´ Zeer Geheim / BSN| Internal Classify -->|ğŸŸ  Vertrouwelijk Intern| Scrub Classify -->|ğŸŸ¢ Openbaar / Publiek| External Scrub -- Ja --> External Scrub -- Nee --> Internal Internal --> Result External --> Result --- 5. OTAP Strategie (Environment Separation) We hanteren een strikte scheiding tu"
  },
  {
    "title": "TO: Component Interactie (Build->Run)",
    "category": "ontwerpen",
    "path": "design/component_interaction.md",
    "content": "Technisch Ontwerp: Component Interactie (Build & Runtime) ğŸ¯ Doelstelling Dit ontwerp detailleert de \"End-to-End Flow\" binnen het Druppie platform. Het beschrijft hoe de componenten van de Build Plane (het maken van software) naadloos integreren met de Runtime (het draaien van software), met focus op de geautomatiseerde checks en balances. Dit is de realisatie van de Spec-Driven en Compliance-by-Design filosofie. --- ğŸ—ï¸ De Componenten Architectuur In onderstaand schema zien we de reis van een \"Idee\" naar een \"Draaiende container\". mermaid graph TD subgraph UserInteraction [\"ğŸ—£ï¸ Interactie\"] User(\"ğŸ‘¤ Gebruiker\") <--> |\"Chst & Specs\"| Agent(\"ğŸ¤– Builder Agent\") end subgraph BuildPlane [\"ğŸ› ï¸ Build Plane (Foundry)\"] Agent --> |\"1. Commit Code & Config\"| Git(\"ğŸ—„ï¸ Gitea (Source)\") Git --> |\"2. Webhook\"| Tekton(\"âš™ï¸ Tekton (CI Pipeline)\") Tekton --> |\"3a. Build & Sign\"| Registry(\"ğŸ“¦ Container Registry\") Tekton --> |\"3b. Scan & Test\"| Scanner(\"ğŸ›¡ï¸ Trivy / SonarQube\") Tekton --> |\"3c. Update Status\"| TraceDB(\"ğŸ“œ Traceability DB\") end subgraph GitOps [\"ğŸ”„ GitOps Bridge\"] Flux(\"reconciler: Flux CD\") Flux <--> |\"4. Pull Config\"| Git end subgraph Runtime [\"ğŸš€ Runtime (Kubernetes)\"] Flux --> |\"5. Apply Manifest\"| K8sAPI(\"Kubernetes API\") K8sAPI --> |\"6. Validate Request\"| Kyverno(\"ğŸ‘® Policy Engine (Kyverno)\") Kyverno -.-> |\"Check Signatures\"| Registry Kyverno -.-> |\"Check AI Register\"| TraceDB Kyverno --> |\"7a. Allow\"| Kubelet(\"ğŸ“¦ Workload (Pod)\") Kyverno --> |\"7b. Deny\"| K8sAPI end subgraph Observability [\"ğŸ‘ï¸ Observability\"] Kubelet --> |\"8. Logs & Metrics\"| Loki(\"Loki / Prometheus\") end --- ğŸ”„ Proces Flow Beschrijving Fase 1: Intent & Code (De Build Plane) 1. Specificatie: De gebruiker vraagt de Builder Agent om een nieuwe Drone Service. De Agent genereert code (Python) en infra-definitie (Helm/Kustomize). 2. Commit: De Agent pusht alles naar Gitea. Dit is het eerste audit-moment (\"Wie heeft dit gemaakt?\"). 3. Continuous Integration (Tekton): Build: Bouwt de container image. Test: Draait unit tests. Security: Scant op bekende vulnerabilities (CVE's). Compliance: Valideert of algorithm.yaml aanwezig is. Sign: Als alles groen is, wordt de image digitaal ondertekend (Cosign) en gepusht naar de Registry. Fase 2: Reconciliatie (GitOps Bridge) 4. Sync: Flux CD bewaakt de Git repo. Zodra er een nieuwe image-tag in de config staat, wordt dit opgepikt. Merk op: Er is geen directe toegang van CI naar Cluster. Flux trekt (Pulls) de wijziging naar binnen. Dit is veiliger. Fase 3: Validatie & Deployment (De Runtime) 5. API Call: Flux stuurt het verzoek (\"Start Service V2\") naar de Kubernetes API. 6. Admission Control (Kyverno): Voordat de Pod start, grijpt Kyverno, onze Policy Engine, in: Validatie 1: \"Is deze image ondertekend door onze Foundry?\" (Voorkomt malafide containers). Validatie 2: \"Heeft deze deployment een AI Register ID?\" Validatie 3: \"Vraagt deze pod niet om root-rechten?\" 7. Execution: Allow: De Pod wordt gestart op de juiste node (bijv. On-Prem GPU node). Deny: De update wordt geweigerd en Flux rapporteert een error. Fase 4: Feedback Loop 8. Observability: De draaiende applicatie stuurt logs en metrics naar de PLG stack. De Builder Agent kan deze data lezen om te zien of zijn creatie goed werkt (\"Self-Healing\"). --- ğŸ›¡ï¸ Security Controles per Laag | Laag | Component | Controle | Doel | | :--- | :--- | :--- | :--- | | Code | Gitea | Branch Protection | Niemand kan direct naar main pushen zonder review (door mens of Agent). | | Build | Tekton | Image Scanning | Geen lekke software in productie. | | Artifact | Registry | Image Signing | Garanderen van herkomst (Supply Chain Security). | | Deployment| Flux | Drift Detection | Voorkomen van handmatige aanpassingen (\"ClickOps\"). | | Runtime | Kyverno | Policy Enforcement | Afdwingen van Run-Time regels (Non-Root, Network Policies). | âœ… Samenvatting Dankzij deze keten is \"Compliance\" geen papierwerk, maar een geautomatiseerde poortwachter. De Builder Agent zorgt voor snelheid. Tekton & Kyverno zorgen voor veiligheid. Git & Flux zorgen voor stabiliteit."
  },
  {
    "title": "TO: Data Lifecycle & Versiebeheer",
    "category": "ontwerpen",
    "path": "design/data_lifecycle_drone.md",
    "content": "Technisch Ontwerp: Data Lifecycle & Versiebeheer (Drone/Satelliet) ğŸ¯ Doelstelling Dit ontwerp beschrijft de end-to-end flow voor het beheren van grote, veranderlijke datasets zoals drone- en satellietbeelden. Centraal staan versiebeheer, privacy (anonimisering) en traceerbaarheid. We beantwoorden de vraag: \"Hoe gaan we van een SD-kaart met ruwe foto's naar een geanonimiseerde, versie-beheerde kaartlaag voor de organisatie?\" --- ğŸ—ï¸ De Data Pipeline Architectuur mermaid graph TD subgraph Source [\"ğŸ“‚ Bron\"] SDCard(\"ğŸ’¾ SD-Kaart / Satelliet Feed\") end subgraph DataLake [\"ğŸŒŠ Data Lake (MinIO)\"] BucketRaw[(\"ğŸª£ Raw (Versleuteld)\")] BucketScrub[(\"ğŸª£ Scrubbed (PrivÃ©)\")] BucketOrtho[(\"ğŸª£ Ortho (Public/Intern)\")] end subgraph Processing [\"âš™ï¸ Processing (Tekton/Argo)\"] Ingest(\"ğŸ“¥ Ingest & DVC Init\") Anonymizer(\"ğŸ§¹ AI Anonimiser (YOLOv8)\") Stitcher(\"ğŸ§© WebODM (Stitching)\") end subgraph Versioning [\"ğŸ“Œ Versiebeheer\"] Git(\"ğŸ—„ï¸ Gitea (Metadata .dvc)\") end subgraph Serving [\"ğŸŒ Serving\"] GeoServer(\"ğŸ—ºï¸ GeoServer (WMS/WFS)\") AI(\"ğŸ¤– AI Models\") end %% Flow SDCard --> |\"1. Upload\"| Ingest Ingest --> |\"2. Store V1\"| BucketRaw Ingest --> |\"3. Commit Hash\"| Git BucketRaw --> |\"4. Trigger\"| Anonymizer Anonymizer --> |\"5. Detect Faces/License Plates\"| Anonymizer Anonymizer --> |\"6. Store V1-Scrubbed\"| BucketScrub BucketScrub --> |\"7. Process\"| Stitcher Stitcher --> |\"8. Generate Ortho\"| BucketOrtho BucketOrtho --> |\"9. Serve\"| GeoServer BucketOrtho --> |\"10. Train\"| AI --- ğŸ”„ Proces Stappen Stap 1: Creatie & Ingestie (Raw Data) Actie: Een dronepiloot uploadt 500 foto's naar de landing-zone. Versiebeheer: Het systeem berekent een unieke hash (MD5) van de dataset. DVC slaat de foto's op in MinIO bucket-raw. DVC maakt een pointer file (raw_flight_2025.dvc) en commit deze naar Gitea. Resultaat: We hebben een onwijzigbare kopie van het origineel (\"Bewijslast\"). Stap 2: Anonimisering (Privacy-by-Design) Voordat beelden breed gedeeld worden, moeten persoonsgegevens verwijderd worden. Processing: Een Tekton pipeline start een container met AI-detectie (bijv. een YOLO model getraind op gezichten en kentekens). Actie: De AI blurt (vervaagt) alle gedetecteerde privacy-gevoelige pixels. Opslag: De opgeschoonde beelden gaan naar bucket-scrubbed. Versiebeheer: DVC trackt deze nieuwe set. We weten nu: De dataset in bucket-scrubbed is afgeleid van Hash X uit bucket-raw met algoritme Versie Y. Stap 3: Aan elkaar plakken (Stitching) De losse foto's worden Ã©Ã©n kaart. Tool: WebODM pakt de beelden uit bucket-scrubbed. Actie: Uitvoeren van SfM (Structure from Motion) om een 2D Orthofoto (GeoTIFF) en 3D Point Cloud (.laz) te maken. Opslag: Resultaat gaat naar bucket-ortho. Dit bestand is vaak enorm (GB's), dus MinIO is essentieel. Stap 4: Beschikbaar Stellen (Serving) Andere tools hebben nu toegang nodig. GIS Gebruikers: GeoServer indexeert de GeoTIFF uit bucket-ortho en serveert deze als WMS (Web Map Service). De ecoloog ziet de kaart in QGIS of GeoNode. AI Modellen: Een Data Scientist wil een nieuw schadedetectie-model trainen. Hij doet: dvc get https://gitea/project/drone.git data/ortho DVC haalt exact de juiste versie van de Orthofoto uit MinIO. Dit garandeert reproduceerbaarheid: \"Dit model is getraind op de geanonimiseerde kaart van 12 mei 2025\". --- ğŸ›¡ï¸ Security & Compliance 1. Toegangsbeheer (IAM): bucket-raw: Alleen toegankelijk voor de Anonimiser-Service en de CISO (voor forensisch onderzoek). bucket-ortho: Leesbaar voor de hele organisatie. 2. Audit Trail: In Gitea zien we de historie: \"Commit 1: Raw Upload\" -> \"Commit 2: Anonymized\" -> \"Commit 3: Processed\". 3. Data Act: Omdat we alles opslaan in open formaten (GeoTIFF) en standaarden (WMS), kunnen we data makkelijk delen met ketenpartners (andere waterschappen) zonder vendor lock-in. âœ… Samenvatting Door DVC te koppelen aan MinIO en WebODM, creÃ«ren we een \"Tijdmachine\" voor onze data. We kunnen altijd terugkijken hoe een foto eruit zag vÃ³Ã³r anonimisering (indien bevoegd) en we weten precies welke data is gebruikt voor welk AI-model."
  },
  {
    "title": "TO: Deployment & Rolling Updates",
    "category": "ontwerpen",
    "path": "design/deployment_strategies.md",
    "content": "Technisch Ontwerp: Deployment StrategieÃ«n & Rolling Upgrades ğŸ¯ Doelstelling Dit ontwerp beschrijft hoe wijzigingen (updates) gecontroleerd worden uitgerold naar de verschillende omgevingen (TEST, ACC, PROD). Het doel is de balans te vinden tussen snelheid (in Test) en stabiliteit (in Productie). De gebruiker heeft regie over de \"Rollout Pace\": hoe agressief of conservatief een update wordt doorgevoerd, afhankelijk van de impact van de wijziging (Major vs. Minor/Patch). --- ğŸ—ï¸ Het Concept: Spec-Driven Deployment Profile In plaats van handmatig kubectl commando's te tikken, definieert de gebruiker (of de Builder Agent) een Deployment Profile in de service.yaml. De Kubernetes Deployment resource biedt native ondersteuning voor Rolling Upgrades via spec.strategy. Wij tunen deze parameters op basis van het profiel. De Paremeters 1. Max Surge: Hoeveel extra pods mogen er tijdelijk bij komen? (Hoger = Sneller, kost meer resources). 2. Max Unavailable: Hoeveel pods mogen er stuk zijn tijdens de update? (0 = Zero Downtime). 3. Min Ready Seconds: Hoe lang moet een nieuwe pod \"goed\" draaien voordat we hem vertrouwen en de volgende stap zetten? (Dit is de \"wachttijd\"). --- ğŸ“Š Strategie Matrix We onderscheiden drie standaard profielen die de Builder Agent automatisch toepast. | Profiel | Omgeving | Type Wijziging | Max Surge | Max Unavail | Ready Wait (s) | Gedrag | | :--- | :--- | :--- | :--- | :--- | :--- | :--- | | Blitz | TEST | Alles | 100% | 50% | 0s | Zo snel mogelijk. Vervang de helft direct. Downtime is acceptabel. | | Cautious | PROD | Minor / Patch | 25% | 0 | 30s | Stabiel. Stap-voor-stap (1 op 4). Geen downtime. Wacht 30s per stap. | | Paranoid | PROD | Major | 1 | 0 | 300s | Zeer Voorzichtig. EÃ©n pod per keer. Wacht 5 minuten (300s) per pod. | --- âš™ï¸ Technische Implementatie (Helm/Flux) De implementatie vindt plaats in de Helm Chart die door Flux wordt uitgerold. 1. Configuratie (values.yaml) De gebruiker specificeert in de HelmRelease: yaml apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: drone-api spec: values: Keuze door gebruiker/agent: deploymentStrategy: \"Paranoid\" Want: Major upgrade V1 -> V2 2. Vertaling naar Kubernetes (deployment.yaml) De Helm chart vertaalt de string \"Paranoid\" naar harde cijfers: yaml apiVersion: apps/v1 kind: Deployment spec: replicas: 10 minReadySeconds: {{ .Values.readinessDelay | default 0 }} De \"Wachttijd\" strategy: type: RollingUpdate rollingUpdate: maxSurge: {{ .Values.maxSurge }} maxUnavailable: {{ .Values.maxUnavailable }} --- ğŸ”„ Visuele Flow: \"De Paranoid Rollout\" Stel we upgraden de Drone API van V1 naar V2 in Productie (Paranoid Mode). We hebben 4 Pods actief. mermaid sequenceDiagram participant Flux as ğŸ”„ Flux CD participant K8s as â˜¸ï¸ Kubernetes participant Pod1 as ğŸ“¦ Pod-1 (V1) participant Pod2 as ğŸ“¦ Pod-2 (V1) participant PodNew as âœ¨ Pod-New (V2) Note over Flux, PodNew: Start Major Update (Paranoid: Surge 1, Wait 300s) Flux->>K8s: Apply Deployment Image: V2 K8s->>PodNew: Start 1x V2 Pod Note right of PodNew: Opstarten... PodNew-->>K8s: Readiness Probe OK! Note over K8s: â±ï¸ Wacht 300 seconden (MinReadySeconds) K8s-->>K8s: Geen crashes? Metrics OK? K8s->>Pod1: Terminate V1 Pod Pod1-->>K8s: Shutdown Note over K8s: Herhaal voor volgende Pod... Safety Gates (Health Checks) Tijdens de \"Wachttijd\" (die 5 minuten) monitort Kubernetes de Liveness en Readiness probes. Als de nieuwe V2 pod crasht (Reboot Loop), stopt de rollout automatisch. De oude V1 pods blijven draaien. Gebruikers merken (bijna) niets, behalve dat de update \"hangt\". --- ğŸš€ Gebruikerservaring Scenario: Developer configureert een update De developer praat tegen de Builder Agent: > User: \"Ik wil de nieuwe Drone AI (V2) naar productie brengen. Het is een grote wijziging, dus doe maar rustig aan.\" > Agent: \"Begrepen. Ik configureer de HelmRelease voor 'drone-ai' met strategie Paranoid. Dit betekent dat de uitrol 1 pod per 5 minuten vervangt. Akkoord?\" > User: \"Maak er maar 2 minuten van.\" > Agent: \"Aangepast. minReadySeconds gezet op 120s.\" De Agent commiit vervolgens: yaml deploy/prod/drone-ai-release.yaml spec: values: deploymentStrategy: \"Custom\" customStrategy: maxSurge: 1 maxUnavailable: 0 readinessDelay: 120 ğŸ“š Bronkeuze: Ramped Slow Rollout & Blue/Green Naar aanleiding van best practices, hebben we gekozen voor Ramped Slow Rollout als de standaard \"base option\" voor productie. Dit biedt de beste balans tussen veiligheid en resource-efficiÃ«ntie. Echter, voor specifieke High-Compliance updates (bijv. een nieuwe versie van de Policy Engine), voegen we de Blue/Green strategie toe. --- ğŸ”µ/ğŸŸ¢ Uitbreiding: Blue/Green Deployment Voor kritieke componenten waar geen enkele fout getolereerd wordt tijdens de switch, of waar een Human Auditor expliciet \"Go\" moet geven, gebruiken we Blue/Green. Het Concept We draaien twee volledige versies naast elkaar: ğŸ”µ Blue: De huidige Live versie (v1). ğŸŸ¢ Green: De nieuwe versie (v2), volledig opgestart maar ontvangt geen publiek verkeer. Implement"
  },
  {
    "title": "TO: IAM & Keycloak Interactie",
    "category": "ontwerpen",
    "path": "design/iam_keycloak_interaction.md",
    "content": "Technisch Ontwerp: IAM & OPA Integratie met Keycloak ğŸ¯ Doelstelling Het beveiligen van applicaties, data (Postgres) en AI-kennis (RAG) door middel van een centraal Identity & Access Management (IAM) systeem. We gebruiken Keycloak als Identity Provider (IdP) en Open Policy Agent (OPA) voor fijnmazige autorisatie. ğŸ—ï¸ Architectuur De beveiliging is opgebouwd uit drie lagen: 1. Authenticatie (Wie ben je?): Via Keycloak (OIDC). 2. Autorisatie (Wat mag je?): Via OPA (Regels in Rego). 3. Handhaving (Enforcement): Via Envoy / Sidecars of in de App code. mermaid sequenceDiagram actor User participant Browser participant Keycloak as Keycloak (IdP) participant App as Druppie App participant OPA as Policy Engine participant DB as Postgres (RLS) participant RAG as Qdrant (Vector) User->>Browser: Open App Browser->>Keycloak: Redirect for Login (OIDC) User->>Keycloak: Credentials Keycloak-->>Browser: JWT Token (Claims: role=analyst, dept=hr) rect rgb(240, 248, 255) note right of Browser: Scenario 1: Data Access Browser->>App: API Request + Bearer Token App->>DB: SQL Query (SET LOCAL role/dept) DB-->>App: Filtered Rows (RLS enforced) App-->>Browser: Data Response end rect rgb(255, 250, 240) note right of Browser: Scenario 2: AI Question Browser->>App: \"Summarize HR Policy\" App->>OPA: Check Access (Token + Query) OPA-->>App: Filter: { dept: \"hr\" } App->>RAG: Vector Search + Filter RAG-->>App: Allowed Context Chunks App-->>Browser: AI Answer rooted in authorized data end 1. Applicatie Toegang (SSO) Gebruikers loggen in via de browser. Protocol: OpenID Connect (OIDC). Flow: Authorization Code Flow met PKCE. Token: JWT (JSON Web Token) bevat gebruikersrollen (bijv. analist, beheerder). 2. Data Toegang (Row Level Security) Toegang tot specifieke rijen in PostgreSQL (bijv. alleen dossiers van jouw afdeling). Mechanisme: PostgreSQL Row Level Security (RLS). Implementatie: 1. De API ontvangt de JWT van de gebruiker. 2. De API \"impersoneert\" de gebruiker in de DB sessie: SET LOCAL request.jwt.claim.role = 'analist'; 3. Postgres Policies filteren automatisch de data. 3. RAG / Kennis Toegang (AI Security) Toegang tot documenten in de Vector DB (Qdrant). Probleem: Een gebruiker mag via de Chatbot niet zoeken in documenten waar hij geen recht op heeft. Oplossing (Attribute Based Access Control - ABAC): 1. Elk document in Qdrant heeft metadata: {\"department\": \"hr\", \"confidentiality\": \"high\"}. 2. De Chatbot stuurt de vraag + JWT naar de Policy Engine. 3. De Policy Engine (OPA) geeft een filter terug: filter = { must: [ { key: \"department\", match: { value: \"hr\" } } ] }. 4. Dit filter wordt toegevoegd aan de zoekopdracht naar Qdrant. ğŸ› ï¸ Technische Implementatie A. Keycloak Configuratie (Terraform) We definiÃ«ren de infrastructuur als code. hcl resource \"keycloak_realm\" \"druppie\" { realm = \"druppie\" enabled = true } resource \"keycloak_openid_client\" \"rag_app\" { realm_id = keycloak_realm.druppie.id client_id = \"rag-chatbot\" access_type = \"CONFIDENTIAL\" valid_redirect_uris = [\"https://chat.druppie.nl/callback\"] } B. Voorbeeld: RAG Security (Python) Hoe de backend het user token gebruikt om de zoekopdracht te filteren. python from fastapi import Depends, HTTPException from fastapi.security import OAuth2PasswordBearer import jwt 1. Valideer Token def get_current_user_claims(token: str = Depends(oauth2_scheme)): try: payload = jwt.decode(token, PUBLIC_KEY, algorithms=[\"RS256\"]) return payload Bevat roles, department, etc. except: raise HTTPException(status_code=401) 2. Stel Zoekfilter Samen (Policy Enforcement) def search_knowledge_base(query: str, user_claims: dict): user_dept = user_claims.get(\"department\") Authorisatie Filter (Alleen eigen afdeling) auth_filter = { \"key\": \"department\", \"match\": {\"value\": user_dept} } Voer zoekopdracht uit in Qdrant met filter results = qdrant_client.search( collection_name=\"bedrijfskennis\", query_vector=encode(query), query_filter=Filter(must=[auth_filter]) <--- CRUCIAAL ) return results C. Voorbeeld: Database RLS (Postgres SQL) Hoe de database zelf de toegang afdwingt. sql -- 1. Maak Table met ownership kolom CREATE TABLE dossiers ( id SERIAL PRIMARY KEY, inhoud TEXT, afdeling TEXT -- bijv. 'hr', 'finance' ); -- 2. Enable RLS ALTER TABLE dossiers ENABLE ROW LEVEL SECURITY; -- 3. Maak Policy: \"Je mag alleen lezen als jouw afdeling matcht met de rij\" CREATE POLICY afdeling_policy ON dossiers FOR SELECT USING (afdeling = current_setting('request.jwt.claim.department', true)); âœ… Samenvatting Door deze 3-traps raket (Web SSO, DB RLS, Vector Filtering) zorgen we dat beveiliging overal wordt afgedwongen, niet alleen aan de voordeur. Zelfs als een AI Agent \"rogue\" gaat, kan hij fysiek geen data ophalen die niet voor de gebruiker bedoeld is."
  },
  {
    "title": "TO: Automated Rebuild (Watchdog)",
    "category": "ontwerpen",
    "path": "design/automated_rebuild.md",
    "content": "Technisch Ontwerp: Automated Rebuild & Patching ğŸ¯ Doelstelling We willen een automatisch \"Self-Healing\" mechanisme implementeren dat continu de definities van onze Bouwblokken bewaakt. Wanneer er een Bugfix of Security Patch wordt gedetecteerd in een fundamenteel bouwblok (bijv. \"Update Base Image Python\"), moet het systeem: 1. Detecteren welke applicaties dit bouwblok gebruiken. 2. Deze applicaties automatisch herbouwen en uitrollen naar TEST. 3. De update klaarzetten voor promotie naar PROD (via de Deployment Strategy). Dit voorkomt dat applicaties verouderen en onveilig worden. --- ğŸ—ï¸ Architectuur: De \"Dependency Watchdog\" We introduceren een nieuw background proces: de Dependency Watchdog. Dit is een lichtgewicht service (of CronJob) die luistert naar wijzigingen in Gitea. mermaid graph TD subgraph Git [\"ğŸ—„ï¸ Gitea (Source)\"] RepoBlock[(\"Repo: Bouwblokken\")] RepoApp1[(\"Repo: Drone App\")] RepoApp2[(\"Repo: GIS Portal\")] end subgraph Logic [\"ğŸ§  Watchdog Service\"] Detector(Change Detector) Parser(Semantic Parser) Graph(Dependency Graph) end subgraph Action [\"âš™ï¸ Build Plane\"] Tekton(Tekton Pipeline) Flux(Flux CD) end %% Flow RepoBlock -- \"Webhook: Push\" --> Detector Detector --> Parser Parser -- \"Is het een FIX?\" --> Graph Graph -- \"Wie gebruikt dit?\" --> Tekton Tekton -- \"Auto-Build App 1 & 2\" --> RepoApp1 Tekton -- \"Push Tag naar Dev-Cluster\" --> Flux --- ğŸ”„ Proces Flow Stap 1: Change Detection De Watchdog ontvangt een webhook event van Gitea wanneer er een commit is op de bouwblokken repository. Stap 2: Semantic Analysis (\"Is dit een Fix?\") De Watchdog analyseert de commit message volgens de Conventional Commits standaard: fix: update python to 3.11.2 (CVE-XYZ) âœ… -> Actie vereist! chore: update readme âŒ -> Negeren. feat: add new capability âŒ -> Negeren (vereist handmatige implementatie). Stap 3: Dependency Resolution De Watchdog kijkt in zijn grafiek (gevoed door de SBOMs in de Traceability DB): \"Welke applicaties hebben een FROM: bouwblokken/python-base:3.11 in hun Dockerfile?\" Resultaat: Drone App en GIS Portal. Stap 4: Automated Rebuild (Cascade) De Watchdog triggert Tekton pipelines voor de geraakte applicaties: 1. Checkout: Haalt de broncode van Drone App. 2. Patch: Update de dependency (bijv. in Dockerfile of requirements.txt). 3. Build & Test: Draait de unit tests om te garanderen dat de fix niets breekt. 4. Publish: Pusht drone-app:v1.2.1-fix naar de registry. Stap 5: Deploy naar TEST De Watchdog past de HelmRelease voor de TEST omgeving aan (via een Git commit op de fleet-infra repo): Versie: v1.2.1-fix Strategy: Blitz (Want het is TEST, mag direct). Stap 6: Aanbod aan Productie De Watchdog maakt automatisch een Pull Request aan voor de PROD omgeving: Titel: fix(deps): propagate security patch to prod Strategy: Cautious (Zie Deployment Design). Status: Pending Approval. De beheerder hoeft alleen maar \"Merge\" te klikken (of de Policy Engine doet het als het een Critical CVE was). --- ğŸ› ï¸ Technische Componenten 1. Renovate Bot (De Engine) We hoeven de \"Watchdog\" niet zelf te bouwen. We gebruiken Renovate Bot. Dit is de industrie-standaard voor geautomatiseerd dependency management. Het snapt Dockerfiles, Helm Charts, Kubernetes manifests en Git submodules. Het kan geconfigureerd worden om bij fix: commits automatisch te mergen naar branches die naar TEST deployen. 2. Configuratie (renovate.json) We plaatsen dit in de root van onze repo's: json { \"extends\": [\"config:base\"], \"packageRules\": [ { \"matchUpdateTypes\": [\"patch\", \"pin\", \"digest\"], \"matchPackagePatterns\": [\"^bouwblokken/\"], \"automerge\": true, \"automergeType\": \"branch\", \"branchPrefix\": \"fix/auto-rebuild-\" } ], \"semanticCommits\": \"enabled\" } âœ… Samenvatting Door Renovate Bot in te zetten als onze \"Watchdog\", realiseren we een self-healing platform. Security: Patches in base-images sijpelen automatisch door naar alle 50+ applicaties. Stabiliteit: Omdat we eerst naar TEST uitrollen en testen, gaat productie nooit stuk door een automatische update. Snelheid: De \"Fix\" cyclus gaat van weken naar minuten."
  },
  {
    "title": "TO: Secure Agentic RAG Network",
    "category": "ontwerpen",
    "path": "design/agentic_rag_network.md",
    "content": "Technisch Ontwerp: Secure Agentic RAG Network ğŸ¯ Doelstelling Dit ontwerp beschrijft een Agentic Network dat ongestructureerde data (bestanden) en publieke data (web) combineert om intelligente acties uit te voeren. Kernpunt is Security by Design data-toegang: Een gebruiker mag via de AI NOOIT informatie vinden die hij via de normale bestandsverkenner niet zou mogen zien. --- ğŸ—ï¸ Architectuur: Het Agenten Netwerk We gebruiken een Multi-Agent opzet waarbij specifieke taken zijn gedelegeerd. mermaid graph TD User(\"ğŸ‘¤ Gebruiker (Context: Groepen)\") <--> |\"Chat Interface\"| Router(\"ğŸ¤– Router Agent\") subgraph DataPlane [\"ğŸ“š Knowledge & Data\"] FS(\"ğŸ“‚ FileSystem (SMB/SharePoint)\") VDB[(\"ğŸ§  Vector DB (Qdrant)\")] Web(\"ğŸŒ Web Search (MCP)\") end subgraph Agents [\"ğŸ•µï¸ Agent Network\"] Ingester(\"ğŸ¤– Ingest Agent\") RAG(\"ğŸ¤– RAG Agent (Search)\") Action(\"ğŸ¤– Action Agent\") end subgraph Execution [\"âš™ï¸ Uitvoering\"] Argo(\"ğŸš€ Argo Workflow\") ExtSys(\"ğŸ–¥ï¸ Extern Systeem (API)\") end %% Inest Flow FS --> |\"1. Read File + ACLs\"| Ingester Ingester --> |\"2. Embed + Tags\"| VDB %% Query Flow Router --> |\"3. Vraag + User Token\"| RAG RAG --> |\"4. Vector Search + Filter\"| VDB RAG -- \"5. Search Web (Opt)\" --> Web RAG --> |\"6. Synthesized Answer\"| Router %% Action Flow Router --> |\"7. Intent: Update Systeem\"| Action Action --> |\"8. Trigger Process\"| Argo Argo --> |\"9. Update\"| ExtSys --- ğŸ” Security by Design: De \"ACL-Aware\" RAG Het grootste risico bij RAG (Retrieval Augmented Generation) is dat de AI alle documenten \"leest\" en antwoord geeft op basis van een geheim document. Dit lossen we op via Metadata Filtering. Stap 1: Ingestie met Rechten (The Ingest Agent) De Ingest Agent leest niet alleen de tekst, maar ook de Access Control List (ACL) van het bestand. Input: Project_Begroting_2025.xlsx ACL: Read access voor group: Management, Finance. Action: 1. Chunk de tekst. 2. Genereer Vector Embedding. 3. Sla op in VectorDB met metadata: json { \"content\": \"Het budget is 1 miljoen...\", \"source\": \"Project_Begroting_2025.xlsx\", \"allowed_groups\": [\"Management\", \"Finance\"] } Stap 2: Zoeken met Context (The RAG Agent) Wanneer gebruiker Jan een vraag stelt, stuurt de frontend zijn JWT Token (van Keycloak) mee. 1. Extract Claims: De RAG Agent ziet in het token: Jan is lid van [\"Engineering\", \"Public\"]. 2. Search Query: De Agent construeert een filter-query voor de VectorDB: Vector: (De vraag van Jan) Filter: metadata.allowed_groups IN [\"Engineering\", \"Public\"] 3. Resultaat: Omdat Finance niet in de lijst van Jan staat, vindt de VectorDB 0 resultaten voor de begroting. De AI antwoordt: \"Ik kan die informatie niet vinden.\" --- ğŸ”„ De Flow: Van Vraag naar Actie Scenario: \"Update de voorraadstatus gebaseerd op leveranciersnieuws\" 1. Vraag: Gebruiker vraagt: \"Zoek uit of onze leverancier X leveringsproblemen heeft en update zo nodig ons ERP systeem.\" 2. Router: Herkent vraag als \"Onderzoek + Actie\". Roept eerst RAG Agent en Web Agent aan. 3. Informatie Vergaring: Web Agent: Zoekt via MCP (Brave Search): \"Leverancier X faillissement nieuws\". -> Vindt nieuwsartikel. RAG Agent: Zoekt intern contract: \"Contract Leverancier X\". -> Vindt clausule over leveringsplicht (mits gebruiker recht heeft!). 4. Redenering: Router combineert info: \"Nieuws meldt stakingen, Contract zegt: 5 dagen boetevrij.\" Conclusie: \"Risico op vertraging.\" 5. Actie: Router roept Action Agent aan: \"Start 'Update Voorraad Risico' proces voor Vendor X.\" Action Agent: Valideert intentie. Roept MCP Tool aan: start_workflow(workflow_id=\"update_erp_risk\", vendor=\"X\"). 6. Uitvoering: Argo Workflow start. Roept de API van het ERP systeem aan om de vlag \"DeliveryRisk\" op \"High\" te zetten. --- ğŸ› ï¸ Technische Componenten Vector Database: Qdrant of Weaviate. Deze ondersteunen native high-performance filtering op metadata. Ingest Framework: LangChain of LlamaIndex voor het lezen van files en splitsen van tekst. MCP Servers: mcp-filesystem: Voor het lezen van lokale shares/SharePoint. mcp-websearch: Voor toegang tot Brave/Bing. mcp-kubernetes: Voor het triggeren van Argo workflows. âœ… Samenvatting Dit ontwerp garandeert dat de AI krachtig is (combi intern + extern), maar nooit lekt. De beveiliging zit niet in de \"prompt\" (\"Negeer geheime data\"), maar hard in de database query (\"Je KRIJGT geen geheime data\")."
  },
  {
    "title": "TO: Continuous Compliance & Lifecycle",
    "category": "ontwerpen",
    "path": "design/compliance_lifecycle_monitoring.md",
    "content": "Technisch Ontwerp: Continuous Compliance & Lifecycle Monitoring ğŸ¯ Doelstelling Compliance is geen eenmalig vinkje bij de start van een project. Het is een continu proces dat loopt van het eerste idee tot de uiteindelijke uitfasering van een applicatie. Dit ontwerp beschrijft hoe wij Compliance by Design borgen over de gehele levenscyclus (Lifecycle Management), met specifieke aandacht voor de AI Act en het Algoritmeregister. --- ğŸ—ï¸ De \"Compliance Loop\" Architectuur We hanteren het \"Three Lines of Defense\" model, maar dan geautomatiseerd. mermaid graph TD subgraph Design [\"Fase 1: Design (De Belofte)\"] Spec(\"ğŸ“ Specificatie & AI Register\") Risk(\"âš–ï¸ Risk Assessment (AIIA)\") end subgraph Build [\"Fase 2: Build (De Validatie)\"] Code(\"ğŸ’» Code Creation\") Scan(\"ğŸ›¡ï¸ Static Analysis (Trivy/Sonar)\") PolicyBuild(\"ğŸ‘® Policy Check (Gatekeeper)\") end subgraph Run [\"Fase 3: Run (De Handhaving)\"] Deploy(\"ğŸš€ Deployment\") Enforce(\"ğŸ›‘ Runtime Enforcement (Kyverno)\") Monitor(\"ğŸ“ˆ Drift & Audit (Prometheus/Loki)\") end subgraph Retire [\"Fase 4: Feedback & Retire\"] Audit(\"ğŸ“œ Audit Trail\") Archief(\"ğŸ—„ï¸ Archivering & Deletion\") end %% Flow Spec --> Risk Risk --> |\"Approved\"| Code Code --> Scan Scan --> PolicyBuild PolicyBuild --> |\"Compliant\"| Deploy PolicyBuild --> |\"Violation\"| Code Deploy --> Enforce Enforce --> |\"Allowed\"| Monitor Monitor --> |\"Drift Detected\"| Audit Audit --> |\"Feedback\"| Design Monitor --> |\"End of Life\"| Archief --- ğŸ”„ Lifecycle Fases in Detail Fase 1: Design & Registratie (De Bron) Compliance begint bij de registratie in het AI Register. Zonder registratie, geen bouw. Actie: De Builder Agent helpt de gebruiker een algorithm.yaml aan te maken. Controle: Is het doel duidelijk omschreven? Is de risicoklasse (Laag/Hoog) bepaald? Is de eigenaar (mens) bekend? Fase 2: Build & Validatie (De Poort) Tijdens het bouwen (Tekton) checken we of de realiteit (code) overeenkomt met de belofte (design). SBOM Check: Gebruiken we veilige componenten? (Trivy). Quality Check: Is de code uitlegbaar en onderhoudbaar? (SonarQube). Dataset Check: Komt de gebruikte dataset hash (DVC) overeen met een geautoriseerde bron? Register Update: Bij succesvolle build wordt het versie-nummer in het AI Register automatisch opgehoogd. Fase 3: Runtime Handhaving (De Bewaker) Wat als iemand de regels probeert te omzeilen na deployment? Kyverno Policies: No Register, No Run: Een pod zonder geldig algorithm-id label wordt direct gestopt. Geofencing: Data gelabeld als \"Intern-Only\" mag niet op Cloud-nodes draaien. Model Monitoring: We monitoren niet alleen CPU/RAM, maar ook Model Drift. Signaal: \"Het AI model geeft vandaag 40% vaker 'Risico' aan dan gisteren. Is de data veranderd?\" -> Trigger alert naar Data Scientist. Fase 4: Feedback & Retirement (De Schoonmaker) Compliance gaat ook over opruimen (Dataminimalisatie / AVG). Retentie Policies: Systeem verwijdert automatisch data uit MinIO die ouder is dan X jaar (tenzij gemarkeerd als 'Legal Hold'). Her-certificering: Elk jaar stuurt de Knowledge Bot een vraag naar de Eigenaar: \"Het algoritme 'Muskusrat V1' draait nog. Is dit nog actueel?\" Geen antwoord = Automatische uitfasering (Scale to 0). --- ğŸ›¡ï¸ Borging: Het Dashboard Alle signalen komen samen in Ã©Ã©n Compliance Dashboard (in de Druppie UI). 1. Stoplicht Model: ğŸŸ¢ Green: Alles compliant. ğŸŸ  Orange: Waarschuwing (bijv. \"Certificaat verloopt bijna\" of \"Model drift > 5%\"). ğŸ”´ Red: Overtreding (blokkade actief). 2. Audit Trail (Traceability DB): De auditor (Accountant/Inspectie) kan met Ã©Ã©n druk op de knop de historie zien: \"Toon mij alle wijzigingen aan Algoritme X tussen 2024 en 2025, en wie deze heeft goedgekeurd.\" âœ… Samenvatting Wij borgen compliance door het onderdeel te maken van de techniek: 1. Static: In de pipeline (Trivy/Sonar). 2. Dynamic: In het cluster (Kyverno). 3. Administratief: In het AI Register (gekoppeld aan GitOps). Hierdoor is \"voldoen aan de wet\" geen extra werk, maar het logische gevolg van het gebruik van het platform."
  },
  {
    "title": "TO: Automated Testing & Documentation",
    "category": "ontwerpen",
    "path": "design/automated_testing_docs.md",
    "content": "Technisch Ontwerp: Automated Testing & Documentation ğŸ¯ Doelstelling Om de ontwikkelingssnelheid hoog te houden zonder in te boeten op kwaliteit, moet het test- en documentatieproces volledig geautomatiseerd zijn. Testen: Van unit tests tot end-to-end (E2E) gebruikersscenario's. Documentatie: Documentatie mag nooit achterlopen op de code (\"Living Documentation\"). --- ğŸ—ï¸ Automated Testing Strategy (The Testing Pyramid) We hanteren de 'Test Piramide' strategie, geÃ¯ntegreerd in de Tekton pipeline. mermaid graph TD subgraph Pyramid [\"De Test Piramide\"] E2E(\"ğŸ”¼ E2E (UI/Workflow) - 10%\") Integration(\"ğŸ”¹ Integratie (API) - 20%\") Unit(\"ğŸ”» Unit (Code) - 70%\") end subgraph Tools [\"ğŸ› ï¸ Tooling\"] Jest(\"Jest / PyTest (Unit)\") Newman(\"Postman / Newman (API)\") Playwright(\"Playwright (UI)\") end subgraph DocGen [\"ğŸ“„ Documentation Generation\"] Pydoc(\"Sphinx / JSDoc\") Swagger(\"OpenAPI Generator\") Mermaid(\"Mermaid Live\") end Unit --> Jest Integration --> Newman E2E --> Playwright Jest --> |\"Genereer Coverage Report\"| DocGen Newman --> |\"Genereer API Docs\"| Swagger 1. Unit Testing (De Basis) Wanneer: Bij elke commit. Wat: Test individuele functies en classes. Tool: PyTest (Python) of Jest (Node.js). Eis: Coverage > 80% (bewaakt door SonarQube). 2. Integration Testing (De Koppeling) Wanneer: Na de build, vÃ³Ã³r deployment naar TEST. Wat: Test of de API endpoints goed reageren. Tool: Newman. We draaien een Postman collectie tegen de container. 3. End-to-End Testing (De Ervaring) Wanneer: Na deployment op TEST. Wat: Simuleer een echte gebruiker (\"Klik op knop X, verwacht Scherm Y\"). Tool: Playwright. Scenario: \"Drone piloot uploadt foto, AI anonimiseert, Ecoloog ziet kaart.\" --- ğŸ“„ Automated Documentation Strategy (\"Docs-as-Code\") Documentatie wordt gegenereerd uit de bron, niet handmatig geschreven. Dit garandeert dat de docs altijd kloppen met de werkelijkheid. 1. API Documentatie (Swagger/OpenAPI) De code is de bron (@app.route('/api/v1/drones')). Tijdens de build genereert de pipeline automatisch een swagger.json. Deze wordt gepubliceerd naar Kong Developer Portal. Developers zien altijd de actuele API specs. 2. Code Documentatie Docstrings in de code leggen de intentie uit. Tools als Sphinx (Python) of TypeDoc (TS) genereren hieruit een leesbare HTML website (\"ReadTheDocs\"). 3. Architectuur Platen (Mermaid) Zoals in dit ontwerpdocument, gebruiken we Mermaid. Deze diagrammen staan als tekst in Markdown. GitHub/Gitea renderen ze direct. Hierdoor is Versiebeheer op diagrammen mogelijk (\"Diff Viewer\" toont: \"Pijl A wees eerst naar B, nu naar C\"). 4. Living Readme De Builder Agent update automatisch de README.md van een project met: Huidige Build Status (Badges). Laatste Test Coverage %. Link naar de actuele Swagger docs. --- ğŸ”„ De Workflow 1. Developer: Commit code (feat: add new drone sensor). 2. Pipeline: Draait Unit Tests -> âœ… Genereert API Docs -> ğŸ“„ openapi.yaml Bouwt container. 3. Deployment (TEST): Update omgeving. 4. Verification: Draait Playwright E2E tests -> âœ… Publiseert docs naar het interne kennisportaal. âœ… Samenvatting Door testen en documentatie te automatiseren: 1. Verhogen we het vertrouwen: We weten dat het werkt, we hopen het niet. 2. Verlagen we drempels: Nieuwe ontwikkelaars hebben altijd actuele documentatie. 3. Besparen we tijd: Geen handmatige Word-documenten meer updaten."
  },
  {
    "title": "FO: Vergunning zoeker",
    "category": "ontwerpen",
    "path": "design/vergunning_zoeker.md",
    "content": "Functioneel Ontwerp: Vergunning zoeker ğŸ¯ Doelstelling Veel oude vergunningen (PDFs, Word-documenten) staan nog op file-shares (S-schijf, SharePoint) in plaats van in het officiÃ«le Zaaksysteem. Dit maakt ze onvindbaar, juridisch kwetsbaar en niet compliant met de Archiefwet. De Vergunning zoeker is een AI-gedreven flow die deze \"verloren\" vergunningen opspoort, analyseert, registreert in het Zaaksysteem en vervolgens opruimt. --- ğŸ‘¥ Gebruikersverhaal > \"Als medewerker Vergunningverlening wil ik dat oude vergunningen automatisch op de juiste plek in het Zaaksysteem komen, zodat ik niet handmatig duizenden mappen hoef door te spitten.\" --- ğŸ—ï¸ Proces Flow (High Level) mermaid graph TD Start(\"ğŸŸ¢ Start Proces\") --> Search(\"ğŸ•µï¸ AI Zoekt Bestanden\") Search --> Classify{{\"Is dit een Vergunning?\"}} Classify -- Nee --> Skip(\"â­ï¸ Negeer bestand\") Classify -- Ja --> Extract(\"ğŸ§  AI Extractie (LLM)\") Extract --> Validate{{\"Validatie (Human-in-Loop?)\"}} Validate -- Afgekeurd --> Manual(\"ğŸ‘· Handmatige Actie\") Validate -- Goedgekeurd --> Register(\"ğŸ“ Registreer in Zaaksysteem\") Register -- Succes --> Archive(\"ğŸ—‘ï¸ Verwijder van Schijf\") Archive --> Log(\"âœ… Audit Log\") --- ğŸ§© Componenten & Werking We gebruiken de Secure Agentic RAG Network architectuur. 1. De Speurder (Ingest Agent + MCP Filesystem) Taak: Scant mappen op de netwerkschijf (SMB). Filter: Zoekt naar bestandsnamen zoals vergunning, beschikking, .pdf. Security: De agent gebruikt de rechten van een \"Service Account\" dat specifiek toegang heeft tot deze mappen. 2. De Analist (Internal AI Agent) Taak: Leest de inhoud van het document (OCR indien nodig). Classificatie: Bepaal Document Type: Watervergunning, Leggerwijziging, Ontheffing. Bepaal Metadata: Huisnummer, Perceel, Datum, Aanvrager. Privacy: Detecteer BSN nummers (via AI Anonymizer logica). 3. De Beslisser (Policy Engine) Check: Is de \"Vertrouwen Score\" van de AI hoog genoeg (> 90%)? Ja: Volledig automatisch verwerken. Nee: Stuur taak naar \"Mens in de Loop\" werklijst in Druppie UI. 4. De Uitvoerder (Action Agent + MCP Zaaksysteem) Actie 1: Roep API van Zaaksysteem (bijv. PowerBrowser/Mozard) aan om een Nieuwe Zaak aan te maken. Actie 2: Upload het document als bijlage. Actie 3: Vul metadatavelden in. Actie 4 (Na bevestiging API): Verwijder het originele bestand van de file-share (Data Clean-up). --- ğŸ›¡ï¸ Waarborgen (Compliance) 1. De \"Prullenbak\" Veiligheid: We verwijderen het bestand niet direct hard (rm), maar verplaatsen het eerst naar een PROCESSED_QUARANTINE map voor 30 dagen. Mocht er iets misgaan, hebben we een backup. 2. Audit Trail: \"Bestand 'Vergunning_Jansen.pdf' is op 21-12-2025 verplaatst naar Zaak Z-2025-001 door Agent Druppie.\" 3. Toegangsrechten: Documenten met BSN nummers worden als \"Vertrouwelijk\" gemarkeerd in het Zaaksysteem. --- âœ… Resultaat Opgeruimde schijven: Minder storage kosten, minder datalek risico. Compleet Dossier: Het Zaaksysteem bevat nu het volledige beeld. Tijdwinst: Geen handmatig overtikken van pdf's. ğŸ”— Relatie met Bouwblokken Gebruikt Secure Agentic RAG voor het vinden. Gebruikt Interne AI (Ollama) voor het lezen van gevoelige data. Gebruikt MCP Servers voor connectie met Filesystem en Zaaksysteem."
  },
  {
    "title": "FO: Exoten Detectie",
    "category": "ontwerpen",
    "path": "design/exoten_detectie.md",
    "content": "Functioneel Ontwerp: Exoten Detectie ğŸ¯ Doelstelling De verspreiding van invasieve waterplanten (exoten) bedreigt de waterkwaliteit en doorstroming. Dit ontwerp richt zich puur op het signaleren en verwerken van deze exoten, gebruikmakend van satelliet- en dronedata. De daadwerkelijke vliegbeweging wordt afgehandeld door de Drone Planner. --- ğŸ—ï¸ Proces Flow (Detectie & Afhandeling) mermaid graph TD subgraph Trigger [\"ğŸ›°ï¸ Stap 1: Signalering (Grof)\"] Sat(Satelliet Data/SuperView) --> ChangeAI(AI: Change Detection) ChangeAI --> |\"Mogelijke Hotspot\"| Planner(Drone Planner) end subgraph Analysis [\"ğŸ”¬ Stap 2: Analyse (Fijn)\"] Planner --> |\"Ruwe Drone Foto's\"| Ingest(Ingest Pipeline) Ingest --> |\"Anonimiseren\"| Privacy(AI Anonymizer) Privacy --> |\"Stitching\"| ODM(WebODM) ODM --> DetectAI(AI: Exoten Herkenning) end subgraph Action [\"ğŸšœ Stap 3: Actie\"] DetectAI --> |\"Locatie + Foto + Confidence\"| Dashboard(Ecoloog Dashboard) Dashboard --> Beoordeel{{\"Ecoloog Akkoord?\"}} Beoordeel -- Ja --> Werk(Werkorder Systeem) Werk --> Aannemer(Verwijdering) Aannemer --> |\"Gereed Melding\"| Feedback(Update Historie) end --- ğŸ§© Componenten & Werking 1. De Satelliet Verkenner (Change Detection) Bron: Dagelijkse/Wekelijkse satellietbeelden (via MCP). Analyse: Een AI vergelijkt het beeld van \"Vandaag\" met \"Vorige Week\" en historische data. Trigger: Detecteert afwijkingen in vegetatie-index (NDVI) op watergangen. Output: Een lijst met coÃ¶rdinaten (Hotspots) die nader onderzoek vereisen. 2. De Exoten Analist (AI Recognition) Na de dronevlucht (zie Drone Planner) komen hoge-resolutie beelden beschikbaar. AI Model: Een gespecialiseerd Computer Vision model (bijv. YOLO of EfficientNet) getraind op specifieke soorten (Grote Waternavel, Japanse Duizendknoop). Output: Een GeoJSON feature voor elke detectie: Type: \"Cabomba\" Confidence: 98% Oppervlakte: 15m2 3. Het Werkproces (Afhandeling) De Ecoloog krijgt een taak in zijn werklijst. Hij ziet de satelliet-trigger, de drone-foto en de AI-detectie. Bij akkoord roept de Action Agent het onderhoudssysteem aan. Feedback Loop: Na verwijdering wordt de locatie gemarkeerd als \"Schoon\", maar blijft een \"Risico Locatie\" voor toekomstige satelliet-checks. --- ğŸ›¡ï¸ Privacy & Compliance Privacy: Beelden worden pas aan de ecoloog getoond NA anonimisering van personen/voertuigen. Doelbinding: Beelden worden alleen gebruikt voor waterbeheer (exoten, schouw), niet voor handhaving op andere gebieden zonder apart besluit."
  },
  {
    "title": "FO: AI Video Workflow",
    "category": "ontwerpen",
    "path": "design/ai_video_workflow.md",
    "content": "Technisch Ontwerp: AI Film Productie Pipeline ğŸ¯ Doelstelling Het automatiseren van het filmproductieproces door middel van Generative AI. Dit ontwerp beschrijft hoe we van een script (tekst) naar een volledige video gaan, gebruikmakend van Headless ComfyUI op Kubernetes voor schaalbare, GPU-intensieve generatie. ğŸ—ï¸ Architectuur De pipeline bestaat uit drie hoofdfasen die worden georkestreerd door de Director Agent (Orchestrator). De \"Heavy Lifting\" vindt plaats in de K8s Render Farm. Componenten 1. Director Agent (LLM): Vertaalt het verhaal naar technische prompts (Storyboard). 2. Scene Generator (ComfyUI API): Genereert losse clips op basis van prompts (HunyuanVideo). 3. Voice Generator (TTS API): Genereert gesproken Nederlandse tekst (XTTSv2 / Parkiet). 4. Editor (FFmpeg Worker): Voegt clips, overgangen en audio samen. --- ğŸ¬ De Workflow Stap 1: Audio Eerst (Timing) Voordat we beeld maken, genereert de TTS Service (XTTSv2/Parkiet) de volledige voice-over. Doel: De lengte van de audio bepaalt de exacte lengte van de videosnede. Action: Text -> Audio (.wav). Result: We weten nu: \"Scene 1 duurt 4.2 seconden\". Stap 2: Storyboard (Thumbnails) We genereren voor elke scÃ¨ne Ã©Ã©n statisch beeld (Start Image). Dit is goedkoop en snel (seconden). Model: Flux.1 of SDXL (via ComfyUI). Output: scene_01_thumb.png. Stap 3: Animatic & Approval (Human-in-the-Loop) De Agent maakt een preview (Animatic): de static images gemonteerd op de audio. User Action: De gebruiker ziet het storyboard met geluid. Feedback: \"Scene 2 is te donker\", \"Tekst in Scene 1 loopt niet lekker\". Kostenbesparing: Mislukte ideeÃ«n worden hier gefixt voordat we dure video-GPU minuten verbranden. Stap 4: Video Productie (Hunyuan I2V) Na \"AKKOORD\" start pas de zware renderfarm. Input: De scene_01_thumb.png (als Image-to-Video input) + de duur van Stap 1. Model: HunyuanVideo (Image-to-Video modus). Consistentie: Omdat we een start-image gebruiken, \"morph\" de video exact vanuit het goedgekeurde plaatje. Stap 5: Final Montage De FFmpeg Worker stikt de High-Res videoclips (.mp4) aan elkaar met de reeds goedgekeurde audio (.wav). Stap 6: Levering 1. De eindfilm (final_movie.mp4) wordt beschikbaar gemaakt in de UI. 2. De tijdelijke render-pods schalen automatisch af (Scale-to-Zero). --- ğŸ› ï¸ Technische Specificatie (ComfyUI API Payload) Voorbeeld payload voor Stap 4 (Image-to-Video): json { \"client_id\": \"director_agent_007\", \"prompt\": { \"10\": { \"class_type\": \"LoadImage\", \"inputs\": { \"image\": \"scene_01_thumb.png\" // Goedgekeurde Start Image } }, \"3\": { \"class_type\": \"HunyuanVideoSampler\", \"inputs\": { \"seed\": 849302, \"steps\": 30, \"frame_count\": 125, // 5.0 seconden audio 25 fps \"fps\": 25, \"visual_condition\": [\"10\", 0], // Link naar Start Image \"text_condition\": [\"6\", 0] } }, \"6\": { \"class_type\": \"CLIPTextEncode\", \"inputs\": { \"text\": \"Cyberpunk detective walking, rain...\" } } } } âœ… Voordelen Schaalbaar: Het cluster verdeelt de scÃ¨nes over alle beschikbare GPU's (Parallel Rendering). Automatisering: Geen menselijke interactie nodig; van tekst tot video in Ã©Ã©n pijplijn. Gestandaardiseerd: Door Docker containers is de output, in tegenstelling tot lokale machines, altijd identiek."
  },
  {
    "title": "FO: Drone Planner",
    "category": "ontwerpen",
    "path": "design/drone_planner.md",
    "content": "Functioneel Ontwerp: Drone Route Planner ğŸ¯ Doelstelling Het automatiseren van de inspectievluchten zodat een drone efficiÃ«nt en veilig de betrouwbaarheid van watergangen en hotspots uit satellietdata kan inspecteren. Dit component is de \"logistieke schakel\" tussen de Exoten Detectie en de fysieke uitvoering. --- ğŸ—ï¸ Proces Flow (Planning & Vlucht) mermaid graph TD subgraph Input [\"ğŸ“ Data Input\"] Hotspots(Hotspots uit Satelliet) History(Historische Risico Locaties) Legger(Watergangen Netwerk) NoFly(No-Fly Zones / CTR) end subgraph Calculator [\"ğŸ§® Route Engine\"] Join(Combineer Locaties) Path(Pad optimalisatie - TSP) Constraint(Check: Boven Water?) Join --> Path --> Constraint end subgraph Execution [\"ğŸš Vlucht Uitvoering\"] Constraint --> Plan(Vluchtplan .waypoint) Plan --> Auth(Luchtvaart Autoriteit API) Auth --> |\"Toestemming\"| Dock(Drone Dock) Dock --> Fly(Vlucht) end --- ğŸ§© Componenten & Werking 1. De Slimme Routeplanner (Algoritme) Taak: Bereken de meest efficiÃ«nte route om X inspectiepunten te bezoeken binnen de batterijduur van de drone. Constraints (Veiligheid): Boven Water: De drone moet 95% van de tijd boven water vliegen. Dit minimaliseert het risico voor grond-objecten en privacy. Batterij: Inclusief \"Return to Home\" marge. Logica: Reistijd vs. Inspectietijd. Soms is het sneller om een stuk \"rechtdoor\" te vliegen (over weiland) als dit mag, dan de meanderende rivier te volgen. De planner weegt deze opties. 2. Integratie met Luchtvaart (Compliance) Voordat een plan wordt \"gecommit\", checkt de planner de No-Fly Zones (vliegvelden, natura2000). Indien vereist, dient de planner het vluchtplan digitaal in bij de luchtvaartautoriteit (UTM - Unmanned Traffic Management). 3. De Mission Upload Het gevalideerde plan (Waypoints, Hoogte, Snelheid, Camera Acties) wordt verstuurd naar het docking station. De drone voert de missie volledig autonoom uit. --- ğŸ›¡ï¸ Privacy by Design Vliegroute: Door primair boven water te vliegen, vermijden we tuinen en openbare wegen. Camera: De camera staat standaard in een hoek die \"vooruit/omlaag\" kijkt (Nadir/Oblique) gericht op het water, waardoor de horizon (en dus ramen/mensen in de verte) geminimaliseerd wordt. ğŸ”— Relaties Wordt getriggerd door Exoten Detectie (Hotspots). Levert beelden aan Data Lifecycle (Raw Images)."
  },
  {
    "title": "AI: Druppie Core",
    "category": "ontwerpen",
    "path": "design/druppie_core.md",
    "content": "Druppie Core Specification 1. System Overview Druppie Core is the central orchestrator of the Druppie Platform. It functions as a scalable, Kubernetes-native autonomous agent system designed to plan, build, deploy, and govern software workloads for Water Authorities. It operates on a \"Spec-Driven\" architecture where intents are translated into declarative infrastructure and code. Key Principles: AI-First: All operations are driven by LLM-based reasoning (Planner/Router). Spec-Driven: All artifacts (Code, Infrastructure) are defined as declarative specs (YAML/HCL). Kubernetes-Native: The core itself runs as a container and interacts directly with the K8s API. Compliance-by-Design: Every action is checked against policy engines before execution. Security-by-Design: Every action is checked against security policies before execution. Traceability-by-Design: Every action is logged and stored in a traceability/observability database. Cost-by-Design: Every action is checked against cost policies before execution. Performance-by-Design: Every action is checked against performance policies before execution. Resilience-by-Design: Every action is checked against resilience/resiliency policies before execution. --- 2. Epics & Multi-Agent Work Breakdown Epic 1: Core Reasoning Engine & Orchestration Goal: Establish the \"Brain\" that accepts natural language prompts and formulates execution plans. Story 1.1: Router Agent Implementation (The Hub) Role: Triage incoming requests. Logic: Analyze intent. If \"General Question\" -> Knowledge Bot. If \"Create/Change\" -> Builder Agent. If \"Approval\" -> Governance Agent. Output: Routed Context Object. Story 1.2: Multi-Agent Planner Role: Break down complex requests into steps (Chain of Thought). Capability: Support sequential execution (Step A -> Step B) and parallel execution (Step A & B). Pass skill to agent to ensure it has the right tools and know what it can do. Artifact: ExecutionPlan JSON object. Story 1.3: Context & Memory Management Requirement: Maintain state across multi-turn conversations (Thread ID). Storage: Persist conversation history and working variables in Redis or CosmosDB/Postgres. Story 1.4: Building Block Resolution & Project Scoping Search Strategy: Before planning, query the Registry (Epic 2) to find existing Building Blocks that match the user's intent. Decomposition: If a monolithic request requires multiple distinct capabilities (e.g., \"Web App + Database\"), split it into multiple Building Blocks. Project Rule: Enforce the rule: \"One Building Block = One Project\". If a block is missing, scope a new Project to build it. Epic 2: Registry & Capability Management Goal: Enable the AI to \"know what it can do\" by reading dynamic definitions of Tools and Skills. Story 2.1: Building Block Registry API Function: A read-heavy API to index .md or .yaml definitions from the bouwblokken/ directory. Schema: extract name, capabilities, inputs, outputs from definitions. Story 2.2: Skill Loader Function: Dynamic injection of \"Persona\" instructions (e.g., \"Act as Python Expert\") based on skills/ definitions. Story 2.3: MCP Client (Model Context Protocol) Function: Connect to remote tools running in separate pods (e.g., mcp-weather, mcp-database). Protocol: Support SSE (Server-Sent Events) transport to discover and invoke tools over HTTP. Epic 3: Project Factory & Source Control Goal: Abstract the creation and management of Git repositories. Story 3.1: Gitea Integration Client Action: Create Repo, Branch, Commit, Pull Request. Auth: Token-based authentication against the internal Gitea service. Story 3.2: Scaffolding Engine Action: Generate initial project structure based on templates (e.g., \"New Python Service\" = pyproject.toml, Dockerfile, k8s/deploy.yaml). Spec: driven by Building Block definitions. Epic 4: Build Plane Interface (The Factory) Goal: Trigger and monitor the production of artifacts (Containers). Story 4.1: Tekton Trigger Interface Action: Create PipelineRun objects in Kubernetes. Params: Pass Git Commit Hash and Image Tags. Story 4.2: Async Build Monitoring Action: Watch PipelineRun status. Stream logs to the Core/User upon failure. Notify: Send event when build is Succeeded or Failed. Epic 5: Runtime Operations (Deploy & Run) Goal: Manage the lifecycle of running applications. Story 5.1: GitOps Enforcer (Flux Wrapper) Action: Commit manifest changes to the infra repository (triggering Flux). Logic: Do not touch the cluster directly (kubectl apply) except for ephemeral debug tasks. Always go through Git. Story 5.2: Resource Observation Action: Query K8s API for Pod status, Logs, and Events. Use Case: User asks \"Why is my drone-service crashing?\" -> Core reads kubectl logs. Story 5.3: Automated Verification (Post-Deploy) Action: Run smoke tests and health checks against the newly deployed service. Logic: Verify endpoints (e.g., /health) return 200 OK before marking the task as complete. Story 5.4: Dynamic Documentation & Cataloging Action: Update the internal S"
  },
  {
    "title": "AI: Druppie UI",
    "category": "ontwerpen",
    "path": "design/druppie_ui.md",
    "content": "Druppie UI Specification 1. System Overview Druppie UI is the visual control plane for the Druppie Platform. It allows users to interact with the AI Core, visualize generated code, manage projects via a Kanban board, and approve sensitive actions. It connects to the Druppie Core via REST, Server-Sent Events (SSE), and WebSockets. Key Principles: Human-in-the-Control-Loop: The UI is designed to give users insight and control over the AI's autonomous actions. Real-Time: State changes in the Core (e.g., Build finished, Plan updated) are reflected instantly. Transparency: No \"hidden\" AI magic; always show the Plan, the Code, and the Logs. 2. Technical Stack Framework: Next.js 14+ (App Router). Styling: Tailwind CSS (adhering to Company Style Guide). State Management: React Query (Server State) + Zustang (Client State). Visualization: Code: monaco-editor or prismjs. Diagrams: mermaid.js. Markdown: react-markdown. Protocol: Chat: SSE (Server-Sent Events) for streaming tokens. Events: WebSockets for Kanban/Status updates. --- 3. Epics & User Stories Epic 1: Conversational Interface (Chat) Goal: Provide a rich, IDE-like chat experience for instructing the AI. Story 1.1: Streaming Response User: \"Build me a new drone service.\" UI: Renders text token-by-token. Supports Markdown rendering (tables, headers, bold). Story 1.2: Interactive Artifacts Function: If the AI mentions a file (e.g., \"I updated deployment.yaml\"), the filename is a clickable link that opens the Code Viewer side-panel. Story 1.3: Thread Management Function: Users can create new threads, rename them, and view history. History is fetched from Core. Epic 2: Visual Code Explorer (The \"Lens\") Goal: Allow users to verify the AI's work without leaving the browser. Story 2.1: File Tree Navigator View: A VSCode-like file tree representing the target Git repository's structure. Source: Fetched live from Gitea or the Core's \"Temporary Workspace\". Story 2.2: Code Editor/Viewer Function: Read-only view of files with Syntax Highlighting (support for Go, Python, YAML, Markdown). Story 2.3: Diff Viewer Use Case: When the AI proposes changes (HITL), show a side-by-side Diff (Red/Green) of Before vs After. Action: \"Approve\" button executes the change; \"Reject\" allows commenting feedback. Epic 3: Project Management (Kanban) Goal: Visualize the Execution Plan as manageable tasks. Story 3.1: Live Board Columns: Planning, In Progress, Review, Done. Sync: When the Core moves a step to \"Completed\", the card moves to \"Done\" automatically via WebSocket. Story 3.2: Drag-and-Drop Control Action: User drags a card from \"In Progress\" back to \"Planning\". Effect: Sends a signal to Core to STOP execution and replan that step. Story 3.3: Project Context Selector View: Dropdown menu in the Sidebar/Header to switch the active Project. Action: \"Create New Project\" button opens a modal to define Project Name and Key (e.g., drone-service). Effect: Filters the Chat History, Kanban Board, and File Browser to the selected Project scope. Epic 4: Registry Explorer Goal: Browse the available capabilities of the platform. Story 4.1: Building Block Catalog View: Grid view of cards for each Building Block (e.g., \"Postgres\", \"Redis\"). Detail: Clicking a card shows its inputs, outputs, and dependencies (rendered from the Markdown definition). Story 4.2: Skill & Persona Viewer View: List active Agents and their Skills. Admin: (If Admin) specific buttons to enable/disable specific skills. Epic 5: Governance Dashboard Goal: Visibility into compliance and security. Story 5.1: Approval Queue View: A dedicated \"Inbox\" for pending requests (Deployment to Prod, Public S3 bucket creation). Action: Approve/Deny with reason. Story 5.2: Compliance Reports View: Tabular list of projects and their latest Compliance Scan status (Pass/Fail). Epic 6: Admin Control Plane Goal: Manage the platform's configuration, users, and health. Story 6.1: IAM & RBAC Management View: Manage Users, Groups, and Role Mappings (UI for Keycloak). Action: Assign \"Platform Admin\" or \"Developer\" roles to users. Story 6.2: System Health Monitor View: Real-time dashboard of Core Services (Router, Planner, Registry). Metric: CPU/Memory usage of Agent pods. Story 6.3: Audit Log Viewer View: Searchable table of all actions taken by Agents and Users. Filter: Filter by UserID, ProjectID, or Timestamp. Detail: View the exact differences (diffs) applied during an action. Story 6.4: Configuration Manager View: Edit Global Settings (e.g., \"Default LLM Model\", \"Max Token Limit\"). Action: Upload new Corporate Guidelines (PDF) to the Compliance Engine. Story 6.5: Building Block Manager View: Master list of all registered Building Blocks (e.g., \"Postgres\", \"Redis\"). Action: Toggle Enable/Disable. Disabled blocks cannot be selected by the Planner. Detail: View metadata, version history, and dependency graph. Story 6.6: MCP Server Manager View: List of connected Model Context Protocol (MCP) servers. Action: Register new MCP endpoint (URL + API Key). Stat"
  },
  {
    "title": "Overview",
    "category": "scripts",
    "path": "script/overview.md",
    "content": "Scripts & Automatisering Hier bewaren we herbruikbare scripts en quick-start commando's die gebruikt kunnen worden voor beheer, setup, of demo doeleinden. ğŸš€ Hoofdmenu Het makkelijkste startpunt is de Master CLI in de root: ./druppie.sh: Interactief menu voor installatie, bootstrap en beheer. ğŸ“‚ Scripts per Categorie ğŸ—ï¸ Infrastructuur install_k8s.sh: Installeert Kubernetes (RKE2 voor Linux/Prod, k3d voor Mac/Dev). uninstall_k8s.sh: Verwijdert de Kubernetes cluster. ğŸ“¦ Platform Services setup_dev_env.sh: Base Layer. Installeert Flux (GitOps), Kyverno (Policy), Tekton (CI) en Kong (Gateway). setup_iam.sh: IAM. Installeert Keycloak (Identity Provider). setup_observability.sh: Observability. Installeert de LGTM stack (Loki, Grafana, Tempo, Prometheus). ğŸ› ï¸ Applicatie Services setup_data_tools.sh: Data. Installeert Gitea (Git) en MinIO (S3 Lake). setup_databases.sh: Storage. Installeert PostgreSQL (SQL/GIS) en Qdrant (Vector). setup_security_tools.sh: Security. Installeert Trivy (Scanning) en SonarQube (Quality). setup_gis.sh: GIS. Installeert GeoServer (Maps), GeoNode (Portal) en NodeODM (Drone). ğŸ§ª Demo & Simulatie simulate_user_login.py (Concept) trigger_drone_flow.sh (Concept) ğŸ¤– Automatisering Deze scripts zijn idempotent en kunnen worden aangeroepen door: 1. Engineers: Via druppie.sh of direct. 2. Builder Agent: Om omgevingen te provisionen. 3. Argo Workflows: Als onderdeel van een grotere keten."
  },
  {
    "title": "Druppie CLI",
    "category": "scripts",
    "path": "druppie.sh",
    "content": "!/bin/bash Druppie Master CLI Interface voor alle beheer taken binnen het Druppie Platform. BASE_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\" SCRIPT_DIR=\"$BASE_DIR/script\" COLOR_CYAN='\\033[0;36m' COLOR_NC='\\033[0m' SECRETS_FILE=\"$BASE_DIR/.secrets\" function load_secrets() { if [ ! -f \"$SECRETS_FILE\" ]; then touch \"$SECRETS_FILE\" fi source \"$SECRETS_FILE\" } function get_or_create_secret() { local key=$1 local existing_value=${!key} if [ -z \"$existing_value\" ]; then Generate a random 16-char secret local new_secret=$(openssl rand -hex 8) echo \"$key=$new_secret\" >> \"$SECRETS_FILE\" export $key=$new_secret else export $key=$existing_value fi } function ensure_secrets() { Define required secrets for each installer get_or_create_secret \"DRUPPIE_K8S_TOKEN\" k8s get_or_create_secret \"DRUPPIE_GITEA_PASS\" data get_or_create_secret \"DRUPPIE_MINIO_PASS\" data get_or_create_secret \"DRUPPIE_SONAR_PASS\" security get_or_create_secret \"DRUPPIE_KEYCLOAK_PASS\" iam get_or_create_secret \"DRUPPIE_GRAFANA_PASS\" observability get_or_create_secret \"DRUPPIE_POSTGRES_PASS\" database get_or_create_secret \"DRUPPIE_QDRANT_KEY\" database get_or_create_secret \"DRUPPIE_GEOSERVER_PASS\" gis Reload to be sure source \"$SECRETS_FILE\" } function show_banner() { clear echo -e \"${COLOR_CYAN}\" echo \" _____ _ \" echo \" | __ \\ (_) \" echo \" | | | |_ __ _ _ _ __ _ __ _ ___ \" echo \" | | | | '__| | | | '_ \\| '_ \\ |/ _ \\\\\" echo \" | |__| | | | |_| | |_) | |_) | | __/\" echo \" |_____/|_| \\__,_| .__/| .__/|_|\\___|\" echo \" | | | | \" echo \" |_| |_| \" echo -e \"${COLOR_NC}\" echo \" v1.0 - Platform CLI\" echo \"\" } function menu() { show_banner echo \"Beschikbare Acties:\" echo \"-------------------\" echo \"1) â˜¸ï¸ Install Kubernetes (RKE2/k3d)\" echo \"2) ğŸš€ Bootstrap Platform (Base Layer)\" echo \"3) ğŸ’¾ Install Data Services (Gitea + MinIO)\" echo \"4) ğŸ›¡ï¸ Install Security Services (Trivy + SonarQube)\" echo \"5) ğŸ”‘ Install IAM (Keycloak)\" echo \"6) ğŸ‘ï¸ Install Observability (LGTM Stack)\" echo \"7) ğŸ—„ï¸ Install Databases (Postgres + Qdrant)\" echo \"8) ğŸŒ Install GIS Services (GeoServer + WebODM)\" echo \"9) ğŸ“ Genereer Documentatie (Living Docs)\" echo \"10) ğŸ§¹ Compliance Audit (Trigger Check)\" echo \"11) ğŸ—‘ï¸ Uninstall Kubernetes\" echo \"12) ğŸ“œ List Installation History\" echo \"q) Quit\" echo \"\" read -p \"Maak een keuze: \" CHOICE case $CHOICE in 1) handle_k8s_install ;; 2) echo \"Bootstrapping Platform...\" bash \"$SCRIPT_DIR/setup_dev_env.sh\" read -p \"Druk op Enter...\" menu ;; 3) echo \"Installing Data Services...\" bash \"$SCRIPT_DIR/setup_data_tools.sh\" read -p \"Druk op Enter...\" menu ;; 4) echo \"Installing Security Services...\" bash \"$SCRIPT_DIR/setup_security_tools.sh\" read -p \"Druk op Enter...\" menu ;; 5) echo \"Installing IAM Services...\" bash \"$SCRIPT_DIR/setup_iam.sh\" read -p \"Druk op Enter...\" menu ;; 6) echo \"Installing Observability Stack...\" bash \"$SCRIPT_DIR/setup_observability.sh\" read -p \"Druk op Enter...\" menu ;; 7) echo \"Installing Database Services...\" bash \"$SCRIPT_DIR/setup_databases.sh\" read -p \"Druk op Enter...\" menu ;; 8) echo \"Installing GIS Services...\" bash \"$SCRIPT_DIR/setup_gis.sh\" read -p \"Druk op Enter...\" menu ;; 9) echo \"Building documentation... (TODO: Link to Sphinx/Docs script)\" read -p \"Druk op Enter...\" menu ;; 10) echo \"Running Compliance Scan... (TODO: Link to Trivy script)\" read -p \"Druk op Enter...\" menu ;; 11) handle_uninstall ;; 12) echo \"\" echo \"Installation History:\" echo \"---------------------\" if [ -f \"$BASE_DIR/.druppie_history\" ]; then cat \"$BASE_DIR/.druppie_history\" else echo \"No history found.\" fi echo \"\" read -p \"Druk op Enter...\" menu ;; q) echo \"Bye!\" exit 0 ;; ) echo \"Ongeldige keuze.\" sleep 1 menu ;; esac } function handle_k8s_install() { echo \"\" echo \"De Kubernetes installer (install_k8s.sh) is bedoeld voor Linux Hosts.\" echo \"Draai je dit lokaal op macOS? Dan moet je het script kopiÃ«ren naar je server.\" echo \"\" echo \"Locatie: $SCRIPT_DIR/install_k8s.sh\" echo \"\" echo \"Opties:\" echo \"1) Ik zit op Linux, draai direct.\" echo \"2) Toon SCP commando (Upload naar remote).\" echo \"3) Terug\" read -p \"Keuze: \" K8S_OPT if [ \"$K8S_OPT\" == \"1\" ]; then sudo bash \"$SCRIPT_DIR/install_k8s.sh\" elif [ \"$K8S_OPT\" == \"2\" ]; then read -p \"Remote Server (user@ip): \" REMOTE echo \"Running: scp $SCRIPT_DIR/install_k8s.sh $REMOTE:~/\" scp \"$SCRIPT_DIR/install_k8s.sh\" \"$REMOTE:~/\" echo \"\" echo \"Klaar! Log nu in op $REMOTE en draai: sudo bash ./install_k8s.sh\" read -p \"Enter...\" fi menu } function handle_uninstall() { echo \"\" echo \"Uninstalling Kubernetes Cluster...\" if [[ \"$(uname)\" == \"Darwin\" ]]; then macOS: Run directly (likely k3d) bash \"$SCRIPT_DIR/uninstall_k8s.sh\" else Linux: Needs sudo sudo bash \"$SCRIPT_DIR/uninstall_k8s.sh\" fi read -p \"Druk op Enter...\" menu } Start load_secrets ensure_secrets menu"
  },
  {
    "title": "Install Kubernetes (RKE2/k3d)",
    "category": "scripts",
    "path": "script/install_k8s.sh",
    "content": "!/bin/bash Druppie Kubernetes Installer (RKE2) Supports: Server (Control Plane) and Workstation (Single Node Dev) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_RED='\\033[0;31m' COLOR_NC='\\033[0m' Log File Location (Project Root) LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[DRUPPIE]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | INSTALL | Kubernetes | $1\" >> \"$LOG_FILE\" } function error() { echo -e \"${COLOR_RED}[ERROR]${COLOR_NC} $1\" exit 1 } Check Root (Only required for RKE2/Linux) IS_ROOT=false if [[ $EUID -eq 0 ]]; then IS_ROOT=true fi OS=\"$(uname)\" Selection Menu echo -e \"${COLOR_GREEN}Select Installation Profile:${COLOR_NC}\" echo \"1) Workstation (RKE2 - Single Node - Linux Only)\" echo \"2) Server (RKE2 - Control Plane - Linux Only)\" echo \"3) Local Dev (k3d - Docker Required - macOS/Linux)\" read -p \"Choice [1-3]: \" PROFILE_OPT Validation if [[ \"$PROFILE_OPT\" == \"1\" || \"$PROFILE_OPT\" == \"2\" ]]; then if [[ \"$OS\" == \"Darwin\" ]]; then error \"RKE2 (Options 1/2) is only supported on Linux. Use Option 3 (k3d) for macOS.\" fi if [ \"$IS_ROOT\" = false ]; then error \"RKE2 installation requires root (sudo).\" fi fi if [ \"$PROFILE_OPT\" == \"3\" ]; then log \"Checking Docker...\" if ! command -v docker &> /dev/null; then error \"Docker is not installed or not in PATH.\" fi if ! docker info &> /dev/null; then error \"Docker daemon is not running.\" fi log \"Checking/Installing k3d...\" if ! command -v k3d &> /dev/null; then if [[ \"$OS\" == \"Darwin\" ]]; then log \"Installing k3d via Homebrew...\" brew install k3d else log \"Installing k3d via Script...\" curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash fi else log \"k3d is already installed.\" fi log \"Checking/Installing kubectl...\" if ! command -v kubectl &> /dev/null; then if [[ \"$OS\" == \"Darwin\" ]]; then log \"Installing kubectl via Homebrew...\" brew install kubectl else log \"Installing kubectl...\" curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x kubectl sudo mv kubectl /usr/local/bin/ fi else log \"kubectl is already installed.\" fi log \"Creating/Updating Cluster 'druppie-dev'...\" Create cluster with Ingress ports mapped k3d cluster create druppie-dev \\ --api-port 6443 \\ -p \"80:80@loadbalancer\" \\ -p \"443:443@loadbalancer\" \\ --k3s-arg \"--disable=traefik@server:0\" \\ --wait log \"Cluster Ready! ğŸš€\" log \"Run: kubectl get nodes\" log_history \"k3d (druppie-dev)\" exit 0 fi RKE2 Logic (Linux Only) RKE2_CONFIG_DIR=\"/etc/rancher/rke2\" CONFIG_FILE=\"$RKE2_CONFIG_DIR/config.yaml\" mkdir -p $RKE2_CONFIG_DIR if [ \"$PROFILE_OPT\" == \"1\" ]; then log \"Configuring for WORKSTATION...\" Workstation: Minimal resource usage cat <<EOF > $CONFIG_FILE write-kubeconfig-mode: \"0644\" tls-san: - \"druppie.local\" - \"127.0.0.1\" disable: - rke2-ingress-nginx profile: \"cis-1.23\" EOF elif [ \"$PROFILE_OPT\" == \"2\" ]; then log \"Configuring for SERVER (Production)...\" if [ -z \"$CLUSTER_TOKEN\" ]; then if [ ! -z \"$DRUPPIE_K8S_TOKEN\" ]; then CLUSTER_TOKEN=\"$DRUPPIE_K8S_TOKEN\" log \"Using Token from Environment.\" else read -p \"Enter Cluster Token (secret): \" CLUSTER_TOKEN fi fi read -p \"Enter Generic S3 Endpoint (for etcd snapshots) [optional]: \" S3_ENDPOINT cat <<EOF > $CONFIG_FILE write-kubeconfig-mode: \"0644\" token: \"$CLUSTER_TOKEN\" cni: \"canal\" profile: \"cis-1.23\" selinux: true kube-apiserver-arg: - \"audit-log-path=/var/lib/rancher/rke2/server/audit.log\" - \"audit-policy-file=/etc/rancher/rke2/audit-policy.yaml\" EOF cat <<EOF > $RKE2_CONFIG_DIR/audit-policy.yaml apiVersion: audit.k8s.io/v1 kind: Policy rules: - level: Metadata EOF if [ ! -z \"$S3_ENDPOINT\" ]; then echo \"etcd-s3: true\" >> $CONFIG_FILE echo \"etcd-s3-endpoint: $S3_ENDPOINT\" >> $CONFIG_FILE fi fi Install RKE2 log \"Downloading and Installing RKE2...\" curl -sfL https://get.rke2.io | sh - Enable & Start log \"Starting RKE2 Server...\" systemctl enable rke2-server.service systemctl start rke2-server.service Symlink kubectl for convenience if [ ! -f /usr/local/bin/kubectl ]; then log \"Symlinking RKE2 kubectl to /usr/local/bin/kubectl...\" ln -s /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl fi Validating log \"Waiting for Node to be Ready...\" export KUBECONFIG=/etc/rancher/rke2/rke2.yaml for i in {1..30}; do if /var/lib/rancher/rke2/bin/kubectl get nodes &> /dev/null; then break fi sleep 2 done /var/lib/rancher/rke2/bin/kubectl get nodes log \"Installation Complete! ğŸš€\" log \"Kubeconfig location: /etc/rancher/rke2/rke2.yaml\" if [ \"$PROFILE_OPT\" == \"1\" ]; then log \"You can copy this to ~/.kube/config on your host.\" log_history \"RKE2 (Workstation)\" elif [ \"$PROFILE_OPT\" == \"2\" ]; then log_history \"RKE2 (Server)\" fi"
  },
  {
    "title": "Platform Bootstrap (Base)",
    "category": "scripts",
    "path": "script/setup_dev_env.sh",
    "content": "!/bin/bash Druppie Dev Environment Bootstrap Installs the Platform Base Layer (Flux, Kyverno, Tekton, Kong) into the current cluster. set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Platform | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" echo \"ğŸ’¡ Run 'Install Kubernetes' first or check your KUBECONFIG.\" exit 1 fi log \"Connected to $(kubectl config current-context).\" 2. Install Helm (if missing) if ! command -v helm &> /dev/null; then log \"Installing Helm...\" curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash fi 3. Add Repos log \"Adding Helm Repositories...\" helm repo add fluxcd-community https://fluxcd-community.github.io/helm-charts helm repo add kyverno https://kyverno.github.io/kyverno helm repo add tekton-triggers https://cdfoundation.github.io/tekton-triggers-charts helm repo add kong https://charts.konghq.com helm repo up 4. Install Flux CD (GitOps Engine) log \"Installing Flux CD...\" helm upgrade --install flux-operator fluxcd-community/flux2 \\ --namespace flux-system --create-namespace \\ --wait log_history \"Flux CD Installed\" 5. Install Kyverno (Policy Engine) log \"Installing Kyverno...\" helm upgrade --install kyverno kyverno/kyverno \\ --namespace kyverno --create-namespace \\ --set admissionController.replicas=1 \\ --wait log_history \"Kyverno Installed\" 6. Install Tekton (Build Engine) Tekton is complex via Helm, often easier via kubectl apply for base log \"Installing Tekton Pipelines...\" kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml log_history \"Tekton Pipelines Installed\" 7. Install Kong (API Gateway) log \"Installing Kong Gateway (Ingress)...\" helm upgrade --install kong kong/kong \\ --namespace kong --create-namespace \\ --set ingressController.installCRDs=false \\ --set proxy.type=LoadBalancer \\ --wait log_history \"Kong Gateway Installed\" 8. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… Platform Base Layer Installed Successfully!\" echo \"-----------------------------------------------\" echo \" - Flux CD (GitOps)\" echo \" - Kyverno (Policies)\" echo \" - Tekton (CI)\" echo \" - Kong (Gateway)\" echo \"\" echo \"You are ready to deploy applications.\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Data Tools (Gitea/MinIO)",
    "category": "scripts",
    "path": "script/setup_data_tools.sh",
    "content": "!/bin/bash Druppie Data & Versioning Setup Installs Gitea (Version Control) and MinIO (Data Lake) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | DataTools | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add gitea-charts https://dl.gitea.io/charts/ helm repo add minio https://charts.min.io/ helm repo up 3. Install Gitea (Lightweight Git Server) log \"Installing Gitea...\" helm upgrade --install gitea gitea-charts/gitea \\ --namespace gitea --create-namespace \\ --set gitea.admin.username=druppie_admin \\ --set gitea.admin.password=${DRUPPIE_GITEA_PASS} \\ --set persistence.size=1Gi \\ --wait log_history \"Gitea Installed\" 4. Install MinIO (S3 Compatible Storage) log \"Installing MinIO...\" helm upgrade --install minio minio/minio \\ --namespace minio --create-namespace \\ --set rootUser=admin \\ --set rootPassword=${DRUPPIE_MINIO_PASS} \\ --set persistence.size=5Gi \\ --wait log_history \"MinIO Installed\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… Data Services Installed!\" echo \"--------------------------\" echo \" - Gitea: http://gitea-http.gitea.svc.cluster.local:3000\" echo \" User: druppie_admin\" echo \" Pass: ${DRUPPIE_GITEA_PASS}\" echo \"\" echo \" - MinIO: http://minio.minio.svc.cluster.local:9000\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_MINIO_PASS}\" echo \"\" echo \"âš ï¸ Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/gitea-http -n gitea 3000:3000\" echo \" kubectl port-forward svc/minio -n minio 9000:9000\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "IAM Setup (Keycloak)",
    "category": "scripts",
    "path": "script/setup_iam.sh",
    "content": "!/bin/bash Druppie IAM Setup Installs Keycloak (Identity Provider) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | IAM | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add bitnami https://charts.bitnami.com/bitnami helm repo up 3. Install Keycloak log \"Installing Keycloak...\" helm upgrade --install keycloak bitnami/keycloak \\ --namespace iam --create-namespace \\ --set auth.adminUser=admin \\ --set auth.adminPassword=${DRUPPIE_KEYCLOAK_PASS} \\ --set production=false \\ --set proxy=edge \\ --set service.type=LoadBalancer \\ --wait log_history \"Keycloak Installed\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… IAM Services Installed!\" echo \"-------------------------\" echo \" - Keycloak: http://keycloak.iam.svc.cluster.local:80\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_KEYCLOAK_PASS}\" echo \"\" echo \"âš ï¸ Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/keycloak -n iam 8080:80\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Observability (LGTM)",
    "category": "scripts",
    "path": "script/setup_observability.sh",
    "content": "!/bin/bash Druppie Observability Setup Installs the LGTM Stack (Loki, Grafana, Tempo, Mimir/Prometheus) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Observability | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add grafana https://grafana.github.io/helm-charts helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo up 3. Install Prometheus (Metrics) log \"Installing Prometheus...\" helm upgrade --install prometheus prometheus-community/prometheus \\ --namespace observability --create-namespace \\ --set alertmanager.enabled=false \\ --set server.persistentVolume.size=5Gi \\ --wait log_history \"Prometheus Installed\" 4. Install Loki (Logs) log \"Installing Loki (Monolithic mode for Dev)...\" helm upgrade --install loki grafana/loki-stack \\ --namespace observability --create-namespace \\ --set fluent-bit.enabled=true \\ --set promtail.enabled=true \\ --wait log_history \"Loki & Promtail Installed\" 5. Install Grafana (Dashboarding) log \"Installing Grafana...\" helm upgrade --install grafana grafana/grafana \\ --namespace observability --create-namespace \\ --set adminPassword=${DRUPPIE_GRAFANA_PASS} \\ --set service.type=LoadBalancer \\ --set persistence.enabled=true \\ --set persistence.size=2Gi \\ --wait log_history \"Grafana Installed\" 6. Install Tempo (Tracing - optional/lightweight) log \"Installing Tempo...\" helm upgrade --install tempo grafana/tempo \\ --namespace observability --create-namespace \\ --set persistence.enabled=false \\ --wait log_history \"Tempo Installed\" 7. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… Observability Stack (LGTM) Installed!\" echo \"---------------------------------------\" echo \" - Grafana: http://grafana.observability.svc.cluster.local:80\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_GRAFANA_PASS}\" echo \" Data: Prometheus (Metrics), Loki (Logs), Tempo (Traces)\" echo \"\" echo \"âš ï¸ Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/grafana -n observability 3000:80\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Databases (Pg/Qdrant)",
    "category": "scripts",
    "path": "script/setup_databases.sh",
    "content": "!/bin/bash Druppie Database Services Setup Installs PostgreSQL (Relational/GIS) and Qdrant (Vector) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Databases | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add qdrant https://qdrant.github.io/qdrant-helm helm repo add bitnami https://charts.bitnami.com/bitnami helm repo up 3. Install Qdrant (Vector DB for AI) log \"Installing Qdrant Vector DB...\" helm upgrade --install qdrant qdrant/qdrant \\ --namespace databases --create-namespace \\ --set replicaCount=1 \\ --set persistence.size=2Gi \\ --set apiKey=${DRUPPIE_QDRANT_KEY} \\ --wait log_history \"Qdrant Installed\" 4. Install PostgreSQL with PostGIS (Geo DB) log \"Installing PostgreSQL + PostGIS...\" We use standard Postgres chart. PostGIS usually requires a specific image or extension enable. For simplicity, we assume standard here, but in real setup we'd select a postgis image. helm upgrade --install postgres bitnami/postgresql \\ --namespace databases --create-namespace \\ --set global.postgresql.auth.postgresPassword=${DRUPPIE_POSTGRES_PASS} \\ --set primary.persistence.size=5Gi \\ --set image.tag=\"16-debian-12\" \\ --wait Note: Enabling PostGIS extension is usually a 'CREATE EXTENSION postgis;' command after boot. We log this as a reminder. log_history \"PostgreSQL Installed\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… Database Services Installed!\" echo \"------------------------------\" echo \" - Qdrant: http://qdrant.databases.svc.cluster.local:6333\" echo \" API Key: ${DRUPPIE_QDRANT_KEY}\" echo \"\" echo \" - Postgres: postgres-postgresql.databases.svc.cluster.local:5432\" echo \" User: postgres\" echo \" Pass: ${DRUPPIE_POSTGRES_PASS}\" echo \"\" echo \"âš ï¸ Note: Enable PostGIS manually if needed:\" echo \" kubectl exec -it -n databases svc/postgres-postgresql -- psql -U postgres -c 'CREATE EXTENSION IF NOT EXISTS postgis;'\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "GIS Tools (GeoServer)",
    "category": "scripts",
    "path": "script/setup_gis.sh",
    "content": "!/bin/bash Druppie GIS Services Setup Installs GeoServer (Map Server) and WebODM (Drone Mapping) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | GIS | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add geoserver https://geosolutions-it.github.io/helm-charts/ GeoNode often doesn't have a stable single Helm chart, we use a simple k8s manifest approach for this simplified setup. helm repo up 3. Create Namespace kubectl create namespace gis --dry-run=client -o yaml | kubectl apply -f - 4. Install GeoServer log \"Installing GeoServer...\" helm upgrade --install geoserver geoserver/geoserver \\ --namespace gis \\ --set service.type=LoadBalancer \\ --wait log_history \"GeoServer Installed\" 5. Install GeoNode (GIS Portal) GeoNode requires Django, Celery, Postgres, and GeoServer integration. This simplifies it to the Core Django app linked to the Postgres we installed earlier (conceptually). log \"Installing GeoNode (Portal)...\" cat <<EOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: geonode namespace: gis spec: replicas: 1 selector: matchLabels: app: geonode template: metadata: labels: app: geonode spec: containers: - name: geonode image: geonode/geonode:4.1.3 env: - name: DATABASE_URL value: \"postgres://postgres:${DRUPPIE_POSTGRES_PASS}@postgres-postgresql.databases.svc.cluster.local:5432/geonode\" - name: GEOSERVER_PUBLIC_LOCATION value: \"http://geoserver.gis.svc.cluster.local:8080/geoserver/\" ports: - containerPort: 8000 --- apiVersion: v1 kind: Service metadata: name: geonode namespace: gis spec: selector: app: geonode ports: - port: 80 targetPort: 8000 type: LoadBalancer EOF log_history \"GeoNode Installed\" 5. Install WebODM (Lightning/NodeODM) WebODM is complex on K8s (Storage/Postgres/Redis). For this 'Light' script, we deploy a simplified NodeODM (processing node) and references. In a real PROD setup this would be full WebODM stack. log \"Installing NodeODM (Drone Processing Engine)...\" Using raw manifest for simplicity as no official stable Helm chart exists for simple setups cat <<EOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: nodeodm namespace: gis spec: replicas: 1 selector: matchLabels: app: nodeodm template: metadata: labels: app: nodeodm spec: containers: - name: nodeodm image: opendronemap/nodeodm:latest ports: - containerPort: 3000 --- apiVersion: v1 kind: Service metadata: name: nodeodm namespace: gis spec: selector: app: nodeodm ports: - port: 3000 targetPort: 3000 type: ClusterIP EOF log_history \"NodeODM Installed\" 6. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… GIS Services Installed!\" echo \"-------------------------\" echo \" - GeoServer: http://geoserver.gis.svc.cluster.local:8080/geoserver\" echo \" User: admin\" echo \" Pass: geoserver\" echo \"\" echo \" - GeoNode: http://geonode.gis.svc.cluster.local:80\" echo \" (Map Portal - Requires DB)\" echo \"\" echo \" - NodeODM: http://nodeodm.gis.svc.cluster.local:3000\" echo \" (Drone Processing API)\" echo \"\" echo \"âš ï¸ Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/geoserver -n gis 8080:8080\" echo \" kubectl port-forward svc/geonode -n gis 8000:80\" echo \" kubectl port-forward svc/nodeodm -n gis 3000:3000\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Security Tools (Trivy)",
    "category": "scripts",
    "path": "script/setup_security_tools.sh",
    "content": "!/bin/bash Druppie Security Services Setup Installs Trivy (Scanning) and SonarQube (Static Analysis) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Security | $1\" >> \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info &> /dev/null; then echo \"âŒ Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add aqua https://aquasecurity.github.io/helm-charts/ helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube helm repo up 3. Install Trivy Operator (Continuous Scanning) log \"Installing Trivy Operator...\" helm upgrade --install trivy-operator aqua/trivy-operator \\ --namespace security-system --create-namespace \\ --set compliance.cron=\"0 /6 \" \\ --wait log_history \"Trivy Operator Installed\" 4. Install SonarQube (Code Quality) log \"Installing SonarQube...\" helm upgrade --install sonarqube sonarqube/sonarqube \\ --namespace security-system --create-namespace \\ --set edition=community \\ --set persistence.enabled=true \\ --set persistence.size=5Gi \\ --set service.type=ClusterIP \\ --wait log_history \"SonarQube Installed\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"âœ… Security Services Installed!\" echo \"------------------------------\" echo \" - Trivy: Background Operator (Check 'trivy-operator' pod)\" echo \" - SonarQube: http://sonarqube-sonarqube.security-system.svc.cluster.local:9000\" echo \" User: admin\" echo \" Pass: admin (Requires change on first login)\" echo \"\" echo \"âš ï¸ Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/sonarqube-sonarqube -n security-system 9000:9000\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Uninstall Kubernetes",
    "category": "scripts",
    "path": "script/uninstall_k8s.sh",
    "content": "!/bin/bash Druppie Uninstaller Removes RKE2 or k3d clusters set -e COLOR_RED='\\033[0;31m' COLOR_NC='\\033[0m' Log File Location (Project Root) LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_RED}[UNINSTALL]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | UNINSTALL | Kubernetes | $1\" >> \"$LOG_FILE\" } echo \"Which Kubernetes distribution do you want to remove?\" echo \"1) RKE2 (Linux Service)\" echo \"2) k3d (Docker Container)\" read -p \"Choice [1-2]: \" OPT if [ \"$OPT\" == \"1\" ]; then RKE2 Uninstall if [[ $EUID -ne 0 ]]; then echo \"RKE2 uninstall requires root.\" exit 1 fi log \"Stopping RKE2...\" systemctl stop rke2-server systemctl disable rke2-server log \"Running RKE2 Uninstall Script...\" if [ -f /usr/local/bin/rke2-uninstall.sh ]; then /usr/local/bin/rke2-uninstall.sh else echo \"Uninstall script not found. Was RKE2 installed?\" exit 1 fi log \"RKE2 removed.\" log_history \"RKE2\" elif [ \"$OPT\" == \"2\" ]; then k3d Uninstall log \"Deleting 'druppie-dev' cluster...\" if command -v k3d &> /dev/null; then k3d cluster delete druppie-dev log \"Cluster deleted.\" log_history \"k3d (druppie-dev)\" else echo \"k3d binary not found.\" fi else echo \"Invalid choice.\" fi"
  },
  {
    "title": "Project Readme",
    "category": "general",
    "path": "README.md",
    "content": "Druppie â€“ Spec-Driven AI Architectuur Druppie is een geavanceerd enterprise platform voor Spec-Driven AI en Human-in-the-Loop automatisering. Dit project beschrijft hoe AI-agents, compliance-regels en menselijke interactie samenkomen om software veilig, schaalbaar en consistent te bouwen en te beheren. De focus ligt op het automatiseren van de volledige lifecycle binnen een overheidscontext (Waterschap/Gemeente), met zware nadruk op Security, Privacy (GDPR) en Compliance (BIO/NIS2/AI Act). > One-Stop-Shop: Deze repository bevat zowel de architectuurdocumentatie als de Infrastructure-as-Code (IaC) scripts om het platform volledig op te zetten. --- ğŸš€ Aan de slag met de Architectuur De volledige architectuur is interactief te verkennen. 1. Open index.html in je browser. 2. Gebruik het dashboard om door de verschillende lagen (Bouwblokken, Skills, Runtime) te navigeren. 3. Draai simulaties (Scenarios) om de interactie tussen componenten te visualiseren. ğŸš€ Snel Starten met het Platform De makkelijkste manier om te beginnen is via de Master CLI: bash ./druppie.sh Dit interactieve menu geeft toegang tot: 1. â˜¸ï¸ Installatie: Kubernetes (RKE2 voor Prod, k3d voor Dev). 2. ğŸ—ï¸ Bootstrap: Platform base layer (Flux, Kyverno, Tekton, Kong). 3. ğŸ“¦ Services: One-click setup voor Gitea, Keycloak, Prometheus, GeoServer, etc. 4. ğŸ“š Documentatie: Genereer de \"Living Documentation\". --- ğŸ“‚ Projectstructuur De repository is opgebouwd uit verschillende lagen: 1. ğŸ§± Bouwblokken De lego-stenen van het platform. Definities van tools en componenten: Security: Trivy, SonarQube. Data: MinIO, Gitea, Qdrant (Vector DB). GIS: GeoServer, PostGIS, WebODM, GeoNode. Observability: LGTM Stack (Loki, Grafana, Tempo, Prometheus). 2. ğŸ—ï¸ Build Plane De \"Agent Factory\". Hier wordt code omgezet in veilige artifacts: Builder Agent: AI die code, tests en docs genereert. Automated Testing: Unit, Integration, E2E in Tekton pipelines. Secure Supply Chain: SBOMs en signatures bij elke build. 3. âš™ï¸ Runtime De landingsplaats (Kubernetes): Hybride Cluster: Draait deels in Azure, deels On-Premise. Policy Engine (Kyverno): Dwingt regels af (bv. \"Geen root containers\"). Agentic RAG: Netwerk van AI agenten die veilig data ontsluiten. 4. ğŸ“ Ontwerpen (Designs) Gedetailleerde technische ontwerpen en functionele beschrijvingen: Exoten Detectie: Satelliet + Drone flow. Vergunning zoeker: AI zoekt oude aktes. Automated Rebuild: Self-healing bij security patches. 5. ğŸ›¡ï¸ Compliance De regels en wetten vertaald naar techniek: AI Act & Register: Verplichte registratie van algoritmes. BIO & NIS2: Baseline Informatiebeveiliging. Goed Bestuur: Principes van transparantie en controleerbaarheid. --- ğŸ’¡ Kernprincipes 1. Alles is een Spec: Van infrastructuur tot agent-gedrag, alles wordt vastgelegd in leesbare files. 2. Human-in-the-Loop: Kritieke beslissingen (vliegroute drone, verwijderen data) vereisen altijd menselijke goedkeuring. 3. Secure by Design: Security tools (Trivy, Kyverno) staan \"aan\" by default. 4. Traceerbaarheid: Elke actie, van prompt tot deployment, wordt gelogd in de Traceability DB. --- ğŸ› ï¸ Scripts & Tools Bekijk de Script Overview voor een lijst van alle beschikbare beheerscripts. Search index De search index is gemaakt met de node generate_search_index.js script en wordt opgeslagen in search_index.json."
  },
  {
    "title": "Het Verhaal Druppie",
    "category": "general",
    "path": "story/story.md",
    "content": "Het Verhaal van Druppie We vertellen hier het verhaal van Druppie, een AI-assistent die is ontwikkeld om te helpen bij het beheer van water door Waterschappen. Introductie !Slide Image <!-- Placeholder, mapping might be off --> De Strategische Verschuiving De kern van de Vaarkaart is de beweging van traditionele automatisering naar een fundamentele digitale transformatie. Van 'Samen Doen' naar 'Samenwerken als Concern': De 21 waterschappen moeten niet langer allemaal hun eigen IT-wiel uitvinden. Het doel is opereren als Ã©Ã©n concern om schaalvoordeel te behalen, kosten te drukken en kwaliteit te verhogen. Datagedreven Waterbeheer: De focus verschuift van het beheren van systemen naar het waardevol maken van data. Data wordt gezien als een strategisch asset om wateroverlast, droogte en waterkwaliteit beter te voorspellen en te beheren. Uniformiteit als Basis: Om data uitwisselbaar te maken en samen te kunnen werken, is standaardisatie van processen en techniek noodzakelijk. Dit betekent minder maatwerk per waterschap en meer gezamenlijke standaarden. De Pijlers van de Transformatie De uitvoering van de digitale agenda in de Vaarkaart rust op een aantal concrete thema's: Informatieveiligheid & Privacy (IBP): Omdat waterbeheer vitale infrastructuur is, is cyberveiligheid topprioriteit. De focus ligt op weerbaarheid tegen hacks en het voldoen aan wetgeving (zoals de BIO en NIS2). De Digitale Werkplek: Het faciliteren van een moderne, plaatsonafhankelijke werkomgeving die samenwerking tussen waterschappen en ketenpartners (zoals Rijkswaterstaat en gemeenten) naadloos maakt. Dataplatforms & Cloud: De beweging naar de cloud (bijvoorbeeld via het Waterschaps Data Platform) om enorme hoeveelheden sensordata en satellietbeelden te kunnen verwerken. Innovatie & Nieuwe Technologie: Actieve inzet van Digital Twins (digitale kopieÃ«n van het watersysteem) om scenario's te simuleren. Gebruik van Artificial Intelligence (AI) en algoritmes voor voorspellend onderhoud en peilbeheer. Mens en Organisatie (De Zachte Kant) De Vaarkaart benadrukt dat digitale transformatie niet alleen over techniek gaat, maar vooral over mensen. Digitaal Veradervermogen: Er is een cultuur nodig waarin men durft te delen, over de grenzen van het eigen waterschap heen kijkt en openstaat voor verandering in werkwijzen. Digitale Vaardigheid: Medewerkers van waterschappen moeten worden opgeleid om met nieuwe digitale tools en data-analyses te kunnen werken. Digitale Innovator: De waterschappen moeten sneller kunnen inspelen op nieuwe technologische ontwikkelingen en veranderende klimaatomstandigheden en hierdoor moeten we durven te experimenteren en innoveren om nieuwe mogelijkheden te ontdekken. We zijn goed op weg !Slide Image <!-- Placeholder, mapping might be off --> Binnen de technologie onderscheiden we verschillende bouwblokken die voortdurend onderling samenwerken en communiceren. Gezamenlijk leveren ze de diensten en digitalisering op. Waar tot nu toe in deze routekaart vooral de kansen van digitalisering zijn belicht, kent het ook significante risicoâ€™s. We zijn en willen een betrouwbaar waterschap blijven dat goed omgaat met de gegevens van haar burgers en bedrijven. Daarom zorgen we er continu voor de digitale weerbaarheid op orde is, zoals tegen hackers en randsomeware. En naarmate we meer digitaliseren zullen algoritmes en kunstmatige intelligentie steeds meer worden toegepast. Dat vraagt naast informatieveiligheid om continue alertheid voor privacy en ethiek. Zodat de kansen van digitalisering verzilverd kunnen worden terwijl de risicoâ€™s tot een minimum beperkt worden.â€‹ Bij het gebruik van algoritmes en kunstmatige intelligentie willen we voorkomen dat er informatie gegeneerd wordt die tegen ethische grenzen aanzitten of er zelfs over heen gaan. Daarom is het een van onze prioriteiten om een ethische AI omgeving te creÃ«ren, waarbinnen digitale ontwikkelingen to bloei kunnen komen. Ook aspecten als inclusie, toegankelijkheid voor iedereen, â€˜de menselijke maatâ€™ en digital violence zijn onderdeel van de ethische afwegingen. Van visie naar uitvoering !Slide Image <!-- Placeholder, mapping might be off --> Digitale transformatie is niet een gewoon project, maar een verandertraject met impact op de gehele organisatie. Uit de praktijk blijkt dan ook als digitale transformatie wordt aangestuurd als een regulier project dat de implementatie moeizaam gaat of mislukt. Daarom is er gekozen voor een meer natuurlijk proces van Leren, Experimenteren en Verbeteren. Om te zorgen dat we de goede dingen kunnen en gaan doen is het noodzakelijk dat er van boven af wordt gestuurd. De stuurgroep is er om de richting en scope te bepalen wat eerst en wat later, maar ook te zorgen dat de juiste middelen en voorwaarden er zijn om te kunnen leren, experimenteren en verbeteren. Een kleine support groep zorgt ervoor dat de randvoorwaarden voor de teams of medewerkers zijn ingevuld voor dat de proces verandering (Minimal Viable Change) wordt gestart en begeleid de groep"
  },
  {
    "title": "License (MIT)",
    "category": "general",
    "path": "LICENSE.md",
    "content": "MIT License Copyright (c) 2025 Project Druppie Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  }
]