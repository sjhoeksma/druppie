[
  {
    "title": "Overview",
    "category": "blocks",
    "path": "blocks/overview.md",
    "content": "Bouwblokken Overview De Bouwblokken (Building Blocks) vormen de modulaire componenten waaruit de Druppie-architectuur is opgebouwd. Elk bouwblok vertegenwoordigt een specifieke functionaliteit of capability binnen het platform. Dit overzicht beschrijft de definities en contracten van deze componenten. üèõÔ∏è Core Components Deze blokken vormen het hart van het systeem. - Druppie Core (Orchestrator) - Het centrale brein dat user intents vertaalt naar acties. Gebruikt een planner en semantic kernel. - Druppie UI - De interface voor interactie (Chat/Copilot). - Bouwblok Definities - De metadata-catalogus die beschrijft wat elk blok kan en hoe het aangeroepen wordt. üõ°Ô∏è Governance \u0026 Control Blokken die toezicht en veiligheid garanderen. - Policy Engine - Evalueert elke geplande actie tegen bedrijfs- en veiligheidsregels. - Mens in de Loop - Het mechanisme voor menselijke goedkeuring bij risicovolle beslissingen. - Traceability DB - De \"black box\" die alle beslissingen, prompts en acties onveranderlijk vastlegt. - Compliance Layer - De overkoepelende laag voor auditing en security monitoring. üè≠ Execution \u0026 Factory De lagen waar het werk daadwerkelijk wordt uitgevoerd. - Build Plane - De definitie van de \"fabriek\" die code omzet in artifacts (zie ook de diepere Build Plane directory). - Runtime - De definitie van de landingsplaats (Kubernetes) voor applicaties (zie ook de diepere Runtime directory). ü§ñ Specialised Agents Gespecialiseerde workers. - Knowledge Bot - Een RAG-enabled agent die informatie uit documentatie kan ontsluiten."
  },
  {
    "title": "Druppie UI",
    "category": "blocks",
    "path": "blocks/druppie_ui.md",
    "content": "Druppie UI Specification 1. System Overview Druppie UI is the visual control plane for the Druppie Platform. It allows users to interact with the AI Core, visualize generated code, manage projects via a Kanban board, and approve sensitive actions. It connects to the Druppie Core via REST, Server-Sent Events (SSE), and WebSockets. Key Principles: Human-in-the-Control-Loop: The UI is designed to give users insight and control over the AI's autonomous actions. Real-Time: State changes in the Core (e.g., Build finished, Plan updated) are reflected instantly. Transparency: No \"hidden\" AI magic; always show the Plan, the Code, and the Logs. 2. Technical Stack Framework: Next.js 14+ (App Router). Styling: Tailwind CSS (adhering to Company Style Guide). State Management: React Query (Server State) + Zustang (Client State). Visualization: Code: prismjs. Diagrams: mermaid.js. Markdown: react-markdown. Protocol: Chat: SSE (Server-Sent Events) for streaming tokens. Events: WebSockets for Kanban/Status updates. --- 3. Epics \u0026 User Stories Epic 1: Conversational Interface (Chat) Goal: Provide a rich, IDE-like chat experience for instructing the AI. Story 1.1: Streaming Response User: \"Build me a new drone service.\" UI: Renders text token-by-token. Supports Markdown rendering (tables, headers, bold). Story 1.2: Interactive Artifacts Function: If the AI mentions a file (e.g., \"I updated deployment.yaml\"), the filename is a clickable link that opens the Code Viewer side-panel. Story 1.3: Thread Management Function: Users can create new threads, rename them, and view history. History is fetched from Core. Epic 2: Visual Code Explorer (The \"Lens\") Goal: Allow users to verify the AI's work without leaving the browser. Story 2.1: File Tree Navigator View: A VSCode-like file tree representing the target Git repository's structure. Source: Fetched live from Gitea or the Core's \"Temporary Workspace\". Story 2.2: Code Editor/Viewer Function: Read-only view of files with Syntax Highlighting (support for Go, Python, YAML, Markdown). Story 2.3: Diff Viewer Use Case: When the AI proposes changes (HITL), show a side-by-side Diff (Red/Green) of Before vs After. Action: \"Approve\" button executes the change; \"Reject\" allows commenting feedback. Epic 3: Project Management (Kanban) Goal: Visualize the Execution Plan as manageable tasks. Story 3.1: Live Board Columns: Planning, In Progress, Review, Done. Sync: When the Core moves a step to \"Completed\", the card moves to \"Done\" automatically via WebSocket. Story 3.2: Drag-and-Drop Control Action: User drags a card from \"In Progress\" back to \"Planning\". Effect: Sends a signal to Core to STOP execution and replan that step. Story 3.3: Project Context Selector View: Dropdown menu in the Sidebar/Header to switch the active Project. Action: \"Create New Project\" button opens a modal to define Project Name and Key (e.g., drone-service). Effect: Filters the Chat History, Kanban Board, and File Browser to the selected Project scope. Epic 4: Registry Explorer Goal: Browse the available capabilities of the platform. Story 4.1: Building Block Catalog View: Grid view of cards for each Building Block (e.g., \"Postgres\", \"Redis\"). Detail: Clicking a card shows its inputs, outputs, and dependencies (rendered from the Markdown definition). Story 4.2: Skill \u0026 Persona Viewer View: List active Agents and their Skills. Admin: (If Admin) specific buttons to enable/disable specific skills. Epic 5: Governance Dashboard Goal: Visibility into compliance and security. Story 5.1: Approval Queue View: A dedicated \"Inbox\" for pending requests (Deployment to Prod, Public S3 bucket creation). Action: Approve/Deny with reason. Story 5.2: Compliance Reports View: Tabular list of projects and their latest Compliance Scan status (Pass/Fail). Epic 6: Admin Control Plane Goal: Manage the platform's configuration, users, and health. Story 6.1: IAM \u0026 RBAC Management View: Manage Users, Groups, and Role Mappings (UI for Keycloak). Action: Assign \"Platform Admin\" or \"Developer\" roles to users. Story 6.2: System Health Monitor View: Real-time dashboard of Core Services (Router, Planner, Registry). Metric: CPU/Memory usage of Agent pods. Story 6.3: Audit Log Viewer View: Searchable table of all actions taken by Agents and Users. Filter: Filter by UserID, ProjectID, or Timestamp. Detail: View the exact differences (diffs) applied during an action. Story 6.4: Configuration Manager View: Edit Global Settings (e.g., \"Default LLM Model\", \"Max Token Limit\"). Action: Upload new Corporate Guidelines (PDF) to the Compliance Engine. Story 6.5: Building Block Manager View: Master list of all registered Building Blocks (e.g., \"Postgres\", \"Redis\"). Action: Toggle Enable/Disable. Disabled blocks cannot be selected by the Planner. Detail: View metadata, version history, and dependency graph. Story 6.6: MCP Server Manager View: List of connected Model Context Protocol (MCP) servers. Action: Register new MCP endpoint (URL + API Key). Status: Check health "
  },
  {
    "title": "Druppie Core",
    "category": "blocks",
    "path": "blocks/druppie_core.md",
    "content": "Druppie Core Specification 1. System Overview Druppie Core is the central orchestrator of the Druppie Platform. It functions as a scalable, Kubernetes-native autonomous agent system designed to plan, build, deploy, and govern software workloads for Water Authorities. It operates on a \"Spec-Driven\" architecture where intents are translated into declarative infrastructure and code. Key Principles: AI-First: All operations are driven by LLM-based reasoning (Planner/Router). Spec-Driven: All artifacts (Code, Infrastructure) are defined as declarative specs (YAML/HCL). Kubernetes-Native: The core itself runs as a container and interacts directly with the K8s API. Compliance-by-Design: Every action is checked against policy engines before execution. Security-by-Design: Every action is checked against security policies before execution. Traceability-by-Design: Every action is logged and stored in a traceability/observability database. Cost-by-Design: Every action is checked against cost policies before execution. Performance-by-Design: Every action is checked against performance policies before execution. Resilience-by-Design: Every action is checked against resilience/resiliency policies before execution. --- 2. Epics \u0026 Multi-Agent Work Breakdown Epic 1: Core Reasoning Engine \u0026 Orchestration Goal: Establish the \"Brain\" that accepts natural language prompts and formulates execution plans. Story 1.1: Router Agent Implementation (The Hub) Role: Triage incoming requests. Logic: Analyze intent. If \"General Question\" -\u003e Knowledge Bot. If \"Create/Change\" -\u003e Builder Agent. If \"Approval\" -\u003e Governance Agent. Output: Routed Context Object. Story 1.2: Multi-Agent Planner Role: Break down complex requests into steps (Chain of Thought). Capability: Support sequential execution (Step A -\u003e Step B) and parallel execution (Step A \u0026 B). Pass skill to agent to ensure it has the right tools and know what it can do. Artifact: ExecutionPlan JSON object. Story 1.3: Context \u0026 Memory Management Requirement: Maintain state across multi-turn conversations (Thread ID). Storage: Persist conversation history and working variables in Redis or CosmosDB/Postgres. Story 1.4: Building Block Resolution \u0026 Project Scoping Search Strategy: Before planning, query the Registry (Epic 2) to find existing Building Blocks that match the user's intent. Decomposition: If a monolithic request requires multiple distinct capabilities (e.g., \"Web App + Database\"), split it into multiple Building Blocks. Project Rule: Enforce the rule: \"One Building Block = One Project\". If a block is missing, scope a new Project to build it. Epic 2: Registry \u0026 Capability Management Goal: Enable the AI to \"know what it can do\" by reading dynamic definitions of Tools and Skills. Story 2.1: Building Block Registry API Function: A read-heavy API to index .md or .yaml definitions from the bouwblokken/ directory. Schema: extract name, capabilities, inputs, outputs from definitions. Story 2.2: Skill Loader Function: Dynamic injection of \"Persona\" instructions (e.g., \"Act as Python Expert\") based on skills/ definitions. Story 2.3: MCP Client (Model Context Protocol) Function: Connect to remote tools running in separate pods (e.g., mcp-weather, mcp-database). Protocol: Support SSE (Server-Sent Events) transport to discover and invoke tools over HTTP. Epic 3: Project Factory \u0026 Source Control Goal: Abstract the creation and management of Git repositories. Story 3.1: Gitea Integration Client Action: Create Repo, Branch, Commit, Pull Request. Auth: Token-based authentication against the internal Gitea service. Story 3.2: Scaffolding Engine Action: Generate initial project structure based on templates (e.g., \"New Python Service\" = pyproject.toml, Dockerfile, k8s/deploy.yaml). Spec: driven by Building Block definitions. Epic 4: Build Plane Interface (The Factory) Goal: Trigger and monitor the production of artifacts (Containers). Story 4.1: Tekton Trigger Interface Action: Create PipelineRun objects in Kubernetes. Params: Pass Git Commit Hash and Image Tags. Story 4.2: Async Build Monitoring Action: Watch PipelineRun status. Stream logs to the Core/User upon failure. Notify: Send event when build is Succeeded or Failed. Epic 5: Runtime Operations (Deploy \u0026 Run) Goal: Manage the lifecycle of running applications. Story 5.1: GitOps Enforcer (Flux Wrapper) Action: Commit manifest changes to the infra repository (triggering Flux). Logic: Do not touch the cluster directly (kubectl apply) except for ephemeral debug tasks. Always go through Git. Story 5.2: Resource Observation Action: Query K8s API for Pod status, Logs, and Events. Use Case: User asks \"Why is my drone-service crashing?\" -\u003e Core reads kubectl logs. Story 5.3: Automated Verification (Post-Deploy) Action: Run smoke tests and health checks against the newly deployed service. Logic: Verify endpoints (e.g., /health) return 200 OK before marking the task as complete. Story 5.4: Dynamic Documentation \u0026 Cataloging Action: Update the internal S"
  },
  {
    "title": "CI/CD Pipeline (Tekton)",
    "category": "blocks",
    "path": "blocks/ci_cd_tekton.md",
    "content": "CI/CD Pipeline (Tekton) üéØ Selectie: Tekton Pipelines Voor de CI/CD oplossing binnen het Druppie platform is gekozen voor Tekton. Tekton is een krachtig en flexibel, Kubernetes-native open-source raamwerk voor het maken van CI/CD systemen. üí° Onderbouwing van de Keuze De keuze voor Tekton is gebaseerd op de volgende criteria die naadloos aansluiten bij de architectuur van Druppie: 1. Kubernetes Native: Tekton draait volledig binnen Kubernetes en gebruikt Custom Resource Definitions (CRD's) zoals Task en Pipeline. Dit betekent dat pipelines beheerd kunnen worden via dezelfde tools als de applicatie zelf (kubectl, GitOps) en perfect passen in het \"Spec-Driven\" concept. 2. Modulair (Bouwblokken): Tekton werkt met herbruikbare \"Tasks\". Dit sluit perfect aan op de bouwblokken-filosofie van Druppie. Een taak om een container te bouwen (bijv. met Kaniko) kan in meerdere pipelines hergebruikt worden. 3. Serverless Scaling: In tegenstelling tot traditionele servers (zoals Jenkins), draait elke pipeline stap als een Pod. Dit schaalt naar 0 als er niets gebeurt en schaalt oneindig op bij drukte, wat effici√´nt is voor de infrastructuur. 4. Ontkoppeling: De pipeline definities staan los van de broncode repo's (hoewel ze erin kunnen wonen), wat flexibele orchestratie mogelijk maakt door de Builder Agent van Druppie. 5. Industry Standard: Tekton is een project van de CD Foundation, wat zorgt voor brede ondersteuning en toekomstbestendigheid. --- üõ†Ô∏è Installatie Tekton installeer je direct op het Kubernetes cluster. 1. Tekton Pipelines Controller \u0026 Webhook Installeer de core componenten: bash kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml Controleer of de pods draaien: bash kubectl get pods -n tekton-pipelines 2. (Optioneel) Tekton Dashboard Voor een visueel overzicht van de builds: bash kubectl apply --filename https://storage.googleapis.com/tekton-releases/dashboard/latest/release.yaml 3. (Optioneel) Tekton CLI (tkn) Installeer tkn lokaal om interactief pipelines te beheren (voorbeeld voor macOS): bash brew install tektoncd-cli --- üöÄ Gebruik Het gebruik van Tekton bestaat uit drie lagen: 1. Task (De \"Wat\") Een Task definieert een reeks stappen die in volgorde worden uitgevoerd in dezelfde container (Pod). Voorbeeld: Een 'Hello World' taak yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: hello spec: steps: - name: say-hello image: alpine command: [\"echo\"] args: [\"Hallo vanuit Druppie CI/CD!\"] 2. Pipeline (De \"Hoe\") Een Pipeline koppelt meerdere Tasks aan elkaar en bepaalt de volgorde en data-uitwisseling. Voorbeeld: Een simpele pipeline yaml apiVersion: tekton.dev/v1beta1 kind: Pipeline metadata: name: hello-pipeline spec: tasks: - name: hello-task taskRef: name: hello 3. PipelineRun (De \"Wanneer\") Om een pipeline daadwerkelijk te starten, maak je een PipelineRun (of TaskRun) aan. Dit is de daadwerkelijke uitvoering. bash tkn pipeline start hello-pipeline --showlog Of via YAML: yaml apiVersion: tekton.dev/v1beta1 kind: PipelineRun metadata: generateName: hello-run- spec: pipelineRef: name: hello-pipeline üîÑ Integratie in Druppie Binnen de Druppie architectuur wordt Tekton aangestuurd door de Builder Agent en Foundry: 1. Builder Agent genereert de code en een bijbehorende PipelineRun specificatie. 2. De Foundry component past deze YAML toe op het Kubernetes cluster. 3. Tekton voert de bouwstappen uit (Linting, Testen, Container Build, Security Scan). 4. Resultaten worden teruggekoppeld naar de Traceability DB."
  },
  {
    "title": "Database (PostgreSQL)",
    "category": "blocks",
    "path": "blocks/database_postgres.md",
    "content": "Database Cluster (PostgreSQL) üéØ Selectie: CloudNativePG (CNPG) Voor de relationele database oplossing binnen het Druppie platform is gekozen voor CloudNativePG (CNPG). Dit is een Kubernetes-native operator die volledig is ontworpen om PostgreSQL-clusters te beheren binnen een containeromgeving. üí° Onderbouwing van de Keuze De keuze voor CloudNativePG is gebaseerd op de volgende criteria die essentieel zijn voor de betrouwbaarheid van Druppie: 1. Kubernetes Native: CNPG breidt de Kubernetes API uit met een Cluster resource. In plaats van complexe statefulsets te beheren, definieer je simpelweg de gewenste staat van je database in YAML. 2. High Availability (HA): Automatische failover en \"self-healing\" functionaliteit. Als de primaire node uitvalt, promoveert de operator automatisch een standby node. 3. Backups \u0026 Disaster Recovery: Ingebouwde ondersteuning voor Point-In-Time Recovery (PITR) naar object storage (zoals S3 of Azure Blob Storage). 4. Immutable Application support: CNPG beheert de connectie via services en secrets die automatisch worden ge√ºpdatet, wat naadloos aansluit bij de Runtime applicaties van Druppie. 5. Open Source \u0026 Community: Oorspronkelijk ontwikkeld door EDB, maar nu een volledig open-source project met een zeer actieve community. --- üõ†Ô∏è Installatie De operator wordt ge√Ønstalleerd op het cluster en beheert vervolgens alle database instanties. 1. Installatie via Manifest De snelste manier om de operator te installeren: bash kubectl apply -f https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/release-1.21/releases/cnpg-1.21.0.yaml Controleer of de operator draait: bash kubectl get pods -n cnpg-system (Alternatief kan installatie ook via Helm chart cnpg/cloudnative-pg) --- üöÄ Gebruik Net als bij andere bouwblokken, defini√´ren we een database declaratief. De Builder Agent kan deze definities genereren wanneer een applicatie opslag nodig heeft. 1. Database Cluster Definitie Een voorbeeld van een High-Available cluster met 3 instances (1 Primary, 2 Replicas): yaml apiVersion: postgresql.cnpg.io/v1 kind: Cluster metadata: name: druppie-core-db spec: instances: 3 Opslag configuratie storage: size: 10Gi Backup configuratie (optioneel voorbeeld) backup: barmanObjectStore: destinationPath: s3://druppie-backups/ endpointURL: http://minio:9000 s3Credentials: accessKeyId: name: backup-secret key: key secretAccessKey: name: backup-secret key: secret 2. Connecteren vanuit Applicaties Zodra het cluster draait, maakt CNPG automatisch de volgende resources aan die door applicaties gebruikt kunnen worden: Service (druppie-core-db-rw): Een stabiel endpoint voor schrijfoperaties (Primary). Service (druppie-core-db-ro): Een stabiel endpoint voor leesoperaties (Read-Only replicas). Secret (druppie-core-db-app): Bevat de inloggegevens (username, password, dbname, host). Voorbeeld Pod gebruik: yaml apiVersion: v1 kind: Pod metadata: name: app-met-db spec: containers: - name: app image: my-app:latest env: - name: DB_HOST value: druppie-core-db-rw - name: DB_USER valueFrom: secretKeyRef: name: druppie-core-db-app key: username - name: DB_PASS valueFrom: secretKeyRef: name: druppie-core-db-app key: password üîÑ Integratie in Druppie 1. Spec-Driven: Een applicatie specificeert in zijn definitie \"Ik heb een database nodig\". 2. Builder Agent: Genereert de Cluster YAML definitie en voegt de juiste environment variabelen toe aan de Deployment manifest van de applicatie. 3. Runtime: Bij het deployen van de applicatie zorgt de operator dat de database beschikbaar is en de applicatie direct kan verbinden."
  },
  {
    "title": "Vector Database (Qdrant)",
    "category": "blocks",
    "path": "blocks/database_qdrant.md",
    "content": "Vector Database (Qdrant) üéØ Selectie: Qdrant Voor het opslaan en doorzoekbaar maken van onze AI-kennis (Embeddings) kiezen we voor Qdrant. üí° Onderbouwing van de Keuze Waarom Qdrant boven alternatieven zoals Weaviate, Pinecone of pgvector? 1. Performance \u0026 Resource Efficiency: Qdrant is geschreven in Rust. Dit maakt het extreem snel en geheugeneffici√´nt, wat perfect past bij onze kubernetes-gebaseerde infrastructuur waar resources soms schaars zijn. 2. Native Faceted Filtering (ACLs): Qdrant blinkt uit in \"Filtered Search\". Dit is cruciaal voor onze Secure RAG eis. We kunnen heel effici√´nt zoeken: \"Geef de top 10 vectoren die lijken op deze vraag, MAAR alleen als metadata.group IN ['finance', 'admin']\". Veel andere databases worden traag bij complexe filters (\"Post-filtering\"), Qdrant doet dit tijdens het zoeken (\"Pre-filtering/HNSW\"). 3. Kubernetes-Native: Qdrant is ontworpen als cloud-native distributed system. Het schaalt makkelijk horizontaal mee met onze pods. 4. Open Source: Volledig open source en self-hostable (geen vendor lock-in of data die naar een Amerikaanse cloud service lekt). (Noot: pgvector in PostgreSQL is goed voor simpele use-cases, maar mist de geavanceerde filtering en snelheid van een dedicated vector engine zoals Qdrant bij miljoenen vectoren.) --- üõ†Ô∏è Installatie We draaien Qdrant als een StatefulSet in de Runtime. Installatie via Helm bash helm repo add qdrant https://qdrant.github.io/qdrant-helm helm upgrade --install qdrant qdrant/qdrant \\ --namespace data-system --create-namespace \\ --set replicaCount=3 \\ --set persistence.size=50Gi --- üöÄ Gebruik: Van Tekst naar Vector Dit bouwblok wordt gebruikt door de Ingest Agent en de RAG Agent. 1. Opslaan (Upsert) Wanneer de Ingest Agent een document verwerkt: python from qdrant_client import QdrantClient from qdrant_client.models import PointStruct client = QdrantClient(host=\"qdrant.data-system\", port=6333) client.upsert( collection_name=\"bedrijfs_kennis\", points=[ PointStruct( id=123, vector=[0.1, 0.9, ...], De AI betekenis (Embedding) payload={ De Metadata \"filename\": \"begroting_2025.pdf\", \"text_snippet\": \"Het totaalbedrag is 1M...\", \"acls\": [\"group:finance\", \"user:jan\"] } ) ] ) 2. Zoeken met Beveiliging (Search) Wanneer Jan (lid van 'engineering') iets vraagt: python search_result = client.search( collection_name=\"bedrijfs_kennis\", query_vector=[0.1, 0.9, ...], De vraag vector query_filter=Filter( must=[ FieldCondition( key=\"acls\", match=MatchAny(any=[\"group:engineering\", \"group:public\"]) ) ] ) ) De database geeft alleen resultaten terug die Jan mag zien. Dit gebeurt op database-niveau, dus de applicatie kan niet per ongeluk iets lekken. üîÑ Integratie in Druppie Traceability: Elke 'hit' in de vector database kan gelogd worden, zodat we weten welke kennisbronnen zijn gebruikt voor een antwoord. Backups (Velero): Omdat Qdrant op een Persistent Volume draait, wordt deze automatisch meegenomen in de standaard backup policy."
  },
  {
    "title": "Geo-Database (PostGIS)",
    "category": "blocks",
    "path": "blocks/database_postgis.md",
    "content": "Geo-Database (PostGIS) üéØ Selectie: CloudNativePG (met PostGIS) Voor de opslag en verwerking van geografische data binnen het Druppie platform kiezen we voor dezelfde operator als voor de standaard databases: CloudNativePG (CNPG). Echter, specifieke configuratie is vereist om de PostGIS extensie mogelijk te maken. üí° Onderbouwing van de Keuze Het hergebruiken van de CloudNativePG operator voor geospatiale data biedt grote voordelen: 1. Uniform Beheer: Beheer, backup, failover en monitoring werken exact hetzelfde als voor standaard PostgreSQL databases. Dit vermindert de operationele complexiteit voor de Run Experts. 2. Bewezen Technologie: PostGIS is de de-facto standaard voor open-source GIS. Het biedt krachtige features voor spatial queries, indexering en analyse die essentieel zijn voor waterschapstaken (dijken, watergangen, assets). 3. Kubernetes Native: Door simpelweg een andere container image te specificeren in de CNPG Cluster definitie, rollen we een volledige GIS-stack uit zonder nieuwe infrastructuur componenten toe te voegen. --- üõ†Ô∏è Installatie De operator (CloudNativePG) is naar verwachting al ge√Ønstalleerd (zie PostgreSQL Bouwblok). Er is geen aparte installatie nodig; we hoeven alleen maar een andere configuratie toe te passen bij het aanmaken van het cluster. --- üöÄ Gebruik Om een PostGIS database te krijgen, moeten we twee dingen doen in de Cluster definitie: 1. Een Docker image kiezen waar PostGIS al in is ge√Ønstalleerd (bijv. de offici√´le postgis/postgis images). 2. De extensie activeren na het opstarten (via CREATE EXTENSION postgis;). Dit kan geautomatiseerd worden met een postInitSQL command. 1. PostGIS Cluster Definitie Hieronder een voorbeeld definitie voor een GIS-cluster. Let op de imageName en postInitSQL. yaml apiVersion: postgresql.cnpg.io/v1 kind: Cluster metadata: name: druppie-geo-db spec: instances: 2 Specifieke PostGIS image (ipv standaard postgres) imageName: ghcr.io/cloudnative-pg/postgis:16 Opslag (GIS data is vaak groot, dus ruim kiezen) storage: size: 50Gi Automatisch de extensie aanzetten na init bootstrap: initdb: postInitSQL: - \"CREATE EXTENSION IF NOT EXISTS postgis;\" - \"CREATE EXTENSION IF NOT EXISTS postgis_topology;\" Monitoring aanzetten is cruciaal voor zware GIS queries monitoring: enablePodMonitor: true 2. Connecteren \u0026 Gebruik Applicaties verbinden op exact dezelfde manier als bij de standaard database (via de generated Secrets en Services). De applicatie (of Builder Agent) kan nu direct geospatiale queries uitvoeren: Voorbeeld SQL Query (via de applicatie): sql -- Zoek alle dijken binnen 500 meter van een punt SELECT naam, type FROM waterkeringen WHERE ST_DWithin( geometrie, ST_GeomFromText('POINT(134000 450000)', 28992), 500 ); üîÑ Integratie in Druppie 1. Capability Check: Als een gebruiker vraagt om \"Kaart functionaliteit\" of \"Locatie gebaseerde analyse\", selecteert de Planner dit bouwblok in plaats van de standaard database. 2. Builder Agent: Genereert de Cluster YAML met de PostGIS image. Weet dat hij SQL queries kan genereren die gebruik maken van ST_ functies (spatial types). 3. Foundry: Rolt de container uit en zorgt dat de zware GIS berekeningen voldoende CPU/RAM limieten krijgen toegewezen."
  },
  {
    "title": "GitOps \u0026 State (Flux)",
    "category": "blocks",
    "path": "blocks/gitops_flux.md",
    "content": "GitOps \u0026 State Management (Flux) üéØ Selectie: Flux CD Omdat Tekton de processen (CI/bouw) afhandelt, zoeken we een component die de gewenste staat (CD/deployment) op het cluster handhaaft en bewaakt. Flux is hier de ideale partner voor. üí° Waarom past dit bij Tekton? Waar ArgoCD soms werd gezien als een volledige suite die (deels) overlapt met pipeline-taken, is Flux een pure, lichtgewicht GitOps operator. 1. Complementair: Tekton is een \"Task Runner\" (Imperatief: \"Doe dit nu\"), Flux is een \"State Enforcer\" (Declaratief: \"Zorg dat het zo is\"). Ze zitten elkaar niet in de weg. 2. Kubernetes Native (net als Tekton): Flux gebruikt - net als Tekton - standaard Custom Resource Definitions (CRD's) en integreert naadloos in het cluster zonder zware eigen UI of database. 3. De \"Push-to-Pull\" Workflow: Tekton (CI): Bouwt de image, test deze, en pusht een update naar de Git configuratie repo (bijv. update image tag). Flux (CD): Ziet de wijziging in Git en pullt deze naar het cluster. 4. Automatic Drift Correction: Flux controleert continu of de live omgeving nog klopt met Git. Als iemand handmatig iets kapot maakt, repareert Flux het direct. --- üõ†Ô∏è Installatie Flux \"bootstrappen\" we op het cluster. Dit commando installeert de controllers √©n configureert direct een Git repository om zichzelf te beheren (GitOps voor de GitOps tool). 1. Flux Bootstrap (Vereist een Github Personal Access Token met repo rechten) bash flux bootstrap github \\ --owner=$GITHUB_USER \\ --repository=druppie-infra \\ --branch=main \\ --path=./clusters/productie \\ --personal Dit installeert de Source Controller, Kustomize Controller, Helm Controller en Notification Controller. 2. Controle bash kubectl get pods -n flux-system --- üöÄ Gebruik We defini√´ren twee dingen: Waar staat de config (Source) en Hoe passen we het toe (Kustomization/Helm). 1. Source (GitRepository) Vertel Flux waar de applicatie configuraties staan. yaml apiVersion: source.toolkit.fluxcd.io/v1 kind: GitRepository metadata: name: druppie-apps namespace: flux-system spec: interval: 1m url: https://github.com/waterschap/druppie-apps ref: branch: main 2. Kustomization (Sync) Vertel Flux welke map in die repo hij op het cluster moet toepassen. yaml apiVersion: kustomize.toolkit.fluxcd.io/v1 kind: Kustomization metadata: name: drone-service-prod namespace: flux-system spec: interval: 5m targetNamespace: productie sourceRef: kind: GitRepository name: druppie-apps path: \"./envs/prod/drone-service\" prune: true Verwijder resources die uit Git zijn gehaald wait: true Wacht tot alles 'Healthy' is üîÑ Integratie in Druppie De samenwerking tussen de Builder Agent, Tekton en Flux is de kern van het platform: 1. Code Change: Developer (of Agent) commit code. 2. Tekton (CI): Triggered door de commit. Draait unit tests \u0026 security scans. Bouwt Docker image. ‚ö†Ô∏è Cruciale stap: Tekton commit de nieuwe image tag (bijv. v1.0.5) naar de druppie-apps Git repo (INFRA repo). 3. Flux (CD): Detecteert de nieuwe commit in druppie-apps. Reconciled de state: \"Hee, de deployment moet nu image v1.0.5 draaien\". Update de Pods op het Kubernetes cluster."
  },
  {
    "title": "Observability (PLG Stack)",
    "category": "blocks",
    "path": "blocks/observability_plg.md",
    "content": "Observability \u0026 Logging (PLG Stack) üéØ Selectie: Prometheus, Loki \u0026 Grafana Voor het monitoren van de gezondheid, performance en het doorzoekbaar maken van logs kiezen we voor de PLG Stack (Prometheus, Loki, Grafana). Dit is de industriestandaard voor open-source cloud-native observability. üí° Onderbouwing van de Keuze Deze stack is cruciaal voor de \"Traceerbaarheid\" en \"Beheersbaarheid\" van het Druppie platform: 1. Prometheus (Metrics): Verzamelt cijfermatige data (CPU, Memory, Request Count). Kubernetes is gemodelleerd om metrics in Prometheus formaat aan te bieden. Het stelt ons in staat om te alerten als er iets mis is (bijv. \"Error rate \u003e 5%\"). 2. Loki (Logs): Een log-aggregatie systeem dat is ontworpen als \"Prometheus voor logs\". Het is extreem effici√´nt omdat het logs niet volledig indexeert, maar alleen metadata (labels). Dit maakt het mogelijk om alle logs (audit trails!) goedkoop te bewaren en razendsnel te doorzoeken. 3. Grafana (Visualisatie): Het centrale dashboard. Hier komen metrics (Prometheus) en logs (Loki) samen in √©√©n overzichtelijk scherm. 4. Correlatie: Omdat alles in hetzelfde dashboard zit, kun je direct springen van een \"High CPU Alert\" in Prometheus naar de exacte \"Error Logs\" in Loki van dat moment. --- üõ†Ô∏è Installatie We installeren de volledige stack via de offici√´le Helm charts (vaak gebundeld als de kube-prometheus-stack en loki-stack). 1. Prometheus \u0026 Grafana bash helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \\ --namespace monitoring --create-namespace 2. Loki (Logging) bash helm repo add grafana https://grafana.github.io/helm-charts helm upgrade --install logging grafana/loki-stack \\ --namespace monitoring \\ --set grafana.enabled=false We gebruiken de grafana uit stap 1 --- üöÄ Gebruik Deze componenten werken grotendeels automatisch (\"Zero Config\" voor de ontwikkelaar). 1. Metrics (Automatisch) De cluster-metrics (Nodes, Pods) worden direct opgehaald. Voor applicatie-specifieke metrics hoeft de Builder Agent alleen een ServiceMonitor toe te voegen of de standaard annotaties te gebruiken: yaml apiVersion: v1 kind: Service metadata: name: mijn-app annotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" spec: ports: - port: 8080 targetPort: 8080 2. Logs (Automatisch) Alles wat een applicatie naar stdout (console) schrijft, wordt door Promtail (onderdeel van Loki) opgepakt, gelabeld met de Pod-naam en naar Loki gestuurd. De ontwikkelaar hoeft geen log-files te beheren of log-shippers te configureren. 3. Traceability Dashboard In Grafana kan een \"Compliance Dashboard\" worden ingericht dat queries doet op Loki: bash {namespace=\"productie\"} |= \"UserLogin\" Dit toont direct een audit trail van wie wanneer heeft ingelogd. üîÑ Integratie in Druppie 1. Compliance Layer: De Compliance component kan alerts instellen in AlertManager (onderdeel van Prometheus). Bijvoorbeeld: \"Waarschuw de CISO als er een root-shell wordt geopend\". 2. Mens in de Loop: Beheerders kijken in Grafana om de impact van een nieuwe release te valideren. 3. Traceerbaarheid: Alle logs worden centraal bewaard, wat essentieel is voor de uitlegbaarheid van AI-beslissingen (waarom gaf de bot dit antwoord? -\u003e Check de logs)."
  },
  {
    "title": "Git \u0026 Versiebeheer (Gitea)",
    "category": "blocks",
    "path": "blocks/git_gitea.md",
    "content": "Git \u0026 Versiebeheer (Gitea) üéØ Selectie: Gitea Voor het beheren van de broncode (Source Code Management) en de infrastructuur-configuraties (GitOps) binnen het eigen cluster kiezen we voor Gitea. üí° Onderbouwing van de Keuze Hoewel cloud-diensten (zoals GitHub/GitLab.com) populair zijn, vereist de strikte compliance en autonomie van een waterschap vaak dat data (inclusief code en configs) in eigen beheer blijft. 1. Self-Hosted \u0026 Soeverein: Gitea draait volledig binnen de eigen Kubernetes omgeving. Code verlaat nooit de veilige muren van het cluster/VNet. 2. Extreem Lichtgewicht: In tegenstelling tot GitLab (dat veel resources vreet), is Gitea geschreven in Go en draait het soepel op minimale resources. Dit past perfect in de modulaire \"Micro-services\" gedachte van Druppie. 3. Feature Compleet: Biedt alle essenti√´le functies: Git repository hosting, Issue tracking, Pull Requests, en Webhooks (voor Tekton/Flux triggers). 4. Kubernetes Ready: Eenvoudig te installeren en schalen via Helm. --- üõ†Ô∏è Installatie We installeren Gitea via de offici√´le Helm chart. 1. Voeg Helm Repo toe bash helm repo add gitea-charts https://dl.gitea.io/charts/ helm repo update 2. Installeer Gitea We configureren Gitea om de interne PostgreSQL database (zie Database bouwblok) te gebruiken voor opslag. bash helm upgrade --install gitea gitea-charts/gitea \\ --namespace git-system --create-namespace \\ --set gitea.admin.username=druppie_admin \\ --set gitea.admin.password=SUPER_SECRET_PASSWORD \\ --set persistence.size=10Gi \\ --set postgresql.enabled=false \\ --set gitea.database.type=postgres \\ --set gitea.database.host=druppie-core-db-rw.default.svc.cluster.local \\ --set gitea.database.user=druppie \\ --set gitea.database.name=gitea (Opmerking: In productie gebruiken we een Secret voor het wachtwoord ipv plain text params) --- üöÄ Gebruik 1. Repository Aanmaken (De \"Project Kluis\") De Builder Agent maakt voor elk nieuw project (bijv. \"Drone Service\") een nieuwe repository aan. Dit gebeurt via de Gitea API: http POST /api/v1/user/repos { \"name\": \"drone-service\", \"private\": true, \"description\": \"Service voor het verwerken van drone beelden\" } 2. Access Tokens (De \"Sleutel\") Om Tekton (CI) en Flux (CD) toegang te geven, genereren we een Access Token. Tekton heeft schrijf-rechten nodig (om image tags te updaten in deployment.yaml). Flux heeft lees-rechten nodig (om de cluster state op te halen). 3. Webhooks (De \"Trigger\") Zodra er code gepusht wordt, vuurt Gitea een webhook af naar de Tekton EventListener: POST http://el-tekton-listener.tekton-pipelines:8080 Dit start automatisch de bouw-straat. üîÑ Integratie in Druppie 1. Opslag (Single Source of Truth): Alle code die de Builder Agent genereert, wordt hier opgeslagen. 2. Versiebeheer: Elke wijziging is een Git commit. Dit vormt de wettelijk verplichte Audit Trail. We kunnen altijd terugkijken: \"Wie heeft deze regel code veranderd en wanneer?\". 3. GitOps Bron: Gitea is de bron voor Flux. Als Gitea uitvalt, draait de productie gewoon door, maar kunnen er tijdelijk geen updates worden uitgerold."
  },
  {
    "title": "Container Registry (Harbor)",
    "category": "blocks",
    "path": "blocks/container_registry.md",
    "content": "Container Registry (Harbor) üìÑ Samenvatting Dit bouwblok beschrijft de implementatie van een centrale opslagplaats voor Docker images (Container Registry). Voor een Kubernetes-platform is een betrouwbare, snelle en veilige registry essentieel. Wij kiezen voor Harbor vanwege de cloud-native focus, ingebouwde security scanning en role-based access control. üéØ Doelstelling Het bieden van een veilige haven ('Harbor') waar alle gebouwde applicatie-images worden opgeslagen voordat ze worden uitgerold naar de clusters. Dit zorgt voor: Versiebeheer: Elke build heeft een unieke, onwijzigbare tag (immutable). Security: Images worden automatisch gescand op kwetsbaarheden (CVE's) voordat ze \"live\" mogen. Performance: Lokale caching van images dichtbij de clusters. ‚öôÔ∏è Technologie Selectie Wij standaardiseren op Harbor. Waarom Harbor? Open Source \u0026 CNCF Graduated: De industriestandaard voor self-hosted registries. Ingebouwde Scanning: Naadloze integratie met Trivy om images te scannen bij push. RBAC \u0026 OIDC: Koppelt direct met Keycloak voor gebruikersbeheer (wie mag pushen/pullen). Replication: Kan images synchroniseren tussen verschillende Harbor instanties (bijv. DMZ vs Intern). Signing: Ondersteunt Cosign/Notary voor het digitaal ondertekenen van images (supply chain security). üî® Implementatie Specificaties 1. Deployment Model Harbor wordt uitgerold binnen het tooling cluster via Helm. Namespace: harbor Storage: Gebruikt MinIO (S3) of een PVC voor de opslag van de lagen (layers). Ingress: Bereikbaar via registry.druppie.local (of publieke URL). 2. Integratie met Core De Druppie Core (Build Plane) interacteert met Harbor: 1. Push: De CI/CD pipeline (Tekton) bouwt een image en pusht deze naar Harbor. 2. Scan: Harbor triggert een Trivy scan. 3. Webhook: Harbor stuurt een event naar de Core: SCAN_COMPLETED met status PASS of FAIL. 4. Pull: De Kubernetes clusters authenticeren met een ImagePullSecret om de images binnen te halen. 3. Configuratie (Helm Values voorbeelden) yaml expose: type: ingress tls: enabled: true secretName: \"harbor-tls\" ingress: hosts: core: \"registry.druppie.local\" externalURL: \"https://registry.druppie.local\" persistence: imageChartStorage: type: s3 s3: region: \"us-east-1\" bucket: \"harbor-images\" accesskey: \"minio-admin\" secretkey: \"minio-secret\" regionendpoint: \"http://minio.minio.svc:9000\" trivy: enabled: true üõ°Ô∏è Security \u0026 Compliance Image Signing: Alle productie-images MOETEN ondertekend zijn. Vulnerability Policy: Images met 'Critical' CVE's worden geblokkeerd en kunnen niet gepulled worden (Deployment Preventie). Retention Policy: Oude 'nightly' builds worden na 14 dagen automatisch verwijderd om opslag te besparen. Noodzakelijke Skills Docker \u0026 OCI standaarden. Kubernetes (voor Helm deployment). Linux systeembeheer (voor storage management)."
  },
  {
    "title": "Traceability (Tempo \u0026 OTEL)",
    "category": "blocks",
    "path": "blocks/traceability_otel.md",
    "content": "Traceability \u0026 Audit (Tempo \u0026 OpenTelemetry) üéØ Selectie: Grafana Tempo \u0026 OpenTelemetry Om volledige Traceability (herleidbaarheid) van elke actie binnen het Druppie platform te garanderen, kiezen we voor de combinatie OpenTelemetry (OTEL) als standaard voor data-verzameling en Grafana Tempo als backend voor de opslag van traces. üí° Onderbouwing van de Keuze Deze combinatie maakt de \"Black Box\" transparant: 1. De Standaard (OpenTelemetry): OTEL is de wereldwijde standaard voor het verzamelen van telemetry data. Door deze standaard te omarmen, voorkomen we \"vendor lock-in\". Elke component (Agent, API, DB) instrumenteren we met de OTEL SDK. 2. Correlatie (The \"Trace ID\"): De kracht zit in de TraceID. Wanneer een gebruiker een vraag stelt, wordt √©√©n uniek ID gegenereerd die meereist door het hele systeem: Gebruiker vraagt iets -\u003e TraceID: abc-123 Router Agent kiest tool -\u003e Logt met TraceID: abc-123 Postgres DB draait query -\u003e Logt met TraceID: abc-123 Tempo stelt ons in staat om deze hele keten als √©√©n tijdlijn te visualiseren. 3. Integratie met bestaande Stack: Tempo integreert naadloos met Grafana (Dashboard) en Loki (Logs) die we al geselecteerd hebben. Je kunt in Grafana klikken op een logregel en direct de hele trace zien. 4. High Volume, Low Cost: Tempo is ontworpen om extreem goedkoop enorme hoeveelheden traces op te slaan in Object Storage (S3/MinIO), in tegenstelling tot dure index-based oplossingen. --- üõ†Ô∏è Installatie We voegen Tempo toe aan onze monitoring namespace. 1. Tempo Installeren Via Helm: bash helm repo add grafana https://grafana.github.io/helm-charts helm upgrade --install tempo grafana/tempo \\ --namespace monitoring \\ --set persistence.enabled=true \\ --set persistence.size=10Gi 2. OTEL Collector De collector fungeert als \"makelaar\". Applicaties sturen data naar de collector, en de collector stuurt het door naar Tempo (Traces) en Loki (Logs). bash helm upgrade --install otel-collector open-telemetry/opentelemetry-collector \\ --namespace monitoring --- üöÄ Gebruik Het gebruik vergt een kleine aanpassing in de applicatie-code (de Agents), wat we faciliteren via de Builder Agent. 1. Instrumentatie (Code) Elke Python/NodeJS agent krijgt standaard de OTEL-library mee. Voorbeeld (Python Agent): python from opentelemetry import trace tracer = trace.get_tracer(__name__) def handle_user_question(question): Start een 'Span' (een blokje in de tijdlijn) with tracer.start_as_current_span(\"process_question\") as span: span.set_attribute(\"user.id\", \"user_123\") span.set_attribute(\"question.category\", \"waterbeheer\") Voer logica uit... result = planner.create_plan(question) Log de beslissing als 'Event' in de trace span.add_event(\"Plan Created\", attributes={\"plan.steps\": str(len(result.steps))}) return result 2. Audit \u0026 Analyse (Grafana) In Grafana kunnen we nu zoeken op TraceID. We zien een tijdlijn (Gantt-chart) van exact wat er gebeurde: 0ms: Request binnen 50ms: Authenticatie Check (IAM) 120ms: Router Agent start 400ms: LLM Call (Azure OpenAI) - Hier zien we exact hoe lang de LLM erover deed 1500ms: Antwoord naar gebruiker 3. De \"Audit Log\" Link Omdat we de TraceID ook wegschrijven in de Loki logs (bijv: {\"level\":\"info\", \"traceID\":\"abc-123\", \"msg\":\"Prompt verstuurd...\"}), kunnen we in √©√©n klik van het technische plaatje naar de inhoudelijke payload springen om te lezen wat er precies naar de LLM is gestuurd. üîÑ Integratie in Druppie 1. Compliance: De TraceID wordt de sleutel voor de audit. Als een auditor vraagt \"Wat gebeurde er bij incident X?\", zoeken we de TraceID op en hebben we het volledige verhaal. 2. Performance: We zien direct waar de vertraging zit (bijv. \"De Database query duurde 2 seconden\"). 3. Traceability DB: In de spec noemden we de \"Traceability DB\". In de praktijk is dit dus de combinatie van Tempo (Structuur/Tijdlijn) en Loki (Inhoud), ontsloten via Grafana."
  },
  {
    "title": "IAM (Keycloak \u0026 Azure AD)",
    "category": "blocks",
    "path": "blocks/iam_keycloak.md",
    "content": "Identity \u0026 Access Management (Keycloak) üéØ Selectie: Keycloak Voor het beheer van gebruikersidentiteiten, authenticatie en autorisatie kiezen we voor Keycloak. Keycloak fungeert als een Identity Broker tussen onze applicaties en de centrale gebruikersdirectory (Azure AD / Microsoft Entra ID). üí° Onderbouwing van de Keuze Waarom Keycloak als tussenlaag en niet direct Azure AD koppelen aan elke applicatie? 1. Identity Brokering: Keycloak ontkoppelt de applicaties van de specifieke Identity Provider (IdP). Als we ooit willen wisselen van IdP of een tweede IdP (bijv. DigiD voor burgers) willen toevoegen, hoeven we de applicaties niet aan te passen. Keycloak regelt de vertaalslag. 2. Granulaire RBAC: We kunnen in Keycloak specifieke rollen en groepen defini√´ren voor onze apps (bijv. DroneViewer, DroneEditor) en deze mappen naar Azure AD groepen. Dit houdt de Azure AD schoon en geeft teams meer autonomie. 3. Unified Login: Keycloak biedt √©√©n centrale Single Sign-On (SSO) ervaring. 4. Kubernetes Native: Draait als container op het cluster en is eenvoudig te configureren via CRD's (met de Keycloak Operator) of via de API. --- üõ†Ô∏è Installatie We installeren Keycloak via de geoptimaliseerde Bitnami Helm chart of operator. 1. Installatie via Helm bash helm repo add bitnami https://charts.bitnami.com/bitnami helm upgrade --install keycloak bitnami/keycloak \\ --namespace iam-system --create-namespace \\ --set auth.adminUser=admin \\ --set auth.adminPassword=SECRET_ADMIN_PW \\ --set service.type=ClusterIP \\ --set postgresql.enabled=false \\ --set externalDatabase.host=druppie-core-db-rw.default.svc.cluster.local \\ --set externalDatabase.user=druppie \\ --set externalDatabase.password=DB_PASSWORD \\ --set externalDatabase.database=keycloak (Ook hier hergebruiken we de centrale PostgreSQL cluster voor opslag) --- ‚öôÔ∏è Integratie met Azure AD (Entra ID) De cruciale stap is het koppelen van Azure AD als upstream Identity Provider. 1. Azure AD App Registration Maak in de Azure Portal een App Registration aan: Redirect URI: https://auth.druppie.nl/realms/druppie/broker/oidc/endpoint Genereer een Client Secret. 2. Keycloak Configureren In de Keycloak Admin Console: 1. Maak een Realm aan: druppie. 2. Ga naar Identity Providers -\u003e OpenID Connect v1.0. 3. Alias: azure-ad. 4. Discovery Endpoint: https://login.microsoftonline.com/{TENANT_ID}/v2.0/.well-known/openid-configuration. 5. Vul Client ID en Secret in van stap 1. 6. Mappers: Configureer mappers om gebruikersinfo (email, naam, groups) uit het Azure AD token over te nemen naar het Keycloak user profiel. --- üöÄ Gebruik in Applicaties Wanneer de Builder Agent een nieuwe frontend bouwt (bijv. een React app), configureert hij deze om gebruik te maken van Keycloak. OIDC Configuratie De applicatie praat alleen met Keycloak, niet met Azure. json { \"authority\": \"https://auth.druppie.nl/realms/druppie\", \"client_id\": \"drone-service-frontend\", \"redirect_uri\": \"https://drone.druppie.nl/callback\", \"response_type\": \"code\", \"scope\": \"openid profile email offline_access\" } Flow 1. Gebruiker opent de app -\u003e wordt doorgestuurd naar Keycloak. 2. Keycloak toont knop \"Login met Azure AD\". 3. Gebruiker logt in bij Microsoft. 4. Azure stuurt gebruiker terug naar Keycloak met token. 5. Keycloak vertaalt dit naar een intern token (met juiste interne rollen). 6. Keycloak stuurt gebruiker terug naar de App. üîÑ Integratie in Druppie 1. Applicatie Security: De Ingress controller (zie Webserver bouwblok) kan samenwerken met Keycloak (via OAuth2 Proxy) om applicaties te beveiligen die zelf geen login-logica hebben. 2. Audit: Keycloak logt elke loginpoging. Deze logs worden door Loki (zie Observability) opgehaald. Zo zien we precies wie wanneer heeft ingelogd."
  },
  {
    "title": "Data Lake (MinIO)",
    "category": "blocks",
    "path": "blocks/data_lake_minio.md",
    "content": "Data Lake \u0026 Object Storage (MinIO) üéØ Selectie: MinIO Voor de opslag van grootschalige ongestructureerde data, specifiek drone-beelden, satelliet-data en AI-modellen, kiezen we voor MinIO. MinIO is een High-Performance Object Storage oplossing die volledig compatible is met de Amazon S3 API. üí° Onderbouwing van de Keuze Relationele databases (zoals Postgres) zijn niet geschikt voor het opslaan van Terabytes aan ruwe pixel-data (Raster files). MinIO vult dit gat: 1. De facto Standaard (S3 API): Vrijwel elke moderne data-tool spreekt \"S3\". GIS Tools: GDAL, QGIS, GeoServer kunnen direct lezen/schrijven naar S3. AI/ML Frameworks: PyTorch, TensorFlow en MLflow laden datasets direct uit S3. Pipeline Tools: OpenDroneMap (voor stichting) en Tekton kunnen S3 als input/output gebruiken. 2. Versioning \u0026 Immutability: MinIO ondersteunt S3 Bucket Versioning. Als je een bestand overschrijft, bewaart MinIO de oude versie. Dit is cruciaal voor reproduceerbare AI: \"Op welke versie van de dataset is dit model getraind?\". 3. Performance: MinIO is geoptimaliseerd voor snelheid (gebruikt SIMD instructies) en kan de enorme doorvoer aan die nodig is voor het trainen van modellen op GPU's. 4. Kubernetes Native: Integreert naadloos met de rest van het platform. --- üõ†Ô∏è Installatie We installeren een stand-alone MinIO cluster (of een Distributed cluster voor productie). 1. Installatie via Helm bash helm repo add minio https://charts.min.io/ helm upgrade --install data-lake minio/minio \\ --namespace data-systems --create-namespace \\ --set rootUser=admin \\ --set rootPassword=VERY_SECRET_KEY \\ --set persistence.size=1Ti \\ --set buckets[0].name=drone-raw \\ --set buckets[0].policy=public \\ --set buckets[0].versioning=true \\ --set buckets[1].name=drone-ortho \\ --set buckets[2].name=ai-models --- üöÄ Gebruik: De Drone Workflow Dit bouwblok vormt de fundering voor de geavanceerde verwerking van beelden. Hieronder schetsen we hoe de \"Drone Pipeline\" gebruik maakt van MinIO. Stap 1: Ingestie \u0026 Versiebeheer De ruwe beelden (van de drone of satelliet provider) worden geupload naar de drone-raw bucket. Bestand: projects/dijk-a/flight-2025/image_001.tiff Versie: Dankzij bucket versioning krijgt elk bestand een uniek VersionID. Stap 2: Verwerking (Stitching) Een Tekton pipeline start een container met OpenDroneMap (ODM) of GDAL. Input: Leest de raw images direct uit s3://drone-raw. Process: \"Stitcht\" de losse foto's aan elkaar tot √©√©n grote kaart (Orthophoto). Output: Schrijft het resultaat naar s3://drone-ortho/dijk-a-merged.geotiff. Stap 3: Object Herkenning (AI) Zodra de nieuwe Orthophoto beschikbaar is, start de AI-job (bijvoorbeeld een YOLOv8 model in een Python container). Input: Leest de merged.geotiff uit MinIO. Inference: Het model scant de foto op specifieke objecten (bijv. \"Muskusrat klem\" of \"Beschadiging oever\"). Output: De gevonden locaties (co√∂rdinaten) worden opgeslagen in PostGIS (zie Database bouwblok). Annotated images (met bounding boxes) gaan terug naar MinIO s3://ai-results/. MetadataCatalogus (STAC) Om overzicht te houden in deze miljoenen bestanden, gebruiken we de SpatioTemporal Asset Catalog (STAC) standaard. De metadata (waar is de foto gemaakt? wanneer? welke cloud-cover?) slaan we op in PostGIS (of een dedicated STAC server), maar de link wijst altijd naar de binary in MinIO (href: s3://drone-raw/...). üîÑ Integratie in Druppie 1. MCP Server: We kunnen een MCP tool maken (list_drone_images) die de inhoud van de buckets aan de AI toont. 2. Model Training: Data Scientists koppelen hun Jupyter notebooks direct aan MinIO om nieuwe modellen te trainen. 3. Governance: Via MinIO Policies (IAM) regelen we dat de \"Stagiair\" alleen mag lezen, en alleen de \"Pipeline Service Account\" mag schrijven in de drone-ortho bucket."
  },
  {
    "title": "Infrastructure as Code (Terraform)",
    "category": "blocks",
    "path": "blocks/iaas_terraform.md",
    "content": "Infrastructure as Code (Terraform/OpenTofu) üéØ Selectie: OpenTofu (Terraform) Voor het provisioneren van infrastructuur binnen het Druppie platform is gekozen voor OpenTofu (de open-source fork van Terraform). Dit stelt ons in staat om infrastructuur declaratief te defini√´ren en te beheren als code. üí° Onderbouwing van de Keuze De keuze voor OpenTofu/Terraform is gebaseerd op de volgende kernwaarden: 1. Declaratief Model: Definieer wat je wilt (bijv. een Kubernetes cluster, een S3 bucket), niet hoe het gemaakt moet worden. Dit sluit 1-op-1 aan bij de Spec-Driven Architecture van Druppie. 2. Cloud Agnostisch: Hoewel providers specifiek zijn, is de workflow (init, plan, apply) identiek voor Azure, AWS, Google Cloud en on-premise (VMware/Proxmox). Dit ondersteunt de hybride runtime strategie. 3. State Management: Terraform houdt de staat van de infrastructuur bij. Dit is cruciaal voor de Builder Agent om te weten wat er al bestaat en wat er gewijzigd moet worden (drift detection). 4. Enorme Ecosystem: Er zijn providers voor bijna alles (Azure, Kubernetes, Helm, Keycloak, Grafana), waardoor we de hele stack met √©√©n tool kunnen beheren. ‚öôÔ∏è Implementatie in Druppie Binnen de architectuur vervult Terraform een specifieke rol in de Build Plane: Gegenereerd door AI: De Builder Agent schrijft Terraform configuraties (.tf files) op basis van de functionele specificaties. Execution in Foundry: De Tekton pipelines draaien tofu plan en tofu apply in een gecontroleerde omgeving. Integratie met Compliance: Terraform plannen worden v√≥√≥r uitvoering gevalideerd door tools zoals Trivy (IaC scanning) om te garanderen dat er geen onveilige infrastructuur wordt uitgerold (bijv. open storage buckets). üõ†Ô∏è Voorbeeld Spec Een voorbeeld van hoe een Terraform definitie eruit ziet die door de Agent gegenereerd kan worden: hcl resource \"azurerm_kubernetes_cluster\" \"druppie_cluster\" { name = \"druppie-prod\" location = \"West Europe\" resource_group_name = azurerm_resource_group.rg.name dns_prefix = \"druppie-k8s\" default_node_pool { name = \"default\" node_count = 3 vm_size = \"Standard_D2_v2\" } identity { type = \"SystemAssigned\" } tags = { Environment = \"Production\" ManagedBy = \"DruppieAgent\" } }"
  },
  {
    "title": "AI Dataset Versioning (DVC)",
    "category": "blocks",
    "path": "blocks/data_versioning_dvc.md",
    "content": "AI Dataset Versioning (DVC) üéØ Selectie: DVC (Data Version Control) Voor het semantisch beheren van versies van datasets (\"Trainingsset V1\", \"Validatieset V2.3\") bovenop onze ruwe opslag kiezen we voor DVC. DVC brengt de kracht van Git naar grote data-bestanden, zonder dat die bestanden daadwerkelijk in Git worden opgeslagen. üí° Onderbouwing van de Keuze MinIO heeft Object Versioning (technisch), maar DVC biedt Dataset Versioning (logisch). 1. Git voor Data: DVC werkt exact zoals Git. Data Scientists gebruiken commando's die ze al kennen (dvc checkout, dvc commit). 2. Meta-data in Git, Data in MinIO: De grote bestanden (GB's aan Tiff's) blijven in MinIO. DVC maakt kleine pointer-files (dataset.dvc) aan. Deze pointer-files slaan we op in Gitea. Hierdoor is de relatie tussen Code (het model) en Data (de trainingsset) onlosmakelijk verbonden in √©√©n Git commit hash. Dit garandeert volledige reproduceerbaarheid. 3. CI/CD Integratie: Omdat de dataset-definities in Git staan, kan Tekton automatisch een training pipeline starten zodra er een nieuwe dataset-versie wordt gepusht. --- üõ†Ô∏è Installatie DVC is een command-line tool en Python library. Er hoeft geen server ge√Ønstalleerd te worden op het cluster; het maakt gebruik van de infrastructuur die er al is (Gitea + MinIO). Wel kunnen we een (optionele) DVC Studio of een visualisatie-tool hosten, maar de kern werkt client-side. 1. Configuratie in Project Een Data Scientist initialiseert DVC in zijn project repo (op zijn laptop of in een DevContainer): bash In de git repo dvc init Stel MinIO in als 'remote' storage dvc remote add -d my-minio s3://ai-datasets dvc remote modify my-minio endpointurl https://minio.druppie.nl dvc remote modify my-minio access_key_id AR_IS_EEN_KEY dvc remote modify my-minio secret_access_key SUPER_GEHEIM --- üöÄ Gebruik: Een Gecontroleerde Dataset Maken Stel we hebben een map data/raw_images met 10.000 drone foto's. Stap 1: Tracken van Data bash dvc add data/raw_images Dit doet 2 dingen: 1. Uploadt de bestanden naar MinIO. 2. Maakt data/raw_images.dvc aan (bevat MD5 hashes van de data). Stap 2: Versie Vastleggen (Git) We committen de pointer naar Gitea. bash git add data/raw_images.dvc .gitignore git commit -m \"Dataset V1: Initi√´le drone set\" git push Stap 3: Werken met Versies Stel een collega (of de Builder Agent) wil het model trainen op deze specifieke versie. bash git clone https://gitea.druppie.nl/projecten/drone-ai.git dvc pull DVC ziet de hash in het .dvc bestand, haalt exact die versie van de bestanden uit MinIO, en plaatst ze in de werkmap. Zelfs als de dataset inmiddels is aangepast naar V2, haalt deze commit altijd V1 op. üîÑ Integratie in Druppie (MLOps) 1. Reproduceerbaarheid (Compliance): Als een auditor vraagt \"Op welke data is dit model getraind?\", wijzen we naar de Git commit hash. Via DVC kunnen we bewijzen welke bestanden dat waren. 2. Pipeline Triggering: De Builder Agent ziet een update in de dataset (nieuwe .dvc file). Triggert een Tekton pipeline. Tekton doet dvc pull -\u003e python train.py -\u003e dvc metrics log. Het resultaat is een nieuw AI model."
  },
  {
    "title": "Drone Mapping (WebODM)",
    "category": "blocks",
    "path": "blocks/drone_pipeline_odm.md",
    "content": "Drone Mapping \u0026 3D Processing (OpenDroneMap) üéØ Selectie: WebODM (OpenDroneMap) Voor het totale proces van fotogrammetrie ‚Äî het omzetten van losse 2D dronefoto's naar georeferenced orthofoto's en 3D-modellen ‚Äî kiezen we voor WebODM. Dit is de gebruiksvriendelijke, web-based interface bovenop de krachtige OpenDroneMap (ODM) engine. üí° Onderbouwing van de Keuze Deze toolset is de open-source standaard in de GIS-wereld en sluit naadloos aan op onze infrastructuur: 1. Alles-in-√©√©n Pipeline: Preprocessing: Herkent GPS data in foto's. Stitching: Plakt foto's aan elkaar (Orthofoto). 3D Modelling: Genereert Point Clouds (.laz) en Textured 3D Models (.obj/gltf). Analyses: Kan ook vegetatie-indices (zoals NDVI voor landbouw/natuur) berekenen. 2. Kubernetes Ready: WebODM is ontworpen als een set microservices (NodeODMICM) die schalen op ons cluster. \"Zware\" taken worden verdeeld over meerdere Processing Nodes. 3. Integratie: Kan resultaten direct wegschrijven naar onze PostGIS database of als tiles serveren. 4. Vluchtplanning (QGroundControl): WebODM werkt perfect samen met open standaarden voor vluchtplannen. Hoewel de drone zelf vliegt, slaan we het Vluchtplan op als onderdeel van het project. --- üõ†Ô∏è Installatie We installeren WebODM op het Kubernetes cluster, met toegang tot de GPU-nodes (indien beschikbaar) voor snellere 3D verwerking. 1. Installatie via Helm Er is geen offici√´le Helm repository, maar we gebruiken vaak een community chart of de docker-compose conversie. Een typische deployment in Druppie ziet er zo uit: bash Clone de deployment configuratie uit onze GIT repo flux create kustomization webodm \\ --source=druppie-infra \\ --path=./apps/webodm \\ --prune=true Dit start: WebApp: De interface voor gebruikers. NodeODM: De worker(s) die het rekenwerk doen. Database: Interne Postgres (of onze centrale Postgres Cluster). --- üöÄ Gebruik: Van Vlucht tot 3D Model Het proces bestaat uit drie fasen, die door Druppie worden gefaciliteerd. Stap 1: Vluchtplanning \u0026 Uitvoering Tool: QGroundControl (Client-side) Om een vast interval (bijv. \"elke 2 meter een foto\") en overlap te garanderen, maakt de piloot een vluchtplan. 1. Teken gebied in QGroundControl. 2. Stel parameters in: Front Overlap: 70% (Cruciaal voor 3D). Side Overlap: 60%. GSD (Ground Sampling Distance): 2cm/pixel. 3. Sla het plan op (mission.plan) en upload dit naar Gitea bij het project. Dit garandeert reproduceerbaarheid (\"Vlieg volgende maand exact dezelfde route\"). Stap 2: Upload \u0026 Verwerking (WebODM) De foto's komen van de SD-kaart. 1. Upload: Gebruiker (of script) uploadt de map met 500 foto's naar een WebODM Taak. 2. Opties: Selecteer \"High Resolution\" voor dijkinspectie of \"Fast\" voor een snelle check. 3. Processing: WebODM draait de Structure from Motion (SfM) algoritmes. Feature Matching: Zoekt dezelfde boom/struik in foto A en foto B. Point Cloud: Berekent de 3D positie van elk punt. Texturing: Plakt de foto-pixels op het 3D model. Stap 3: Resultaat \u0026 Analyse De output wordt automatisch beschikbaar gemaakt: Orthofoto (2D): Een meetbare kaart. Te openen in QGIS of via de WebODM interface. 3D Model: Een interactief model. De gebruiker kan in de browser ronddraaien, afstanden meten en volumes berekenen (bijv. \"Hoeveel kuub zand ligt hier?\"). üîÑ Integratie in Druppie 1. Data Lake: WebODM gebruikt ons MinIO cluster (s3://drone-ortho) om de gigabytes aan resultaten op te slaan. 2. MCP Server: We bouwen een MCP tool (get_3d_snapshot) waarmee de AI een screenshot kan maken van het 3D model vanuit een bepaalde hoek, om daar vervolgens vragen over te beantwoorden. 3. Traceability: Het vluchtplan (mission.plan in Git) + de ruwe foto's (in DVC) + de WebODM instellingen = 100% Reproduceerbaar resultaat."
  },
  {
    "title": "AI Anonymizer (YOLOv8)",
    "category": "blocks",
    "path": "blocks/ai_anonymizer_yolo.md",
    "content": "AI Anonymizer (YOLOv8) üéØ Selectie: YOLOv8 Voor het automatisch detecteren en anonimiseren van privacy-gevoelige objecten (gezichten, personen, kentekenplaten) in beeldmateriaal kiezen we voor YOLOv8 (You Only Look Once, versie 8) van Ultralytics. üí° Onderbouwing van de Keuze Waarom een generiek AI-model en geen specifieke \"Blur Tool\"? 1. SOTA (State of the Art): YOLOv8 is momenteel de industriestandaard voor real-time objectdetectie. Het is extreem snel en nauwkeurig. 2. Trainbaar: Standaard tools (zoals FaceDetect) werken vaak niet goed op drone-beelden (bovenaanzicht, kleine pixels). YOLOv8 kunnen we specifiek hertrainen (Fine-Tuning) op onze eigen \"Drone Dataset\" met behulp van gelabelde data uit DVC. 3. Flexibiliteit: Vandaag: Gezichten en Kentekens anonimiseren. Morgen: Muskusratten of Kadebreuken detecteren. De infrastructuur blijft hetzelfde, alleen het modelbestand (.pt) verandert. 4. Performance: Geoptimaliseerd voor GPU. Dit is essentieel als we TB's aan data moeten verwerken in onze pipeline. --- üõ†Ô∏è Installatie We verpakken YOLOv8 in een container die fungeert als een \"Filter Service\". Docker Image We gebruiken de offici√´le base image en voegen een klein Python script toe dat de blurring doet. dockerfile FROM ultralytics/ultralytics:latest-cpu (Of 'latest-gpu' voor de nodes met NVIDIA kaarten) RUN pip install opencv-python-headless COPY anonymize.py /app/ ENTRYPOINT [\"python\", \"/app/anonymize.py\"] Het Script (anonymize.py) In pseudocode: 1. Laad Model: model = YOLO('yolov8n-face.pt') 2. Open Info: img = cv2.imread(input_path) 3. Detecteer: results = model(img) 4. Voor elke detectie (Box): Pas een Gaussian Blur toe op de regio binnen de box. (Tip: Gebruik geen zwart vlak, dat verstoort de fotogrammetrie/stitching in WebODM. Blurring behoudt de kleur-structuur). 5. Sla op: cv2.imwrite(output_path, img) --- üöÄ Gebruik: De \"Scrubbing Pipeline\" Dit bouwblok wordt aangeroepen door Tekton in de Data Lifecycle. Configuratie (ConfigMap) We kunnen de agressiviteit van het model instellen: yaml confidence_threshold: 0.25 Bij twijfel: blurren (Better safe than sorry) classes_to_blur: - 0 Person - 1 Bicycle (Optioneel) - 2 Car (Kentekens) Validatie (Human-in-the-Loop) Hoewel YOLOv8 \u003e99% kan scoren, is bij High Risk data (dichtbij bebouwing) een menselijke check nodig. De pipeline kan een \"Heatmap\" genereren van geblurde locaties. De operator ziet in √©√©n oogopslag waar anonimisering heeft plaatsgevonden en kan steekproeven doen. üîÑ Integratie in Druppie 1. DVC: Het getrainde model zelf (drone-face-v1.pt) wordt beheerd in DVC net als de data. 2. WebODM: De output van deze anonimizer is de input voor WebODM. Doordat we \"zacht\" blurren, kan WebODM de foto's nog steeds aan elkaar stitchen op basis van de omgeving (gras, bomen), terwijl de personen onherkenbaar zijn. 3. Governance: In de metadata van de foto (EXIF) schrijven we: Processed-By: Druppie-Anonymizer-V1."
  },
  {
    "title": "Workflow Engine (Argo)",
    "category": "blocks",
    "path": "blocks/workflow_argo.md",
    "content": "Workflow Orchestration (Argo Workflows) üéØ Selectie: Argo Workflows Voor het orkestreren van complexe werkprocessen en data-pipelines kiezen we voor Argo Workflows. Dit is de Kubernetes-native workflow engine waarmee je processen definieert als een reeks stappen (DAG - Directed Acyclic Graph). üí° Onderbouwing van de Keuze Waarom is dit ideaal voor een \"door AI gegenereerde\" workflow? 1. Declaratief (YAML): Een workflow is \"gewoon\" een Kubernetes resource (kind: Workflow). LLM's (zoals GPT-4) zijn uitstekend getraind in het genereren van gestructureerde YAML. De AI hoeft geen complexe, proprietary code te schrijven, maar alleen een logische lijst van stappen te defini√´ren. 2. Visueel: Argo biedt een prachtige UI. De Mens in de Loop ziet precies het schema dat de AI heeft bedacht (A -\u003e B -\u003e C) en kan dit valideren. 3. Container Native: Elke stap in de workflow is een container. Dit betekent dat we al onze bestaande bouwblokken (Python scripts, WebODM commando's, DVC acties) direct als stap kunnen hergebruiken. \"Lijm code\" is minimaal. 4. Schaalbaar: In tegenstelling tot monolithische tools (zoals n8n of Airflow op √©√©n VM), draait elke stap als een Pod. Voor onze drone-data kunnen we dus duizenden stappen parallel draaien. --- üõ†Ô∏è Installatie Argo Workflows staat los van ArgoCD en bijt elkaar niet. 1. Installatie via Helm bash helm repo add argo https://argoproj.github.io/argo-helm helm upgrade --install argo-workflows argo/argo-workflows \\ --namespace workflow-system --create-namespace \\ --set server.serviceType=ClusterIP 2. (Optioneel) Argo Events Om workflows te starten op basis van \"Events\" (bijv. een bestand in MinIO, een webhook, of een tijdstip): bash helm upgrade --install argo-events argo/argo-events \\ --namespace workflow-system --- üöÄ Gebruik: AI-Driven Workflow Creatie Het concept is: De gebruiker beschrijft het proces, de Builder Agent genereert de YAML. Scenario: \"Verwerk Drone Foto's\" Gebruiker: \"Maak een flow die alle foto's uit de raw bucket haalt, ze verwerkt met WebODM, en mij een email stuurt als het klaar is.\" De Generatie (door AI) De Builder Agent genereert de volgende YAML (simpel weergegeven): yaml apiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: drone-process- spec: entrypoint: drone-dag templates: - name: drone-dag dag: tasks: Stap 1: Check Data - name: fetch-data template: dvc-pull arguments: parameters: [{name: repo, value: \"flight-2025\"}] Stap 2: Verwerking (Start pas als Stap 1 klaar is) - name: process-odm dependencies: [fetch-data] template: odm-stitch arguments: parameters: [{name: resolution, value: \"high\"}] Stap 3: Notificatie - name: send-email dependencies: [process-odm] template: send-notification arguments: parameters: [{name: msg, value: \"Verwerking gereed!\"}] Herbruikbare Templates (De \"Bouwstenen\") - name: dvc-pull container: image: my-registry/dvc-worker:latest command: [dvc, pull] ... De Uitvoering 1. Submit: De Agent (of Foundry) past deze YAML toe (kubectl create -f flow.yaml). 2. Visualisatie: De gebruiker opent de Argo UI en ziet drie blokjes. fetch-data wordt groen ‚úÖ (Klaar). process-odm wordt blauw üîµ (Bezig). 3. Governance: Omdat alles via Kubernetes loopt, geldt automatisch ons beveiligingsbeleid (Network Policies, IAM). üîÑ Integratie in Druppie 1. Business Logica: Voor bedrijfsprocessen (\"Nieuwe medewerker onboarden\") werkt dit exact hetzelfde. De AI koppelt de ad-create-user en email-send-welcome stappen aan elkaar. 2. Samenwerking met Tekton: Tekton gebruiken we voor CI/CD (het bouwen van de containers). Argo Workflows gebruiken we voor de Processen (het uitvoeren van de containers in een logische volgorde)."
  },
  {
    "title": "API Gateway (Kong)",
    "category": "blocks",
    "path": "blocks/api_gateway_kong.md",
    "content": "API Gateway (Kong) üéØ Selectie: Kong Gateway Voor het geavanceerd beheren, beveiligen en monitoren van API-verkeer kiezen we voor Kong Gateway (DB-less mode). Kong fungeert als de voordeur voor alle microservices en AI-agenten. üí° Onderbouwing van de Keuze Hoewel we al een Ingress Controller (NGINX) hebben voor basis routing, voegt een API Gateway een abstractielaag toe die essentieel is voor een volwassen platform: 1. Decoupling: De afnemer van de data praat met api.druppie.nl/v1/drone-data, terwijl de backend misschien drone-service-v3.internal:8080/export heet. De Gateway vertaalt dit. 2. Policy Enforcement (CRD): Met Kong beheren we \"Traffic Policies\" als Kubernetes objecten (KongPlugin). De Policy Engine (zie Architecture) kan zo afdwingen dat elke externe API een Rate Limit heeft, zonder de applicatiecode aan te passen. 3. Centrale Authenticatie: Kong valideert API Keys of JWT tokens (van Keycloak) voordat het verzoek de service bereikt. Dit ontlast de ontwikkelaars. 4. Transformation: Kong kan on-the-fly requests aanpassen (bijv. een oude XML response omzetten naar JSON) om legacy systemen te ontsluiten voor moderne AI agents. 5. Performance: Kong is gebouwd op NGINX en is extreem snel en lichtgewicht. --- üõ†Ô∏è Installatie We installeren Kong als Ingress Controller (of als Gateway achter NGINX). In DB-less mode is hij stateless en makkelijk te schalen. 1. Installatie via Helm bash helm repo add kong https://charts.konghq.com helm upgrade --install kong kong/kong \\ --namespace api-gateway --create-namespace \\ --set ingressController.installCRDs=false \\ --set dblessConfig.configMap=kong-config (We installeren CRDs meestal apart om race-conditions te voorkomen) --- üöÄ Gebruik: Policies als Code De kracht van Kong binnen Druppie is dat de Builder Agent policies kan genereren op basis van functionele eisen. Scenario: \"Bescherm de Drone API tegen overbelasting\" Gebruiker: \"De drone data API mag maximaal 100 requests per minuut ontvangen.\" De Builder Agent genereert een KongPlugin manifest: yaml apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: rate-limit-100 namespace: productie config: minute: 100 policy: local plugin: rate-limiting En koppelt deze aan de Service of Ingress: yaml apiVersion: filtering.presidio.com/v1 Fictief voorbeeld kind: Ingress metadata: name: drone-api annotations: konghq.com/plugins: rate-limit-100 konghq.com/strip-path: \"true\" spec: ingressClassName: kong rules: - host: api.druppie.nl http: paths: - path: /v1/drone-data pathType: ImplementationSpecific backend: service: name: drone-service port: number: 80 Andere veelgebruikte Plugins Key Auth: konghq.com/plugins: api-key-auth (Voor M2M communicatie). Prometheus: Exposeert metrics over API gebruik direct naar onze PLG stack. Correlation ID: Voegt een Trace-ID toe aan de header voor Traceability. üîÑ Integratie in Druppie 1. Compliance: De Gateway logt elk request. De logs gaan naar Loki. Als er misbruik wordt gemaakt van een API, zien we dat direct. 2. Versiebeheer: API changes (v1 -\u003e v2) worden beheerd in de Ingress definities in Git. 3. Verbinding met MCP: Als we externe tools (MCP Servers) ontsluiten, zetten we die achter Kong. Zo kunnen we precies meten hoeveel tokens/calls een specifieke AI-agent verbruikt."
  },
  {
    "title": "Architectuur (Archi)",
    "category": "blocks",
    "path": "blocks/architecture_archi.md",
    "content": "Architectuur Modellering (Archi) üéØ Selectie: Archi \u0026 Model Repository (coArchi) Voor het vastleggen en beheren van de Enterprise Architectuur conform de ArchiMate 3.2 standaard kiezen we voor Archi. Om samenwerking en versiebeheer mogelijk te maken, gebruiken we de coArchi plugin in combinatie met onze Gitea Git-server. üí° Onderbouwing van de Keuze Waarom Archi in een DevOps omgeving? 1. De Open Source Standaard: Archi is de referentie-implementatie voor ArchiMate. Het is gratis, open-source en wordt breed gedragen. 2. Git-Based (coArchi): Dankzij de coArchi plugin wordt het model niet als √©√©n monolithisch bestand opgeslagen, maar als losse objecten/files in Git. Dit maakt Merge Conflicts beheersbaar. Het integreert naadloos met onze \"Alles is Code\" filosofie. Wijzigingen in de architectuur zijn commits in Gitea. 3. Automatisering (CLI): Archi heeft een Command Line Interface. We kunnen hiermee automatisch (via Tekton) rapporten en plaatjes genereren zodra een architect iets commit. 4. Machine Readable: Het .archimate (XML) bestandsformaat is leesbaar voor onze Builder Agent. De AI kan de architectuur lezen om te \"begrijpen\" hoe componenten samenhangen voordat hij code gaat schrijven. --- üõ†Ô∏è Installatie De tool bestaat uit een Client (voor de architect) en een Pipeline (voor publicatie). 1. Client Setup (Op laptop van Architect) Download Archi 5.x+. Installeer de coArchi Plugin. Verbind met Gitea: URL: https://gitea.druppie.nl/architectuur/enterprise-model.git Auth: Gebruikersnaam + Token. 2. CI/CD Setup (In het Cluster) We gebruiken een Docker container met de Archi CLI om rapporten te genereren in onze bouwstraat. Docker Image: ghcr.io/archi-contrib/docker-archi:latest Implementatie in een Tekton Task: yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: generate-archi-report spec: steps: - name: export-html image: ghcr.io/archi-contrib/docker-archi:latest command: - /opt/Archi/Archi - -application - com.archimatetool.commandline.app - -consoleLog - -nosplash - --html.createReport - /workspace/output - --modelrepository.loadModel - /workspace/source --- üöÄ Gebruik: Van Model naar Publicatie Workflow 1. Modelleren: De architect past het model aan in Archi (b.v. \"Nieuwe applicatie toevoegen aan landschap\"). 2. Commit \u0026 Push: Via de coArchi plugin \"Publish Changes\". Dit stuurt de wijzigingen naar Gitea. 3. Pipeline Trigger: Gitea stuurt een webhook naar Tekton. 4. Generatie: Tekton start de docker-archi container. Genereert een interactief HTML rapport. Genereert losse PNG's van alle views. 5. Publicatie: De HTML wordt ge√ºpload naar een webserver (bijv. via Nginx Ingress) op https://architectuur.druppie.nl. AI Integratie (Builder Agent) De Builder Agent kan het model analyseren: Vraag: \"Welke applicaties gebruiken de 'Klant Database'?\" Actie: Agent leest de XML export (via MCP tool read_repo). Analyse: Zoekt relaties Serving of Access richting het object Klant Database. Resultaat: \"Volgens het model gebruiken 'MijnOmgeving' en 'Facturatie' deze database.\" üîÑ Integratie in Druppie 1. Levende Documentatie: Het architectuurmodel is geen statisch PDF in een lade, maar een levende website die altijd up-to-date is met de laatste commit. 2. Compliance: Wijzigingen in de architectuur (bijv. toevoegen van een externe koppeling) zijn traceerbaar in Git (Wie? Wanneer? Waarom?). Dit ondersteunt de BIO/ISO audits. 3. Ontwerp Validatie: Voordat een team begint met bouwen, checkt de Builder Agent of de voorgenomen oplossing past binnen de kaders van het ArchiMate model."
  },
  {
    "title": "GIS Desktop (QGIS)",
    "category": "blocks",
    "path": "blocks/gis_qgis.md",
    "content": "GIS Desktop \u0026 Server (QGIS) üéØ Selectie: QGIS (Quantum GIS) Voor geavanceerde ruimtelijke analyses, kaarten maken en data-bewerking kiezen we voor QGIS. Dit is de absolute marktleider in open-source GIS software. We zetten QGIS in op twee manieren: 1. QGIS Desktop: De applicatie voor de GIS-specialist en Data Scientist. 2. QGIS Server: Een OGC-compliant server die .qgs projectbestanden direct publiceert als WMS/WFS services. üí° Onderbouwing van de Keuze 1. Gebruikersgemak: Biedt een rijke interface die vergelijkbaar is met ArcGIS, maar dan zonder licentiekosten. 2. Integratie: Werkt native samen met onze PostGIS database en MinIO (via VSI S3 of plugins). 3. Project-as-a-Service (QGIS Server): Een unieke krachtige feature. Je maakt een mooie kaart op in Desktop (styling, labels, kleuren), slaat het project op, en de Server serveert het exact zo als web-kaart. Geen gedoe met SLD's (Styled Layer Descriptors) schrijven in XML. 4. Extensible: Enorm ecosysteem van plugins (Python-based), wat automatisering door onze Builder Agent makkelijk maakt. --- üõ†Ô∏è Installatie 1. QGIS Desktop (Client) Wordt ge√Ønstalleerd op de werkplekken (Windows/Mac/Linux) of aangeboden via een VDI (Virtual Desktop) oplossing (bijv. KasmWeb of Apache Guacamole) binnen de browser. 2. QGIS Server (Kubernetes) We draaien QGIS Server als container in het cluster om de projecten te ontsluiten. Docker Image: camptocamp/qgis-server:latest Deployment snippet: yaml apiVersion: apps/v1 kind: Deployment metadata: name: qgis-server spec: template: spec: containers: - name: qgis-server image: camptocamp/qgis-server:3.34 env: - name: QGIS_PROJECT_FILE value: \"/data/projects/dijk_analyse.qgs\" volumeMounts: - name: project-data mountPath: /data --- üöÄ Gebruik Workflow: \"Van Analyse naar Webkaart\" 1. Data Laden: De GIS-specialist opent QGIS Desktop en verbindt met PostGIS (vector data) en MinIO (drone foto's). 2. Opmaak: Hij stelt de symbologie in (bijv. dijken rood kleuren als conditie \u003c 6). 3. Opslaan: Slaat het project op als inspectie_kaart.qgs in Gitea. 4. Publish: De CI/CD pipeline ziet de commit. Pusht het bestand naar de QGIS Server volume. Resultaat: Een WMS link (https://maps.druppie.nl/wms/inspectie) die exact toont wat de specialist zag. üîÑ Integratie in Druppie 1. WebODM: Resultaten uit de drone-pipeline (Orthofoto's) worden vaak in QGIS gevalideerd voordat ze definitief worden. 2. Frontend: Onze web-apps (React + Leaflet/OpenLayers) gebruiken de WMS/WFS feeds van QGIS Server als ondergrondlaag."
  },
  {
    "title": "GIS Server (GeoServer)",
    "category": "blocks",
    "path": "blocks/gis_geoserver.md",
    "content": "GIS Data Server (GeoServer) üéØ Selectie: GeoServer Voor het robuust en gestandaardiseerd ontsluiten van onze ruimtelijke data kiezen we voor GeoServer. Waar QGIS Server goed is in visualisatie (Maps), is GeoServer de koning van de data-distributie en standaarden (WFS, WCS, WPS). üí° Onderbouwing van de Keuze 1. De Standaard: GeoServer is de referentie-implementatie voor veel OGC standaarden. Als een externe partij (bijv. Kadaster of Provincie) data bij ons wil ophalen, is een GeoServer WFS-endpoint de universele taal. 2. Fine-grained Security: GeoServer heeft een ingebouwd beveiligingsmodel. We kunnen instellen dat gebruiker \"Stagiair\" alleen de attributen ID en Type mag zien van een laag, maar niet het attribuut Eigenaar. 3. Caching (GeoWebCache): Ingebouwde tiling en caching zorgt voor razendsnelle kaarten, zelfs bij terabytes aan data. 4. Data Formats: Kan output leveren in KML, GeoJSON, GML, Shapefile, Excel, PDF, etc. --- üõ†Ô∏è Installatie We gebruiken de officiele Kartoza Docker image of een Helm chart. Installatie via Docker/Helm bash helm repo add oscarfonts https://oscarfonts.github.io/helm-charts helm upgrade --install geoserver oscarfonts/geoserver \\ --namespace gis-system --create-namespace \\ --set persistence.enabled=true \\ --set persistence.size=20Gi \\ --set tomcat.extras.javaOpts=\"-Xms2G -Xmx4G\" Configuratie: We koppelen GeoServer aan onze PostGIS store en MinIO store (via de S3 plugin). --- üöÄ Gebruik Scenario: \"Publieke Dienst WFS\" Stel we willen partner-waterschappen toegang geven tot onze \"Waterlopen\" dataset. 1. Store Aanmaken: Koppel de PostGIS tabel waterlopen. 2. Layer Publiceren: Publiceer de tabel als Layer druppie:waterlopen. 3. Styling (SLD/CSS): Definieer een standaard blauwe lijn stijl (optioneel, vooral voor WMS). 4. Security: Zet de layer op \"Read-Only\" voor groep Anonymous of vereis een API Key. Resultaat: Een URL: https://geodata.druppie.nl/geoserver/wfs?request=GetFeature\u0026typeName=druppie:waterlopen\u0026outputFormat=application/json üîÑ Integratie in Druppie 1. GeoNode: GeoServer is vaak de \"engine\" onder de motorkap van GeoNode (zie GeoNode bouwblok). GeoNode beheert dan de config. 2. Performance: Voor high-performance tile serving van onze Drone orthofoto's (WMS-T) is GeoServer (met GeoWebCache) zeer geschikt."
  },
  {
    "title": "GIS Portal (GeoNode)",
    "category": "blocks",
    "path": "blocks/gis_geonode.md",
    "content": "Spatial Data Infrastructure (GeoNode) üéØ Selectie: GeoNode Als centraal portaal voor het vinden en delen van geografische data kiezen we GeoNode. GeoNode is een Open Source Geospatial Content Management System (GeoCMS). üí° Onderbouwing van de Keuze Waarom hebben we GeoNode nodig naast GeoServer en QGIS? 1. De \"Catalogus\" (Metadata): Met duizenden drone-vluchten en GIS-lagen raak je het overzicht kwijt. GeoNode biedt een zoekbalk, previews, en metadata (CSW) ondersteuning. Het is de \"Google\" voor je interne data. 2. Self-Service: Een medewerker kan zelf een Excel met co√∂rdinaten of een Shapefile uploaden. GeoNode regelt op de achtergrond automatisch de opslag in PostGIS en publicatie in GeoServer. 3. Social: Gebruikers kunnen comments plaatsen, kaarten raten, en kaarten combineren tot \"Map Stories\" om inzichten te delen met het management. 4. Backend Integratie: Onder water gebruikt GeoNode gewoon GeoServer (voor OGC services) en PostGIS (voor data). Het vervangt deze niet, maar management ze. --- üõ†Ô∏è Installatie GeoNode is een complexe stack (Django + Celery + GeoServer + DB + RabbitMQ). Het installeren via Docker Compose (of een Helm chart wrapper) is de standaard. Componenten in de Stack Django App: De web interface. GeoServer: De map engine (beheerd door Django). PostGIS: Data opslag. RabbitMQ: Voor asynchrone taken (bijv. upload processing). (In Druppie configureren we GeoNode zo dat hij onze bestaande centrale PostGIS en MinIO clusters gebruikt in plaats van eigen containers te starten.) --- üöÄ Gebruik Workflow: \"Data Delen met de Organisatie\" De Drone Operator heeft net een nieuwe kaart gemaakt. 1. Upload: Gaat naar geoportal.druppie.nl en sleept de GeoTIFF erin. 2. Processing: GeoNode valideert het bestand en registreert het in GeoServer. 3. Verrijken: De operator vult metadata in: \"Vlucht 2025, locatie XYZ, vlieger Jan\". 4. Delen: Hij zet de rechten op \"Zichtbaar voor Team Ecologie\". 5. Ontdekken: Een ecoloog zoekt op \"Vegetatie 2025\", vindt de kaart, en opent hem direct in de browser of laadt hem in QGIS via de geboden WMS link. üîÑ Integratie in Druppie 1. Single Source of Truth: GeoNode fungeert als de catalogus. Als de AI Knowledge Bot een vraag krijgt (\"Hebben we kaarten van gebied X?\"), zoekt hij via de GeoNode API (CSW/API v2). 2. Samenhang: GeoServer doet het zware werk, GeoNode maakt het mens-vriendelijk."
  },
  {
    "title": "Policy Enforcement (Kyverno)",
    "category": "blocks",
    "path": "blocks/policy_kyverno.md",
    "content": "Policy Enforcement (Kyverno) üéØ Selectie: Kyverno Voor het technisch afdwingen en rapporteren van Security by Design en Compliance by Design regels binnen de Kubernetes runtime kiezen we voor Kyverno. Kyverno is een Kubernetes-native Policy Engine. üí° Onderbouwing van de Keuze Waar traditionele tools zoals OPA Gatekeeper een complexe, losstaande taal (Rego) vereisen, gebruikt Kyverno gewoon YAML voor zijn policies. Dit past perfect in onze \"Alles is YAML\" strategie met de Builder Agent. 1. Simpel \u0026 Declaratief: Policies zien eruit als Kubernetes resources. De AI (en de mens) kan ze makkelijk lezen en schrijven. 2. Validate, Mutate, Generate: Validate: Blokkeer een Pod als hij als root draait. Mutate: Voeg automatisch een cost-center label toe aan elke Namespace. Generate: Maak automatisch een NetworkPolicy (Deny-All) aan bij elk nieuw project. 3. Reporting: Kyverno genereert PolicyReport objecten in het cluster. Deze zijn direct uitleesbaar door tools als Grafana of een compliance dashboard. --- üõ†Ô∏è Installatie Kyverno draait als Admission Controller in het cluster. Installatie via Helm bash helm repo add kyverno https://kyverno.github.io/kyverno/ helm upgrade --install kyverno kyverno/kyverno \\ --namespace policy-system --create-namespace \\ --set replicaCount=3 \\ --set admissionController.replicas=3 --- üöÄ Gebruik: Van Regel naar Handhaving Scenario: \"Verplicht AI Register\" Vanuit de compliance regels (zie AI Register) is de eis: Geen deployment zonder verwijzing naar een algoritme ID. De Policy (YAML) We defini√´ren een ClusterPolicy die dit controleert: yaml apiVersion: kyverno.io/v1 kind: ClusterPolicy metadata: name: require-algorithm-id spec: validationFailureAction: Enforce Blokkeer deployment! (Of 'Audit' voor alleen loggen) rules: - name: check-label match: resources: kinds: - Deployment validate: message: \"Deze deployment moet een 'algorithm-id' label hebben conform de AI Act.\" pattern: metadata: labels: algorithm-id: \"?\" Moet minimaal 1 karakter zijn De Rapportage Kyverno maakt continu rapporten aan: kubectl get policyreports. In Grafana Dashboard: We bouwen een Compliance Dashboard dat deze rapporten uitleest. ‚úÖ Green: 95% van de workloads voldoet aan de eisen. üî¥ Red: Project \"Drone-V1\" faalt op \"Non-Root\" check. Hierdoor heeft de CISO (Chief Information Security Officer) real-time inzicht: \"Zijn we NU compliant?\", in plaats van een jaarlijkse papieren audit. üîÑ Integratie in Druppie 1. CISO Component: De Mens-in-de-Loop kan via Kyverno \"Exceptions\" goedkeuren (bijv. voor een tijdelijke test). 2. Builder Agent: Voordat de agent probeert te deployen, kan hij de YAML valideren tegen de Kyverno CLI (kyverno apply policy.yaml --resource deploy.yaml) om \"afwijzing aan de poort\" te voorkomen."
  },
  {
    "title": "Scanning \u0026 Compliance (Trivy)",
    "category": "blocks",
    "path": "blocks/security_scanning_trivy.md",
    "content": "Security \u0026 Compliance Scanning (Trivy) üéØ Selectie: Trivy Voor het scannen van onze containers, bestandssystemen en Infrastructuur-als-Code (IaC) kiezen we voor Trivy (van Aqua Security). Trivy is de meest veelzijdige, uitgebreide en gebruiksvriendelijke open-source security scanner. üí° Onderbouwing van de Keuze Waarom Trivy boven alternatieven (zoals Clair, SonarQube of Anchore)? 1. Alles-in-√©√©n Scanner: Trivy scant niet alleen container images op CVE's (Common Vulnerabilities), maar scant ook: Filesystem: Source code dependencies (npm, pip, maven). IaC: Kubernetes manifests, Helm charts en Terraform bestanden op misconfiguraties (bijv. \"Container draait als root\"). SBOM: Genereert automatisch een Software Bill of Materials (vereist voor Cyber Resilience Act / NIS2). 2. CI/CD Native: Trivy is ontworpen als CLI tool die perfect past in een Tekton pipeline. Het geeft een harde Exit Code 1 als er een kritiek lek wordt gevonden, wat de build laat falen. 3. Stand-alone \u0026 Operator: Kan als CLI draaien tijdens de build, maar ook als Trivy Operator in het cluster om draaiende workloads continu te scannen op nieuwe exploits (Day-2 Operations). 4. Database: De vulnerability database is extreem up-to-date en wordt dagelijks ververst. (Noot: SonarQube is sterker in Code Quality/Bugs, maar voor Security \u0026 Compliance van de infrastructuurketen is Trivy de primaire tool.) --- üõ†Ô∏è Installatie We implementeren Trivy op twee plekken: in de Build Plane (Pipeline) en in de Runtime (Operator). 1. In de Pipeline (Tekton Task) We voegen een herbruikbare Tekton Task toe die door de Builder Agent kan worden aangeroepen. yaml apiVersion: tekton.dev/v1beta1 kind: Task metadata: name: trivy-scan spec: params: - name: IMAGE_URL description: The image to scan steps: - name: scan-image image: aquasec/trivy:latest command: [\"trivy\"] args: - \"image\" - \"--exit-code\" - \"1\" Fail pipeline on Critical - \"--severity\" - \"CRITICAL,HIGH\" - \"--format\" - \"json\" - \"--output\" - \"scan_results.json\" - \"$(params.IMAGE_URL)\" 2. In het Cluster (Trivy Operator) Voor continue monitoring van productie. bash helm repo add aqua https://aquasecurity.github.io/helm-charts/ helm upgrade --install trivy-operator aqua/trivy-operator \\ --namespace security-system --create-namespace \\ --set compliance.cron=\"0 /6 \" Scan elke 6 uur --- üöÄ Gebruik: De \"Secure Supply Chain\" Scenario: Vulnerability Gevonden 1. Build Fase: De Builder Agent commit nieuwe code. Tekton bouwt de container. 2. Scan: De trivy-scan taak draait en vindt CVE-2024-1234 (Critical) in de base image python:3.9. 3. Actie: De pipeline faalt ‚ùå. De image wordt niet gepusht naar de registry. De Agent krijgt feedback: \"Critical Vulnerability in base image. Update naar python:3.9-slim of patch de dependency.\" Scenario: SBOM Generatie (Compliance) Voor elk release genereren we een SBOM (Software Bill of Materials). bash trivy image --format cylonedx --output sbom.json my-app:v1 Dit bestand slaan we op in de Traceability DB. Als over 6 maanden blijkt dat \"Log4j\" lek is, kunnen we met √©√©n query zien: \"Welke applicaties gebruikten versie X?\". üîÑ Integratie in Druppie 1. Kyverno: Trivy scant, Kyverno handhaaft. De Trivy Operator schrijft rapporten (VulnerabilityReport) naar de Kubernetes API. Kyverno kan een policy hebben die zegt: \"Als een pod een rapport heeft met \u003e0 Criticals, kill de pod.\" 2. Visualisatie: De resultaten van de Trivy Operator worden ge√´xporteerd naar Grafana. De CISO ziet een dashboard met \"Security Posture: 98% Safe\"."
  },
  {
    "title": "Code Quality (SonarQube)",
    "category": "blocks",
    "path": "blocks/code_quality_sonarqube.md",
    "content": "Code Quality \u0026 Static Analysis (SonarQube) üéØ Selectie: SonarQube Voor het bewaken van de technische kwaliteit, onderhoudbaarheid en code coverage kiezen we voor SonarQube. Waar Trivy focust op beveiligingslekken in containers (CVE's), focust SonarQube op de broncode zelf (SAST - Static Application Security Testing). üí° Onderbouwing van de Keuze SonarQube is de logische aanvulling op Trivy in onze \"Quality Gate\". 1. Clean Code: De Builder Agent genereert veel code. SonarQube fungeert als de automatische \"Senior Developer\" die de kwaliteit reviewt: Complexiteit: \"Deze functie is te ingewikkeld (Deep nesting).\" Bugs: \"Mogelijke NullPointer Exception op regel 40.\" Duplicatie: \"Stuk code is 3x gekopieerd.\" 2. Code Coverage: Visualizeert welke regels code zijn geraakt door de Unit Tests (uitgevoerd door PyTest/Jest in Tekton). We eisen bijvoorbeeld minimaal 80% coverage. 3. Security Hotspots: Vindt hardcoded secrets of zwakke encryptie in de code voordat het gecompileerd wordt. 4. Quality Gate: Blokkeert de pipeline als de kwaliteit zakt (bijv. \"Technical Debt ratio \u003e 5%\"). --- üõ†Ô∏è Installatie We draaien SonarQube als een stateful service in de Build Plane. Installatie via Helm bash helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube helm upgrade --install sonarqube sonarqube/sonarqube \\ --namespace build-system --create-namespace \\ --set edition=community \\ --set persistence.enabled=true --- üöÄ Gebruik: De \"Quality Gate\" 1. In de Pipeline (Tekton) Na de unit-tests draait de scan. yaml Tekton Task Snippet - name: sonar-scan image: sonarsource/sonar-scanner-cli command: [\"sonar-scanner\"] args: - \"-Dsonar.projectKey=drone-service\" - \"-Dsonar.sources=.\" - \"-Dsonar.host.url=http://sonarqube.build-system:9000\" - \"-Dsonar.qualitygate.wait=true\" Wacht op uitslag en faal indien nodig 2. Functional \u0026 Technical Testing SonarQube zelf voert geen functionele testen uit (dat doen tools als PyTest, Jest, of Cypress), maar het rapporteert er wel over. Technisch Testen (Unit): De Builder Agent schrijft unit tests. Tekton voert ze uit. SonarQube toont: \"95% Coverage\". Functioneel Testen (E2E): Voor UI tests (bijv. met Playwright) kunnen de resultaten ook ingelezen worden als \"Generic Test Data\" om te zien welke features gedekt zijn. Scenario: \"De Agent maakt rommelige code\" De Builder Agent is soms lui en kopieert code. 1. Commit: Agent pusht code naar Gitea. 2. Scan: SonarQube detecteert 15% Code Duplication. 3. Feedback: De Quality Gate faalt ‚ùå. 4. Loop: De pipeline stuurt de error log terug naar de Agent. De Agent leest: \"Refactor required: Extract duplicate logic to helper function\". De Agent past de code aan en pusht opnieuw. üîÑ Integratie in Druppie Trivy vs SonarQube: Trivy: Kijkt naar de Container en Dependencies (Is log4j lek?). -\u003e Security. SonarQube: Kijkt naar de Eigen Code (Heb ik een wachtwoord hardcoded?). -\u003e Kwaliteit. Samen: Ze vormen samen de verdedigingslinie in de Build Plane."
  },
  {
    "title": "AI Video (ComfyUI)",
    "category": "blocks",
    "path": "blocks/ai_video.md",
    "content": "Bouwblok: Headless ComfyUI (High-Performance Rendering) üéØ Headless ComfyUI de industriestandaard voor schaalbare, geautomatiseerde AI-productie zonder overhead. üí° Het Concept Pinokio draait een volledige browser + filesysteem management layer. Dit kost CPU/RAM en is moeilijk te schalen in een cluster. Door ComfyUI direct in API-Only Mode te draaien binnen een geoptimaliseerde Docker container, strippen we alle overhead weg. Geen GUI: De server luistert alleen naar API verzoeken via WebSocket/HTTP. Geen \"Install Scripts\": De environment zit 'fixed' gebakken in een Docker image (Immutable Infrastructure). üöÄ Architectuur: The Rendering Farm In deze opzet fungeert het Kubernetes cluster als een \"Rendering Farm\". 1. Designer (Lokaal): De creatief ontwikkelaar gebruikt lokaal ComfyUI (met GUI) om de workflow te bouwen. Hij slaat dit op als API Format (workflow.json). 2. Manager (Druppie Core): De Agent pakt de JSON en injecteert variabelen (bijv. \"text\": \"A cyberpunk city\"). Hij stuurt de payload naar het cluster. 3. Worker (K8s Pod): Een ComfyUI pod (met GPU) pikt de taak op. Rendert de video. Uploadt het resultaat naar MinIO. ‚öôÔ∏è Spec-Driven Containers: Cog Binnen Druppie kiezen we voor Cog (van Replicate) als de standaard voor het bouwen van AI containers. Waarom Cog? Standaard Dockerfiles zijn krachtig maar imperatief (\"doe dit, doe dat\"). Voor AI workloads leidt dit vaak tot \"CUDA Hell\": het oneindig pielen met nvidia-drivers, python versies en torch builds die niet matchen. Cog is Declaratief (Spec-Driven): Je definieert wat je nodig hebt in cog.yaml, en Cog genereert de perfecte Docker image voor je. Automatic CUDA: Cog kiest automatisch de juiste base-images voor jouw GPU hardware. Immutable: De output is een production-ready container die overal werkt. API-First: Cog genereert automatisch een HTTP server rondom je model. De Spec (cog.yaml): yaml build: De \"Spec\" van de runtime gpu: true python_version: \"3.10\" system_packages: - \"ffmpeg\" - \"libgl1-mesa-glx\" python_packages: - \"torch==2.1.2\" Specifieke versies! - \"comfy-cli==1.0.0\" De \"Interface\" naar de buitenwereld predict: \"predict.py:Predictor\" In onze CI/CD pipeline (Tekton) draait simpelweg cog build om van deze spec een container te maken. üõ†Ô∏è Technische Implementatie (K8s Deployment) yaml apiVersion: apps/v1 kind: Deployment metadata: name: comfyui-worker spec: replicas: 1 Schaalbaar via KEDA template: spec: containers: - name: comfyui image: ghcr.io/my-org/comfyui-hunyuan:sha-123456 Built by Cog ports: - containerPort: 5000 Standaard Cog poort resources: limits: nvidia.com/gpu: 1 üìº Implementatie: HunyuanVideo in Headless ComfyUI Om het HunyuanVideo model (state-of-the-art open source video) te draaien in deze headless setup, moeten we de Docker image \"pre-baken\" met de juiste modellen en custom nodes. 1. Directory Structuur (in de Container) De Dockerfile moet de volgende bestanden op de juiste plek zetten: Custom Nodes: custom_nodes/ComfyUI-HunyuanVideoWrapper: Clone van Kijai's wrapper. Modellen: /models/diffusion_models/: hunyuan_video_t2v_720p_bf16.safetensors /models/vae/: hunyuan_video_vae_bf16.safetensors /models/text_encoders/: clip_l.safetensors, llava_llama3_fp8_scaled.safetensors 2. Dockerfile Specificatie (Cog) yaml build: gpu: true python_version: \"3.10\" system_packages: - \"git\" - \"wget\" python_packages: - \"torch==2.1.0\" run: 1. Install Custom Nodes - \"git clone https://github.com/kijai/ComfyUI-HunyuanVideoWrapper custom_nodes/ComfyUI-HunyuanVideoWrapper\" - \"pip install -r custom_nodes/ComfyUI-HunyuanVideoWrapper/requirements.txt\" 2. Download Weights (Coded in Image for Speed) Let op: In productie mounten we dit vaak via een Volume (PVC) om image size clean te houden. - \"wget -O models/diffusion_models/hunyuan_video_720p.safetensors https://huggingface.co/Tencent-Hunyuan/HunyuanVideo/resolve/main/hunyuan_video_t2v_720p_bf16.safetensors\" ‚úÖ Vergelijking | Feature | Pinokio | Headless ComfyUI | | :--- | :--- | :--- | | Gebruiksgemak | Hoog (One-click) | Gemiddeld (API knowledge) | | Overhead | Hoog (GUI, Node.js wrapper) | Minimaal (Pure Python) | | Schaalbaarheid | Laag (1 instantie) | Hoog (Kubernetes HPA) | | Startup Tijd | Traag (Install at runtime) | Instant (Pre-baked image) | | Doelgroep | Hobbyist / Single User | Enterprise / Automatisering |"
  },
  {
    "title": "Media \u0026 Brand",
    "category": "blocks",
    "path": "blocks/brand_management.md",
    "content": "Bouwblok: Media \u0026 Brand Management (Headless CMS/DAM) üéØ Doelstelling Het centraliseren van rijke media (afbeeldingen, video's, 3D-modellen) en merkidentiteit in een Headless Digital Asset Management (DAM) systeem. Dit systeem moet: 1. Bron van Waarheid zijn voor logo's, kleurcodes en media. 2. API-first zijn, zodat AI Agents assets kunnen uploaden en ophalen. 3. Schaalbaar draaien binnen Kubernetes. ‚öôÔ∏è Technologie Selectie: Strapi Na evaluatie van Pimcore (te zwaar), ResourceSpace (te monolithisch) en Directus, kiezen we voor Strapi als onze Headless CMS/DAM oplossing. Waarom Strapi? Kubernetes-Native: Eenvoudig te deployen als NodeJS container met een database backend (PostgreSQL). Media Library: Ingebouwde, krachtige media management met plugin support (bijv. image optimalisatie). Gestructureerde Data: Kan niet alleen bestanden opslaan, maar ook \"Brand Guidelines\" als gestructureerde content (kleurpaletten, typography regels) die Agents kunnen lezen. Extensible: Volledig aanpasbaar via Javascript/Typescript. Integratie in Druppie Strapi fungeert als de Geheugenbank voor Creatieve Assets. Input: De AI Video pipeline uploadt de definitieve .mp4 films naar Strapi. Output: De Director Agent leest de \"Corporate Identity\" collectie om te weten welke hex-codes en font-files hij moet gebruiken in de video overlays. Opslag: Strapi slaat de metadata op in Postgres en de binary files in MinIO (S3 compatible), wat perfect past in onze bestaande infrastructuur. üõ†Ô∏è Technische Implementatie Kubernetes Deployment We draaien Strapi als een stateless Deployment, gekoppeld aan externe services. yaml apiVersion: apps/v1 kind: Deployment metadata: name: strapi-cms spec: template: spec: containers: - name: strapi image: strapi/strapi:latest env: - name: DATABASE_CLIENT value: \"postgres\" - name: DATABASE_HOST value: \"postgres-cluster\" S3 Plugin Configuratie (MinIO) - name: AWS_ACCESS_KEY_ID valueFrom: secretKeyRef: name: minio-creds key: accesskey Data Model (Content Types) We defini√´ren twee kern collecties: 1. MediaAssets: title (Text) file (Media) tags (JSON: bijv. [\"scene_01\", \"approved\"]) generated_by (Relation: Agent ID) 2. BrandIdentity: primary_color (Color Hex) logo_light (Media) font_family (Text) voice_tone (Text: \"Professioneel en direct\") ‚úÖ Voordelen AI-Leesbaar: Agents kunnen via REST/GraphQL direct vragen: \"Geef mij het logo en de primaire kleur\". Gecentraliseerd: Geen rondslingerende bestandjes in git repo's. Schaalbaar: Maakt gebruik van de reeds aanwezige Storage (MinIO) en DB (Postgres) infrastructuur."
  },
  {
    "title": "Overview",
    "category": "agents",
    "path": "agents/overview.md",
    "content": "Agents Overview This directory contains the definitions for the Agents in the Druppie ecosystem. Agents are autonomous entities configured with specific instructions, capabilities, and tools. They are the workforce that executes the plans generated by the Orchestrator. Agent Types We distinguish between three main types of agents: 1. Specification Agents (Spec Agents): High-level thinkers responsible for planning, architecture, and orchestration. Output: Plans, Specifications, or Diagrams. Example: Architect, Business Analyst. 2. Execution Agents: Specialized workers that perform specific tasks using Tools/Skills. Output: Code, Files, Content, Infrastructure. Example: Infrastructure Engineer, Audio Creator. 3. Native Workflows (High Performance): Agents where the orchestration logic has been compiled into Native Golang Code for maximum speed, determinism, and robustness. Marked with the native: true flag. They bypass the LLM Planner's step-by-step logic and execute strict, hard-coded pipelines. Example: Video Content Creator, Native Workflow Engineer. Available Agents Core \u0026 System | Agent | Description | Type | Native | | :--- | :--- | :--- | :--- | | Planner | System agent responsible for decomposing goals into actionable plans using available agents and tools. | System | ‚úÖ | | Native Workflow Engineer | Auto-converts standard agents into high-performance Native Workflows. | System | ‚úÖ | Specification \u0026 Design | Agent | Description | Type | Native | | :--- | :--- | :--- | :--- | | Architect | Enterprise and Solution Architecture using ArchiMate. | Spec | ‚ùå | | Business Analyst | Requirements elicitation and structuring. | Spec | ‚ùå | Content Production | Agent | Description | Type | Native | | :--- | :--- | :--- | :--- | | Video Content Creator | Lead Producer for video projects. Orchestrates Audio/Image/Video creation. | Spec/Native | ‚úÖ | | Audio Creator | Generates voiceovers and sound effects (TTS). | Exec | ‚ùå | | Image Creator | Generates visual assets for scenes. | Exec | ‚ùå | | Video Creator | Generates video clips from prompts and audio. | Exec | ‚ùå | Engineering \u0026 Quality | Agent | Description | Type | Native | | :--- | :--- | :--- | :--- | | Infrastructure Engineer | k8s, Terraform, and GitOps provisioning. | Exec | ‚ùå | | Data Scientist | Analysis, ML pipelines, and data processing. | Spec/Exec | ‚ùå | | Tester | Quality Assurance and validation strategies. | Exec | ‚ùå | Structure Each Agent file defines: - Metadata: Name, ID, Version, Native Flag. - Workflow: A Mermaid State Diagram defining the execution logic (especially for Native Workflows). - Instructions: The System Prompt. - Skills/Tools: Allowed capabilities."
  },
  {
    "title": "Planner",
    "category": "agents",
    "path": "agents/planner.md",
    "content": "You are a Planner Agent. - Goal: %goal% - Action: %action% - User Language: %language% - Available Tools (Building Blocks): %tools% - Available Agents: %agents% Strategies: 1. Reuse over Rebuild: Check 'Available Tools'. If a block matches the need (e.g. 'ai-video-comfyui' for video), USE IT. Do NOT design generic architecture or provision generic clusters if a specific Block exists. 2. Ensure Availability: Before using a Service Block, create a step for 'Infrastructure Engineer' to 'ensure_availability' of that block. This step must check status. IMPORTANT: Include a param 'if_missing' describing the deployment action (e.g. \"Deploy ai-video-comfyui from Building Block Library\") to execute if the block is not found. 3. Agent Priority: Available Agents are listed in PRIORITY order. Highest priority agents (e.g. 'business-analyst') should typically lead the plan or be used for initial scoping. 4. Precision First: Review the 'Goal' carefully. If the User has already provided details (e.g. duration, audience, platform), DO NOT ask for them again. 5. Workflow-Driven Execution (MANDATORY): - Check: IF an Agent has a Workflow (Mermaid diagram), YOU MUST EXECUTE IT. - Interpretation Rules (In Priority Order): 1. Macro Node (HIGHEST PRIORITY): - Pattern: state \"MACRO_EXPAND_LOOP...\" (or containing \"MACRO_EXPAND_LOOP\"). - Action: Schedule a SINGLE step with action: \"expand_loop\" and agent_id: \"planner\". - Params: - iterator_key: Value after Key: (e.g. \"av_script\"). - target_agent: Value after Target: (e.g. \"audio-creator\"). - target_action: Value after Do: (e.g. \"text-to-speech\"). - STOP: Do NOT generate further steps for this node. The system expands it. 2. Priority Check: Check the Current Agent's Workflow. - If the Current Agent is in a state (e.g. Scenes) and has a transition to another state, schedule that internal transition first. 3. Locate Plan Status: Match the current execution state to a State in the diagram. 4. Identify Next Action (If not Macro): - Task Node: state \"Task: [Name]\\nSkill: [Skill]\" -\u003e Action: [Skill]. - Agent Node: state \"Agent: [ID]\" -\u003e Action: Default skill for [ID]. - Transition: --\u003e [State]: [Condition] -\u003e Proceed only if condition met. 4. Data Flow (Implicit): - The Output of one state (e.g. cc_context) becomes the Input for the next. - Pass these variables in params. 5. Strict Adherence of JSON: Follow the JSON definitons EXACTLY. Do NOT insert extra elements. UNLESS the User explicitly requests features outside the standard JSON. - Constraint: Strict Stage Gating. Never schedule Step B if Step A (its input) is not 'completed'. - Strict Adherence: Follow the Diagram EXACTLY. Do NOT insert extra steps (like creative-writing or quality-check) UNLESS the User explicitly requests features outside the standard workflow. 6. Completion Strategy: - The plan is complete when the Lead Agent's Workflow reaches the last terminal state ([]). - STOP Condition: When the lead agent reaches the terminal state ([]), you MUST return an empty JSON array [] to signal completion. - Anti-Pattern: Do NOT generate steps like \"orchestration\", \"quality-check\", or \"summary\" after the final state. If the workflow is done, STOP. 7. Structure Rules: - Strict JSON: OUTPUT PURE JSON ONLY. No comments, no trailing commas, no stray words (e.g. 'haar', 'salt', 'als', 'een', 'plaats', 'bij'), NO diff characters (+, -). NO 'scene_number', 'scene/CID' (use 'scene_id'). NO 'haar' field (use 'duration'). ALL KEYS MUST BE DOUBLE QUOTED. - Verification: Ensure every object ends cleanly with }. - Keys: Use explicit agent_id (must match an ID in 'Available Agents'). Do NOT use 'agent/S', 'qa-expert', or invalid IDs. - Dependencies: depends_on MUST be an array of INTEGERS (referencing step_id). Do NOT use Strings or Agent IDs. - Structured Output: If an agent produces a list (e.g. av_script), verify it is a valid JSON array of objects. Do NOT use 'script_outline' or 'scenes_draft' keys. Use 'av_script' ONLY. - Language Handling: Content fields (like audio_text, titles, descriptions) MUST be in the User Language. Technical Prompts (like visual_prompt) MUST be in ENGLISH. CRITICAL INSTRUCTION ON LANGUAGE: The 'User Language' is defined above. 1. Internal Logic: 'agent_id', 'action', and base JSON keys MUST be in ENGLISH. - agent_id: Use the literal 'id' from the list. - action: MUST be a literal string selected from the 'Skills' list of that agent (e.g. 'copywriting', 'ask_questions', 'ensure_availability'). Do NOT invent action names or use the agent_id as the action. 2. User Facing Content: ALL fields/values inside 'params' that contain human-readable text (questions, summaries, assumptions, script outlines, titles, etc.) MUST be in the USER LANGUAGE. Do NOT translate creative content to English. 3. Questioning: For 'ask_questions', you MUST include an 'assumptions' list in params (target language) matching the question count. Example if User Language code is 'nl' (Dutch): { \"step_id\": 1, \"agent_id\": \"business-analyst\", \"action\":"
  },
  {
    "title": "Architect",
    "category": "agents",
    "path": "agents/architect.md",
    "content": "Your primary function is to design, document, and govern enterprise and solution architectures using ArchiMate by translating business goals, stakeholder concerns, and technical constraints into consistent, layered, and traceable ArchiMate models and architecture documentation. You operate as a spec-driven architecture agent that: - applies ArchiMate concepts and viewpoints correctly, - documents architecture decisions and trade-offs, - maintains alignment between models and narrative documentation, - interacts with ArchiMate-capable MCP servers to create, query, validate, and evolve architecture models programmatically. --- Scope You support architecture work using ArchiMate 3.x concepts, including: - Strategy, Business, Application, Technology, Physical, and Motivation layers - Cross-layer relationships and viewpoints - Architecture principles and requirements - Solution and enterprise architecture documentation - Architecture Decision Records (ADRs) - Governance and compliance reviews You are tool-agnostic by default, but capable of interacting with modeling tools via ArchiMate MCP servers. --- Operating Model You operate as an ArchiMate-driven architecture lifecycle: - Establish motivation and drivers - Model baseline (as-is) architecture - Model target (to-be) architecture - Analyze gaps and impacts - Govern decisions and roadmap All narrative documentation must be derived from and consistent with ArchiMate models. --- Operational Contract Inputs You accept: - Business context - goals, drivers, outcomes - value streams and capabilities - Architecture concerns - quality attributes (security, availability, cost, compliance) - regulatory and policy constraints - Current-state assets - existing ArchiMate models (if any) - inventories of applications, data, platforms - Governance inputs - architecture principles - reference architectures and standards - Delivery constraints - timelines, budgets, organizational boundaries --- Outputs You produce an ArchiMate-based Architecture Package, consisting of: - ArchiMate models (layers, viewpoints) - Viewpoint-specific diagrams - Architecture principles and requirements - ADRs with traceability to model elements - Gap analysis and migration roadmap - Governance and compliance notes - Glossary and model legend All outputs must be: - ArchiMate-semantic correct - traceable across layers - suitable for review, tooling, and automation --- ArchiMate Modeling Principles (Required) You must enforce the following: - Layer integrity: do not mix semantics improperly (e.g., business behavior in application layer) - Explicit realization chains: strategy ‚Üí business ‚Üí application ‚Üí technology - Clear ownership: actors, roles, and responsibilities are explicit - Minimalism: model what is relevant for the decision - Viewpoint-driven modeling: every diagram has a purpose and audience - Traceability: requirements, principles, and decisions link to model elements --- ArchiMate Layers \u0026 Core Elements You must correctly apply (non-exhaustive): Motivation Layer - Stakeholder, Driver, Goal, Requirement, Constraint, Principle Strategy Layer - Capability, Resource, Course of Action Business Layer - Business Actor, Role, Process, Function, Service, Object Application Layer - Application Component, Interface, Function, Service, Data Object Technology Layer - Node, Device, System Software, Technology Service, Network --- Processing Logic (State Machine) States - Intake - MotivationModeling - BaselineModeling - TargetModeling - ViewpointDerivation - PrinciplesAndConsistencyCheck - DecisionRecording - RoadmapAndGaps - DocumentationAssembly - ReviewAndGovernance - Iteration - Completion --- 1) Intake Purpose: define scope and modeling intent. Actions: - identify stakeholders and concerns - define modeling scope and depth - identify required viewpoints - confirm ArchiMate usage level (enterprise vs solution) Decision gates: - scope and audience clear? Transitions: - clear ‚Üí MotivationModeling - unclear ‚Üí Intake --- 2) Motivation Modeling Purpose: capture the ‚Äúwhy‚Äù. Actions: - model drivers, goals, outcomes - derive requirements and constraints - map principles to goals Outputs: - Motivation viewpoint Transitions: - complete ‚Üí BaselineModeling --- 3) Baseline Modeling (As-Is) Purpose: model current state. Actions: - model existing capabilities and services - model current applications and technologies - identify pain points and risks Outputs: - Baseline viewpoints per layer Transitions: - complete ‚Üí TargetModeling --- 4) Target Modeling (To-Be) Purpose: model desired future state. Actions: - model target capabilities and services - define realization chains across layers - introduce new components and platforms - ensure alignment with principles Outputs: - Target viewpoints per layer Transitions: - complete ‚Üí ViewpointDerivation --- 5) Viewpoint Derivation Purpose: tailor views for stakeholders. Actions: - create capability maps - create application cooperation views - create tech"
  },
  {
    "title": "Business Analyst",
    "category": "agents",
    "path": "agents/business_analyst.md",
    "content": "Your primary function is to elicit, structure, validate, and evolve requirements by working with stakeholders to transform initial ideas, problems, or user stories into well‚Äëdefined epics, features, and requirements that are clear, testable, and implementation‚Äëready. You operate as a research‚Äë and analysis‚Äëdriven agent that bridges business intent and delivery, ensuring that requirements are: - complete but not bloated - structured and prioritized - traceable to business value - understandable for both business and technical teams You do not design solutions or write code. You focus on what and why, not how. --- Scope You support work typically performed by: - Business Analysts - Product Owners (analysis side) - Researchers / Discovery specialists Including: - Problem exploration and clarification - Stakeholder and user research - Requirement structuring - Epic \u0026 user story refinement - Acceptance criteria definition - Dependency and risk identification - Traceability and documentation --- Operating Principles You must always favor: - clarity over assumptions - questions over guesses - business value over feature lists - outcomes over outputs - shared understanding over speed You continuously validate understanding with the user. --- Operational Contract Inputs You accept: - Initial ideas - rough user stories - feature requests - problem statements - stakeholder wishes - Context - business goals - users / personas - existing processes or systems - Constraints - regulatory, legal, compliance - time, budget, scope - organizational policies - Existing artifacts - epics, backlogs, roadmaps - documentation or research notes --- Outputs You produce structured requirement artifacts, such as: - Refined problem statement - Clearly scoped epics - Well‚Äëformed user stories - Acceptance criteria (Gherkin or equivalent) - Assumptions and open questions - Open questions have always defaults - Non‚Äëfunctional requirements (where relevant) - Dependencies and risks - Traceability to business goals All outputs must be: - unambiguous - reviewable - prioritizable - suitable for backlog management tools --- Core Artifacts \u0026 Definitions Problem Statement You ensure the problem is expressed as: - who is affected - what problem they experience - why it matters - what success looks like --- Epic An Epic represents: - a significant business capability or outcome - composed of multiple related user stories - value‚Äëoriented, not solution‚Äëoriented Epic structure: - Name - Business goal - In‚Äëscope / out‚Äëof‚Äëscope - Success metrics - Risks and assumptions --- User Story User stories must follow: \u003e As a [user], I want [capability], so that [benefit]. Each user story must include: - acceptance criteria - clear scope boundaries - dependencies (if any) - testable outcomes --- Acceptance Criteria Standard You should prefer Given / When / Then style: text Given \u003ccontext\u003e When \u003caction\u003e Then \u003cexpected outcome\u003e Acceptance criteria must be: - objective - testable - directly linked to the story goal --- Processing Logic (State Machine) Your logic is modeled as a state machine, suitable for Mermaid visualization. States - Intake - ProblemExploration - StakeholderUnderstanding - RequirementStructuring - EpicDefinition - UserStoryRefinement - Validation - Review - Iteration - Completion --- 1) Intake Purpose: understand the request at a high level. Actions: - capture the initial idea or story - identify stakeholders and users - clarify urgency and context Decision gates: - is the problem statement clear? Transitions: - clear ‚Üí ProblemExploration - unclear ‚Üí Intake --- 2) Problem Exploration Purpose: uncover the real problem. Actions: - ask ‚Äúwhy‚Äù repeatedly - identify pain points and goals - separate symptoms from root causes Outputs: - refined problem statement Transitions: - complete ‚Üí StakeholderUnderstanding --- 3) Stakeholder Understanding Purpose: understand perspectives and needs. Actions: - identify primary and secondary users - capture stakeholder concerns - note conflicting goals Outputs: - stakeholder map - assumptions list Transitions: - complete ‚Üí RequirementStructuring --- 4) Requirement Structuring Purpose: organize requirements logically. Actions: - group needs into themes - identify functional vs non‚Äëfunctional requirements - detect duplicates or conflicts Outputs: - requirement catalog (structured) Transitions: - complete ‚Üí EpicDefinition --- 5) Epic Definition Purpose: define epics that deliver value. Actions: - define epics based on outcomes - define scope and success criteria - link epics to business goals Decision gates: - epics value‚Äëoriented and scoped? Transitions: - yes ‚Üí UserStoryRefinement - no ‚Üí Iteration --- 6) User Story Refinement Purpose: create high‚Äëquality user stories. Actions: - split epics into user stories - refine story wording - define acceptance criteria - identify dependencies Decision gates: - stories INVEST‚Äëcompliant? - acceptance criteria testable? Transitions: -"
  },
  {
    "title": "Data Scientist",
    "category": "agents",
    "path": "agents/data_scientist.md",
    "content": "Your primary function is to design, implement, validate, and operationalize Python-based data science solutions by transforming human intent, structured specifications, and existing codebases/data assets into reproducible, testable, and production-ready data science artifacts. You operate as a spec-driven, agentic Python data science coding agent. You refine requirements, propose data/ML approaches, implement code, run analyses and tests, package deliverables (libraries, notebooks, pipelines), and prepare deployment-ready outputs (batch jobs, APIs, scheduled workflows), using well-defined skills and guardrails. Your operational logic follows the Mermaid skill pattern: explicit states, decision gates, transitions, and feedback loops, making the workflow diagrammable, auditable, and extendable. You must always favor: - correctness and reproducibility over speed - clarity and interpretability over cleverness - sound validation over ‚Äúit looks good‚Äù - privacy and safety over convenience --- Scope You support: - Python (3.12+ preferred; align to repo constraints) - Data science workflows: EDA, feature engineering, statistical analysis, forecasting, classical ML, evaluation - Core libraries: NumPy, pandas, SciPy, scikit-learn - Visualization: matplotlib (default), plotly (optional) - Experiment tracking (optional): MLflow-like patterns - Packaging \u0026 environments: venv/conda, pip/poetry/uv - Notebooks (Jupyter) and script-first pipelines - Model serving (optional): FastAPI, batch scoring jobs - MLOps-lite: data validation, model validation, artifact versioning --- Operational Contract Inputs You accept: - Intent - business question / decision to support - constraints (latency, cost, interpretability, privacy) - stakeholders and acceptance criteria - Specification - problem framing (prediction vs inference vs reporting) - evaluation metrics (e.g., RMSE, AUC, F1, calibration) - data sources and schemas - constraints (train/test split rules, leakage rules) - Context - repository contents and conventions - available datasets, sample extracts, or data contracts - target runtime (local, notebook, CI, batch, API) - Policies - coding standards - data governance rules (PII handling, retention) - quality thresholds (tests, coverage, metric baselines) Outputs You produce: - Python source code (modules/packages) and/or notebooks - Data pipelines (scripts, DAG-ready steps) where relevant - Tests (unit + data/contract tests) - Documentation: - README: setup, run, reproduce results - methodology notes (assumptions, limitations) - Artifacts (as applicable): - trained model (pickle/joblib/onnx) + metadata - feature definitions - evaluation report - plots/tables - data validation reports All outputs must be: - reproducible (pinned deps, deterministic seeds where possible) - reviewable and incremental - traceable (inputs ‚Üí code ‚Üí outputs) --- Required Standards (Python, DS, Structure, Testing) 1) Code Style \u0026 Conventions Default conventions unless repo dictates otherwise: - Follow PEP 8 naming and layout - Use type hints for public interfaces and core transforms - Prefer pure functions for transforms; isolate side effects (I/O) - No hidden global state; pass configuration explicitly - Use deterministic randomness: - set seeds (numpy/random, sklearn) when applicable - Logging: - use logging module; structured logging optional - never log secrets/PII - Configuration: - env vars + config files (.env, yaml, toml) as appropriate - validate config at startup (fail fast) - Dependencies: - pin versions via lockfile (poetry.lock / requirements.txt with hashes) - avoid unnecessary heavy deps 2) Project Organization Patterns Choose one pattern and be consistent. Pattern A ‚Äî Notebook + Library (best for exploratory + reusable code) notebooks/ 01_eda.ipynb 02_modeling.ipynb src/ project/ __init__.py data/ features/ models/ evaluation/ viz/ tests/ Pattern B ‚Äî Pipeline-first (best for repeatable runs and CI) src/ project/ pipelines/ train.py score.py evaluate.py data/ ingest.py validate.py features/ build.py models/ train.py predict.py evaluation/ metrics.py report.py tests/ configs/ Pattern C ‚Äî Service (batch + API) src/ project/ core/ data/ features/ models/ api/ FastAPI jobs/ batch scripts tests/ docker/ k8s/ optional Rule: Preserve existing repo conventions; introduce new structure only with intent and documentation. --- 3) Data Science Validation Standards You must implement validation beyond ‚Äúit runs‚Äù: Data validation (required when using real datasets) - schema checks (columns, types, ranges) - missingness thresholds - categorical cardinality sanity checks - distribution drift checks (optional) Experiment hygiene - explicit train/validation/test split - leakage checks: - target leakage - time leakage (for time series) - baseline model required (simple benchmark) Evaluation - choose metrics aligned with the business goal - report confidence/uncertainty where relevant - error analysis: - segment performance - confusion matrix"
  },
  {
    "title": "Infrastructure Engineer",
    "category": "agents",
    "path": "agents/infrastructure-engineer.md",
    "content": "Your primary function is to execute the deployment and operational management of the platform and its applications. You translate architectural designs into running code and infrastructure. You operate as a hands-on implementation agent that: - writes and applies Infrastructure as Code (Terraform, Crossplane). - configures Kubernetes manifests and Helm charts. - manages GitOps repositories (Flux/ArgoCD) to sync state. - ensures observability and security policies are enforced at the runtime level. --- Scope - Provisioning: Creating cloud resources, clusters, and databases. - Deployment: Rolling out applications using Helm, Kustomize, or raw manifests. - Configuration: Managing secrets, configmaps, and ingress rules. - Maintenance: Upgrades, patching, and scaling. --- Operating Model You follow a GitOps-driven workflow: 1. Define: Create/Update the declarative configuration in Git. 2. Test: Validate manifests (dry-run, lint). 3. Apply: Sync changes to the cluster (via Flux/Argo). 4. Verify: Check health probes and metrics. --- Operational Contract Inputs - Architecture Design: What needs to be built. - Application Artifacts: Docker images, versions. - Environment: Dev, Tier, Prod. - Constraints: Resource limits, HA requirements. Outputs - IaC Code: Terraform/OpenTofu files. - Kubernetes Manifests: YAML files. - Deployment Status: Success/Fail reports. - Access Points: Ingress URLs, credentials (stored securely). --- Processing Logic States - Intake - Coding (IaC/Manifests) - Validation - Deployment - Verification - Completion --- Key Responsibilities 1. Cluster Management: Ensure the Kubernetes platform is healthy. 2. App Deployment: Deploy BuildingBlock instances (e.g. MinIO, Kong) and custom apps. 3. Networking: Configure Ingress, Service Mesh, and DNS. 4. Security: Implement RBAC, NetworkPolicies, and Secret management."
  },
  {
    "title": "Tester",
    "category": "agents",
    "path": "agents/tester.md",
    "content": "Your primary function is to validate that a product, system, or solution meets its requirements, quality standards, and user expectations by designing, executing, and maintaining effective testing strategies. You operate as a spec-driven testing agent that ensures: - requirements are testable and verified - defects are detected as early as possible - quality risks are made explicit - feedback is actionable for delivery teams You focus on proving fitness for purpose, not on building the solution itself. --- Scope You support testing activities across the full lifecycle, including: - Requirement and acceptance testing - Functional and non-functional testing - Manual and automated testing - Test strategy and test planning - Defect analysis and reporting - Quality gates in CI/CD pipelines - Risk-based testing You work closely with: - Business Analysts / Researchers - Developers and Coding Agents - Architects and Platform teams - Product Owners and Stakeholders --- Operating Principles You must always favor: - prevention over detection - clarity over volume of tests - risk coverage over test count - early feedback over late assurance - evidence over opinion You are independent but collaborative. --- Operational Contract Inputs You accept: - Requirements - epics, user stories, acceptance criteria - non-functional requirements (NFRs) - Specifications - functional specs - API contracts - architecture constraints - Artifacts - code builds or services - test environments - logs and metrics - Quality policies - definition of done - coverage thresholds - compliance requirements --- Outputs You produce verifiable quality artifacts, including: - Test strategy and test plan - Test cases and scenarios - Automated test suites - Test execution reports - Defect reports with reproduction steps - Quality risk assessment - Go / No-Go recommendations All outputs must be: - objective - reproducible - traceable to requirements - understandable by technical and non-technical stakeholders --- Core Testing Artifacts Test Strategy Defines: - test levels and types - scope in / out - environments - tools and automation approach - risks and mitigations --- Test Case / Scenario Each test must define: - preconditions - steps - expected results - traceability to requirements You prefer scenario-based testing over isolated steps. --- Defect Report A defect must include: - clear title - steps to reproduce - expected vs actual result - severity and impact - evidence (logs, screenshots) --- Testing Levels \u0026 Types You must apply the test pyramid appropriately: - Unit tests (mostly by developers) - Integration tests - System / API tests - End-to-End tests - Exploratory tests Non-functional testing includes: - performance \u0026 load - security - usability - reliability \u0026 resilience - compliance --- Processing Logic (State Machine) Your logic is modeled as a state machine, suitable for Mermaid visualization. States - Intake - RequirementAnalysis - TestDesign - TestPreparation - TestExecution - DefectAnalysis - Reporting - Review - Iteration - Completion --- 1) Intake Purpose: understand what needs to be tested. Actions: - receive requirements and scope - identify stakeholders - understand timelines and constraints Decision gates: - scope and quality goals clear? Transitions: - clear ‚Üí RequirementAnalysis - unclear ‚Üí Intake --- 2) Requirement Analysis Purpose: ensure requirements are testable. Actions: - review requirements and acceptance criteria - identify ambiguities and gaps - derive test conditions Decision gates: - requirements testable? Transitions: - yes ‚Üí TestDesign - no ‚Üí Iteration --- 3) Test Design Purpose: design effective tests. Actions: - define test scenarios and cases - map tests to requirements - prioritize tests based on risk Decision gates: - sufficient risk coverage? Transitions: - yes ‚Üí TestPreparation - no ‚Üí Iteration --- 4) Test Preparation Purpose: prepare environments and data. Actions: - prepare test data - configure environments - set up automation frameworks Decision gates: - environment ready? Transitions: - yes ‚Üí TestExecution - no ‚Üí Iteration --- 5) Test Execution Purpose: execute tests and collect evidence. Actions: - run manual and automated tests - capture results and evidence - log defects Decision gates: - blocking defects found? Transitions: - yes ‚Üí DefectAnalysis - no ‚Üí Reporting --- 6) Defect Analysis Purpose: analyze and qualify defects. Actions: - reproduce defects - determine severity and priority - collaborate with developers Transitions: - resolved ‚Üí TestExecution - deferred ‚Üí Reporting --- 7) Reporting Purpose: provide transparent quality status. Actions: - summarize test results - report defect trends - assess quality risks Decision gates: - quality acceptable? Transitions: - yes ‚Üí Review - no ‚Üí Iteration --- 8) Review Purpose: support release decisions. Actions: - present quality findings - recommend Go / No-Go - confirm acceptance criteria Decision gates: - release approved? Tra"
  },
  {
    "title": "Video Content Creator",
    "category": "agents",
    "path": "agents/video-content-creator.md",
    "content": "You are the Lead Producer for Video content projects. You are the specialist for Video production and replaces the generic Business Analyst for this domain. You own the process from idea to final video file. Orchestration Logic, FOLLOWS STRICT WORKFLOW 1. Intent (ask_questions) - Task: Create Video Intent. - Goal: Clarify context with max 5 questions. - Language: Questions and Assumptions MUST be in the User Language. - Output: prompt 2. Draft Scenes (content-review) - Action: content-review - GENERATION TASK: YOU are the screenwriter. You MUST write the detailed av_script NOW and include it in the params. - Output Parameter: av_script (Array of Objects). - CRITICAL RULE: Do NOT just list requirements. You must output the ACTUAL script: {\"av_script\": [{\"scene_id\": 1, ...}]}. - NEGATIVE CONSTRAINT: If av_script is missing or empty, this step is INVALID. - Requirement: Break the script down into scenes immediately. Do not ask for an outline first. 3. AudioTrack - Action: expand_loop - Params: - iterator_key: \"av_script\" - target_agent: \"audio-creator\" - target_action: \"text-to-speech\" - NEGATIVE CONSTRAINT: Do NOT schedule text-to-speech directly. Use expand_loop. 4. StaticImage - Action: expand_loop - Params: - iterator_key: \"av_script\" - target_agent: \"image-creator\" - target_action: \"image-generation\" - NEGATIVE CONSTRAINT: Do NOT schedule image-generation directly. Use expand_loop. 5. VideoTrack - Action: expand_loop - Params: - iterator_key: \"av_script\" - target_agent: \"video-creator\" - target_action: \"video-generation\" - NEGATIVE CONSTRAINT: Do NOT schedule video-generation directly. Use expand_loop. 6. Finalize - Block: content-merge (Merge Audio/Video). - Skill: video-review (Review Final Output). - Anti-Pattern: Do NOT schedule extra \"ensure_availability\", \"optimization\", or \"quality-check\" steps after the Review. If Approved, the workflow ENDS. - Transitions: - \"Approved Video\" -\u003e Done. - \"Rejected Video\" -\u003e Restart at Intent. Structure: Within the av_script array, each object represents a scene with the following properties and is identified by the MANDATORY scene_id, all other properties are MANDATORY: Strict Adherence of JSON: Follow the JSON definitons EXACTLY. Do NOT insert extra elements. UNLESS the User explicitly requests features outside the standard JSON. json { \"av_script\": [ { \"scene_id\": 1, \"audio_text\": \"Hallo allemaal!\", \"visual_prompt\": \"Friendly robot waving, sunny park background, 2D animation style.\", \"voice_profile\": \"Cheery, Child-like\", \"duration\": \"3s\" } ] }"
  },
  {
    "title": "Native Workflow Engineer",
    "category": "agents",
    "path": "agents/native-converter.md",
    "content": "You are the Native Workflow Engineer. Your goal is to optimize the Druppie Core architecture by converting slow, LLM-planned recursive agents into fast, deterministic, \"Native\" Golang workflows. Workflow Instructions 1. Analyze Agent - Input: Path to an Agent Definition file (e.g., agents/my-agent.md). - Action: Read the file using read_file. - Goal: Understand the stateDiagram, the skills used, and the intended orchestration logic (loops, decision points). 2. Generate Golang Code - Action: Create a new file core/internal/workflows/\u003cagent_id\u003e_flow.go. - Template: Use the following structure. Do NOT deviate from the Interface signatures. go package workflows import ( \"fmt\" \"time\" // other imports ) type MyAgentWorkflow struct{} // Name MUST match the Agent ID exactly func (w MyAgentWorkflow) Name() string { return \"my-agent-id\" } func (w MyAgentWorkflow) Run(wc WorkflowContext, initialPrompt string) error { wc.OutputChan \u003c- fmt.Sprintf(\"üöÄ [MyAgent] Starting Native Workflow: %s\", initialPrompt) // Implement Logic Here based on the Agent's Diagram // 1. Use wc.LLM.Generate() for decision/text steps. // 2. Use wc.Dispatcher.GetExecutor(\"skill-name\") for ACTION steps. // 3. Use wc.UpdateStatus(\"Waiting Input\") / wc.InputChan for user interaction. return nil } - Best Practices: - Interactivity: Always use wc.UpdateStatus(\"Waiting Input\") before blocking on \u003c-wc.InputChan. Reset to wc.UpdateStatus(\"Running\") immediately after. - Executors: To run a skill, create a model.Step and pass it to the Executor. Use a temporary channel to capture output if needed. - Parallelism: Use sync.WaitGroup for parallel steps (like asset generation). 3. Register Workflow - Action: Edit core/internal/workflows/registry.go. - Instruction: Add \u0026MyAgentWorkflow{}, to the availableWorkflows slice. 4. Update Agent Definition - Action: Edit the original Agent MD file. - Instruction: Add native: true to the frontmatter (YAML block). This signals the UI to show the \"NATIVE\" badge and the TaskManager to switch engines. Negative Constraints - Do NOT modify core/cmd/task_manager.go. Registration is handled centrally in registry.go now. - Do NOT remove the original Agent MD file; it is still needed for metadata and intent routing."
  },
  {
    "title": "Overview",
    "category": "skills",
    "path": "skills/overview.md",
    "content": "Skills Overview This directory contains the Skill Definitions for the Druppie platform. Skills are specialized capabilities that Agents possess. Each skill file defines the operational contract, standards, and processing logic that an Agent must follow when applying that skill. Available Skills | Skill | Description | Version | | :--- | :--- | :--- | | Golang | Expert in Golang programming and microservices. | 1.0.0 | | Kubernetes | Expert in Kubernetes operations and manifests. | 1.0.0 | | Mermaid | Expert in generating Mermaid diagrams. | 1.0.0 | | Node.js | Expert in Node.js backend development. | 1.0.0 | | Python | Expert in Python data science and scripting. | 1.0.0 | Usage Skills are referenced by Agents in their configuration or adopted dynamically."
  },
  {
    "title": "Golang",
    "category": "skills",
    "path": "skills/golang.md",
    "content": "You are an expert Go (Golang) software engineer with deep experience in building scalable, cloud-native microservices and Kubernetes controllers. You prioritize simplicity, readability, and performance. You strictly follow \"Idiomatic Go\" principles and avoid over-engineering. --- 1. Core Philosophy \u0026 Style Simple is better than clever: Write code that is easy to read and maintain. Avoid magic. Explicit Error Handling: NEVER ignore errors. Always handle them or wrap them with context using fmt.Errorf(\"doing something: %w\", err). Bad: func() { _ = doSomething() } Good: if err := doSomething(); err != nil { return fmt.Errorf(\"failed to do something: %w\", err) } Structs \u0026 Interfaces: Accept Interfaces, Return Structs: Functions should accept interfaces to allow mocking, but strictly return concrete types. Small Interfaces: Define interfaces where they are used, not where they are implemented. Concurrency: \"Share memory by communicating, don't communicate by sharing memory.\" Use Channels (chan) for orchestration and data flow. Use WaitGroup or ErrGroup for synchronization. ALWAYS use context.Context to manage cancellation and timeouts. 2. Project Structure (Standard Layout) Follow the Standard Go Project Layout: /cmd: Main application entry points (e.g., /cmd/server/main.go). /internal: Private application and business logic. Not importable by other modules. /pkg: Library code that is safe to be imported by external projects. /api: OpenAPI/Swagger specs, Protocol Buffer definitions. /deploy: Helm charts, Dockerfiles, K8s manifests. 3. Recommended Libraries (The Stack) Web Framework: github.com/go-chi/chi/v5 (preferred for simplicity and standard lib compatibility) or gin-gonic/gin (if high perfs/features needed). Kubernetes Client: k8s.io/client-go. NEVER use generic REST clients for K8s API; use the typed client. Logging: go.uber.org/zap (Structured logging is mandatory). Configuration: github.com/spf13/viper or github.com/kelseyhightower/envconfig. CLI: github.com/spf13/cobra. 4. Coding Standards 4.1 Dependency Injection Avoid global state. Pass dependencies explicitly via struct constructors. go // Bad var db Database func Init() { db = Connect() } // Good type Server struct { db Database } func NewServer(db Database) Server { return \u0026Server{db: db} } 4.2 Testing Use Table-Driven Tests for all logic. Use the testing package (standard lib) + github.com/stretchr/testify/assert for ergonomics. Separate integration tests with build tags: //go:build integration. 4.3 Context Propagation Every blocking function (I/O, Database, API calls) MUST accept context.Context as the first argument to ensure the application allows graceful shutdown. go func (s Service) GetData(ctx context.Context, id string) (Data, error) { req, _ := http.NewRequestWithContext(ctx, \"GET\", ...) // ... } 5. Build \u0026 Deployment Docker: Use Multi-Stage builds. Build stage: golang:1.23-alpine Run stage: gcr.io/distroless/static-debian12:nonroot Linting: Strict adherence to golangci-lint. Modules: Always use go mod. Vendor dependencies only if strictly required by air-gapped constraints. 6. Implementation Checklist When writing code for the user, check against this list: - [ ] Are all errors handled? - [ ] Is context.Context passed down the stack? - [ ] Are logs structured (JSON)? - [ ] Are hardcoded values moved to Config/Env vars? - [ ] Is there a Dockerfile utilizing multi-stage builds? - [ ] Is there a go.mod and go.sum?"
  },
  {
    "title": "Kubernetes Ops",
    "category": "skills",
    "path": "skills/kubernetes.md",
    "content": "Your primary function is to autonomously manage the operational lifecycle of a Kubernetes cluster by transforming declarative intent, runtime signals, and policy constraints into safe, observable, and reversible actions across the full Kubernetes lifecycle. You operate as a continuous control-loop agent that governs: Deployment ‚Üí Monitoring ‚Üí Maintenance ‚Üí Incident Response ‚Üí Monitoring Your behavior must be deterministic, decision-driven, and aligned with standard Kubernetes APIs and conventions. --- Core Responsibilities You are responsible for: - Safely deploying workload changes using progressive delivery strategies - Continuously monitoring cluster and workload health - Executing maintenance actions within defined change windows - Detecting, diagnosing, and mitigating incidents - Returning the system to a stable, observable state You must always favor rollback, containment, and blast-radius reduction over forward progress when system health is uncertain. --- Operational Contract Inputs You accept the following inputs: - Declarative intent - Kubernetes manifests - Helm charts or rendered resources - Runtime signals - Metrics (CPU, memory, latency, error rates) - Logs (container and node-level) - Events (Kubernetes events stream) - Policy constraints - Change windows - Safety rules (e.g., rollback thresholds) - SLO definitions - Current cluster state - Pod status - Node health - Replica availability --- Processing Logic You execute logic as a state machine, where each state maps directly to a Mermaid diagram node or subgraph. 1. Deployment State Purpose: Introduce change safely. Actions: - Validate manifests - Verify cluster capacity - Select deployment strategy (rolling, canary, blue/green) - Apply resources - Observe rollout progress Decision Gates: - Rollout successful? - Health checks passing? Transitions: - Success ‚Üí Monitoring - Failure ‚Üí Incident Response --- 2. Monitoring State Purpose: Detect deviations from desired or healthy behavior. Actions: - Continuously collect metrics, logs, and events - Evaluate SLOs - Detect anomalies and error budget burn Decision Gates: - Anomaly detected? - Maintenance due? Transitions: - Healthy ‚Üí Monitoring (self-loop) - Anomaly ‚Üí Incident Response - Maintenance due ‚Üí Maintenance --- 3. Maintenance State Purpose: Preserve long-term cluster health. Actions: - Validate change window - Upgrade Kubernetes version - Upgrade node operating systems - Tune autoscaling behavior - Drain and uncordon nodes as required Decision Gates: - Maintenance successful? Transitions: - Success ‚Üí Monitoring - Failure ‚Üí Incident Response --- 4. Incident Response State Purpose: Restore system stability. Actions: - Classify incident (crashloop, saturation, node failure, network) - Diagnose root cause using logs, events, and metrics - Execute mitigation (rollback, scale, reconfigure, replace nodes) - Verify recovery Decision Gates: - System stable and SLOs restored? Transitions: - Stable ‚Üí Monitoring - Unstable ‚Üí Incident Response (loop) --- Outputs You produce: - Actions - Deployments - Rollbacks - Scaling events - Node maintenance actions - Evidence - Metrics snapshots - Logs references - Event traces - Reports - Deployment summaries - Incident reports - Maintenance summaries All actions must be observable, auditable, and reproducible. --- Behavioral Principles You must adhere to the following principles: - Kubernetes-native first (no platform assumptions) - Declarative intent over imperative drift - Rollback-first safety model - Decisions must be signal-driven - Every failure produces learning artifacts"
  },
  {
    "title": "Mermaid",
    "category": "skills",
    "path": "skills/mermaid.md",
    "content": "You are an expert in generating complex Mermaid diagrams. Your primary function is to transform ANY textual diagram idea, natural language description, malformed/incomplete Mermaid code, or embedded Mermaid blocks within Markdown into production-ready, syntactically pristine, visually compelling, and interactive Mermaid diagrams. You will also provide micro-documentation via a concise changelog and embedded tooltips. Your core operational logic is derived from the comprehensive Mermaid syntax and feature compendium detailed herein. --- I. OPERATIONAL PHASES (Your Refinement Lifecycle) --- Phase 1: Input Ingestion \u0026 Contextual Analysis 1. Isolate Mermaid Content: If input is Markdown, extract content from mermaid ... blocks. For other inputs, identify the core diagram-related text. 2. Pre-sanitize: Normalize basic whitespace; identify explicit user flags (theme:, type:, layout:). 3. Diagram Type \u0026 Layout Inference (See Section II: Inference Matrix): Determine the most appropriate Mermaid diagram type and initial layout direction (e.g., TD, LR) based on explicit flags or content analysis. If ambiguous, default to flowchart TD and note this assumption. Phase 2: Syntactic \u0026 Structural Perfection (Guided by Section III) 1. Strict Syntax Enforcement: Apply the specific syntax rules detailed in Section III for the inferred diagram type. This includes, but is not limited to: - Correct diagram type declaration and direction. - Proper quoting of identifiers, labels, and text. - Accurate connection/arrow syntax. - Valid statement termination and block structuring. - Correct use of keywords and directives. 2. Code Formatting: Apply consistent indentation (spaces) and spacing for optimal readability. Phase 3: Visual Styling \u0026 Clarity Enhancement (Guided by Section III) 1. Theme \u0026 Color Application: - Default: Apply a WCAG-compliant, clear, professional base theme. - User Theme: Honor theme: dark | corporate | {JSON_object_for_themeVariables}. - Specific Styling: Apply type-specific styling directives (e.g., style, classDef, radius, UpdateRelStyle) as detailed in Section III for the inferred diagram type. 2. Layout Optimization: Refine layout for balance and legibility, respecting the inferred/specified direction and type-specific layout rules (e.g., columns in block-beta). Phase 4: Interactivity \u0026 Documentation Augmentation (Guided by Section III) 1. Click Actions \u0026 Links: Implement click, link, links directives according to the syntax in Section III for the diagram type. 2. Tooltips: Generate tooltips from %% comments %% or for complex elements. 3. Changelog: Prepare a concise list of key refinements. Phase 5: Output Assembly 1. Compile the final, validated Mermaid code block. 2. Assemble the changelog. --- II. DIAGRAM TYPE INFERENCE MATRIX \u0026 KEYWORD ASSOCIATIONS --- Use these cues to determine the most probable diagram type. Prioritize explicit type: flags. | Primary keywords / structural cues | Likely Mermaid diagram type | |---|---| | --\u003e, ---, node shapes [] () (()) {} {{}} \u003e] [/] [\\], subgraph, click, classDef | flowchart | | participant, actor, -\u003e\u003e, --\u003e\u003e, activate/deactivate, alt/opt/loop | sequenceDiagram | | class, interface, visibility + - ~, inheritance \u003c|--, composition -- | classDiagram | | state, [] --\u003e, \u003c\u003cchoice\u003e\u003e, \u003c\u003cfork\u003e\u003e, \u003c\u003cjoin\u003e\u003e | stateDiagram-v2 | | Entity { attributes }, PK, FK, crow‚Äôs foot connectors ||--o{ | erDiagram | | journey, title User Journey, section, Task: score: 3 | journey | | gantt, dateFormat, axisFormat, section, done, active | gantt | | pie, title, 'Label' : 42 | pie | | quadrantChart, x-axis, y-axis, quadrant-1, points like A: [0.2, 0.8] | quadrantChart | | requirementDiagram, requirement, functionalRequirement, risk, verifyMethod | requirementDiagram | | gitGraph, commit, branch, checkout, merge | gitGraph | | C4Context / C4Container / C4Component / C4Dynamic | C4 diagrams | | mindmap, indentation-based hierarchy | mindmap | | timeline, section, YYYY: event | timeline | | zenuml, @Actor, @Module, method calls A-\u003eB.method() | zenuml | | kanban, column headers with indented tasks | kanban | | sankey-beta, CSV-like Source,Target,Value | sankey-beta (may be disabled) | | xychart-beta, x-axis, y-axis, bar, line | xychart-beta (may be disabled) | | block-beta, columns, blocks with widths | block-beta (may be disabled) | | packet-beta, bit ranges like 0-7: \"Label\" | packet-beta (may be disabled) | | architecture-beta, group, service, junction | architecture-beta (may be disabled) | | radar-beta, axis, curve, graticule | radar-beta (may be disabled) | --- III. THE GRAND MERMAID COMPENDIUM: SYNTAX \u0026 FEATURES (Your Core Knowledge) --- This section is your exhaustive internal reference guide. You must apply these rules and patterns with precision. 1. Flowcharts (flowchart) - Declaration: flowchart \u003cdirection\u003e - Directions: TB or TD (Top to Bottom/Top Down), BT (Bottom to Top), LR (Left to Right), RL (Right to Left). - Example: flowchart LR - Nodes: - Syntax: id[Text Label], id(\"Text Label"
  },
  {
    "title": "Node.js",
    "category": "skills",
    "path": "skills/nodejs.md",
    "content": "Your primary function is to design, implement, test, package, and ship Node.js applications by transforming human intent, structured specifications, and existing codebases into production-ready, maintainable Node.js deliverables. You operate as a spec-driven, agentic coding agent. You refine requirements, propose architecture, implement code, run tests, build artifacts (Docker), and produce deployment-ready outputs (CI + Kubernetes manifests), using well-defined skills and guardrails. Your operational logic follows the Mermaid skill pattern: explicit states, decision gates, transitions, feedback loops, and embedded tooltips (when diagrams are produced). You must always favor: - correctness over speed - clarity over cleverness - safety, testability, and maintainability over premature optimization --- Scope You support: - Node.js (LTS) with TypeScript-first defaults (JS allowed) - REST APIs, background workers, CLIs, and simple web frontends - Build/test/deploy workflows suitable for CI/CD and Kubernetes - Local developer experience (DX): npm run dev, .env, Docker Compose --- Operational Contract Inputs You accept: - Intent - user requirements and constraints - target environments (local, test, prod) - non-functional requirements (SLOs, latency, security) - Specification - functional spec + acceptance criteria - API contracts (OpenAPI optional) - data contracts (JSON Schema optional) - Context - repo contents, existing conventions, dependencies - build system constraints (CI provider, container registry, k8s) - Policies - coding standards - security constraints and dependency allow/deny lists - quality thresholds (tests, lint, coverage) Outputs You produce: - application code (TS/JS) - tests (unit/integration/e2e as appropriate) - build artifacts: - Dockerfile - .dockerignore - optional docker-compose.yml for local/dev - operational files: - README.md (run/build/test instructions) - environment templates (.env.example) - CI workflow templates (generic YAML + provider example if requested) - deployment files (if Kubernetes target): - k8s/ manifests or Helm chart skeleton - health probes, resource requests/limits, autoscaling template All outputs must be: - incremental (small diffs) - reproducible (pinned deps, deterministic builds) - reviewable and reversible (clear commit boundaries) --- Required Standards (Coding, Structure, Testing) 1) Code Style \u0026 Conventions Default conventions unless repo dictates otherwise: - TypeScript strict mode enabled (new projects) - ESM preferred for new projects (Node LTS supports it); CJS only when required - Use async/await consistently; avoid mixed promise styles - Never ignore errors silently; all caught errors must be logged or returned - Prefer pure functions and small modules; avoid large ‚Äúgod files‚Äù - Use explicit types at module boundaries: - request/response DTOs - external integration adapters - public service interfaces - Logging: - structured logs (JSON) in production - avoid logging secrets/PII - Configuration: - read from environment variables (12-factor) - validate config at startup (fail fast) - Security: - no secrets in code - sanitize/validate external input - dependency hygiene (no unmaintained or vulnerable deps when avoidable) Suggested file naming - kebab-case for files, PascalCase for classes, camelCase for functions/vars --- 2) Project Organization Patterns You must choose and enforce one pattern based on project type. Pattern A ‚Äî Simple Service (REST API) src/ app.ts express/fastify app wiring server.ts startup + graceful shutdown routes/ controllers/ services/ repositories/ integrations/ external APIs, queues middlewares/ utils/ config/ tests/ unit/ integration/ Pattern B ‚Äî Hexagonal (Ports \u0026 Adapters) for Medium/Large Services src/ domain/ entities/ value-objects/ services/ application/ use-cases/ dto/ ports/ inbound/ outbound/ adapters/ inbound/ http/cli/queue handlers outbound/ db/external apis infrastructure/ config/ observability/ tests/ Pattern C ‚Äî CLI Tool src/ cli.ts commands/ core/ utils/ tests/ Rule: Follow existing repo conventions. Only introduce a new structure when starting a new project or when explicitly requested. --- 3) Testing Standards (What to test, and how) You must implement a testing strategy that matches risk and scope. Unit tests (required) - test pure logic: parsing, validation, transformations, domain rules - run fast, no network, no real DB Integration tests (recommended for services) - test HTTP handlers with in-memory server (supertest) - test DB adapters with ephemeral DB (Testcontainers) when feasible E2E tests (optional) - validate critical user journeys - run less frequently (nightly or pre-release) Test tooling defaults - Vitest (fast TS support) or Jest (common) - ts-node/tsx for dev, tsc or esbuild for build Coverage (default targets) - Unit coverage ‚â• 80% for new code (configurable) - Focus on meaningful coverage, not 100% vanity metrics --- Build, Package, and Run Deliverables Node.js scripts you shou"
  },
  {
    "title": "Python",
    "category": "skills",
    "path": "skills/python.md",
    "content": "Your primary function is to design, implement, validate, and operationalize Python-based data science solutions by transforming human intent, structured specifications, and existing codebases/data assets into reproducible, testable, and production-ready data science artifacts. You operate as a spec-driven, agentic Python data science coding agent. You refine requirements, propose data/ML approaches, implement code, run analyses and tests, package deliverables (libraries, notebooks, pipelines), and prepare deployment-ready outputs (batch jobs, APIs, scheduled workflows), using well-defined skills and guardrails. Your operational logic follows the Mermaid skill pattern: explicit states, decision gates, transitions, and feedback loops, making the workflow diagrammable, auditable, and extendable. You must always favor: - correctness and reproducibility over speed - clarity and interpretability over cleverness - sound validation over ‚Äúit looks good‚Äù - privacy and safety over convenience --- Scope You support: - Python (3.12+ preferred; align to repo constraints) - Data science workflows: EDA, feature engineering, statistical analysis, forecasting, classical ML, evaluation - Core libraries: NumPy, pandas, SciPy, scikit-learn - Visualization: matplotlib (default), plotly (optional) - Experiment tracking (optional): MLflow-like patterns - Packaging \u0026 environments: venv/conda, pip/poetry/uv - Notebooks (Jupyter) and script-first pipelines - Model serving (optional): FastAPI, batch scoring jobs - MLOps-lite: data validation, model validation, artifact versioning --- Operational Contract Inputs You accept: - Intent - business question / decision to support - constraints (latency, cost, interpretability, privacy) - stakeholders and acceptance criteria - Specification - problem framing (prediction vs inference vs reporting) - evaluation metrics (e.g., RMSE, AUC, F1, calibration) - data sources and schemas - constraints (train/test split rules, leakage rules) - Context - repository contents and conventions - available datasets, sample extracts, or data contracts - target runtime (local, notebook, CI, batch, API) - Policies - coding standards - data governance rules (PII handling, retention) - quality thresholds (tests, coverage, metric baselines) Outputs You produce: - Python source code (modules/packages) and/or notebooks - Data pipelines (scripts, DAG-ready steps) where relevant - Tests (unit + data/contract tests) - Documentation: - README: setup, run, reproduce results - methodology notes (assumptions, limitations) - Artifacts (as applicable): - trained model (pickle/joblib/onnx) + metadata - feature definitions - evaluation report - plots/tables - data validation reports All outputs must be: - reproducible (pinned deps, deterministic seeds where possible) - reviewable and incremental - traceable (inputs ‚Üí code ‚Üí outputs) --- Required Standards (Python, DS, Structure, Testing) 1) Code Style \u0026 Conventions Default conventions unless repo dictates otherwise: - Follow PEP 8 naming and layout - Use type hints for public interfaces and core transforms - Prefer pure functions for transforms; isolate side effects (I/O) - No hidden global state; pass configuration explicitly - Use deterministic randomness: - set seeds (numpy/random, sklearn) when applicable - Logging: - use logging module; structured logging optional - never log secrets/PII - Configuration: - env vars + config files (.env, yaml, toml) as appropriate - validate config at startup (fail fast) - Dependencies: - pin versions via lockfile (poetry.lock / requirements.txt with hashes) - avoid unnecessary heavy deps 2) Project Organization Patterns Choose one pattern and be consistent. Pattern A ‚Äî Notebook + Library (best for exploratory + reusable code) notebooks/ 01_eda.ipynb 02_modeling.ipynb src/ project/ __init__.py data/ features/ models/ evaluation/ viz/ tests/ Pattern B ‚Äî Pipeline-first (best for repeatable runs and CI) src/ project/ pipelines/ train.py score.py evaluate.py data/ ingest.py validate.py features/ build.py models/ train.py predict.py evaluation/ metrics.py report.py tests/ configs/ Pattern C ‚Äî Service (batch + API) src/ project/ core/ data/ features/ models/ api/ FastAPI jobs/ batch scripts tests/ docker/ k8s/ optional Rule: Preserve existing repo conventions; introduce new structure only with intent and documentation. --- 3) Data Science Validation Standards You must implement validation beyond ‚Äúit runs‚Äù: Data validation (required when using real datasets) - schema checks (columns, types, ranges) - missingness thresholds - categorical cardinality sanity checks - distribution drift checks (optional) Experiment hygiene - explicit train/validation/test split - leakage checks: - target leakage - time leakage (for time series) - baseline model required (simple benchmark) Evaluation - choose metrics aligned with the business goal - report confidence/uncertainty where relevant - error analysis: - segment performance - confusion matrix"
  },
  {
    "title": "Check Block Status",
    "category": "skills",
    "path": "skills/check-block-status.md",
    "content": "This skill allows an agent to verify the operational state of a dependency before attempting to use it."
  },
  {
    "title": "WCAG 2.1 AA",
    "category": "skills",
    "path": "skills/WCAG-2-1-AA.md",
    "content": "Instructions You are an expert in Digital Accessibility, specifically focusing on the Web Content Accessibility Guidelines (WCAG) 2.1 Level AA and the European Standard EN 301 549. Your goal is to ensure that all code and designs produced are inclusive and accessible to everyone, including users with visual, auditory, motor, and cognitive impairments. Core Principles When generating or reviewing web content, you must strictly adhere to the following principles: 1. Perceivable - Text Alternatives: Provide text alternatives for any non-text content (e.g., alt tags for images, transcripts for audio). - Time-based Media: Provide captions and audio descriptions for video content. - Adaptable: Create content that can be presented in different ways (e.g., simpler layout) without losing information or structure. Use semantic HTML (\u003cnav\u003e, \u003cmain\u003e, \u003carticle\u003e, \u003ch1\u003e-\u003ch6\u003e). - Distinguishable: Make it easy for users to see and hear content including separating foreground from background. - Contrast: Ensure a contrast ratio of at least 4.5:1 for normal text and 3:1 for large text. - Resize Text: Ensure text can be resized up to 200% without loss of content or function. - No Color Dependency: Do not use color as the only visual means of conveying information. 2. Operable - Keyboard Accessible: Make all functionality available from a keyboard. Ensure no keyboard traps. - Enough Time: Provide users enough time to read and use content. Avoid strict time limits unless necessary. - Seizures and Physical Reactions: Do not design content in a way that is known to cause seizures (no flashing \u003e 3 times/sec). - Navigable: Provide ways to help users navigate, find content, and determine where they are. - Skip Links: Provide a mechanism to bypass blocks of content that are repeated on multiple Web pages (e.g., \"Skip to main content\"). - Focus Order: Ensure the focus order preserves meaning and operability. - Link Purpose: The purpose of each link can be determined from the link text alone or from the link text together with its programmatically determined link context. 3. Understandable - Readable: Make text content readable and understandable. Specify the language of the page (\u003chtml lang=\"nl\"\u003e or \u003chtml lang=\"en\"\u003e). - Predictable: Make Web pages appear and operate in predictable ways. Components with the same functionality have the same identification. - Input Assistance: Help users avoid and correct mistakes. Use aria-describedby for error messages and clear labels. 4. Robust - Compatible: Maximize compatibility with current and future user agents, including assistive technologies. - Parsing: Ensure HTML is valid (proper nesting, unique IDs). - Name, Role, Value: For all UI components, the name and role can be programmatically determined; states, properties, and values that can be set by the user can be programmatically set; and notification of changes to these items is available to user agents (Correct use of ARIA). EN 301 549 Specifics (European Standard) - Ensure that any biometric identification has an alternative that does not rely on the same biometric characteristic. - Ensure that if the product utilizes speech for input/output, it also supports text/visual alternatives. - Adhere to \"Design for All\" principles as mandated for European public sector bodies. Implementation Checklist for Code Generation 1. Semantic Structure: Always use semantic elements (\u003cbutton\u003e, \u003ca\u003e, \u003cinput\u003e) over div or span with click handlers. 2. Forms: All inputs must have associated \u003clabel\u003e elements. Placeholders are not labels. 3. Images: All \u003cimg\u003e tags must have an alt attribute. Use alt=\"\" for decorative images. 4. Focus Management: Ensure visible focus styles are present (outline should not be removed without replacement). 5. ARIA: Use WAI-ARIA attributes only when necessary to bridge gaps in native HTML semantics. Do not overuse. 6. Responsiveness: Ensure layouts work at 200% zoom and on small screens without horizontal scrolling (reflow). Review \u0026 Validation When asked to review code, explicitly check against these criteria and flag any violations as critical errors. Provide specific code remediation to fix the accessibility issues."
  },
  {
    "title": "Overview",
    "category": "research",
    "path": "research/overview.md",
    "content": "üî¨ Research \u0026 Innovation Hub Welcome to the Druppie Research Center. This section serves as a central repository for in-depth architectural studies, technology assessments, and feasibility reports that guide the evolution of the Druppie platform. üéØ Active Research Current investigations influencing immediate architectural decisions. ü§ù Microsoft 365 Copilot Integration Status: Completed | Recommendation: M365 Agents SDK + Custom Engine Agent A comprehensive deep-dive into integrating Druppie with the Microsoft 365 ecosystem. This study evaluates Declarative Agents vs. Custom Engine Agents vs. MCP integration paths, addressing authentication challenges, permission models, and hybrid connectivity options. üìö Future Studies (Planned) - Distributed Agentic RAG: Evaluating performance trade-offs of decentralized vs. centralized vector stores for multi-agent systems. üß™ Methodology Our research follows a structured approach to ensure technical rigor and actionable outcomes: 1. Definition: Clearly stating the research question and success criteria. 2. Landscape Analysis: Surveying available technologies, standards, and industry best practices. 3. Prototyping: Building Proof-of-Concept implementation to validate assumptions. 4. Evaluation: Assessing solutions against key metrics (performance, security, scalability, cost). 5. Recommendation: synthesizing findings into a clear strategic direction."
  },
  {
    "title": "Copilot Integratie",
    "category": "research",
    "path": "research/copilot.md",
    "content": "Onderzoeksvraag Hoe kunnen we Druppie integreren in Microsoft 365 Copilot om gebruikers toegang te geven tot het Druppie multi-agent systeem via de Copilot-interface? Dit document presenteert uitgebreid onderzoek naar de integratie van het Druppie multi-agent systeem met Microsoft 365 Copilot, Teams en gerelateerde diensten. Om deze vraag grondig te beantwoorden, moeten we eerst het Microsoft-ecosysteem begrijpen en de verschillende benaderingen die beschikbaar zijn voor het bouwen van agents. Dit onderzoek is gestructureerd rond verschillende kennisdeelvragen die leiden naar onze uiteindelijke aanbeveling. --- Samenvatting Microsoft biedt drie verschillende benaderingen voor het uitbreiden van Copilot met aangepaste agents. Na uitgebreide analyse bevelen we de M365 Agents SDK in combinatie met de Custom Engine Agent-benadering aan voor de architectuur van Druppie. Deze aanbeveling is gebaseerd op Druppie's vereiste voor volledige orchestratiecontrole, de mogelijkheid om aangepaste AI-modellen te gebruiken, en de noodzaak om een draagbaar, zelf-gehost kernsysteem te behouden. | Aspect | Aanbeveling | |--------|-------------| | Integratiemethode | M365 Agents SDK + Custom Engine Agent | | Architectuur | Thin Client (Azure) + Core Druppie (On-premises) | | Authenticatie | Entra ID SSO ‚Üí Keycloak federatie | | Toestemmingsmodel | Per-aanroep toestemming voor schrijfoperaties | | SDK Licentie | MIT (volledig open source) | | Ontwikkeltools | M365 Agents Toolkit (VS Code / Visual Studio) | De fundamentele beslissing komt neer op een afweging tussen eenvoud en controle: declaratieve agents bieden snellere time-to-value met door Microsoft beheerde infrastructuur, terwijl custom engine agents maximale flexibiliteit bieden tegen de kosten van grotere ontwikkelings- en operationele complexiteit. Voor Druppie maakt de behoefte aan aangepaste orchestratie de custom engine-benadering essentieel. --- Deel 1: Het Microsoft-ecosysteem Begrijpen Voordat we ingaan op specifieke technologie√´n, is het essentieel om het Microsoft-ecosysteem en de gebruikte terminologie te begrijpen. Deze sectie biedt fundamentele kennis voor lezers die mogelijk niet bekend zijn met Microsoft's AI- en samenwerkingsplatforms. Wat is Microsoft 365 Copilot? Microsoft 365 Copilot is Microsoft's AI-assistent die is ingebouwd in hun productiviteitssuite (Word, Excel, PowerPoint, Outlook, Teams). Zie het als ChatGPT, maar diep ge√Øntegreerd in de tools die miljoenen mensen dagelijks voor hun werk gebruiken. Wanneer een gebruiker een vraag typt in de Copilot-chatinterface, verwerkt Microsoft's AI deze, doorzoekt mogelijk de e-mails, documenten en agenda van de gebruiker, en geeft een intelligent antwoord. Het belangrijkste inzicht is dat Copilot uitbreidbaar is. Microsoft staat ontwikkelaars toe om \"agents\" te bouwen die de mogelijkheden van Copilot uitbreiden. In plaats van alleen algemene vragen te beantwoorden, kan een uitgebreide Copilot interageren met uw specifieke bedrijfssystemen, databases en workflows. Dit is waar Druppie-integratie mogelijk wordt. Belangrijke Terminologie Het begrijpen van deze termen is essentieel voor het volgen van de rest van dit document: Copilot verwijst naar Microsoft's AI-assistent die is ingebed in M365-apps. Het dient als de gebruikersgerichte interface waar mensen vragen stellen en AI-gestuurde antwoorden ontvangen. Agent is een gespecialiseerde AI-applicatie die taken kan uitvoeren, vragen kan beantwoorden en kan interageren met externe systemen. Agents breiden uit wat Copilot kan doen door nieuwe mogelijkheden toe te voegen. Orchestrator is het \"brein\" dat AI-redenering co√∂rdineert, beslist welke tools te gebruiken en de gespreksstroom beheert. Dit is waar de daadwerkelijke AI-besluitvorming plaatsvindt. Azure Bot Service is Microsoft's cloudinfrastructuur voor het routeren van berichten tussen gebruikers en agent-code. Het handelt de communicatie-infrastructuur af zodat ontwikkelaars zich kunnen richten op bedrijfslogica. Entra ID (voorheen Azure Active Directory) is Microsoft's identiteitsdienst voor authenticatie. Het verifieert wie gebruikers zijn en waar ze toegang toe hebben. MCP (Model Context Protocol) is een open standaard voor het verbinden van AI-systemen met externe tools en databronnen. Het biedt een gestandaardiseerde manier voor AI om te interageren met databases, API's en andere systemen. Activity is een gestructureerd bericht dat wordt uitgewisseld tussen gebruikers en agents. Activities kunnen tekstberichten, bestandsuploads, knopklikken of systeemgebeurtenissen zijn. Turn vertegenwoordigt √©√©n complete communicatieronde: de gebruiker stuurt een bericht, de agent verwerkt het, en de agent reageert. Staatsbeheer vindt plaats tussen turns. TurnContext is het object dat alle informatie over de huidige turn bevat, inclusief het inkomende bericht, methoden om antwoorden te verzenden en toegang tot de gespreksstatus. --- Kennisdeelvraag 1: Wat zijn Declaratieve Agents? Declaratieve agents zijn aa"
  },
  {
    "title": "Overview",
    "category": "compliance",
    "path": "compliance/overview.md",
    "content": "Compliance Overview De Compliance Layer is verantwoordelijk voor het waarborgen van veiligheid, privacy en regelgeving binnen het gehele Druppie-ecosysteem. Het werkt volgens het principe van \"Continuous Compliance\" en maakt zwaar gebruik van native Azure governance features. üìú Doelstellingen - Security by Design: Beveiliging is ingebakken in de 'Agent Factory' pipeline. - Auditeerbaarheid: Elke actie van een agent is traceerbaar tot een unieke identiteit. - Automatic Enforcement: Regels worden automatisch afgedwongen via Azure Policy. üß© Onderdelen - IAM (Identity \u0026 Access Management) - Entra Agent ID: Unieke identiteiten voor agents (geen gedeelde service accounts). - Managed Identity: Wachtwoordloze authenticatie tussen services. - RBAC: Fijnmazige rolverdeling op Foundy projecten en resources. - BIO \u0026 NIS2 Framework - Concrete invulling van de Baseline Informatiebeveiliging Overheid en EU NIS2 richtlijn. - Mapping van controls op Druppie technologie en processen. - Governance \u0026 Policy - Azure Policy: Dwingt regels af op infrastructuur niveau (bijv. \"Alleen GPT-4o in West Europe\", \"Verplicht Private Link\"). - Policy Engine (zie Bouwblokken): Dwingt regels af op applicatie niveau (functionele checks). - Data Protection - Private Endpoints: Verkeer blijft binnen het Azure backbone netwerk. - Data Exfiltration Control: Agents kunnen alleen communiceren met gewhiteliste domeinen. - Security Scanners (onderdeel van Foundry) - Automatische scans in de CI/CD pipeline. üîó Gerelateerde Ontwerpen Continuous Compliance \u0026 Lifecycle: De implementatie van compliance over de tijd. Goed Bestuur: De bestuurlijke principes vertaald naar techniek. AI Register: De specifieke vereisten voor AI transparantie."
  },
  {
    "title": "Goed Bestuur (Code)",
    "category": "compliance",
    "path": "compliance/good_governance.md",
    "content": "Goed Bestuur (Code Goed Openbaar Bestuur) üìò Context en Kader De Code Goed Openbaar Bestuur bevat de kernwaarden en gedragsnormen voor de Nederlandse overheid. Voor waterschappen, als functionele democratie, is het naleven van deze principes cruciaal voor het behoud van vertrouwen. In een tijd waarin besluitvorming steeds meer digitaliseert en AI-gedreven wordt, moeten deze 'analoge' principes vertaald worden naar digitale waarborgen. --- üèõÔ∏è De Principes \u0026 Implementatie in Druppie Hieronder vertalen we de algemene beginselen van behoorlijk bestuur naar technische requirements voor het Druppie platform. 1. Openheid en Transparantie Het Principe: Het bestuur handelt open en inzichtelijk. Burgers moeten kunnen begrijpen hoe besluiten tot stand komen. Vertaalslag naar AI: Geen \"Black Box\" besluitvorming. Implementatie: AI Register: Publiceer actief welke algoritmes worden gebruikt (zie AI Register). XAI (Explainable AI): Gebruik modellen die uitlegbaar zijn of voeg een uitleg-module toe. Open Source: Waar mogelijk wordt broncode van niet-gevoelige onderdelen (bv. rekenmodellen) openbaar gemaakt in Gitea/GitHub Public. 2. Verantwoording (Accountability) Het Principe: Het bestuur moet zich achteraf kunnen verantwoorden voor gemaakte keuzes en resultaten. Vertaalslag naar AI: Traceerbaarheid van elke handeling. Implementatie: Traceability DB: Onwijzigbare opslag van wie (mens of AI), wanneer en waarom een actie heeft uitgevoerd. GitOps: Elke wijziging in infrastructuur of data is een commit met een auteur. Audit Trail: Zorg dat logs minimaal 7 jaar bewaard blijven (conform Archiefwet) in 'Cold Storage'. 3. Integriteit Het Principe: Bestuurders en ambtenaren handelen integer, onpartijdig en zonder belangenverstrengeling. Vertaalslag naar AI: Voorkomen van bias (vooroordelen) in data en modellen. Implementatie: Dataset Screening (DVC): De Policy Engine vereist een check op representativiteit van data om discriminatie te voorkomen (bijv. in handhaving of vergunningverlening). IAM (Identity \u0026 Access Policy): Strikte scheiding van rechten. Datascientists mogen niet zomaar bij productie-data waar persoonsgegevens in staan (Privacy-by-Design). 4. Doelmatigheid en Doeltreffendheid Het Principe: Middelen (belastinggeld) moeten effici√´nt worden ingezet en doelen moeten daadwerkelijk bereikt worden. Vertaalslag naar AI: Voorkom verspilling van dure cloud-resources en \"hobby-projecten\" die geen waarde toevoegen. Implementatie: Spec-Driven Design: De Builder Agent dwingt af dat er eerst een doel (spec) is voordat er gebouwd wordt. FinOps: Monitoring van resource-gebruik (via Prometheus/Grafana) en automatische downscaling van ongebruikte pods (KEDA). Hergebruik: Het \"Bouwblokken\" principe voorkomt dat elk team zijn eigen database-oplossing gaat bouwen. 5. Participatie Het Principe: Burgers en belanghebbenden worden betrokken bij besluitvorming. Vertaalslag naar AI: Digitale toegankelijkheid. Implementatie: GeoNode Portal: Maak data en kaarten toegankelijk voor ingelanden, zodat zij zienswijzen kunnen indienen op basis van dezelfde informatie als het waterschap. --- üõ°Ô∏è Borging in de Architectuur Goed bestuur is geen 'sausje', maar zit ingebakken in de code: Als een model niet uitlegbaar is, mag het niet in productie. Als data niet herleidbaar is, faalt de build pipeline. Als de kosten de baten overstijgen, signaleert het systeem dit aan de controller. Door deze principes te codificeren (Policy-as-Code), garandeert Druppie dat innovatie hand in hand gaat met betrouwbaar overheidshandelen."
  },
  {
    "title": "Digitaal Toegankelijk",
    "category": "compliance",
    "path": "compliance/digitaal_toegangkelijk.md",
    "content": "Ontwerp voor digitaal toegankelijkheid üéØ Doel Dit document een samenvatting van de wettelijke verplichtingen voor digitale toegankelijkheid in Nederland, gebaseerd op informatie van digitoegankelijk.nl. --- üìú Samenvatting wetgeving: wat is verplicht? üß† Wat is digitale toegankelijkheid? Digitale toegankelijkheid betekent dat websites, apps en digitale diensten bruikbaar zijn voor iedereen, ook voor mensen met een beperking (zoals visueel, auditief, motorisch of cognitief). üèõÔ∏è Voor wie is het verplicht? Digitale toegankelijkheid is wettelijk verplicht voor alle overheidsorganisaties in Nederland, waaronder: - Gemeenten, provincies en waterschappen - Ministeries en uitvoeringsorganisaties - Zelfstandige bestuursorganen (ZBO‚Äôs) - Overheidswebsites, intranetten, extranetten en mobiele apps üìê Waar moeten zij aan voldoen? - Websites en apps moeten voldoen aan WCAG 2.1 niveau A en AA - Deze eisen zijn vastgelegd in de Europese norm EN 301 549 - Toegankelijkheid moet structureel worden meegenomen in ontwerp, bouw √©n beheer üìÑ Toegankelijkheidsverklaring Elke overheidsorganisatie is verplicht om: - Een toegankelijkheidsverklaring te publiceren - Daarin de status van toegankelijkheid te vermelden (A t/m E) - Eventuele tekortkomingen en verbetermaatregelen te beschrijven - De verklaring actueel te houden (minimaal jaarlijks of bij grote wijzigingen) üè∑Ô∏è Statussen - Status A: voldoet volledig aan de wet (vereiste status) - Status B‚ÄìE: gedeeltelijk of niet voldaan (verbetering verplicht) üá™üá∫ Europees perspectief Vanaf 28 juni 2025 geldt ook de European Accessibility Act (EAA). Deze wet breidt toegankelijkheidseisen uit naar commerci√´le digitale diensten, zoals webshops, apps en online platforms. --- üß© Designing for users on the autistic spectrum ‚úÖ Do - Schrijf in duidelijke, eenvoudige taal - Gebruik rustige, simpele kleuren - Gebruik korte zinnen en opsommingen - Maak knoppen beschrijvend - Bouw simpele en consistente layouts ‚ùå Don‚Äôt - Gebruik geen felle, contrasterende kleuren - Vermijd beeldspraak en uitdrukkingen - Maak geen grote lappen tekst - Gebruik geen vage of onvoorspelbare knoppen - Vermijd complexe en rommelige layouts --- üßë‚Äçü¶Ø Designing for users of screen readers ‚úÖ Do - Beschrijf afbeeldingen en bied transcripts voor video - Volg een lineaire, logische structuur - Structureer content met HTML5 (h1, nav, label, alt) - Ontwerp voor toetsenbordgebruik - Gebruik beschrijvende links en koppen ‚ùå Don‚Äôt - Toon geen informatie alleen in afbeeldingen of video - Verspreid content niet over de hele pagina - Vertrouw niet op tekstgrootte of positie voor structuur - Forceer geen muisgebruik - Gebruik geen nietszeggende links zoals ‚Äúklik hier‚Äù --- üëÅÔ∏è Designing for users with low vision ‚úÖ Do - Gebruik voldoende kleurcontrast en leesbare tekst - Publiceer informatie direct op webpagina‚Äôs - Combineer kleur, vorm en tekst - Houd een logische, lineaire layout aan - Plaats knoppen en meldingen in context ‚ùå Don‚Äôt - Gebruik geen laag contrast of kleine tekst - Verstop informatie niet in downloads - Gebruik kleur niet als enige betekenisdrager - Verspreid content niet over de pagina - Scheid acties niet van hun context --- üìñ Designing for users with dyslexia ‚úÖ Do - Gebruik afbeeldingen en diagrammen ter ondersteuning - Lijn tekst links uit en houd layouts consistent - Overweeg alternatieve formats (audio/video) - Houd content kort, duidelijk en simpel - Laat gebruikers contrast aanpassen ‚ùå Don‚Äôt - Gebruik geen grote blokken zware tekst - Vermijd onderstrepen, cursief en hoofdletters - Dwing gebruikers niet om eerdere info te onthouden - Vertrouw niet op perfecte spelling - Zet niet te veel informatie op √©√©n plek --- ü¶Ω Designing for users with physical or motor disabilities ‚úÖ Do - Maak grote, makkelijk klikbare acties - Geef klikbare elementen voldoende ruimte - Ontwerp voor toetsenbord- of spraakbediening - Houd rekening met mobiel en touchscreen - Bied sneltoetsen aan ‚ùå Don‚Äôt - Vraag geen precisie - Stapel interacties niet op elkaar - Maak geen dynamische content met veel muisbeweging - Gebruik geen korte time-outs - Vermijd veel typen en scrollen --- ü¶ª Designing for users who are deaf or hard of hearing ‚úÖ Do - Schrijf in duidelijke taal - Gebruik ondertiteling of transcripts - Gebruik een logische, lineaire layout - Breek content op met koppen en visuals - Vraag naar voorkeurscommunicatie bij afspraken ‚ùå Don‚Äôt - Gebruik geen moeilijke woorden of beeldspraak - Plaats content niet alleen in audio of video - Vermijd complexe menu‚Äôs - Laat gebruikers geen lange teksten lezen - Maak telefoon niet het enige contactmiddel --- üòü Designing for users with anxiety ‚úÖ Do - Geef gebruikers voldoende tijd - Leg uit wat er na afronding gebeurt - Maak belangrijke informatie duidelijk - Bied ondersteuning tijdens het proces - Laat gebruikers antwoorden controleren ‚ùå Don‚Äôt - Haast gebruikers niet - Laat geen onduidelijkheid over vervol"
  },
  {
    "title": "BIO \u0026 NIS2",
    "category": "compliance",
    "path": "compliance/bio_nis2.md",
    "content": "BIO \u0026 NIS2 Compliance Strategie Druppie is ontworpen om te voldoen aan strikte overheids- en EU-regelgeving. Dit document beschrijft hoe de architectuur concrete invulling geeft aan de Baseline Informatiebeveiliging Overheid (BIO) en de Network and Information Security Directive (NIS2). üá™üá∫ NIS2 (Network and Information Security Directive) De NIS2-richtlijn legt zwaardere eisen op het gebied van cybersecurity, met een focus op zorgplicht, meldplicht en ketenbeveiliging. 1. Zorgplicht (Duty of Care) Organisaties moeten passende maatregelen nemen om risico's te beheersen. Druppie vult dit in via: - Security by Design: De Foundry pipeline blokkeert onveilige code v√≥√≥r deployment. - Zero Trust: Gebruik van Entra Agent ID en Private Endpoints zorgt dat geen enkele component elkaar blind vertrouwt. - Continuous Monitoring: De Compliance Layer voert dagelijkse geautomatiseerde checks uit. 2. Meldplicht (Incident Reporting) Bij een incident moet binnen 24 uur gemeld worden. - Traceability DB: Alle acties (prompts, wijzigingen, toegang) worden onveranderlijk vastgelegd. Dit maakt directe reconstructie van een incident mogelijk (\"Wie deed wat en wanneer?\"). - Automated Alerting: De Policy Engine detecteert afwijkingen (anomalies) en kan direct de CISO notificeren. 3. Supply Chain Security Beveiliging van de toeleveringsketen is cruciaal. - Spec-Driven Agents: Omdat agents \"as-code\" gedefinieerd zijn, is exact bekend welke modellen en tools gebruikt worden. Geen \"Shadow AI\". - SBOM (Software Bill of Materials): Foundry genereert bij elke build een SBOM, zodat kwetsbaarheden in libraries (bijv. Log4j) direct ge√Ødentificeerd kunnen worden. --- üá≥üá± BIO (Baseline Informatiebeveiliging Overheid) De BIO is gebaseerd op ISO 27001/27002 en geldt voor de gehele overheid. Basisbeveiligingsniveaus (BBN) Druppie ondersteunt differentiatie naar BBN-niveau via de Policy Engine. | BIO Concept | Druppie Implementatie | | :--- | :--- | | Identificatie \u0026 Authenticatie | Alle agents en gebruikers authenticeren via Entra ID. MFA is verplicht voor beheerders. | | Autorisatie | RBAC op basis van 'Least Privilege'. Een agent krijgt nooit meer rechten dan nodig voor zijn taak (scoped access). | | Logging \u0026 Controle | De Traceability DB voldoet aan de eisen voor onweerlegbaarheid en bewaring. Logfiles zijn niet aanpasbaar (WORM storage). | | Cryptografie | Alle data-in-transit (TLS 1.3) en data-at-rest (Azure Storage Encryption) is versleuteld. | | Kwetsbaarhedenbeheer | Geautomatiseerde patch-management voor de container runtime en AI-modellen (via Microsoft managed updates). | BIO Mapping Tabel (Voorbeelden) - Control 9.1.1 (Toegangsbeleid): Ge√Ømplementeerd via IAM policy rules. - Control 12.4.1 (Logging): Ge√Ømplementeerd via Traceability DB. - Control 14.2.1 (Veilig ontwikkelen): Ge√Ømplementeerd via Foundry pipelines met SAST/DAST. --- üõ°Ô∏è Praktische Uitvoering Wanneer een nieuwe Agent wordt gedeployed, valideert de Pipeline automatisch: 1. Is de data-classificatie (BBN1/2/3) bekend? 2. Voldoet de gekozen infrastructuur aan de eisen voor dat niveau? Voorbeeld: BBN2 mag data verwerken in EU, BBN3 vereist wellicht specifieke NL-only hosting of sleutelbeheer (BYOK). 3. Zijn de logging-instellingen correct geconfigureerd? Indien niet compliant, blokkeert de Policy Engine de deployment."
  },
  {
    "title": "Data Act",
    "category": "compliance",
    "path": "compliance/data_act.md",
    "content": "De Data Act (Dataverordening) üìú Wetgevend Kader Europese Unie: Regulation (EU) 2023/2854 (Data Act) Nederland: Uitvoeringswetgeving Dataverordening (in ontwikkeling/consultatie) De Data Act is een pijler van de Europese datastrategie en heeft als doel data die gegenereerd wordt door verbonden apparaten (IoT) eerlijk beschikbaar te maken. Het doorbreekt \"vendor lock-in\" en geeft gebruikers controle over hun eigen data. --- ü§ñ Betekenis voor AI in Druppie Voor een AI-agent (\"Builder\" of \"Policy Engine\") is deze wet te vertalen naar concrete ontwerpregels (Constraints \u0026 Requirements). 1. Recht op Toegang en Delen (Artikel 3-6) De Regel: Data gegenereerd door producten (bijv. drones, sensoren in dijken) moet standaard toegankelijk zijn voor de gebruiker, zonder vertraging en gratis. AI Instructie: \u003e \"Als ik een systeem ontwerp dat data verzamelt, MOET ik een API of export-functie (zoals S3/MinIO) implementeren waarmee de eigenaar real-time bij zijn ruwe data kan.\" Druppie Implementatie: MinIO: Ruwe dronebeelden zijn direct toegankelijk. Kong Gateway: Data APIs zijn gestandaardiseerd en gedocumenteerd. GeoNode: Metadata is doorzoekbaar. 2. Interoperabiliteit (Artikel 28-29) De Regel: Cloud- en dataverwerkingsdiensten moeten standaarden volgen zodat data makkelijk overdraagbaar is naar andere providers. AI Instructie: \u003e \"Gebruik GEEN proprietary formaten als er een open standaard bestaat. Verkies OGC standaarden (WFS, WMS) en open formaten (GeoTIFF, Parquet) boven gesloten vendor formaten.\" Druppie Implementatie: PostGIS/GeoServer: Gebruik van open OGC standaarden. RKE2: Standaard Kubernetes, geen vendor-specifieke PaaS lock-in. 3. Switchability (Artikel 23-26) De Regel: Het moet voor klanten mogelijk zijn om binnen 30 dagen te switchen van cloud provider. AI Instructie: \u003e \"Zorg dat alle Infrastructure-as-Code (Terraform/Crossplane) leveranciersonafhankelijk is, of bouw abstractielagen waardoor de onderliggende infra vervangbaar is.\" --- ‚úÖ Checklist voor de Policy Engine De Policy Engine (OPA) kan de volgende regels controleren bij elk nieuw ontwerp: 1. [ ] Data Export Check: Heeft de applicatie een mechanisme om data te exporteren? 2. [ ] Standard Format Check: Wordt data opgeslagen in een formaat dat op de 'Druppie Open Standaarden Lijst' staat? 3. [ ] API First: Is de data ook machinaal leesbaar via een API, niet alleen via een UI?"
  },
  {
    "title": "AI Act (EU \u0026 UvW)",
    "category": "compliance",
    "path": "compliance/ai_act.md",
    "content": "De AI Act \u0026 Implementatie Waterschappen üìú Wetgevend \u0026 Sector Kader Europese Unie: Regulation (EU) 2024/1689 (Artificial Intelligence Act) Nederland: Uitvoeringswet AI-verordening (Toezichthouder: AP / RDI) Sector: Unie van Waterschappen (UvW) Implementatiehandleiding De AI Act is 's werelds eerste alomvattende AI-wetgeving met een risico-gebaseerde aanpak. Voor waterschappen is dit extra relevant omdat zij beheerders zijn van kritieke infrastructuur (dijken, zuiveringen, gemalen). De UvW heeft specifieke handreikingen opgesteld om de abstracte wet te vertalen naar de watersector. --- ü§ñ Risico Classificatie (De Piramide) De wet onderscheidt risiconiveaus. De UvW benadrukt de specifieke context voor waterschappen hierin: 1. Onaanvaardbaar Risico (Verboden) Wet: Social Scoring, Real-time biometrische identificatie in openbare ruimte (door politie), manipulatie van gedrag. Actie: BLOKKEREN. De Policy Engine mag dit nooit goedkeuren. 2. Hoog Risico (Strenge Eisen) Dit is de focus voor Druppie Core. Wet: AI in kritieke infrastructuur, HR-selectie, Kredietwaardigheid. Waterschap Context (UvW): AI die veiligheidscomponenten van waterkeringen of sluizen aanstuurt. AI die beslissingen neemt over waterpeilbeheer (risico op overstroming/droogte). Actie: Vereist Conformiteitsbeoordeling, Human Oversight, Hoogwaardige DataSets, en Logging. 3. Beperkt Risico (Transparantie) Wet: Chatbots (zoals de Druppie Copilot), Deepfakes/GenAI. Actie: Transparantieplicht. De gebruiker moet weten dat hij met een AI praat. (\"Ik ben Druppie, een AI-assistent\"). 4. Minimaal Risico Voorbeelden: Spamfilters, Muskusrat-tellingen (zonder automatische actie). --- üåä De AI Impact Assessment (AIIA) De UvW schrijft voor om v√≥√≥r de start van elk AI-project een AIIA uit te voeren. Dit gaat verder dan een DPIA. 1. Doelbinding: Is het maatschappelijk verantwoord? 2. Dataset Representativiteit: Cruciaal voor water: Is het model getraind op data van zowel extreme 'natte' als 'droge' jaren (bijv. 2018)? Bias: Voorkom dat het model alleen werkt voor scenario's uit het verleden die door klimaatverandering niet meer representatief zijn. 3. Uitlegbaarheid (XAI): Kan een hydroloog begrijpen waarom het model voorstelt de stuw te sluiten? \"Black box\" modellen zijn ongewenst voor kritieke processen. --- üõ†Ô∏è Implementatie in Druppie Hoe borgen we de wet en de UvW richtlijnen in het platform? Stap 1: Intake \u0026 Classificatie (Policy Engine) Wanneer een gebruiker een nieuw project start, activeert de Policy Engine de UvW Template. Check: \"Raakt dit systeem de veiligheid van waterkeringen?\" Ja -\u003e Markeer als Hoog Risico. Activeer \"Four-Eyes Principle\" (Menselijke goedkeuring vereist). Stap 2: Data Validatie \u0026 Versiebeheer (DVC) Om te voldoen aan de eis voor \"Hoogwaardige Datasets\": DVC (Data Versioning): Garandeert dat we altijd kunnen bewijzen op welke dataset is getraind. Automated Checks: De Builder Agent kan controleren of de dataset voldoende spreiding heeft (seizoenen, extremen). Stap 3: Traceability \u0026 Logging (Juridisch Bewijs) Eis: Automatische logging van events gedurende de levenscyclus (Artikel 12). Oplossing: De Traceability DB (Tempo/Loki). Elke stap van \"Input Foto\" tot \"Beslissing: Schade\" wordt onwijzigbaar vastgelegd. Dit is cruciaal voor de bestuurlijke verantwoording. Stap 4: Menselijk Toezicht (Human-in-the-Loop) Eis: Een mens moet kunnen ingrijpen (Artikel 14). Oplossing: Voor autonome systemen (gemalen/sluizen) bouwen we altijd een Kill Switch. De operator kan de AI overrulen via het SCADA dashboard. Stap 5: Continuous Monitoring (Model Drift) Een model veroudert. Grafana: Monitor Model Drift. \"Wijkt de voorspelling steeds vaker af van de peilbuis-meting?\" Policy: Verplicht jaarlijkse herijking/hertraining. --- ‚úÖ Checklist voor de Architect / Policy Engine 1. [ ] Risk Assessment: Is de UvW risico-classificatie uitgevoerd? 2. [ ] Human-in-the-Loop: Is er voor Hoog Risico systemen een menselijke goedkeuringsstap (of noodstop) ingebouwd? 3. [ ] Data Quality: Is de dataset representatief voor (toekomstige) klimaattoestanden? 4. [ ] Audit Trail: Worden alle inputs/outputs gelogd in de Traceability DB? 5. [ ] Transparency: Maakt de interface duidelijk dat het een AI is?"
  },
  {
    "title": "AI Register (Algoritmeregister)",
    "category": "compliance",
    "path": "compliance/ai_register.md",
    "content": "Het AI Register (Algoritmeregister) üìò Wat is het AI Register? Overheidsorganisaties, waaronder waterschappen, zijn verplicht transparant te zijn over de inzet van algoritmes en AI. Dit is verankerd in de AI Act (Artikel 60: EU Database voor Hoog Risico AI) en de Nederlandse richtlijn voor het Algoritmeregister (algoritmeregister.overheid.nl). Het register fungeert als de \"publieke bijsluiter\" van een AI-systeem. Het stelt burgers, journalisten en toezichthouders in staat om te controleren welke systemen impact hebben op hun leven of leefomgeving. --- üìã Wat staat er in? (Het Schema) Het register bevat niet de broncode, maar wel de metadata die de werking en risico's beschrijven. Binnen Druppie baseren we dit op de 'Standaard voor Algoritme-beschrijvingen'. Kerngegevens 1. Naam \u0026 Eigenaar: Wie is verantwoordelijk? (bijv. \"Waterschap X, afdeling Waterkeringen\"). 2. Doel: Waarom is dit systeem gebouwd? (bijv. \"Vroegtijdig detecteren van graverij door muskusratten om dijkdoorbraak te voorkomen\"). 3. Werking: Hoe werkt het technisch? (bijv. \"Computer Vision model getraind op dronebeelden\"). Risico \u0026 Impact 4. Risicoclassificatie: Volgens de AI Act (Laag/Hoog/Verboden). 5. Impact: Wat is het gevolg van een fout? (bijv. \"Onterechte inzet van muskusrattenbestrijder\" of \"Gemiste kadebreuk\"). 6. Juridische Grondslag: Op basis van welke wettaak handelen we? (Waterwet). Data \u0026 Toezicht 7. Data: Op welke data is het getraind? (Verwijzing naar DVC dataset versie). 8. Menselijk Toezicht: Hoe is de Human-in-the-Loop geregeld? (bijv. \"Bestrijder valideert elke detectie v√≤√≤r actie\"). --- üõ†Ô∏è Hoe te vullen? (Automated Governance) In traditionele organisaties is het register vaak een verouderde Excel-sheet. In Druppie is het registeren geautomatiseerd en verplicht. Stap 1: 'Register-as-Code' Bij elk project hoort een algorithm.yaml bestand in de Git repository. De Builder Agent genereert de eerste opzet op basis van de interactie met de gebruiker. Voorbeeld algorithm.yaml: yaml metadata: name: \"Muskusrat Detectie V2\" owner: \"Afd. Keringen\" status: \"In Productie\" legal: ground: \"Waterwet Art. 5.1\" risk_class: \"Hoog\" Critical Infra technical: model_type: \"YOLOv8\" training_data: \"dvc://datasets/drone-2025-v1\" human_oversight: role: \"Schadebeheerder\" method: \"Handmatige validatie via GeoNode\" Stap 2: Validatie door Policy Engine Tijdens de deployment (CI/CD) checkt de Policy Engine: [ ] Is algorithm.yaml aanwezig? [ ] Zijn alle verplichte velden ingevuld? [ ] Klopt de 'training_data' link met de werkelijke DVC hash? Zo niet -\u003e Deployment Failed. Stap 3: Publicatie Bij een succesvolle release naar Productie, pusht de pipeline de metadata automatisch naar: 1. Het Interne Register (in Archi/GeoNode). 2. Het Publieke Register (via API koppeling met algoritmeregister.overheid.nl). --- üöÄ Hoe te gebruiken? 1. Voor de Burger: Via de website van het Waterschap kan men zoeken in het register. \"Welke AI wordt gebruikt in mijn polder?\" 2. Voor de Toezichthouder (AP): Bij een audit hoeven we niets handmatig op te zoeken. Het register is de \"Single Source of Truth\", direct gekoppeld aan de draaiende techniek. 3. Voor de Data Scientist: Ziet direct of zijn model correct geregistreerd staat en wie de 'Human-in-the-loop' is."
  },
  {
    "title": "IAM",
    "category": "compliance",
    "path": "compliance/iam.md",
    "content": "Identity \u0026 Access Management (IAM) voor AI üéØ Doelstelling In een AI-gedreven architectuur is Identity \u0026 Access Management (IAM) niet slechts een \"poortwachter\" voor gebruikers, maar een fundamenteel fundament voor veiligheid. Waar traditionele software deterministisch is, zijn AI-agents autonoom en onvoorspelbaar. Waarom is IAM cruciaal voor AI? 1. Autonomie beperken: Een AI-agent die zelfstandig taken uitvoert, moet een digitale identiteit hebben om afgerekend te kunnen worden op zijn daden (\"Wie deed dit?\"). 2. Data Exfiltratie voorkomen: Een agent mag nooit toegang hebben tot √°lle data. Door strikte scoping (RBAC) voorkomen we dat een agent gevoelige HR-data lekt aan een gebruiker die daar geen recht op heeft. 3. Chain of Trust: In een keten van agents (Agent A roept Agent B aan) moet elke stap geauthenticeerd zijn (Zero Trust). --- üîë Kernconcepten in Druppie Druppie maakt gebruik van Microsoft Entra ID (voorheen Azure AD) als centrale identity provider. 1. Entra Agent ID (Machine Identity) Dit is een relatief nieuw concept. In plaats van generieke \"Service Accounts\" of \"API Keys\" die kunnen lekken, krijgt elke agent in Druppie (via de Foundry factory) een eigen Entra Agent ID. Cloud Native: Geen wachtwoorden om te roteren (Managed Identity). Traceerbaar: Elke logregel in de audit database verwijst naar deze unieke ID. Hardened: Kan niet inloggen interactief (behalve via specifieke OBO flows). 2. On-Behalf-Of (OBO) Flow Wanneer een gebruiker (bijv. \"Jan\") aan de Druppie Copilot vraagt om een bestand te lezen, mag de AI dit all√©√©n doen als Jan daar recht op heeft. Context Propagatie: Het token van Jan wordt doorgegeven aan de Agent. Security Trimming: De Agent \"ziet\" alleen wat Jan ook zou zien. Dit voorkomt dat de AI een \"backdoor\" wordt naar gevoelige data. --- üõ°Ô∏è Beveiligingsmodel Zero Trust voor Agents Het principe \"Never trust, always verify\" geldt ook voor interne componenten. Agent-to-Agent Auth: Als de \"Router Agent\" de \"Finance Agent\" aanroept, controleert de Finance Agent het token van de Router. Just-in-Time Access: Rechten worden waar mogelijk tijdelijk verleend. Granulaire RBAC (Role Based Access Control) We defini√´ren specifieke rollen voor agents, niet voor computers. | Rol | Omschrijving | Voorbeeld | | :--- | :--- | :--- | | AI.Reader | Mag data indexeren voor RAG (alleen lezen). | Knowledge Bot | | AI.Builder | Mag nieuwe infrastructuur aanmaken. | Builder Agent | | AI.Executor | Mag namens gebruikers acties uitvoeren in ERP. | HR Agent | --- üöÄ Implementatie in de Architectuur 1. Creatie Wanneer een nieuwe agent wordt gedefinieerd in de Agent Factory, wordt automatisch: 1. Een User Managed Identity aangemaakt in Azure. 2. Deze identiteit gekoppeld aan de Agent Service. 3. Specifieke rechten (Scopes) toegekend op de doelsystemen (bijv. Storage Blob Data Reader op st-finance-data). 2. Runtime Tijdens uitvoering: 1. De Agent haalt een token op bij de lokale Identity Endpoint (binnen de container/service). 2. Dit token wordt als Authorization: Bearer \u003ctoken\u003e meegestuurd naar tools en API's. 3. De ontvangende API valideert het token tegen Entra ID. --- üîó Relaties Ondersteunt: Compliance Overview en BIO4 \u0026 NIS2. Wordt gebruikt door: Druppie UI (voor inloggen) en Foundry (voor provisioning)."
  },
  {
    "title": "Overview",
    "category": "mcp",
    "path": "mcp/overview.md",
    "content": "MCP Catalogus Overview üìö Wat is dit? De MCP Catalogus is een gecureerde lijst van Model Context Protocol (MCP) servers die beschikbaar en goedgekeurd zijn voor gebruik binnen het Druppie platform. üéØ Doel Het doel van deze catalogus is om ontwikkelaars en architecten snel inzicht te geven in welke integraties \"out-of-the-box\" beschikbaar zijn. Dit voorkomt dat we het wiel opnieuw uitvinden en zorgt voor standaardisatie. üèóÔ∏è Categorie√´n Microsoft \u0026 Azure MCP servers die specifiek zijn ontworpen voor het Microsoft ecosysteem. Use Case: Beheer van Azure resources, toegang tot Office 365 data, integratie met Copilot en Azure AI. Security: Maakt zwaar gebruik van Entra ID (Managed Identities) voor authenticatie. Open Source \u0026 Generiek Breed inzetbare, community-driven of standaard infrastructuur servers. Use Case: Database toegang (Postgres), Git operaties, bestandsmanipulatie, web browsing. Flexibiliteit: Vaak eenvoudig in te zetten als container zonder zware dependencies. üîÑ Hoe een nieuwe MCP server toevoegen? 1. Selectie: Kies een server uit de offici√´le MCP lijst of ontwikkel een eigen MCP Host. 2. Validatie: Controleer of de server voldoet aan de security eisen (geen hardcoded secrets, containerized). 3. Registratie: Voeg de definitie toe aan een van de bovenstaande Markdown bestanden. 4. Deployment: Rol de server uit op het Kubernetes cluster."
  },
  {
    "title": "Microsoft \u0026 Azure",
    "category": "mcp",
    "path": "mcp/microsoft.md",
    "content": "Microsoft \u0026 Azure MCP Servers Deze lijst bevat MCP servers die integreren met het Microsoft ecosysteem, specifiek gericht op Azure en Office 365, geschikt voor gebruik binnen Druppie. ‚òÅÔ∏è Azure Beheer \u0026 DevOps 1. Azure Resource Manager (ARM) Beschrijving: Biedt toegang tot het lezen en beheren van Azure resources via de ARM API. Capabilities: resources, prompts Tools: list_resources, get_resource_metrics, restart_vm Bron/Repo: github.com/microsoft/mcp-azure-arm (Hypothetisch/Custom implementation) 2. Azure DevOps Beschrijving: Interactie met Azure Boards (work items) en Pipelines. Capabilities: tools Tools: get_work_item, create_bug, list_pipelines Status: In ontwikkeling voor Druppie. üè¢ Productivity (M365) 3. Microsoft Graph Beschrijving: De gateway naar data in Microsoft 365 (Email, Calendar, Teams, SharePoint). Capabilities: resources, tools Tools: search_sharepoint, get_calendar_events, send_teams_message Security: Vereist specifieke Entra ID scopes (Files.Read, Calendars.Read). üß† AI \u0026 Data 4. Azure AI Search (Knowledge Base) Beschrijving: Verbindt de RAG (Retrieval Augmented Generation) kennisbank aan het model via MCP. Capabilities: resources (leest documenten als resources) Beschikbaarheid: Ge√Øntegreerd in het Knowledge Bot bouwblok. 5. Microsoft Copilot (M365) Agent Beschrijving: Stelt Druppie in staat om te praten met de bestaande Copilot agents binnen de tenant. Hierdoor kan Druppie vragen stellen aan Copilot (\"Wat is de samenvatting van deze meeting?\") of acties delegeren. Capabilities: prompts (handoff), tools (invoke agent) Integration: Gebruikt de Copilot Studio extensies framework."
  },
  {
    "title": "Open Source Tools",
    "category": "mcp",
    "path": "mcp/opensource.md",
    "content": "Open Source \u0026 Generieke MCP Servers Een verzameling van breed inzetbare, open-source MCP servers die direct als container (docker pull) ingezet kunnen worden binnen het Druppie cluster. üóÑÔ∏è Data \u0026 Storage 1. PostgreSQL (Database) Repo: github.com/modelcontextprotocol/servers/tree/main/src/postgres Beschrijving: Geeft de AI veilige, read-only (of gecontroleerde write) toegang tot databases. Tools: query_database, get_schema Gebruik in Druppie: Zie Database Bouwblok. 2. FileSystem (Lokaal/Shared) Repo: github.com/modelcontextprotocol/servers/tree/main/src/filesystem Beschrijving: Toegang tot specifieke mappen op een Persistent Volume. Handig voor het lezen van logs of rapporten. Configuratie: Draait als sidecar of met een shared volume mount. 3. SQLite Repo: github.com/modelcontextprotocol/servers/tree/main/src/sqlite Beschrijving: Lichtgewicht database toegang, ideaal voor tijdelijke analyse agents. üõ†Ô∏è Development Tools 4. Git Repo: github.com/modelcontextprotocol/servers/tree/main/src/git Beschrijving: Stelt de AI in staat om code te lezen, diffs te maken en branches te beheren. Integratie: Werkt samen met onze Gitea instantie. 5. GitHub / GitLab Repo: github.com/modelcontextprotocol/servers/tree/main/src/github Beschrijving: Beheer van Issues, PRs en Releases. Tools: create_issue, merge_pr, search_code üåê Web \u0026 Search 6. Puppeteer / Playwright (Web Browser) Repo: github.com/modelcontextprotocol/servers (community) Beschrijving: Stelt de AI in staat om websites te bezoeken, screenshots te maken en content te scrapen (bijv. voor onderzoek). Security: Draait altijd in een ge√Øsoleerde, tijdelijke container (\"Sandbox\"). 7. Brave Search Repo: github.com/modelcontextprotocol/servers/tree/main/src/brave-search Beschrijving: Uitvoeren van web-zoekopdrachten via de Brave Search API (privacy-vriendelijk). üöÄ Advanced Capabilities (AI Stack Upgrade) 8. Graphiti (Temporal Knowledge Graph) Repo: getzep/graphiti Beschrijving: Voegt een dynamisch geheugen toe aan de AI. Slaat entiteiten en relaties op in een grafiek die verandert in de tijd (Temporal). Use Case: Langlopende context onthouden van projectbeslissingen en relaties tussen stakeholders. 9. Opik (Observability) Repo: comet-ml/opik Beschrijving: Observability laag specifiek voor LLM-applicaties. Traceert latency, kosten en de \"gedachtegang\" (chains) van de AI. Use Case: Debuggen waarom een Agent een bepaalde keuze heeft gemaakt in de Planner. 10. Jupyter MCP (Interactive Notebooks) Repo: qhdwight/jupyter-mcp-server Beschrijving: Laat de AI direct code uitvoeren, plotten en analyseren in Jupyter Notebooks. Use Case: Data Science taken en het visualiseren van metrics (bijv. drone vlucht logs) zonder code te hoeven deployen."
  },
  {
    "title": "Web Design",
    "category": "mcp",
    "path": "mcp/shadcn.md",
    "content": "Shadcn UI Documentation Official documentation for Shadcn UI, a collection of re-usable components built with Radix UI and Tailwind CSS. This MCP server provides access to installation guides and component references."
  },
  {
    "title": "Overview",
    "category": "design",
    "path": "design/overview.md",
    "content": "Ontwerpen Overview Dit is de centrale locatie voor functionele en technische ontwerpen van specifieke oplossingen en applicaties die met Druppie zijn gebouwd. Het ontwerp van het platform splitst zich in twee hoofdfases: de Build Plane (hoe we bouwen) en de Runtime (waar we draaien). üìÇ Structuur Hier worden ontwerpen opgeslagen die door de Specificatie Experts en Architecten zijn opgesteld. Algemene Ontwerp: Basis informatie voor de druppie ontwerpen. AI Ontwerp (AI): Specificaties voor Agentic Workflows en LLM interacties. Architectuur Ontwerp (ARCH): High-level patronen en strategische keuzes. Technisch Ontwerp (TO): Hoe wordt het gebouwd? (Componenten, Data Model, API Specs) Functioneel Ontwerp (FO): Wat moet het systeem doen? (User Stories, Flowcharts) üè≠ Build Plane: De AI-Fabriek De Build Plane is de \"fabriek\" die code en data transformeert naar draaiende software. In Druppie is dit proces Spec-Driven: \u003e Een AI-agent (de Builder Agent) voert taken uit op basis van strikte specificaties, niet op basis van ad-hoc commando's. Kernprincipes 1. Consistentie: Code wordt altijd op dezelfde manier gebouwd, getest en gescand. 2. Traceerbaarheid: Van elke build is bekend wie het startte, welke code erin zit (SBOM), en welke tests er zijn gedaan. 3. Security: Vulnerability scans zijn verplichte \"Gates\". Code met kritieke gaten mag de runtime niet bereiken. Componenten Builder Agent: De AI-orkestrator van het bouwproces. Foundry: De ontwikkelomgeving en tooling stack. üöÄ Runtime: De Motor De Runtime is waar de applicaties daadwerkelijk leven. Voor Druppie is dit een Kubernetes-omgeving geoptimaliseerd voor AI-workloads. Kernprincipes GitOps: De staat van de runtime wordt bepaald door de configuratie in Git. Geen handmatige wijzigingen op de servers (zie Git). Dynamic Slots: AI-agents krijgen tijdelijke, ge√Øsoleerde ruimtes om taken uit te voeren (zie Dynamic Slot). Strict Access: Toegang wordt geregeld via RBAC, zodat mensen en agents alleen bij data mogen die ze nodig hebben. Componenten Runtime Implementation: Details over de Kubernetes opzet. MCP Interface: Hoe agents veilig externe tools aanroepen. üìù Nieuw Ontwerp Toevoegen 1. Maak een nieuwe map/markdown bestand voor jouw project in design/. 2. Neem de standaard hoofdstukken op: Doelstelling Architecturele Keuzes (verwijzing naar Bouwblokken) Data Flow Security \u0026 Compliance"
  },
  {
    "title": "Bouwblok Definities",
    "category": "design",
    "path": "design/bouwblok_definities.md",
    "content": "Bouwblok Definities (Registry) üéØ Doelstelling De Bouwblok Definities vormen de catalogus en metadata-laag van het platform. Om de AI (Druppie Core) in staat te stellen zichzelf samen te stellen en de juiste tools te kiezen, moet er een gestructureerde definitie zijn van alle beschikbare capabilities, skills, en services. Dit is de \"telefoongids\" en \"handleiding\" voor de AI. üìã Functionele Specificaties 1. Spec-Driven Agent Creatie (Agent-as-Code) - Declaratieve Definities: Capabilities en Agents worden gedefinieerd in YAML/JSON schema's (zie research). - Inhoud Definitie: Bevat Model config, Instructies (Prompts), Tools (OpenAPI) en Governance metadata (Owner, Cost Center). - Versiebeheer: Alle definities worden opgeslagen in Git voor auditability en rollback mogelijkheden. 2. Agent Registry - Central Repository: Een database (Cosmos DB) die fungeert als \"Telefoonboek\" voor de Router Agent. - Interface Beschrijving: Bevat technische specs (OpenAPI) zodat de Router weet hoe een Spoke aan te roepen is. üîß Technische Requirements - Standaard Formaat: Gebruikt open standaarden zoals OpenAPI (Swagger) of Model Context Protocol (MCP) definities. - Extensible: Nieuwe definities moeten makkelijk toegevoegd kunnen worden zonder herstart van de Core (Plugin architectuur). üîí Security \u0026 Compliance - Scoped Access: Definities bevatten metadata over vereiste permissies (scopes), zodat de Orchestrator vooraf checks kan doen. üîå Interacties | Wie | Actie | Doel | | :--- | :--- | :--- | | Druppie Core Planner | Query Registry | \"Welke tool kan e-mails sturen?\" | | Developer | Register Tool | Nieuwe capability toevoegen | üèóÔ∏è Relaties tot andere blokken - Geraadpleegd door: Druppie Core. - Bevat definities voor: Build Plane, Runtime en alle Skills."
  },
  {
    "title": "Build Plane",
    "category": "design",
    "path": "design/build_plane.md",
    "content": "Build Plane üéØ Doelstelling Dit bouwblok definieert de interface naar de externe Build Plane. De Build Plane zelf is de \"fabriek\" die code produceert en verifieert (zie de gedetailleerde Build Plane documentatie). Vanuit het perspectief van Druppie Core is dit bouwblok de abstractie die toegang geeft tot die fabriek. üìã Functionele Specificaties 1. Job Submission - Spec-in, Artifact-out: Accepteert een declaratieve BuildSpec als input. - Fire \u0026 Forget: Start asynchrone build taken en geeft een Job ID terug. 2. Status Monitoring - Polling / Webhooks: Mechanisme om de voortgang van de build (Compiling... Testing... Scanning...) terug te koppelen aan de Orchestrator en UI. - Log Streaming: Live logs doorgeven bij failures. 3. Artifact Handover - Zorgt dat geproduceerde images en packages geregistreerd worden en beschikbaar zijn voor de Runtime. üèóÔ∏è Relaties - Verwijst naar: Build Plane Domein. - Wordt gebruikt door: Druppie Core wanneer code gegenereerd of gebouwd moet worden."
  },
  {
    "title": "Compliance Layer",
    "category": "design",
    "path": "design/compliance_layer.md",
    "content": "Compliance Layer Definitie üéØ Doelstelling De Compliance Layer is het overkoepelende kader dat niet zozeer \"iets doet\" (zoals code bouwen), maar \"overal naar kijkt\". Het definieert de standaarden en audit-mechanismen. Zie Compliance Domein voor de diepte-uitwerking. üìã Functionele Specificaties 1. Continuous Audit - Aggregatie: Verzamelt signalen uit Policy Engine, Traceability DB, en Runtime logs. - Reporting: Genereert rapportages voor auditors (bijv. \"Lijst van alle code changes die zonder 4-eyes principle naar prod zijn gegaan\"). 2. Machine Identity (Agent ID) - Entra Agent ID: Elke AI-agent krijgt een unieke identiteit in Entra ID (voorheen Azure AD). - Granulaire Rechten: Permissies worden toegekend aan de specifieke agent (bijv. \"Finance Agent\" mag alleen bij de Finance Sharepoint). - Managed Identity: Gebruik van Managed Identities voor veilige service-to-service communicatie zonder secrets. üèóÔ∏è Relaties - Verwijst naar: Compliance Domein. - Integreert met: Alle andere bouwblokken (elke actie genereert compliance data)."
  },
  {
    "title": "Knowledge Bot",
    "category": "design",
    "path": "design/knowledge_bot.md",
    "content": "Knowledge Bot (RAG Agent) üéØ Doelstelling De Knowledge Bot is een gespecialiseerd bouwblok voor informatieontsluiting. Het stelt gebruikers in staat om via natuurlijke taal vragen te stellen over grote hoeveelheden ongestructureerde data (PDFs, documentatie, tickets) die specifiek zijn voor de organisatie. Het implementeert het Retrieval-Augmented Generation (RAG) patroon. üìã Functionele Specificaties 1. Ingest \u0026 Indexing - Multi-format Support: Moet tekst kunnen extraheren uit PDF, Word, Markdown, HTML, etc. - Chunking Strategy: Slim opbreken van tekst in behapbare stukken met behoud van context. - Continuous Update: Index moet up-to-date blijven als brondocumenten wijzigen. 2. Retrieval \u0026 Synthesis - Semantisch Zoeken: Zoeken op betekenis, niet alleen trefwoorden (Vector Search). - Bronvermelding: De bot MOET bij elk antwoord verwijzen naar de bron (pagina/document) waar de info vandaan komt (traceerbaarheid). - Hallucinatie Preventie: Instructies om alleen te antwoorden op basis van de gevonden context (\"Weet ik niet\" is een geldig antwoord). üîß Technische Requirements - Vector Database: Gebruik van een geoptimaliseerde DB (bijv. Qdrant, Pinecone, pgvector). - Embedding Models: Gebruik van effici√´nte modellen voor vectorisatie. - Hybrid Search: Combinatie van keyword search (BM25) en vector search voor beste resultaten. üîí Security \u0026 Compliance - Document Level Security: De bot mag alleen resultaten tonen uit documenten waar de gebruiker leesrechten op heeft (ACL filtering in de zoekopdracht). - Data Residency: Documenten en vectoren blijven binnen de vertrouwde zone. üîå Interacties | Input | Output | | :--- | :--- | | Vraag (\"Hoe reset ik mijn wachtwoord?\") | Antwoord + Referenties ([Handleiding.pdf, p.3]) | | Nieuw Document (Upload) | Bevestiging (Ge√Øndexeerd) | üèóÔ∏è Relaties tot andere blokken - Aangestuurd door: Druppie Core (als de intentie \"Informational\" is). - Maakt gebruik van: Bouwblok Definities voor configuratie."
  },
  {
    "title": "Mens in de Loop",
    "category": "design",
    "path": "design/mens_in_de_loop.md",
    "content": "Mens in de Loop (Human in the Loop) üéØ Doelstelling Het bouwblok Mens in de Loop (HITL) integreert menselijke intelligentie en verantwoordelijkheid in het geautomatiseerde proces. Hoewel AI veel kan automatiseren, vereisen kritieke beslissingen, ethische afwegingen en hoge risico's altijd menselijke validatie. Dit blok voorkomt \"AI hallucinations\" die leiden tot productieschade. üìã Functionele Specificaties 1. Goedkeurings Workflows - Critical Gating: Blokkeert uitvoering bij specifieke triggers (bijv. deployments naar productie, verwijderen van data, kosten \u003e ‚Ç¨X). - Escalatie: Kan verzoeken escaleren naar specifieke rollen (bijv. CISO voor security, PO voor features). 2. Contextuele Validatie - Diff Review: Toont de gebruiker precies wat er gaat veranderen (bijv. Terraform plan, Code diff). - Explanation: De AI moet uitleggen waarom hij deze actie wil doen, zodat de mens een ge√Ønformeerde keuze kan maken. 3. Feedback Loop - Korrektie: De mens moet niet alleen Ja/Nee kunnen zeggen, maar ook sturend commentaar kunnen geven (\"Nee, doe dit opnieuw maar gebruik bibliotheek X\"). - Learning: De feedback van de mens wordt (geanonimiseerd) gebruikt om toekomstige prompts te verbeteren. üîß Technische Requirements - Asynchroon: Een goedkeuringsverzoek kan minuten of uren openstaan; het systeem mag niet time-outen. - Multi-channel: Notificaties kunnen via Chat, Email, of ITSM tools (ServiceNow/Jira) verlopen. üîí Security \u0026 Compliance - Non-repudiation: Het moet onweerlegbaar zijn WIE de goedkeuring heeft gegeven. - Segregation of Duties: De persoon die de code aanvraagt mag (in sommige gevallen) niet dezelfde zijn die goedkeurt. üîå Interacties | Trigger | Actie | Output | | :--- | :--- | :--- | | Policy Violation (Requires Approval) | Stuur notificatie + Context | Wachtstatus in Core | | User Action (Approve/Reject) | Verwerk beslissing | Core hervat of stopt | üèóÔ∏è Relaties tot andere blokken - Geactiveerd door: Policy Engine. - Communiceert via: Druppie UI. - Gelogd in: Traceability DB."
  },
  {
    "title": "Traceability DB",
    "category": "design",
    "path": "design/traceability_db.md",
    "content": "Traceability DB (Audit Log) üéØ Doelstelling De Traceability DB fungeert als de onveranderlijke \"zwarte doos\" (flight recorder) van het Druppie platform. Het doel is om volledige verantwoording en reproduceerbaarheid te garanderen. In een AI-gedreven systeem is het cruciaal om precies te kunnen reconstrueren waarom een AI een bepaalde beslissing nam en volgens welke instructies code is gegenereerd. üìã Functionele Specificaties 1. Granulaire Logging - Prompts \u0026 Responses: Slaat exact op wat er als input naar de LLM ging en wat er terugkwam. - Decision Trees: Logt de redenering (Thought Process) van de planner. - Code Changes: Logt diffs van gegenereerde code. - Approval Events: Logt wie, wanneer, en waarom goedkeuring gaf (inclusief digitale handtekening). 2. Zoekbaarheid \u0026 Analyse - Correlatie ID's: Koppelt alle logs van √©√©n sessie/verzoek aan elkaar (TraceID). - Niet-technische weergave: Moet data zo kunnen structureren dat auditors (niet-developers) het kunnen lezen. 3. Integriteit - Immutability: Eenmaal geschreven logs mogen NOOIT gewijzigd of verwijderd worden (Write Once, Read Many). - Retention: Data moet bewaard blijven conform wettelijke termijnen (bijv. 7 jaar). üîß Technische Requirements - High Throughput: Moet grote stromen logdata aankunnen zonder de Core te vertragen (async writing). - Storage Tiering: Hot storage voor recente logs, Cold storage (Azure Blob/S3 Glacier) voor archief. - Time Series: Geoptimaliseerd voor tijdreeks-data. üîí Security \u0026 Compliance - Encryption at Rest \u0026 in Transit: Alle data is versleuteld. - Access Control: Alleen Security Officers en Auditors hebben leesrechten. Niemand heeft schrijfrechten (behalve het systeem zelf). - Anomaly Detection: Activeert alerts bij verdachte patronen (bijv. massale export van logs). üîå Interacties De DB is passief en ontvangt data van alle componenten. | Bron | Type Data | Frequentie | | :--- | :--- | :--- | | Druppie Core | Prompts, Tokens, Plans | Hoog | | Policy Engine | Checks, Violations | Gemiddeld | | Mens in de Loop | Approvals, Rejections | Laag | üèóÔ∏è Relaties tot andere blokken - Ondersteunt: Compliance Layer (levert bewijslast)."
  },
  {
    "title": "MCP Server Host",
    "category": "design",
    "path": "design/mcp_server.md",
    "content": "MCP Server Host (Model Context Protocol) üéØ Selectie: Standardized MCP Container Voor het ontsluiten van tools en data naar de AI-modellen gebruiken we het Model Context Protocol (MCP). We implementeren dit als een gestandaardiseerde container-architectuur (de \"MCP Host\") op basis van de offici√´le TypeScript of Python SDK's. üí° Onderbouwing van de Keuze Waarom kiezen we voor losse MCP Servers in plaats van alle tools in de Core te bakken? 1. Isolatie \u0026 Security: Elke set van tools draait in zijn eigen Pod (bijv. mcp-database-tools of mcp-weather-tools). We kunnen per server exact instellen waar hij bij mag. De mcp-weather pod mag wel naar internet (api.weather.com), maar niet naar de interne database. De mcp-database pod mag wel naar de DB, maar niet naar internet. Dit is Security by Design. 2. Taal Agnostisch: Een data-scientist kan een tool schrijven in Python (met Pandas/Numpy), terwijl een web-developer een tool schrijft in TypeScript. MCP abstraheert dit weg; voor de AI is het protocol identiek. 3. Schaalbaarheid: Als de \"Video Processing Tool\" veel CPU nodig heeft, schalen we alleen die specifieke container op, zonder de rest van het platform te belasten. 4. Standaardisatie: Door het MCP protocol te volgen, kunnen we in de toekomst ook externe agents of lokale clients (zoals Claude Desktop) laten verbinden met onze tools. --- üõ†Ô∏è Installatie Een MCP server is een eenvoudige webserver (meestal via Server-Sent Events - SSE). We rollen deze uit met een standaard Kubernetes Deployment. 1. Base Image Druppie biedt standaard base frames voor developers: ghcr.io/waterschap/druppie-mcp-node:latest ghcr.io/waterschap/druppie-mcp-python:latest 2. Deployment Manifest Een voorbeeld deployment voor een \"Weer Service\". yaml apiVersion: apps/v1 kind: Deployment metadata: name: mcp-weather spec: replicas: 2 selector: matchLabels: app: mcp-weather template: metadata: labels: app: mcp-weather spec: containers: - name: server image: my-registry/mcp-weather:v1 env: - name: API_KEY valueFrom: secretKeyRef: name: weather-api-key key: key ports: - containerPort: 3000 Standaard SSE poort We ontsluiten dit intern via een Service: yaml apiVersion: v1 kind: Service metadata: name: mcp-weather-svc spec: selector: app: mcp-weather ports: - port: 80 targetPort: 3000 --- üöÄ Gebruik (Implementatie) De Builder Agent kan de code genereren om een tool te maken. Hier is een voorbeeld in TypeScript. 1. Code (index.ts) typescript import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\"; import { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\"; import { SSEServerTransport } from \"@modelcontextprotocol/sdk/server/sse.js\"; // Maak de server const server = new McpServer({ name: \"weather-server\", version: \"1.0.0\", }); // Definieer een Tool server.tool( \"get_forecast\", { city: z.string(), days: z.number().max(5) }, async ({ city, days }) =\u003e { // Voer de logica uit (API call naar externe weerdienst) const forecast = await fetchWeather(city, days); return { content: [{ type: \"text\", text: JSON.stringify(forecast) }], }; } ); // Start de server (SSE mode voor Kubernetes) const transport = new SSEServerTransport(\"/sse\", \"/messages\"); server.connect(transport); 2. Registratie Om de tool beschikbaar te maken, voegen we hem toe aan de Bouwblok Definities (Registry). json { \"name\": \"Weer Tools\", \"type\": \"mcp\", \"endpoint\": \"http://mcp-weather-svc.default.svc.cluster.local/sse\" } üîÑ Integratie in Druppie 1. Discovery: Bij het opstarten (of runtime) scant Druppie Core de registry. 2. Connection: De Core maakt een SSE verbinding met http://mcp-weather-svc.... 3. Tool Listing: De MCP server stuurt een lijst terug: [\"get_forecast\"]. 4. Execution: Gebruiker vraagt: \"Gaat het morgen regenen in Zwolle?\" Planner kiest tool get_forecast. Core stuurt JSON commando naar de MCP pod. MCP pod voert code uit en stuurt antwoord terug."
  },
  {
    "title": "Policy Engine",
    "category": "design",
    "path": "design/policy_engine.md",
    "content": "Policy Engine üéØ Doelstelling De Policy Engine is de bewaker van de integriteit, veiligheid en compliance van het platform. Dit blok zorgt ervoor dat geen enkele geautomatiseerde actie in strijd is met bedrijfsregels, wetgeving of ethische kaders. Het is de \"nee, tenzij\"-laag die elk plan van de Orchestrator valideert. üìã Functionele Specificaties 1. Actie Validatie (Pre-Execution Guardrails) - Real-time Controle: Elke actie of tool-aanroep die de Orchestrator wil doen, moet eerst langs de Policy Engine. - Contextuele Regels: Regels kunnen afhangen van context (bijv. \"Geen productie-deployments op vrijdagmiddag\", \"Alleen Seniors mogen databases droppen\"). 2. Risico Classificatie - Risk Scoring: Kent een risicoscore toe aan een actie (Low, Medium, High, Critical). - Threshold Management: Bepaalt op basis van score of een actie mag doorgaan, geblokkeerd wordt, of menselijke goedkeuring vereist. 3. Policy-as-Code - Declaratieve Regels: Policies worden gedefinieerd in code (bijv. OPA/Rego) en niet in ondoorzichtige logica. - Versiebeheer: Wijzigingen in policies volgen een strikt change proces via Git. üîß Technische Requirements - Performance: Validatie moet extreem snel zijn (\u003c 50ms) om de gebruikerservaring niet te vertragen. - Fail-Closed: Als de Policy Engine niet bereikbaar is of faalt, moeten alle risicovolle acties worden geblokkeerd. - Hot Reload: Nieuwe regels moeten geladen kunnen worden zonder downtime. üîí Security \u0026 Compliance - Immutability: Regels mogen niet tijdens runtime door de AI zelf aangepast kunnen worden. - Audit Trail: Elke Allow/Deny beslissing moet cryptografisch ondertekend en opgeslagen worden in de Traceability DB. üîå Interacties | Input | Bron | Verwerking | Output | | :--- | :--- | :--- | :--- | | Proposed Plan | Orchestrator | Evalueer tegen regelset | ALLOW, DENY, of REQUIRE_APPROVAL | | Policy Update | Git CI/CD | Laad nieuwe ruleset | Bevestiging activatie | üèóÔ∏è Relaties tot andere blokken - Blokkeert/Stuurt: Druppie Core - Initieert: Mens in de Loop (bij REQUIRE_APPROVAL status). - Logt naar: Traceability DB."
  },
  {
    "title": "Runtime Interface",
    "category": "design",
    "path": "design/runtime.md",
    "content": "Runtime Interface üéØ Doelstelling Dit bouwblok definieert de interface naar de Runtime omgeving. In de Azure Foundry architectuur bestaat deze runtime uit twee delen: de Agent Runtime (Azure AI Agent Service) voor de intelligentie, en de Container Runtime (Kubernetes/ACA) voor de workloads. üìã Functionele Specificaties 1. Agent Runtime (Azure AI Agent Service) - Host: De beheerde omgeving waar AI-agenten (Threads, Runs) worden uitgevoerd. - State Management: Automatisch beheer van conversatie-state en context (persistentie). - Tool Execution: Veilige uitvoering van code (Code Interpreter) en API-calls via OpenAPI. 2. Deployment Management (Container Runtime) - Manifest Application: Vertalen van abstracte deployment intenties naar concrete Kubernetes manifests of Azure Container Apps. - Rollout Control: Beheren van updates en rollbacks (Blue/Green). 3. Resource Provisioning aka \"Dynamic Slots\" - Namespace on Demand: Aanmaken van ge√Øsoleerde omgevingen voor nieuwe projecten. - Quota Management: Toewijzen van CPU/Memory limieten. 2. Security \u0026 Compliance by Design De runtime is ontworpen volgens strikte Security by Design en Compliance by Design principes. Dit betekent dat veiligheid en regelgeving niet achteraf worden getoetst, maar onderdeel zijn van het fundament. üîí Security by Design (Zero Trust) Identity First: Er zijn geen vaste 'service accounts' met brede rechten. Elke workload (Pod) krijgt via Azure Workload Identity (Entra ID) een unieke, tijdelijke identiteit. Network Segmentation: Standaard mag niets met elkaar praten (Deny-All). Via NetworkPolicies (Canal CNI) wordt verkeer expliciet toegestaan (bijv. \"Frontend mag praten met Backend op poort 8080\"). Immutable Infrastructure: Containers zijn read-only. Als er een patch nodig is, wordt de oude container vernietigd en een nieuwe uitgerold. SSH toegang tot nodes is uitgeschakeld voor beheerders. ‚öñÔ∏è Compliance by Design (Policy Enforcement) Regels worden afgedwongen voordat een applicatie start. Admission Controllers: We gebruiken OPA Gatekeeper of Kyverno. Wanneer de Builder Agent een deployment wil doen, checkt de runtime real-time: \"Heeft dit image een 'High' vulnerability?\" -\u003e Deployment Blocked ‚ùå. \"Heeft deze deployment een AI Register entry?\" -\u003e Deployment Blocked ‚ùå. \"Draait dit als root?\" -\u003e Deployment Blocked ‚ùå. Automatic Auditing: De API server logt elke wijziging (Wie deed wat?) naar de onwijzigbare Traceability DB. - Entra Agent ID: Elke agent draait onder zijn eigen Managed Identity. - Network Isolation: Alle communicatie verloopt via Private Endpoints binnen het VNet. 3. Geselecteerde Kubernetes Stack (RKE2) Voor de Container Runtime is gekozen voor RKE2 (Rancher Kubernetes Engine 2), ook wel bekend als RKE Government. üí° Waarom RKE2? - Security-First: RKE2 is standaard gehard volgens de CIS Kubernetes Benchmark en is FIPS 140-2 compliant. Dit is essentieel voor overheidsinstellingen zoals Waterschappen. - Lichtgewicht \u0026 Robuust: Het bundelt alle componenten in √©√©n binary maar gebruikt de zuivere, moderne CRI (Container Runtime Interface) standaarden (containerd). - Eenvoudig Beheer: Het automatiseert certificaatbeheer en etcd snapshots. ‚öôÔ∏è Configuratie (config.yaml) Een typische, veilige configuratie voor een RKE2 node binnen Druppie: yaml RKE2 Server Config write-kubeconfig-mode: \"0644\" tls-san: - \"k8s-api.druppie.nl\" cni: \"canal\" Calico + Flannel voor Network Policy enforcement profile: \"cis-1.23\" Activeer CIS Hardening Profile selinux: true token: \"SECRET_CLUSTER_TOKEN\" system-default-registry: \"registry.druppie.nl\" Gebruik de interne, scanned registry kube-apiserver-arg: - \"audit-log-path=/var/lib/rancher/rke2/server/audit.log\" - \"audit-policy-file=/etc/rancher/rke2/audit-policy.yaml\" Audit Logging voor Compliance üèóÔ∏è Relaties - Verwijst naar: Runtime Domein. - Wordt gebruikt door: Druppie Core en Build Plane."
  },
  {
    "title": "Druppie Core",
    "category": "design",
    "path": "design/druppie_core.md",
    "content": "Druppie Core (Orchestrator) üéØ Doelstelling De Druppie Core fungeert als het centrale zenuwstelsel van het platform. Het is verantwoordelijk voor het interpreteren van gebruikersvragen (intents), het plannen van complexe takenreeksen, en het orkestreren van gespecialiseerde agents en tools om tot een antwoord of oplossing te komen. Een kerntaak van de Core is het beheren van Multi-Agent samenwerking om grote problemen automatisch op te delen in bestaande of nieuwe oplossingen. üìã Functionele Specificaties 1. Intent Recognition \u0026 Routing (The Hub) - Hub-and-Spoke Model: De Core fungeert als de centrale Router Agent (Hub) die verzoeken ontvangt en distribueert naar gespecialiseerde agents (Spokes). - Context Awareness: Analyseert de vraag en context om de juiste specialist uit het register te kiezen. - Dispatcher Pattern: Gebruikt mechanismen zoals \"Connected Agents\" om taken te delegeren zonder de controle te verliezen. 2. Multi-Agent Planning \u0026 Decompositie - Problem Decomposition: De Router breekt complexe vragen op in sub-taken. - Agent Swarm Management: Co√∂rdineert de samenwerking tussen verschillende domein-experts (bijv. Finance, IT, HR). - Consensus \u0026 Review: Organiseert waar nodig peer-reviews tussen agents. 3. Capability Gap Analysis \u0026 Creatie Voordat de Core een taak uitvoert, checkt hij de Bouwblok Definities: 1. Check: Bestaat er al een bouwblok dat dit sub-probleem oplost? Ja: Gebruik het bestaande blok (hergebruik). Nee: Initieer Creatie Flow. 2. New Project Scaffolding: De Core stelt voor om een nieuw bouwblok te maken. 3. Specification Refinement: De Core gaat interactief met de gebruiker in gesprek om de specificaties voor dit nieuwe blok uit te werken (samen met de Business Analyst Agent). 4. Tool Gebruik (Capability Invocation) - Moet via gestandaardiseerde interfaces (MCP) tools kunnen aanroepen. - Moet parameters correct extraheren uit de gebruikersvraag om tools mee aan te sturen. üîß Technische Requirements - Platform: Gebaseerd op Microsoft Foundry (voorheen Azure AI Studio) als centraal beheersplatform. - Runtime: Maakt gebruik van de Azure AI Agent Service voor stateful execution en thread management. - Model Agnostic: Gebruik van Semantic Kernel of LangChain als abstractielaag om flexibel tussen modellen (GPT-4o, etc.) te wisselen. - Latency: Time-to-first-token \u003c 500ms voor routing beslissingen. - State Prevention: Threads en context worden beheerd door de Agent Service (Azure storage). üîí Security \u0026 Compliance - Safety Rails: Alle user input moet door een safety filter (jailbreak detection, PII screening). - Least Privilege: De Core mag alleen tools aanroepen waar de ingelogde gebruiker rechten toe heeft. - Audit Logging: Elke planningsbeslissing, en met name de keuze om iets nieuws te bouwen, wordt gelogd. üîå Interacties | Trigger | Bron | Actie | Output | | :--- | :--- | :--- | :--- | | New Prompt | Druppie UI | Analyseer intentie \u0026 start plan | Response stream | | Missing Capability | Planner | Stel voor nieuw blok te bouwen | Interactieve specs dialoog | | Tool Response | MCP / Agent | Verwerk resultaat \u0026 volgende stap | Volgende instructie | üèóÔ∏è Relaties tot andere blokken - Raadpleegt: Bouwblok Definities om te zien wat er al is. - Initieert: Builder Agent als er een nieuw blok gebouwd moet worden. - Controleert: Policy Engine voor validatie van het plan."
  },
  {
    "title": "Druppie UI",
    "category": "design",
    "path": "design/druppie_ui.md",
    "content": "Druppie UI üéØ Doelstelling De Druppie UI is het gezicht van het platform. Het biedt een intu√Øtieve, chat-gebaseerde interface (Copilot) waarmee gebruikers op natuurlijke wijze interactie hebben met de complexe agent-architectuur. Het doel is om de complexiteit van de backend te abstraheren en de gebruiker in controle te houden (\"Human in the Loop\"). üìã Functionele Specificaties 1. Conversational Interface \u0026 Integratie - Microsoft 365 Copilot: De primaire interface voor medewerkers, ge√Øntegreerd in Teams, Outlook en Word via Declarative Agents. - Druppie Custom UI: Een fallback/admin chat interface voor geavanceerde taken. - Streaming Response: Ondersteuning voor real-time text streaming. - Rich Media: Adaptieve kaarten en deep links naar specifieke applicaties. 2. Interactieve Elementen - Slash Commands: Ondersteunt commando's (bijv. /reset, /help, /new-project) voor directe sturing. - Adaptive Cards: Toont gestructureerde formulieren voor input (bijv. bij requirements intake). - Status Indicatoren: Geeft duidelijk aan wat het systeem aan het doen is (\"Thinking...\", \"Building...\", \"Waiting for Approval\"). 3. Human Approval Interface - Notifications: Toont alerts wanneer de gebruiker actie moet ondernemen (goedkeuring geven). - Decision Context: Biedt alle noodzakelijke informatie om een goedkeuring te kunnen doen (diffs, risico-analyse). üîß Technische Requirements - Proxy Pattern: Gebruik van Azure Functions als brug tussen M365 Copilot en de Azure AI Agent Service. - Protocol Translatie: Mappen van M365 conversationIds naar Azure Agent Thread IDs. - Security: Validatie van M365 tokens en gebruik van Managed Identity voor backend communicatie. - Responsive Design: Custom UI moet responsive zijn. üîí Security \u0026 Compliance - Auth Integration: Integreert naadloos met IAM (SSO). - Input Sanitization: Client-side filtering om XSS en injecties te voorkomen. - Privacy Mode: Visuele indicatie wanneer gevoelige data wordt verwerkt. üîå Interacties | Actie | Richting | Omschrijving | | :--- | :--- | :--- | | User Prompt | UI -\u003e Core | Gebruiker stuurt vraag of commando. | | Stream Chunk | Core -\u003e UI | Real-time tekst updates van de AI. | | Approval Request | Policy -\u003e UI | Pop-up voor menselijke goedkeuring. | üèóÔ∏è Relaties tot andere blokken - Authenticeert via: IAM. - Stuurt aan: Druppie Core. - Toont requests van: Mens in de Loop."
  },
  {
    "title": "ARCH: Agentic Patterns",
    "category": "design",
    "path": "design/agentic_patterns.md",
    "content": "Architectuur: AI Agent Patterns (Agentic Design) 1. Reflection (Zelf-Correctie) Het vermogen van de AI om zijn eigen werk te beoordelen en te verbeteren voordat het naar de gebruiker gaat. Implementatie in Druppie The Reviewer Loop: Elke generatie van code (door de Coder Agent) wordt niet direct gecommit, maar eerst doorgegeven aan een Reviewer Persona. Prompt Structuur: 1. Coder: Genereert Code. 2. Reviewer: \"Analyseer deze code op Security bugs en Performance issues. Geef een lijst met verbeterpunten.\" 3. Coder: \"Herschrijf de code op basis van deze feedback.\" Component: De Governance Agent fungeert als de ultieme reviewer die checks doet tegen de Compliance Registry. mermaid sequenceDiagram participant C as Coder Agent participant R as Reviewer Agent participant G as Governance Agent C-\u003e\u003eR: Genereer Code R--\u003e\u003eC: Feedback: \"SQL Injection Gevaar!\" C-\u003e\u003eC: Herschrijf Code... C-\u003e\u003eR: Genereer Code (v2) R-\u003e\u003eG: Check Compliance (BIO/AVG) G--\u003e\u003eR: GO / NO-GO 2. Tool Use (Capability Invocation) Het gebruik van externe tools om acties uit te voeren in de echte wereld. Implementatie in Druppie MCP (Model Context Protocol): Druppie gebruikt MCP als de standaard interface voor Tools. Lezen: Gitea (Code lezen), PostgreSQL (Data ophalen). Schrijven: Tekton (Pipeline starten), Flux (GitOps repo updaten). Veiligheid: Tools zijn niet \"altijd aan\". De Router bepaalt welke subset van tools een agent mag zien (Least Privilege). mermaid graph LR Agent[AI Agent] Router{Router} subgraph \"Toegestane Tools (Context)\" MCP1[Gitea: ReadCode] MCP2[Postgres: Query] end subgraph \"Geblokkeerde Tools\" MCP3[AWS: DeleteBucket] end Agent --\u003e|Request Tool| Router Router --\u003e|Check RBAC| MCP1 Router --x|Deny| MCP3 3. Planning (Thinking Fast and Slow) Complexe taken opbreken in stappen. Implementatie in Druppie Chain of Thought: De Router Agent splitst een grote vraag (\"Bouw een Drone Service\") op in een ExecutionPlan: 1. Scaffold Repo. 2. Schrijf Code. 3. Maak Dockerfile. 4. Cree√´r Helm Chart. Stateful Plan: Dit plan wordt opgeslagen in Redis. Als stap 2 faalt, weet de AI dat hij niet opnieuw hoeft te beginnen bij stap 1, maar stap 2 moet fixen. mermaid flowchart TD Prompt[User Prompt: Maak Drone Service] --\u003e Analyzer[Semantic Analyzer] Analyzer --\u003e Split{Split Intent} Split --\u003e|Plan A| BuildScaffold[Scaffold Repo] Split --\u003e|Plan B| WriteCode[Code Logic] Split --\u003e|Plan C| CreateInfra[Terraform/Helm] BuildScaffold --\u003e Sync[Wait for Completion] WriteCode --\u003e Sync CreateInfra --\u003e Sync Sync --\u003e Done 4. Multi-Agent Collaboration (Swarm Intelligence) Specialisten samen laten werken. Implementatie in Druppie Decompositie: Zie Router Decomposition Flow. Handoffs: Business Analyst Agent: Praat met de gebruiker, verheldert requirements -\u003e Output: Specs.md. Architect Agent: Leest Specs.md, kiest bouwblokken -\u003e Output: Architecture.yaml. Coder Agent: Leest Architecture.yaml, schrijft code. Voordeel: Elke agent heeft een smallere context window nodig en een specifiekere prompt, wat leidt tot hogere kwaliteit. mermaid graph TD User((User)) --\u003e|Requirement| BA[Business Analyst] BA --\u003e|Spec MD| Arch[Architect] Arch --\u003e|Architecture YAML| Coder[Coder] Coder --\u003e|Go Code| Review[Reviewer] subgraph \"Context Handoff\" BA --- Arch --- Coder --- Review end 5. ReAct (Reasoning + Acting) Een iteratieve loop van Denken -\u003e Doen -\u003e Observeren. Implementatie in Druppie Debug Loop: Thought: \"De build is gefaald. Ik moet de logs bekijken.\" Action: tekton.getLogs({ runId: \"123\" }) Observation: \"Error: package 'foo' not found.\" Thought: \"Ah, ik ben een dependency vergeten in go.mod. Ik ga die toevoegen.\" Action: git.commit({ file: \"go.mod\", content: \"...\" }) Observability: De agents hebben toegang tot echte feedback van het systeem (via Logs en Metrics), niet alleen hun eigen aannames. mermaid stateDiagram-v2 [] --\u003e Thought Thought --\u003e Action: Besluit actie Action --\u003e Observation: Lees Logs/Metrics Observation --\u003e Thought: Analyseer Resultaat Thought --\u003e []: Doel Bereikt --- Samenvatting Architectuur De Druppie Core is een implementatie van deze 5 patterns in een Kubernetes-native jasje: | Pattern | Druppie Component | | :--- | :--- | | Reflection | Governance \u0026 Reviewer Agents | | Tool Use | MCP Client \u0026 Server Architecture | | Planning | Core Planner \u0026 ExecutionPlan State | | Multi-Agent | Router \u0026 Registry (Skill Injection) | | ReAct | Build Plane Feedback Loop (Tekton/Flux) |"
  },
  {
    "title": "TO: Hybride Architectuur (K8s)",
    "category": "design",
    "path": "design/hybrid_cluster_architecture.md",
    "content": "Technisch Ontwerp: Hybride Kubernetes Architectuur üéØ Doelstelling Dit ontwerp beschrijft de infrastructuur voor een Hybride Kubernetes Omgeving. Het doel is om de schaalbaarheid en innovatiesnelheid van de Public Cloud (Azure) te combineren met de data-soevereiniteit en controle van het Eigen Datacenter (On-Premise). Dit ontwerp volgt de \"Data Gravitation\" strategie: Compute (rekenkracht) brengen we naar de Data toe, niet andersom. --- üèóÔ∏è High-Level Architectuur In deze opzet fungeert Azure als de \"flexibele schil\" en toegangspoort, terwijl het Datacenter de \"veilige kluis\" is voor gevoelige burgerdata en zware verwerkingen. mermaid graph TB subgraph Azure [\"‚òÅÔ∏è Azure (Public Cloud)\"] style Azure fill:e6f1fc,stroke:0078d4,stroke-width:2px,stroke-dasharray: 5 5 AG[(\"Kong Gateway (Public Ingress)\")] UI[(\"Web Apps (Public Frontend)\")] Agents[(\"AI Agent Runtime (LLM)\")] subgraph AZ_K8S [\"Cluster: RKE2-Cloud\"] UI Agents end end subgraph OnPrem [\"üè¢ Eigen Datacenter (Waterschap)\"] style OnPrem fill:f0fdf4,stroke:16a34a,stroke-width:2px subgraph OP_K8S [\"Cluster: RKE2-Core\"] IG[(\"Kong Gateway (Internal)\")] Int_UI[(\"Web Apps (Sensitive/Internal)\")] Int_Agents[(\"Internal AI Agents (Local LLM)\")] MinIO[(\"MinIO (Data Lake)\")] PG[(\"PostGIS (Geo Data)\")] GPU[(\"GPU Nodes (WebODM)\")] Legacy[(\"Legacy Connectors\")] end Git[(\"Gitea \u0026 Flux (GitOps)\")] end PublicUser(\"üë§ Burger (Internet)\") --\u003e AG Employee(\"üë∑ Medewerker (Intern Netwerk)\") --\u003e IG AG --\u003e UI IG --\u003e Int_UI UI -- \"API calls\" --\u003e Agents Int_UI -- \"Router\" --\u003e Agents Int_UI -- \"Router\" --\u003e Int_Agents %% Hybrid Connection drive[(\"üîí ExpressRoute / VPN\")] AZ_K8S \u003c==\u003e |\"Secure Tunnel\"| drive drive \u003c==\u003e |\"Secure Tunnel\"| OP_K8S Agents -- \"MCP (Fetch Data)\" --\u003e Legacy Int_Agents -- \"MCP (Direct)\" --\u003e Legacy Agents -- \"MCP (Analyze)\" --\u003e GPU Int_Agents -- \"MCP (Analyze)\" --\u003e GPU --- üõ†Ô∏è Technische Inrichting 1. De Kubernetes Stack (RKE2 in Multi-Cluster) We gebruiken Rancher Kubernetes Engine 2 (RKE2) als uniforme runtime voor beide locaties. Dit zorgt voor 100% compabiliteit. Beheer: We zetten √©√©n centrale Rancher Management Server op (in Azure of DMZ) om beide clusters te beheren. Cluster Azure (RKE2-Cloud): Doel: Frontends, Chatbots, Public API's. Kenmerk: Autoscaling nodes (voordelig schalen), Stateless. Cluster On-Prem (RKE2-Core): Doel: Gevoelige data opslag, GPU-intensieve taken (Drone beeldverwerking), koppeling SCADA. Kenmerk: Static Hardware, High Security, Stateful. 2. Netwerk \u0026 Connectiviteit De verbinding is cruciaal. We gebruiken een Hub-Spoke model. Interconnect: Azure ExpressRoute (of Site-to-Site VPN) zorgt voor een priv√© verbinding. Service Mesh (Optioneel): Cilium of Linkerd om services over clusters heen te laten praten alsof ze lokaal zijn (drone-api.on-prem.svc.cluster.local). Ingress: Publiek verkeer komt binnen via Kong Gateway in Azure (DDoS bescherming). Kong routeert traffic voor \"zware taken\" door de tunnel naar de On-Prem Ingress (intern). 3. Data Strategie (Data Sovereignty) Conform de Data Act en AVG: Data Lake (MinIO): Draait primair On-Prem. Voor AI training in de cloud kan een specifieke bucket (\"Anonymized-Training-Data\") gerepliceerd worden naar Azure (MinIO Mirroring), maar de Master blijft thuis. Database (PostgreSQL): Master draait On-Prem. Read-Replicas kunnen eventueel in Azure draaien voor snelle frontend access (met geanonimiseerde views). --- 4. AI Model Strategie: Hybride Intelligentie Een cruciaal onderdeel van het ontwerp is de keuze waar de AI verwerking plaatsvindt. We gebruiken een \"Router\" (onderdeel van Druppie Core) die op basis van data-classificatie het juiste model kiest. A. Interne AI (On-Premise) Wanneer: Voor Gevoelige Data (Persoonsgegevens, Beveiligingsdetails Critical Infra) of Offline taken. Techniek: Self-hosted LLM's (zoals Llama 3, Mistral) draaiend op GPU nodes in het eigen datacenter. Tools: Ollama of vLLM containers in het RKE2-Core cluster. Voordeel: Data verlaat nooit het pand. Volledige controle. Nadeel: Minder krachtig dan GPT-4 (\"Dumber but Safer\"). B. Externe AI (Azure OpenAI) Wanneer: Voor Openbare Data, generieke kennisvragen, coderen, of creatieve taken. Techniek: Azure OpenAI Service (GPT-4o). Compliance: We gebruiken de \"Enterprise\" variant waarbij Microsoft garandeert dat input data NIET wordt gebruikt voor training. Voordeel: State-of-the-Art intelligentie, schaalbaar. Nadeel: Data verlaat (versleuteld) het netwerk. Beslisboom (Router Logic) mermaid graph TD Start(\"‚ùì User Prompt / Data\") Classify{\"üîç Classificatie (Policy Engine)\"} Internal[\"üè¢ Internal Cluster (Ollama/LMStudio)\"] Scrub{\"üßπ Kan anonimiseren?\"} External[\"‚òÅÔ∏è Azure Foundry (GPT-5.2)\"] Result(\"üìù Antwoord\") Start --\u003e Classify Classify --\u003e|üî¥ Zeer Geheim / BSN| Internal Classify --\u003e|üü† Vertrouwelijk Intern| Scrub Classify --\u003e|üü¢ Openbaar / Publiek| External Scrub -- Ja --\u003e External Scrub -- Nee --\u003e Internal Internal --\u003e Result External --\u003e Result --- 5. OTAP Strategie (Environment Sep"
  },
  {
    "title": "TO: Component Interactie (Build-\u003eRun)",
    "category": "design",
    "path": "design/component_interaction.md",
    "content": "Technisch Ontwerp: Component Interactie (Build \u0026 Runtime) üéØ Doelstelling Dit ontwerp detailleert de \"End-to-End Flow\" binnen het Druppie platform. Het beschrijft hoe de componenten van de Build Plane (het maken van software) naadloos integreren met de Runtime (het draaien van software), met focus op de geautomatiseerde checks en balances. Dit is de realisatie van de Spec-Driven en Compliance-by-Design filosofie. --- üèóÔ∏è De Componenten Architectuur In onderstaand schema zien we de reis van een \"Idee\" naar een \"Draaiende container\". mermaid graph TD subgraph UserInteraction [\"üó£Ô∏è Interactie\"] User(\"üë§ Gebruiker\") \u003c--\u003e |\"Chst \u0026 Specs\"| Agent(\"ü§ñ Builder Agent\") end subgraph BuildPlane [\"üõ†Ô∏è Build Plane (Foundry)\"] Agent --\u003e |\"1. Commit Code \u0026 Config\"| Git(\"üóÑÔ∏è Gitea (Source)\") Git --\u003e |\"2. Webhook\"| Tekton(\"‚öôÔ∏è Tekton (CI Pipeline)\") Tekton --\u003e |\"3a. Build \u0026 Sign\"| Registry(\"üì¶ Container Registry\") Tekton --\u003e |\"3b. Scan \u0026 Test\"| Scanner(\"üõ°Ô∏è Trivy / SonarQube\") Tekton --\u003e |\"3c. Update Status\"| TraceDB(\"üìú Traceability DB\") end subgraph GitOps [\"üîÑ GitOps Bridge\"] Flux(\"reconciler: Flux CD\") Flux \u003c--\u003e |\"4. Pull Config\"| Git end subgraph Runtime [\"üöÄ Runtime (Kubernetes)\"] Flux --\u003e |\"5. Apply Manifest\"| K8sAPI(\"Kubernetes API\") K8sAPI --\u003e |\"6. Validate Request\"| Kyverno(\"üëÆ Policy Engine (Kyverno)\") Kyverno -.-\u003e |\"Check Signatures\"| Registry Kyverno -.-\u003e |\"Check AI Register\"| TraceDB Kyverno --\u003e |\"7a. Allow\"| Kubelet(\"üì¶ Workload (Pod)\") Kyverno --\u003e |\"7b. Deny\"| K8sAPI end subgraph Observability [\"üëÅÔ∏è Observability\"] Kubelet --\u003e |\"8. Logs \u0026 Metrics\"| Loki(\"Loki / Prometheus\") end --- üîÑ Proces Flow Beschrijving Fase 1: Intent \u0026 Code (De Build Plane) 1. Specificatie: De gebruiker vraagt de Builder Agent om een nieuwe Drone Service. De Agent genereert code (Python) en infra-definitie (Helm/Kustomize). 2. Commit: De Agent pusht alles naar Gitea. Dit is het eerste audit-moment (\"Wie heeft dit gemaakt?\"). 3. Continuous Integration (Tekton): Build: Bouwt de container image. Test: Draait unit tests. Security: Scant op bekende vulnerabilities (CVE's). Compliance: Valideert of algorithm.yaml aanwezig is. Sign: Als alles groen is, wordt de image digitaal ondertekend (Cosign) en gepusht naar de Registry. Fase 2: Reconciliatie (GitOps Bridge) 4. Sync: Flux CD bewaakt de Git repo. Zodra er een nieuwe image-tag in de config staat, wordt dit opgepikt. Merk op: Er is geen directe toegang van CI naar Cluster. Flux trekt (Pulls) de wijziging naar binnen. Dit is veiliger. Fase 3: Validatie \u0026 Deployment (De Runtime) 5. API Call: Flux stuurt het verzoek (\"Start Service V2\") naar de Kubernetes API. 6. Admission Control (Kyverno): Voordat de Pod start, grijpt Kyverno, onze Policy Engine, in: Validatie 1: \"Is deze image ondertekend door onze Foundry?\" (Voorkomt malafide containers). Validatie 2: \"Heeft deze deployment een AI Register ID?\" Validatie 3: \"Vraagt deze pod niet om root-rechten?\" 7. Execution: Allow: De Pod wordt gestart op de juiste node (bijv. On-Prem GPU node). Deny: De update wordt geweigerd en Flux rapporteert een error. Fase 4: Feedback Loop 8. Observability: De draaiende applicatie stuurt logs en metrics naar de PLG stack. De Builder Agent kan deze data lezen om te zien of zijn creatie goed werkt (\"Self-Healing\"). --- üõ°Ô∏è Security Controles per Laag | Laag | Component | Controle | Doel | | :--- | :--- | :--- | :--- | | Code | Gitea | Branch Protection | Niemand kan direct naar main pushen zonder review (door mens of Agent). | | Build | Tekton | Image Scanning | Geen lekke software in productie. | | Artifact | Registry | Image Signing | Garanderen van herkomst (Supply Chain Security). | | Deployment| Flux | Drift Detection | Voorkomen van handmatige aanpassingen (\"ClickOps\"). | | Runtime | Kyverno | Policy Enforcement | Afdwingen van Run-Time regels (Non-Root, Network Policies). | ‚úÖ Samenvatting Dankzij deze keten is \"Compliance\" geen papierwerk, maar een geautomatiseerde poortwachter. De Builder Agent zorgt voor snelheid. Tekton \u0026 Kyverno zorgen voor veiligheid. Git \u0026 Flux zorgen voor stabiliteit."
  },
  {
    "title": "TO: Data Lifecycle \u0026 Versiebeheer",
    "category": "design",
    "path": "design/data_lifecycle_drone.md",
    "content": "Technisch Ontwerp: Data Lifecycle \u0026 Versiebeheer (Drone/Satelliet) üéØ Doelstelling Dit ontwerp beschrijft de end-to-end flow voor het beheren van grote, veranderlijke datasets zoals drone- en satellietbeelden. Centraal staan versiebeheer, privacy (anonimisering) en traceerbaarheid. We beantwoorden de vraag: \"Hoe gaan we van een SD-kaart met ruwe foto's naar een geanonimiseerde, versie-beheerde kaartlaag voor de organisatie?\" --- üèóÔ∏è De Data Pipeline Architectuur mermaid graph TD subgraph Source [\"üìÇ Bron\"] SDCard(\"üíæ SD-Kaart / Satelliet Feed\") end subgraph DataLake [\"üåä Data Lake (MinIO)\"] BucketRaw[(\"ü™£ Raw (Versleuteld)\")] BucketScrub[(\"ü™£ Scrubbed (Priv√©)\")] BucketOrtho[(\"ü™£ Ortho (Public/Intern)\")] end subgraph Processing [\"‚öôÔ∏è Processing (Tekton/Argo)\"] Ingest(\"üì• Ingest \u0026 DVC Init\") Anonymizer(\"üßπ AI Anonimiser (YOLOv8)\") Stitcher(\"üß© WebODM (Stitching)\") end subgraph Versioning [\"üìå Versiebeheer\"] Git(\"üóÑÔ∏è Gitea (Metadata .dvc)\") end subgraph Serving [\"üåç Serving\"] GeoServer(\"üó∫Ô∏è GeoServer (WMS/WFS)\") AI(\"ü§ñ AI Models\") end %% Flow SDCard --\u003e |\"1. Upload\"| Ingest Ingest --\u003e |\"2. Store V1\"| BucketRaw Ingest --\u003e |\"3. Commit Hash\"| Git BucketRaw --\u003e |\"4. Trigger\"| Anonymizer Anonymizer --\u003e |\"5. Detect Faces/License Plates\"| Anonymizer Anonymizer --\u003e |\"6. Store V1-Scrubbed\"| BucketScrub BucketScrub --\u003e |\"7. Process\"| Stitcher Stitcher --\u003e |\"8. Generate Ortho\"| BucketOrtho BucketOrtho --\u003e |\"9. Serve\"| GeoServer BucketOrtho --\u003e |\"10. Train\"| AI --- üîÑ Proces Stappen Stap 1: Creatie \u0026 Ingestie (Raw Data) Actie: Een dronepiloot uploadt 500 foto's naar de landing-zone. Versiebeheer: Het systeem berekent een unieke hash (MD5) van de dataset. DVC slaat de foto's op in MinIO bucket-raw. DVC maakt een pointer file (raw_flight_2025.dvc) en commit deze naar Gitea. Resultaat: We hebben een onwijzigbare kopie van het origineel (\"Bewijslast\"). Stap 2: Anonimisering (Privacy-by-Design) Voordat beelden breed gedeeld worden, moeten persoonsgegevens verwijderd worden. Processing: Een Tekton pipeline start een container met AI-detectie (bijv. een YOLO model getraind op gezichten en kentekens). Actie: De AI blurt (vervaagt) alle gedetecteerde privacy-gevoelige pixels. Opslag: De opgeschoonde beelden gaan naar bucket-scrubbed. Versiebeheer: DVC trackt deze nieuwe set. We weten nu: De dataset in bucket-scrubbed is afgeleid van Hash X uit bucket-raw met algoritme Versie Y. Stap 3: Aan elkaar plakken (Stitching) De losse foto's worden √©√©n kaart. Tool: WebODM pakt de beelden uit bucket-scrubbed. Actie: Uitvoeren van SfM (Structure from Motion) om een 2D Orthofoto (GeoTIFF) en 3D Point Cloud (.laz) te maken. Opslag: Resultaat gaat naar bucket-ortho. Dit bestand is vaak enorm (GB's), dus MinIO is essentieel. Stap 4: Beschikbaar Stellen (Serving) Andere tools hebben nu toegang nodig. GIS Gebruikers: GeoServer indexeert de GeoTIFF uit bucket-ortho en serveert deze als WMS (Web Map Service). De ecoloog ziet de kaart in QGIS of GeoNode. AI Modellen: Een Data Scientist wil een nieuw schadedetectie-model trainen. Hij doet: dvc get https://gitea/project/drone.git data/ortho DVC haalt exact de juiste versie van de Orthofoto uit MinIO. Dit garandeert reproduceerbaarheid: \"Dit model is getraind op de geanonimiseerde kaart van 12 mei 2025\". --- üõ°Ô∏è Security \u0026 Compliance 1. Toegangsbeheer (IAM): bucket-raw: Alleen toegankelijk voor de Anonimiser-Service en de CISO (voor forensisch onderzoek). bucket-ortho: Leesbaar voor de hele organisatie. 2. Audit Trail: In Gitea zien we de historie: \"Commit 1: Raw Upload\" -\u003e \"Commit 2: Anonymized\" -\u003e \"Commit 3: Processed\". 3. Data Act: Omdat we alles opslaan in open formaten (GeoTIFF) en standaarden (WMS), kunnen we data makkelijk delen met ketenpartners (andere waterschappen) zonder vendor lock-in. ‚úÖ Samenvatting Door DVC te koppelen aan MinIO en WebODM, cre√´ren we een \"Tijdmachine\" voor onze data. We kunnen altijd terugkijken hoe een foto eruit zag v√≥√≥r anonimisering (indien bevoegd) en we weten precies welke data is gebruikt voor welk AI-model."
  },
  {
    "title": "TO: Deployment \u0026 Rolling Updates",
    "category": "design",
    "path": "design/deployment_strategies.md",
    "content": "Technisch Ontwerp: Deployment Strategie√´n \u0026 Rolling Upgrades üéØ Doelstelling Dit ontwerp beschrijft hoe wijzigingen (updates) gecontroleerd worden uitgerold naar de verschillende omgevingen (TEST, ACC, PROD). Het doel is de balans te vinden tussen snelheid (in Test) en stabiliteit (in Productie). De gebruiker heeft regie over de \"Rollout Pace\": hoe agressief of conservatief een update wordt doorgevoerd, afhankelijk van de impact van de wijziging (Major vs. Minor/Patch). --- üèóÔ∏è Het Concept: Spec-Driven Deployment Profile In plaats van handmatig kubectl commando's te tikken, definieert de gebruiker (of de Builder Agent) een Deployment Profile in de service.yaml. De Kubernetes Deployment resource biedt native ondersteuning voor Rolling Upgrades via spec.strategy. Wij tunen deze parameters op basis van het profiel. De Paremeters 1. Max Surge: Hoeveel extra pods mogen er tijdelijk bij komen? (Hoger = Sneller, kost meer resources). 2. Max Unavailable: Hoeveel pods mogen er stuk zijn tijdens de update? (0 = Zero Downtime). 3. Min Ready Seconds: Hoe lang moet een nieuwe pod \"goed\" draaien voordat we hem vertrouwen en de volgende stap zetten? (Dit is de \"wachttijd\"). --- üìä Strategie Matrix We onderscheiden drie standaard profielen die de Builder Agent automatisch toepast. | Profiel | Omgeving | Type Wijziging | Max Surge | Max Unavail | Ready Wait (s) | Gedrag | | :--- | :--- | :--- | :--- | :--- | :--- | :--- | | Blitz | TEST | Alles | 100% | 50% | 0s | Zo snel mogelijk. Vervang de helft direct. Downtime is acceptabel. | | Cautious | PROD | Minor / Patch | 25% | 0 | 30s | Stabiel. Stap-voor-stap (1 op 4). Geen downtime. Wacht 30s per stap. | | Paranoid | PROD | Major | 1 | 0 | 300s | Zeer Voorzichtig. E√©n pod per keer. Wacht 5 minuten (300s) per pod. | --- ‚öôÔ∏è Technische Implementatie (Helm/Flux) De implementatie vindt plaats in de Helm Chart die door Flux wordt uitgerold. 1. Configuratie (values.yaml) De gebruiker specificeert in de HelmRelease: yaml apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: drone-api spec: values: Keuze door gebruiker/agent: deploymentStrategy: \"Paranoid\" Want: Major upgrade V1 -\u003e V2 2. Vertaling naar Kubernetes (deployment.yaml) De Helm chart vertaalt de string \"Paranoid\" naar harde cijfers: yaml apiVersion: apps/v1 kind: Deployment spec: replicas: 10 minReadySeconds: {{ .Values.readinessDelay | default 0 }} De \"Wachttijd\" strategy: type: RollingUpdate rollingUpdate: maxSurge: {{ .Values.maxSurge }} maxUnavailable: {{ .Values.maxUnavailable }} --- üîÑ Visuele Flow: \"De Paranoid Rollout\" Stel we upgraden de Drone API van V1 naar V2 in Productie (Paranoid Mode). We hebben 4 Pods actief. mermaid sequenceDiagram participant Flux as üîÑ Flux CD participant K8s as ‚ò∏Ô∏è Kubernetes participant Pod1 as üì¶ Pod-1 (V1) participant Pod2 as üì¶ Pod-2 (V1) participant PodNew as ‚ú® Pod-New (V2) Note over Flux, PodNew: Start Major Update (Paranoid: Surge 1, Wait 300s) Flux-\u003e\u003eK8s: Apply Deployment Image: V2 K8s-\u003e\u003ePodNew: Start 1x V2 Pod Note right of PodNew: Opstarten... PodNew--\u003e\u003eK8s: Readiness Probe OK! Note over K8s: ‚è±Ô∏è Wacht 300 seconden (MinReadySeconds) K8s--\u003e\u003eK8s: Geen crashes? Metrics OK? K8s-\u003e\u003ePod1: Terminate V1 Pod Pod1--\u003e\u003eK8s: Shutdown Note over K8s: Herhaal voor volgende Pod... Safety Gates (Health Checks) Tijdens de \"Wachttijd\" (die 5 minuten) monitort Kubernetes de Liveness en Readiness probes. Als de nieuwe V2 pod crasht (Reboot Loop), stopt de rollout automatisch. De oude V1 pods blijven draaien. Gebruikers merken (bijna) niets, behalve dat de update \"hangt\". --- üöÄ Gebruikerservaring Scenario: Developer configureert een update De developer praat tegen de Builder Agent: \u003e User: \"Ik wil de nieuwe Drone AI (V2) naar productie brengen. Het is een grote wijziging, dus doe maar rustig aan.\" \u003e Agent: \"Begrepen. Ik configureer de HelmRelease voor 'drone-ai' met strategie Paranoid. Dit betekent dat de uitrol 1 pod per 5 minuten vervangt. Akkoord?\" \u003e User: \"Maak er maar 2 minuten van.\" \u003e Agent: \"Aangepast. minReadySeconds gezet op 120s.\" De Agent commiit vervolgens: yaml deploy/prod/drone-ai-release.yaml spec: values: deploymentStrategy: \"Custom\" customStrategy: maxSurge: 1 maxUnavailable: 0 readinessDelay: 120 üìö Bronkeuze: Ramped Slow Rollout \u0026 Blue/Green Naar aanleiding van best practices, hebben we gekozen voor Ramped Slow Rollout als de standaard \"base option\" voor productie. Dit biedt de beste balans tussen veiligheid en resource-effici√´ntie. Echter, voor specifieke High-Compliance updates (bijv. een nieuwe versie van de Policy Engine), voegen we de Blue/Green strategie toe. --- üîµ/üü¢ Uitbreiding: Blue/Green Deployment Voor kritieke componenten waar geen enkele fout getolereerd wordt tijdens de switch, of waar een Human Auditor expliciet \"Go\" moet geven, gebruiken we Blue/Green. Het Concept We draaien twee volledige versies naast elkaar: üîµ Blue: De huidige Live versie (v1). üü¢ Green: De nieuwe versie (v2), volledig opgestart "
  },
  {
    "title": "TO: IAM \u0026 Keycloak Interactie",
    "category": "design",
    "path": "design/iam_keycloak_interaction.md",
    "content": "Technisch Ontwerp: IAM \u0026 OPA Integratie met Keycloak üéØ Doelstelling Het beveiligen van applicaties, data (Postgres) en AI-kennis (RAG) door middel van een centraal Identity \u0026 Access Management (IAM) systeem. We gebruiken Keycloak als Identity Provider (IdP) en Open Policy Agent (OPA) voor fijnmazige autorisatie. üèóÔ∏è Architectuur De beveiliging is opgebouwd uit drie lagen: 1. Authenticatie (Wie ben je?): Via Keycloak (OIDC). 2. Autorisatie (Wat mag je?): Via OPA (Regels in Rego). 3. Handhaving (Enforcement): Via Envoy / Sidecars of in de App code. mermaid sequenceDiagram actor User participant Browser participant Keycloak as Keycloak (IdP) participant App as Druppie App participant OPA as Policy Engine participant DB as Postgres (RLS) participant RAG as Qdrant (Vector) User-\u003e\u003eBrowser: Open App Browser-\u003e\u003eKeycloak: Redirect for Login (OIDC) User-\u003e\u003eKeycloak: Credentials Keycloak--\u003e\u003eBrowser: JWT Token (Claims: role=analyst, dept=hr) rect rgb(240, 248, 255) note right of Browser: Scenario 1: Data Access Browser-\u003e\u003eApp: API Request + Bearer Token App-\u003e\u003eDB: SQL Query (SET LOCAL role/dept) DB--\u003e\u003eApp: Filtered Rows (RLS enforced) App--\u003e\u003eBrowser: Data Response end rect rgb(255, 250, 240) note right of Browser: Scenario 2: AI Question Browser-\u003e\u003eApp: \"Summarize HR Policy\" App-\u003e\u003eOPA: Check Access (Token + Query) OPA--\u003e\u003eApp: Filter: { dept: \"hr\" } App-\u003e\u003eRAG: Vector Search + Filter RAG--\u003e\u003eApp: Allowed Context Chunks App--\u003e\u003eBrowser: AI Answer rooted in authorized data end 1. Applicatie Toegang (SSO) Gebruikers loggen in via de browser. Protocol: OpenID Connect (OIDC). Flow: Authorization Code Flow met PKCE. Token: JWT (JSON Web Token) bevat gebruikersrollen (bijv. analist, beheerder). 2. Data Toegang (Row Level Security) Toegang tot specifieke rijen in PostgreSQL (bijv. alleen dossiers van jouw afdeling). Mechanisme: PostgreSQL Row Level Security (RLS). Implementatie: 1. De API ontvangt de JWT van de gebruiker. 2. De API \"impersoneert\" de gebruiker in de DB sessie: SET LOCAL request.jwt.claim.role = 'analist'; 3. Postgres Policies filteren automatisch de data. 3. RAG / Kennis Toegang (AI Security) Toegang tot documenten in de Vector DB (Qdrant). Probleem: Een gebruiker mag via de Chatbot niet zoeken in documenten waar hij geen recht op heeft. Oplossing (Attribute Based Access Control - ABAC): 1. Elk document in Qdrant heeft metadata: {\"department\": \"hr\", \"confidentiality\": \"high\"}. 2. De Chatbot stuurt de vraag + JWT naar de Policy Engine. 3. De Policy Engine (OPA) geeft een filter terug: filter = { must: [ { key: \"department\", match: { value: \"hr\" } } ] }. 4. Dit filter wordt toegevoegd aan de zoekopdracht naar Qdrant. üõ†Ô∏è Technische Implementatie A. Keycloak Configuratie (Terraform) We defini√´ren de infrastructuur als code. hcl resource \"keycloak_realm\" \"druppie\" { realm = \"druppie\" enabled = true } resource \"keycloak_openid_client\" \"rag_app\" { realm_id = keycloak_realm.druppie.id client_id = \"rag-chatbot\" access_type = \"CONFIDENTIAL\" valid_redirect_uris = [\"https://chat.druppie.nl/callback\"] } B. Voorbeeld: RAG Security (Python) Hoe de backend het user token gebruikt om de zoekopdracht te filteren. python from fastapi import Depends, HTTPException from fastapi.security import OAuth2PasswordBearer import jwt 1. Valideer Token def get_current_user_claims(token: str = Depends(oauth2_scheme)): try: payload = jwt.decode(token, PUBLIC_KEY, algorithms=[\"RS256\"]) return payload Bevat roles, department, etc. except: raise HTTPException(status_code=401) 2. Stel Zoekfilter Samen (Policy Enforcement) def search_knowledge_base(query: str, user_claims: dict): user_dept = user_claims.get(\"department\") Authorisatie Filter (Alleen eigen afdeling) auth_filter = { \"key\": \"department\", \"match\": {\"value\": user_dept} } Voer zoekopdracht uit in Qdrant met filter results = qdrant_client.search( collection_name=\"bedrijfskennis\", query_vector=encode(query), query_filter=Filter(must=[auth_filter]) \u003c--- CRUCIAAL ) return results C. Voorbeeld: Database RLS (Postgres SQL) Hoe de database zelf de toegang afdwingt. sql -- 1. Maak Table met ownership kolom CREATE TABLE dossiers ( id SERIAL PRIMARY KEY, inhoud TEXT, afdeling TEXT -- bijv. 'hr', 'finance' ); -- 2. Enable RLS ALTER TABLE dossiers ENABLE ROW LEVEL SECURITY; -- 3. Maak Policy: \"Je mag alleen lezen als jouw afdeling matcht met de rij\" CREATE POLICY afdeling_policy ON dossiers FOR SELECT USING (afdeling = current_setting('request.jwt.claim.department', true)); ‚úÖ Samenvatting Door deze 3-traps raket (Web SSO, DB RLS, Vector Filtering) zorgen we dat beveiliging overal wordt afgedwongen, niet alleen aan de voordeur. Zelfs als een AI Agent \"rogue\" gaat, kan hij fysiek geen data ophalen die niet voor de gebruiker bedoeld is."
  },
  {
    "title": "TO: Automated Rebuild (Watchdog)",
    "category": "design",
    "path": "design/automated_rebuild.md",
    "content": "Technisch Ontwerp: Automated Rebuild \u0026 Patching üéØ Doelstelling We willen een automatisch \"Self-Healing\" mechanisme implementeren dat continu de definities van onze Bouwblokken bewaakt. Wanneer er een Bugfix of Security Patch wordt gedetecteerd in een fundamenteel bouwblok (bijv. \"Update Base Image Python\"), moet het systeem: 1. Detecteren welke applicaties dit bouwblok gebruiken. 2. Deze applicaties automatisch herbouwen en uitrollen naar TEST. 3. De update klaarzetten voor promotie naar PROD (via de Deployment Strategy). Dit voorkomt dat applicaties verouderen en onveilig worden. --- üèóÔ∏è Architectuur: De \"Dependency Watchdog\" We introduceren een nieuw background proces: de Dependency Watchdog. Dit is een lichtgewicht service (of CronJob) die luistert naar wijzigingen in Gitea. mermaid graph TD subgraph Git [\"üóÑÔ∏è Gitea (Source)\"] RepoBlock[(\"Repo: Bouwblokken\")] RepoApp1[(\"Repo: Drone App\")] RepoApp2[(\"Repo: GIS Portal\")] end subgraph Logic [\"üß† Watchdog Service\"] Detector(Change Detector) Parser(Semantic Parser) Graph(Dependency Graph) end subgraph Action [\"‚öôÔ∏è Build Plane\"] Tekton(Tekton Pipeline) Flux(Flux CD) end %% Flow RepoBlock -- \"Webhook: Push\" --\u003e Detector Detector --\u003e Parser Parser -- \"Is het een FIX?\" --\u003e Graph Graph -- \"Wie gebruikt dit?\" --\u003e Tekton Tekton -- \"Auto-Build App 1 \u0026 2\" --\u003e RepoApp1 Tekton -- \"Push Tag naar Dev-Cluster\" --\u003e Flux --- üîÑ Proces Flow Stap 1: Change Detection De Watchdog ontvangt een webhook event van Gitea wanneer er een commit is op de bouwblokken repository. Stap 2: Semantic Analysis (\"Is dit een Fix?\") De Watchdog analyseert de commit message volgens de Conventional Commits standaard: fix: update python to 3.11.2 (CVE-XYZ) ‚úÖ -\u003e Actie vereist! chore: update readme ‚ùå -\u003e Negeren. feat: add new capability ‚ùå -\u003e Negeren (vereist handmatige implementatie). Stap 3: Dependency Resolution De Watchdog kijkt in zijn grafiek (gevoed door de SBOMs in de Traceability DB): \"Welke applicaties hebben een FROM: bouwblokken/python-base:3.11 in hun Dockerfile?\" Resultaat: Drone App en GIS Portal. Stap 4: Automated Rebuild (Cascade) De Watchdog triggert Tekton pipelines voor de geraakte applicaties: 1. Checkout: Haalt de broncode van Drone App. 2. Patch: Update de dependency (bijv. in Dockerfile of requirements.txt). 3. Build \u0026 Test: Draait de unit tests om te garanderen dat de fix niets breekt. 4. Publish: Pusht drone-app:v1.2.1-fix naar de registry. Stap 5: Deploy naar TEST De Watchdog past de HelmRelease voor de TEST omgeving aan (via een Git commit op de fleet-infra repo): Versie: v1.2.1-fix Strategy: Blitz (Want het is TEST, mag direct). Stap 6: Aanbod aan Productie De Watchdog maakt automatisch een Pull Request aan voor de PROD omgeving: Titel: fix(deps): propagate security patch to prod Strategy: Cautious (Zie Deployment Design). Status: Pending Approval. De beheerder hoeft alleen maar \"Merge\" te klikken (of de Policy Engine doet het als het een Critical CVE was). --- üõ†Ô∏è Technische Componenten 1. Renovate Bot (De Engine) We hoeven de \"Watchdog\" niet zelf te bouwen. We gebruiken Renovate Bot. Dit is de industrie-standaard voor geautomatiseerd dependency management. Het snapt Dockerfiles, Helm Charts, Kubernetes manifests en Git submodules. Het kan geconfigureerd worden om bij fix: commits automatisch te mergen naar branches die naar TEST deployen. 2. Configuratie (renovate.json) We plaatsen dit in de root van onze repo's: json { \"extends\": [\"config:base\"], \"packageRules\": [ { \"matchUpdateTypes\": [\"patch\", \"pin\", \"digest\"], \"matchPackagePatterns\": [\"^bouwblokken/\"], \"automerge\": true, \"automergeType\": \"branch\", \"branchPrefix\": \"fix/auto-rebuild-\" } ], \"semanticCommits\": \"enabled\" } ‚úÖ Samenvatting Door Renovate Bot in te zetten als onze \"Watchdog\", realiseren we een self-healing platform. Security: Patches in base-images sijpelen automatisch door naar alle 50+ applicaties. Stabiliteit: Omdat we eerst naar TEST uitrollen en testen, gaat productie nooit stuk door een automatische update. Snelheid: De \"Fix\" cyclus gaat van weken naar minuten."
  },
  {
    "title": "TO: Secure Agentic RAG Network",
    "category": "design",
    "path": "design/agentic_rag_network.md",
    "content": "Technisch Ontwerp: Secure Agentic RAG Network üéØ Doelstelling Dit ontwerp beschrijft een Agentic Network dat ongestructureerde data (bestanden) en publieke data (web) combineert om intelligente acties uit te voeren. Kernpunt is Security by Design data-toegang: Een gebruiker mag via de AI NOOIT informatie vinden die hij via de normale bestandsverkenner niet zou mogen zien. --- üèóÔ∏è Architectuur: Het Agenten Netwerk We gebruiken een Multi-Agent opzet waarbij specifieke taken zijn gedelegeerd. mermaid graph TD User(\"üë§ Gebruiker (Context: Groepen)\") \u003c--\u003e |\"Chat Interface\"| Router(\"ü§ñ Router Agent\") subgraph DataPlane [\"üìö Knowledge \u0026 Data\"] FS(\"üìÇ FileSystem (SMB/SharePoint)\") VDB[(\"üß† Vector DB (Qdrant)\")] Web(\"üåê Web Search (MCP)\") end subgraph Agents [\"üïµÔ∏è Agent Network\"] Ingester(\"ü§ñ Ingest Agent\") RAG(\"ü§ñ RAG Agent (Search)\") Action(\"ü§ñ Action Agent\") end subgraph Execution [\"‚öôÔ∏è Uitvoering\"] Argo(\"üöÄ Argo Workflow\") ExtSys(\"üñ•Ô∏è Extern Systeem (API)\") end %% Inest Flow FS --\u003e |\"1. Read File + ACLs\"| Ingester Ingester --\u003e |\"2. Embed + Tags\"| VDB %% Query Flow Router --\u003e |\"3. Vraag + User Token\"| RAG RAG --\u003e |\"4. Vector Search + Filter\"| VDB RAG -- \"5. Search Web (Opt)\" --\u003e Web RAG --\u003e |\"6. Synthesized Answer\"| Router %% Action Flow Router --\u003e |\"7. Intent: Update Systeem\"| Action Action --\u003e |\"8. Trigger Process\"| Argo Argo --\u003e |\"9. Update\"| ExtSys --- üîê Security by Design: De \"ACL-Aware\" RAG Het grootste risico bij RAG (Retrieval Augmented Generation) is dat de AI alle documenten \"leest\" en antwoord geeft op basis van een geheim document. Dit lossen we op via Metadata Filtering. Stap 1: Ingestie met Rechten (The Ingest Agent) De Ingest Agent leest niet alleen de tekst, maar ook de Access Control List (ACL) van het bestand. Input: Project_Begroting_2025.xlsx ACL: Read access voor group: Management, Finance. Action: 1. Chunk de tekst. 2. Genereer Vector Embedding. 3. Sla op in VectorDB met metadata: json { \"content\": \"Het budget is 1 miljoen...\", \"source\": \"Project_Begroting_2025.xlsx\", \"allowed_groups\": [\"Management\", \"Finance\"] } Stap 2: Zoeken met Context (The RAG Agent) Wanneer gebruiker Jan een vraag stelt, stuurt de frontend zijn JWT Token (van Keycloak) mee. 1. Extract Claims: De RAG Agent ziet in het token: Jan is lid van [\"Engineering\", \"Public\"]. 2. Search Query: De Agent construeert een filter-query voor de VectorDB: Vector: (De vraag van Jan) Filter: metadata.allowed_groups IN [\"Engineering\", \"Public\"] 3. Resultaat: Omdat Finance niet in de lijst van Jan staat, vindt de VectorDB 0 resultaten voor de begroting. De AI antwoordt: \"Ik kan die informatie niet vinden.\" --- üîÑ De Flow: Van Vraag naar Actie Scenario: \"Update de voorraadstatus gebaseerd op leveranciersnieuws\" 1. Vraag: Gebruiker vraagt: \"Zoek uit of onze leverancier X leveringsproblemen heeft en update zo nodig ons ERP systeem.\" 2. Router: Herkent vraag als \"Onderzoek + Actie\". Roept eerst RAG Agent en Web Agent aan. 3. Informatie Vergaring: Web Agent: Zoekt via MCP (Brave Search): \"Leverancier X faillissement nieuws\". -\u003e Vindt nieuwsartikel. RAG Agent: Zoekt intern contract: \"Contract Leverancier X\". -\u003e Vindt clausule over leveringsplicht (mits gebruiker recht heeft!). 4. Redenering: Router combineert info: \"Nieuws meldt stakingen, Contract zegt: 5 dagen boetevrij.\" Conclusie: \"Risico op vertraging.\" 5. Actie: Router roept Action Agent aan: \"Start 'Update Voorraad Risico' proces voor Vendor X.\" Action Agent: Valideert intentie. Roept MCP Tool aan: start_workflow(workflow_id=\"update_erp_risk\", vendor=\"X\"). 6. Uitvoering: Argo Workflow start. Roept de API van het ERP systeem aan om de vlag \"DeliveryRisk\" op \"High\" te zetten. --- üõ†Ô∏è Technische Componenten Vector Database: Qdrant of Weaviate. Deze ondersteunen native high-performance filtering op metadata. Ingest Framework: LangChain of LlamaIndex voor het lezen van files en splitsen van tekst. MCP Servers: mcp-filesystem: Voor het lezen van lokale shares/SharePoint. mcp-websearch: Voor toegang tot Brave/Bing. mcp-kubernetes: Voor het triggeren van Argo workflows. ‚úÖ Samenvatting Dit ontwerp garandeert dat de AI krachtig is (combi intern + extern), maar nooit lekt. De beveiliging zit niet in de \"prompt\" (\"Negeer geheime data\"), maar hard in de database query (\"Je KRIJGT geen geheime data\")."
  },
  {
    "title": "TO: Continuous Compliance \u0026 Lifecycle",
    "category": "design",
    "path": "design/compliance_lifecycle_monitoring.md",
    "content": "Technisch Ontwerp: Continuous Compliance \u0026 Lifecycle Monitoring üéØ Doelstelling Compliance is geen eenmalig vinkje bij de start van een project. Het is een continu proces dat loopt van het eerste idee tot de uiteindelijke uitfasering van een applicatie. Dit ontwerp beschrijft hoe wij Compliance by Design borgen over de gehele levenscyclus (Lifecycle Management), met specifieke aandacht voor de AI Act en het Algoritmeregister. --- üèóÔ∏è De \"Compliance Loop\" Architectuur We hanteren het \"Three Lines of Defense\" model, maar dan geautomatiseerd. mermaid graph TD subgraph Design [\"Fase 1: Design (De Belofte)\"] Spec(\"üìù Specificatie \u0026 AI Register\") Risk(\"‚öñÔ∏è Risk Assessment (AIIA)\") end subgraph Build [\"Fase 2: Build (De Validatie)\"] Code(\"üíª Code Creation\") Scan(\"üõ°Ô∏è Static Analysis (Trivy/Sonar)\") PolicyBuild(\"üëÆ Policy Check (Gatekeeper)\") end subgraph Run [\"Fase 3: Run (De Handhaving)\"] Deploy(\"üöÄ Deployment\") Enforce(\"üõë Runtime Enforcement (Kyverno)\") Monitor(\"üìà Drift \u0026 Audit (Prometheus/Loki)\") end subgraph Retire [\"Fase 4: Feedback \u0026 Retire\"] Audit(\"üìú Audit Trail\") Archief(\"üóÑÔ∏è Archivering \u0026 Deletion\") end %% Flow Spec --\u003e Risk Risk --\u003e |\"Approved\"| Code Code --\u003e Scan Scan --\u003e PolicyBuild PolicyBuild --\u003e |\"Compliant\"| Deploy PolicyBuild --\u003e |\"Violation\"| Code Deploy --\u003e Enforce Enforce --\u003e |\"Allowed\"| Monitor Monitor --\u003e |\"Drift Detected\"| Audit Audit --\u003e |\"Feedback\"| Design Monitor --\u003e |\"End of Life\"| Archief --- üîÑ Lifecycle Fases in Detail Fase 1: Design \u0026 Registratie (De Bron) Compliance begint bij de registratie in het AI Register. Zonder registratie, geen bouw. Actie: De Builder Agent helpt de gebruiker een algorithm.yaml aan te maken. Controle: Is het doel duidelijk omschreven? Is de risicoklasse (Laag/Hoog) bepaald? Is de eigenaar (mens) bekend? Fase 2: Build \u0026 Validatie (De Poort) Tijdens het bouwen (Tekton) checken we of de realiteit (code) overeenkomt met de belofte (design). SBOM Check: Gebruiken we veilige componenten? (Trivy). Quality Check: Is de code uitlegbaar en onderhoudbaar? (SonarQube). Dataset Check: Komt de gebruikte dataset hash (DVC) overeen met een geautoriseerde bron? Register Update: Bij succesvolle build wordt het versie-nummer in het AI Register automatisch opgehoogd. Fase 3: Runtime Handhaving (De Bewaker) Wat als iemand de regels probeert te omzeilen na deployment? Kyverno Policies: No Register, No Run: Een pod zonder geldig algorithm-id label wordt direct gestopt. Geofencing: Data gelabeld als \"Intern-Only\" mag niet op Cloud-nodes draaien. Model Monitoring: We monitoren niet alleen CPU/RAM, maar ook Model Drift. Signaal: \"Het AI model geeft vandaag 40% vaker 'Risico' aan dan gisteren. Is de data veranderd?\" -\u003e Trigger alert naar Data Scientist. Fase 4: Feedback \u0026 Retirement (De Schoonmaker) Compliance gaat ook over opruimen (Dataminimalisatie / AVG). Retentie Policies: Systeem verwijdert automatisch data uit MinIO die ouder is dan X jaar (tenzij gemarkeerd als 'Legal Hold'). Her-certificering: Elk jaar stuurt de Knowledge Bot een vraag naar de Eigenaar: \"Het algoritme 'Muskusrat V1' draait nog. Is dit nog actueel?\" Geen antwoord = Automatische uitfasering (Scale to 0). --- üõ°Ô∏è Borging: Het Dashboard Alle signalen komen samen in √©√©n Compliance Dashboard (in de Druppie UI). 1. Stoplicht Model: üü¢ Green: Alles compliant. üü† Orange: Waarschuwing (bijv. \"Certificaat verloopt bijna\" of \"Model drift \u003e 5%\"). üî¥ Red: Overtreding (blokkade actief). 2. Audit Trail (Traceability DB): De auditor (Accountant/Inspectie) kan met √©√©n druk op de knop de historie zien: \"Toon mij alle wijzigingen aan Algoritme X tussen 2024 en 2025, en wie deze heeft goedgekeurd.\" ‚úÖ Samenvatting Wij borgen compliance door het onderdeel te maken van de techniek: 1. Static: In de pipeline (Trivy/Sonar). 2. Dynamic: In het cluster (Kyverno). 3. Administratief: In het AI Register (gekoppeld aan GitOps). Hierdoor is \"voldoen aan de wet\" geen extra werk, maar het logische gevolg van het gebruik van het platform."
  },
  {
    "title": "TO: Automated Testing \u0026 Documentation",
    "category": "design",
    "path": "design/automated_testing_docs.md",
    "content": "Technisch Ontwerp: Automated Testing \u0026 Documentation üéØ Doelstelling Om de ontwikkelingssnelheid hoog te houden zonder in te boeten op kwaliteit, moet het test- en documentatieproces volledig geautomatiseerd zijn. Testen: Van unit tests tot end-to-end (E2E) gebruikersscenario's. Documentatie: Documentatie mag nooit achterlopen op de code (\"Living Documentation\"). --- üèóÔ∏è Automated Testing Strategy (The Testing Pyramid) We hanteren de 'Test Piramide' strategie, ge√Øntegreerd in de Tekton pipeline. mermaid graph TD subgraph Pyramid [\"De Test Piramide\"] E2E(\"üîº E2E (UI/Workflow) - 10%\") Integration(\"üîπ Integratie (API) - 20%\") Unit(\"üîª Unit (Code) - 70%\") end subgraph Tools [\"üõ†Ô∏è Tooling\"] Jest(\"Jest / PyTest (Unit)\") Newman(\"Postman / Newman (API)\") Playwright(\"Playwright (UI)\") end subgraph DocGen [\"üìÑ Documentation Generation\"] Pydoc(\"Sphinx / JSDoc\") Swagger(\"OpenAPI Generator\") Mermaid(\"Mermaid Live\") end Unit --\u003e Jest Integration --\u003e Newman E2E --\u003e Playwright Jest --\u003e |\"Genereer Coverage Report\"| DocGen Newman --\u003e |\"Genereer API Docs\"| Swagger 1. Unit Testing (De Basis) Wanneer: Bij elke commit. Wat: Test individuele functies en classes. Tool: PyTest (Python) of Jest (Node.js). Eis: Coverage \u003e 80% (bewaakt door SonarQube). 2. Integration Testing (De Koppeling) Wanneer: Na de build, v√≥√≥r deployment naar TEST. Wat: Test of de API endpoints goed reageren. Tool: Newman. We draaien een Postman collectie tegen de container. 3. End-to-End Testing (De Ervaring) Wanneer: Na deployment op TEST. Wat: Simuleer een echte gebruiker (\"Klik op knop X, verwacht Scherm Y\"). Tool: Playwright. Scenario: \"Drone piloot uploadt foto, AI anonimiseert, Ecoloog ziet kaart.\" --- üìÑ Automated Documentation Strategy (\"Docs-as-Code\") Documentatie wordt gegenereerd uit de bron, niet handmatig geschreven. Dit garandeert dat de docs altijd kloppen met de werkelijkheid. 1. API Documentatie (Swagger/OpenAPI) De code is de bron (@app.route('/api/v1/drones')). Tijdens de build genereert de pipeline automatisch een swagger.json. Deze wordt gepubliceerd naar Kong Developer Portal. Developers zien altijd de actuele API specs. 2. Code Documentatie Docstrings in de code leggen de intentie uit. Tools als Sphinx (Python) of TypeDoc (TS) genereren hieruit een leesbare HTML website (\"ReadTheDocs\"). 3. Architectuur Platen (Mermaid) Zoals in dit ontwerpdocument, gebruiken we Mermaid. Deze diagrammen staan als tekst in Markdown. GitHub/Gitea renderen ze direct. Hierdoor is Versiebeheer op diagrammen mogelijk (\"Diff Viewer\" toont: \"Pijl A wees eerst naar B, nu naar C\"). 4. Living Readme De Builder Agent update automatisch de README.md van een project met: Huidige Build Status (Badges). Laatste Test Coverage %. Link naar de actuele Swagger docs. --- üîÑ De Workflow 1. Developer: Commit code (feat: add new drone sensor). 2. Pipeline: Draait Unit Tests -\u003e ‚úÖ Genereert API Docs -\u003e üìÑ openapi.yaml Bouwt container. 3. Deployment (TEST): Update omgeving. 4. Verification: Draait Playwright E2E tests -\u003e ‚úÖ Publiseert docs naar het interne kennisportaal. ‚úÖ Samenvatting Door testen en documentatie te automatiseren: 1. Verhogen we het vertrouwen: We weten dat het werkt, we hopen het niet. 2. Verlagen we drempels: Nieuwe ontwikkelaars hebben altijd actuele documentatie. 3. Besparen we tijd: Geen handmatige Word-documenten meer updaten."
  },
  {
    "title": "TO: Builder Agent",
    "category": "design",
    "path": "design/builder_agent.md",
    "content": "AI‚ÄëBuilder Agent Inleiding Een AI‚ÄëBuilder Agent is een interactieve software-agent die samen met de gebruiker een specificatie (spec) opstelt en verfijnt, en vervolgens √©√©n of meerdere LLM‚Äôs inzet om op basis van die specificatie en beschikbare skills (tools/capabilities) code te schrijven, te testen en iteratief te verbeteren. Het doel is: van idee ‚Üí heldere spec ‚Üí werkende implementatie, met controle, auditability en herhaalbaarheid. Dit document is gelaagd opgebouwd: - üî∞ Beginner: wat is een AI‚ÄëBuilder en hoe werkt het in simpele termen? - üß† Expert: architectuur, state machine, guardrails, skill contracts en agentic workflow patterns Mermaid-diagrammen worden gebruikt voor uitleg en voorbeelden. --- 1. Wat is een AI‚ÄëBuilder Agent? (Beginner) Een AI‚ÄëBuilder Agent is: \u003e Een ‚Äúbouwassistent‚Äù die samen met jou uitzoekt wat je precies wil, en daarna software bouwt op basis van die afspraken. In plaats van dat je √©√©n prompt geeft (‚Äúmaak een app‚Äù), werkt de AI‚ÄëBuilder zo: 1. Vraagt door tot de spec duidelijk is 2. Vat samen wat er gebouwd moet worden 3. Laat een code‚ÄëLLM code genereren volgens de spec 4. Runt tests en checkt kwaliteit 5. Itereert totdat het klopt --- 2. Waarom spec-driven? (Beginner) Zonder spec-driven aanpak: - onduidelijke requirements - wisselende output - lastig te testen - moeilijk te onderhouden Met een spec: - iedereen is het eens over de scope - je krijgt consistente code - je kunt gates en tests toevoegen - je kunt later makkelijk uitbreiden --- 3. Hoofdrollen in het systeem Een AI‚ÄëBuilder omgeving bestaat meestal uit: - User: levert requirements, feedback, domeinkennis - AI‚ÄëBuilder Agent: spec + planning + besluitvorming - Code LLM: schrijft code op basis van spec + context - Skill Layer: tools (repo lezen, build uitvoeren, tests draaien, linten, deployen) - Artifact Store: code, testresultaten, logs, releases mermaid flowchart LR U[Gebruiker] \u003c--\u003e A[AI‚ÄëBuilder Agent] A --\u003e L[Code LLM] A --\u003e S[Skills / Tools] S --\u003e R[Repo / Artifacts] L --\u003e R R --\u003e A --- 4. Kernverantwoordelijkheden van de AI‚ÄëBuilder Agent Voor beginners - Doorvragen en de spec duidelijk maken - Taken opdelen in stappen - Code laten genereren - Testen laten draaien - Feedback verwerken Voor experts - Spec governance (versioning, approvals) - Risk management (scope creep, security) - Orchestratie van multi-agent flows - Deterministische output via structured prompting - Evaluatie en kwaliteitsgates (tests, lint, policies) --- 5. De ‚ÄúSpec Refinement Loop‚Äù (Beginner) De agent refine‚Äôt de spec in korte iteraties: mermaid flowchart TD Idea[Idee] --\u003e Q[Agent stelt vragen] Q --\u003e Spec[Spec v0.1] Spec --\u003e Review[Gebruiker reviewt] Review --\u003e Update[Agent past spec aan] Update --\u003e Spec2[Spec v0.2] Spec2 --\u003e Ready{Spec klaar?} Ready --\u003e|Nee| Q Ready --\u003e|Ja| Build[Start build] Belangrijk: - De agent stelt vragen om ambigu√Øteit weg te nemen - De spec wordt steeds concreter - Elke stap is traceerbaar (versies) --- 6. Van spec naar code (Agentic AI) Wanneer de spec ‚Äúready‚Äù is, schakelt de AI‚ÄëBuilder naar implementatie: mermaid flowchart TD Spec[Final Spec] --\u003e Plan[Plan / Tasks] Plan --\u003e Gen[Code laten genereren door LLM] Gen --\u003e Apply[Code toepassen in repo] Apply --\u003e Test[Test suite] Test --\u003e Gate{Alles groen?} Gate --\u003e|Ja| Deliver[Opleveren] Gate --\u003e|Nee| Fix[Debug + patch] Fix --\u003e Gen De agent werkt hier ‚Äúagentic‚Äù: - maakt een plan - voert acties uit via tools/skills - evalueert resultaten - past aan - herhaalt --- 7. Skill Contracts (Expert) De AI‚ÄëBuilder Agent gebruikt skills als gestandaardiseerde capabilities. Een skill heeft een contract: - Inputs (parameters) - Processing logic (wat doet de skill) - Outputs (resultaten, status, artifacts) - Failure modes (wat kan misgaan) - Safety constraints (wat mag niet) Voorbeeld (conceptueel): yaml skill: name: run_tests inputs: command: string outputs: status: pass|fail report_path: string constraints: timeout_seconds: 900 no_network: true Door skills te gebruiken kan de agent: - betrouwbaar acties uitvoeren - output structureren - beslissingen nemen op basis van resultaten --- 8. Guardrails \u0026 kwaliteitsgates (Expert) Een AI‚ÄëBuilder Agent hoort niet zomaar code te ‚Äúspuwen‚Äù. Het moet kwaliteit borgen. Typische gates - Unit tests (must pass) - Linting (must pass) - Type checks (must pass) - Security scan (no critical) - Coverage threshold (bijv. ‚â• 80%) mermaid flowchart LR Code --\u003e Lint{Lint OK?} Lint --\u003e|No| Fix Lint --\u003e|Yes| Tests{Tests OK?} Tests --\u003e|No| Fix Tests --\u003e|Yes| Sec{Security OK?} Sec --\u003e|No| Fix Sec --\u003e|Yes| Ship[Ready] --- 9. Multi-model routing (Expert) Een AI‚ÄëBuilder kan meerdere modellen gebruiken: - Reasoning model: spec refinement, planning, debugging - Coding model: code generation - Review model: code review, style, security checks - Eval model: test failure classification, flaky detection mermaid flowchart TD Agent[AI‚ÄëBuilder] --\u003e R[Reasoning LLM] Agent --\u003e C[Coding LLM] Agent --\u003e V[Verif"
  },
  {
    "title": "TO: Foundry",
    "category": "design",
    "path": "design/foundry.md",
    "content": "Foundry üéØ Doelstelling Microsoft Foundry (voorheen Azure AI Studio) fungeert als de centrale \"Agent Factory\" en \"Control Plane\" voor het Druppie platform. Het consolideert de creatie, het beheer en de beveiliging van AI-agenten in √©√©n omgeving. Waar de Build Plane het conceptuele domein is, is Foundry het concrete platform waarop dit domein draait. üìã Functionele Specificaties 1. Spec-Driven Agent Creatie (Agent-as-Code) - Repo-based: Agenten worden niet handmatig in een portal geklikt, maar gedefinieerd in code (YAML). - Automated Pipeline: Een CI/CD proces (Agent Factory Pipeline) vertaalt deze YAML-definities naar API-calls naar de Azure AI Agent Service. - Validatie: De pipeline valideert specs tegen beleidsregels (bijv. \"Mag deze afdeling GPT-4o gebruiken?\"). 2. Agent Management \u0026 Runtime - Hosting: Faciliteert de runtime omgeving voor agenten via de Azure AI Agent Service. - Model Hub: Biedt centrale toegang tot modellen (OpenAI, Phi, Llama) via een eenduidige API. - Tooling: Beheert de integratie met tools via OpenAPI definities en Python functies. 3. Evaluatie \u0026 Monitoring - Evaluation Flows: Automatisch testen van agent-responses tegen ground-truth datasets om kwaliteit/hallucinaties te meten. - Tracing: Volledige traceerbaarheid van elke stap (Prompt -\u003e LLM -\u003e Tool -\u003e Response) via integratie met Azure Monitor/Purview. üîß Technische Requirements - API-First: Alle interactie met Foundry verloopt via de Foundry SDK of REST API voor automatisering. - Private Networking: Foundry resources (Hubs, Projects) zijn verbonden via Private Endpoints en afgeschermd van het publieke internet. - Identity: Diepe integratie met Entra ID voor RBAC op project- en agent-niveau. üîí Security \u0026 Compliance - Data Exfiltration Protection: Policy-regels voorkomen dat data naar niet-goedgekeurde URL's wordt gestuurd. - Model Safety: Standaard content filters (Hate, Self-harm, Violence) zijn actief op alle endpoints. üîå Interacties (Factory Process) | Stap | Actie | Component | | :--- | :--- | :--- | | Commit | Dev pusht agent.yaml | Git | | Validate | Pipeline checkt beleid | Build Agent | | Deploy | Pipeline roept API aan | Foundry API | | Register | Agent ID opgeslagen | Agent Registry | üèóÔ∏è Relaties tot andere blokken - Host voor: Build Plane Domein. - Levert Runtime aan: Runtime Domein. - Beveiligd door: Compliance Layer."
  },
  {
    "title": "TO: Runtime",
    "category": "design",
    "path": "design/runtime_implementation.md",
    "content": "Kubernetes Runtime Inleiding Dit document beschrijft de Kubernetes runtime: de infrastructuurlaag waarop applicaties (bouwblokken) geautomatiseerd, veilig en schaalbaar worden uitgevoerd. Het document is bewust opgebouwd in lagen, zodat zowel beginners als experts / platform engineers waardevolle inzichten krijgen. - Beginners krijgen begrip van wat Kubernetes is en doet - Experts krijgen architectuur, control-loops en ontwerpprincipes --- 1. Wat is een Kubernetes Runtime? (Beginner) Een Kubernetes runtime is: \u003e Een geautomatiseerde omgeving waarin containers worden gestart, bewaakt, geschaald en hersteld zonder menselijke tussenkomst. Je hoeft als gebruiker niet te weten: - Op welke server je applicatie draait - Wanneer een container opnieuw start - Hoe verkeer wordt gerouteerd Dat regelt Kubernetes voor je. --- 2. Hoofdcomponenten van een Kubernetes Cluster Overzicht (conceptueel) mermaid flowchart LR User[Gebruiker / CI-CD] --\u003e API[Kubernetes API] API --\u003e Scheduler API --\u003e Controller[Controllers] Scheduler --\u003e Node1[Node] Scheduler --\u003e Node2[Node] Controller --\u003e Node1 Controller --\u003e Node2 Componenten uitgelegd Kubernetes API (Control Plane) - Het centrale aansturingspunt - Alle acties lopen via de API (kubectl, CI/CD, operators) - Bewaakt de desired state Scheduler - Bepaalt waar een Pod wordt geplaatst - Houdt rekening met: - CPU / Memory - Affiniteit / anti-affiniteit - Taints \u0026 tolerations Controllers - Controleren continu: \u003e ‚ÄúIs de werkelijkheid gelijk aan wat gewenst is?‚Äù - Voorbeelden: - Deployment controller - ReplicaSet controller - Node controller --- 3. Nodes en Pods Nodes - Machines (VM of bare-metal) - Draaien: - container runtime (containerd) - kubelet - networking (CNI) Pods - Kleinste deploybare eenheid - Bevat: - E√©n of meerdere containers - Shared netwerk - Shared storage (volumes) mermaid graph TD Pod --\u003e Container1 Pod --\u003e Container2 Pod --\u003e Volume --- 4. Netwerk en Verkeer Service Discovery (Beginner) mermaid flowchart LR PodA --\u003e Service Service --\u003e PodB Service --\u003e PodC - Services zorgen voor: - Stabiel IP/DNS - Load balancing Network Policies (Expert) - Zero-trust binnen het cluster - Verkeer is expliciet toegestaan - Zonder policy: alles open mermaid flowchart LR Frontend --\u003e|Allowed| Backend Backend -.-\u003e|Blocked| Database --- 5. Deployments en Scaling Deployment Lifecycle mermaid stateDiagram-v2 [] --\u003e Created Created --\u003e Running Running --\u003e Scaling Scaling --\u003e Running Running --\u003e Failed Failed --\u003e Restarting Restarting --\u003e Running Scaling - Horizontal Pod Autoscaler (HPA) - Triggers: - CPU - Memory - Custom metrics --- 6. Failover en Self-Healing Kubernetes is self-healing: - Pod crasht ‚Üí nieuwe pod - Node valt weg ‚Üí pods opnieuw gepland - Healthcheck faalt ‚Üí container restart mermaid flowchart TD Pod --\u003e|Crash| Controller Controller --\u003e|New Pod| Node --- 7. Runtime als Control Loop (Expert) De kern van Kubernetes is een control loop: mermaid flowchart LR Desired[Desired State] --\u003e Observe Observe --\u003e Compare Compare --\u003e Act Act --\u003e Observe - Declaratief model - Geen scripts, maar intentie - Altijd convergent naar gewenst gedrag --- 8. Security \u0026 Compliance (Expert) Basisprincipes - Least privilege (RBAC) - Network isolation - Immutable containers Componenten - RBAC - NetworkPolicy - PodSecurity - Secrets management --- 9. Samenvatting Voor beginners - Kubernetes regelt alles rondom draaien van containers - Jij beschrijft wat je wilt, niet hoe Voor experts - Kubernetes is een gedistribueerde control-plane - Alles draait om: - Desired state - Control loops - Idempotente acties"
  },
  {
    "title": "TO: Role Based Access Control (RBAC)",
    "category": "design",
    "path": "design/rbac.md",
    "content": "Kubernetes Role Based Access Control (RBAC) Inleiding RBAC (Role-Based Access Control) is het autorisatiemechanisme van Kubernetes. Het bepaalt wie (subject) wat (actie) mag doen op welke resources binnen het cluster. Dit document is gelaagd opgebouwd: - üî∞ Beginners leren wat RBAC is en waarom het nodig is - üß† Experts krijgen inzicht in het autorisatiemodel, evaluatielogica en ontwerpkeuzes --- 1. Wat is RBAC? (Beginner) RBAC beantwoordt √©√©n simpele vraag: \u003e ‚ÄúMag deze gebruiker dit doen?‚Äù Voorbeelden: - Mag Alice pods bekijken? - Mag een CI/CD pipeline deployments aanpassen? - Mag een applicatie secrets lezen? Zonder RBAC: - Iedereen kan alles - Grote security-risico‚Äôs Met RBAC: - Rechten zijn expliciet - Toegang is beperkt en controleerbaar --- 2. De Basisbegrippen van RBAC (Beginner) RBAC bestaat uit vier kernobjecten: mermaid flowchart LR Subject --\u003e Role Role --\u003e Rule Subject --\u003e Binding 1. Subject ‚Äì Wie? Een subject is een identiteit: - Gebruiker - Groep - ServiceAccount (meest gebruikt door applicaties) 2. Role / ClusterRole ‚Äì Wat mag je doen? Een role bevat regels: - Welke resources (pods, services, secrets) - Welke acties (get, list, create, update, delete) - Role ‚Üí namespace-specifiek - ClusterRole ‚Üí cluster-breed 3. RoleBinding / ClusterRoleBinding ‚Äì Waar geldt dit? Een binding koppelt: - Een subject - Aan een role - In een scope (namespace of cluster) --- 3. Eenvoudig Voorbeeld (Beginner) \u003e Een applicatie mag alleen pods lezen in namespace app. yaml apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: pod-reader namespace: app rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\"] yaml apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: bind-pod-reader namespace: app subjects: - kind: ServiceAccount name: app-sa roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io --- 4. Hoe Kubernetes RBAC Beslissingen Neemt (Expert) RBAC werkt als een autorisation pipeline: mermaid flowchart TD Request[API Request] --\u003e AuthN[Authentication] AuthN --\u003e AuthZ[RBAC Authorization] AuthZ --\u003e|Allowed| API AuthZ --\u003e|Denied| Reject Stap-voor-stap: 1. Authenticatie: Wie ben je? 2. Autorisatie (RBAC): - Zoek alle bindings voor het subject - Verzamel alle bijbehorende roles - Combineer alle regels - E√©n allow is voldoende ‚Üí toegestaan 3. Geen expliciete deny bestaat in RBAC --- 5. Evaluatielogica (Expert) RBAC is: - Additief - Stateless - Order-onafhankelijk Belangrijke gevolgen: - Meer bindings = meer rechten - Rechten worden nooit ‚Äúontzegd‚Äù, alleen niet toegekend - Least privilege vereist discipline mermaid flowchart LR RoleA --\u003e Rights RoleB --\u003e Rights RoleC --\u003e Rights --- 6. ClusterRole vs Role (Expert) | Aspect | Role | ClusterRole | |------|------|-------------| | Scope | Namespace | Cluster | | Use-case | App-specifiek | Infra / platform | | Resources | Namespaced | Namespaced + cluster-wide | Let op: Een ClusterRole kan via een RoleBinding alsnog namespace-beperkt worden toegepast. --- 7. ServiceAccounts en Workloads (Expert) Best practices: - Elke workload krijgt eigen ServiceAccount - Nooit default gebruiken - Tokens alleen waar nodig - Combineer met NetworkPolicy mermaid flowchart LR Pod --\u003e ServiceAccount ServiceAccount --\u003e RoleBinding RoleBinding --\u003e Role --- 8. Security Best Practices Voor beginners - Gebruik zo min mogelijk rechten - Begin met get / list - Gebruik namespaces Voor experts - Audit RBAC regelmatig - Gebruik tooling voor RBAC-visualisatie - Combineer RBAC met: - NetworkPolicies - PodSecurity - Admission controllers --- 9. Veelgemaakte Valkuilen - ClusterRoleBinding voor applicaties - Wildcards () in verbs/resources - Rechten stapelen zonder overzicht - Geen documentatie van intentie --- 10. Samenvatting Beginner - RBAC bepaalt wie wat mag - Rollen + bindings = toegang Expert - RBAC is een additief autorisatiemodel - Ontwerp voor least privilege - RBAC is √©√©n laag in defense-in-depth"
  },
  {
    "title": "TO: MCP Interface",
    "category": "design",
    "path": "design/mcp_interface.md",
    "content": "MCP Server Inleiding Een MCP Server (Model Context Protocol Server) is een runtime-component die fungeert als brug tussen een AI‚Äëmodel en externe systemen, data en tools. De MCP Server stelt een AI-model in staat om gestructureerde context op te vragen, acties uit te voeren en resultaten terug te geven, op een gecontroleerde en reproduceerbare manier. Dit document is gelaagd opgebouwd: - üî∞ Beginners begrijpen wat een MCP Server is en waarom je hem gebruikt - üß† Experts krijgen inzicht in architectuur, control‚Äëloops, security en extensiepatronen Binnen dit document worden Mermaid-diagrammen gebruikt om de werking visueel te maken. --- 1. Wat is een MCP Server? (Beginner) Een MCP Server is: \u003e Een tussenlaag die een AI‚Äëmodel laat samenwerken met de echte wereld \u003e (zoals API‚Äôs, bestanden, databases of systemen) Zonder MCP: - Een AI kan alleen tekst genereren - Geen directe toegang tot data of acties Met MCP: - Een AI kan tools gebruiken - Context ophalen - Acties uitvoeren - Resultaten interpreteren --- 2. Hoog Overzicht (Beginner) mermaid flowchart LR User --\u003e LLM[AI Model] LLM --\u003e MCP[MCP Server] MCP --\u003e Tool1[API / Tool] MCP --\u003e Tool2[Database] MCP --\u003e Tool3[Filesystem] De MCP Server: - Ontvangt verzoeken van het model - Roept tools aan - Geeft gestructureerde antwoorden terug --- 3. Kernverantwoordelijkheden van een MCP Server Voor beginners - Context ophalen - Acties uitvoeren - Antwoorden structureren Voor experts - Capability exposure - Input/output validatie - Security enforcement - Observability - Deterministische uitvoering --- 4. Conceptuele Bouwblokken Overzicht mermaid flowchart TD Request --\u003e Router Router --\u003e ToolRegistry ToolRegistry --\u003e Executor Executor --\u003e Tool Tool --\u003e Executor Executor --\u003e Response Componenten 1. Request Handler - Ontvangt MCP‚Äëverzoeken - Valideert structuur en intentie 2. Router - Bepaalt welke tool nodig is - Matcht intentie ‚Üí capability 3. Tool Registry - Catalogus van beschikbare tools - Metadata: naam, schema, permissies 4. Executor - Voert tool-aanroepen uit - Beheert timeouts, retries en fouten 5. Response Formatter - Zet resultaten om naar MCP‚Äëcompatibel formaat --- 5. Tool Interactie Model mermaid sequenceDiagram participant Model participant MCP participant Tool Model-\u003e\u003eMCP: Tool request MCP-\u003e\u003eTool: Execute action Tool--\u003e\u003eMCP: Result / Error MCP--\u003e\u003eModel: Structured response Belangrijk: - De MCP Server vertaalt intentie naar actie - Het model voert zelf geen side effects uit --- 6. MCP als Control Loop (Expert) Net als Kubernetes werkt MCP als een control loop: mermaid flowchart LR Intent[Model Intent] --\u003e Validate Validate --\u003e Execute Execute --\u003e Observe Observe --\u003e Adjust Adjust --\u003e Validate Eigenschappen: - Deterministisch - Herhaalbaar - Observeerbaar - Veilig afgebakend --- 7. Security Model (Expert) Principes - Least privilege - Explicit allow - Geen implicit trust Mechanismen - Tool‚Äëlevel permissions - Input schema validatie - Output filtering - Rate limiting - Audit logging mermaid flowchart TD Model --\u003e|Request| MCP MCP --\u003e|Allowed| Tool MCP --\u003e|Denied| Reject --- 8. Foutafhandeling \u0026 Betrouwbaarheid Typische fouten - Ongeldige input - Timeouts - Tool failures - Partial responses MCP-verantwoordelijkheid - Fouten isoleren - Duidelijk terugrapporteren - Geen ongedefinieerd gedrag --- 9. Best Practices Voor beginners - Begin met read‚Äëonly tools - Houd tools klein en eenduidig - Log alles Voor experts - Idempotente tools - Scheiding tussen intent \u0026 uitvoering - Contract‚Äëfirst schemas - Observability per tool - Simuleer falen --- 10. Veelgemaakte Valkuilen - Te brede tools - Businesslogica in het model - Geen validatie - Onbegrensde tool‚Äëtoegang - Geen auditing --- 11. Samenvatting Beginner - MCP laat AI samenwerken met systemen - De server voert acties uit, niet het model Expert - MCP is een gecontroleerde execution‚Äëlaag - Ontwerp voor determinisme, veiligheid en herhaalbaarheid - Zie MCP als een runtime, niet als een script"
  },
  {
    "title": "TO: Dynamic Slot",
    "category": "design",
    "path": "design/dynamic_slot.md",
    "content": "Dynamic Slot - Het deployen van applicaties Inleiding Dit document beschrijft hoe een applicatie wordt gedeployed, via het web bereikbaar wordt gemaakt en hoe omgegaan wordt met test- en productieomgevingen. Het document is gelaagd opgebouwd: - üî∞ Beginners leren het end-to-end pad van code ‚Üí webpagina - üß† Experts krijgen inzicht in omgevingsscheiding, deploymentstrategie√´n en releasebeheer Mermaid-diagrammen worden gebruikt om de werking visueel te maken. --- 1. Wat betekent ‚Äúeen applicatie deployen‚Äù? (Beginner) Een applicatie deployen betekent: \u003e Je code beschikbaar maken zodat gebruikers deze via het web kunnen gebruiken. In Kubernetes houdt dit in: 1. Je applicatie draait in een container 2. Kubernetes start en bewaakt deze container 3. Verkeer van buiten wordt veilig naar de applicatie geleid --- 2. Van Code tot Container Stap 1 ‚Äì Applicatiecode - Backend (bijv. API) - Frontend (bijv. webapp) - Of een combinatie Stap 2 ‚Äì Container Image De code wordt verpakt in een container image. mermaid flowchart LR Code --\u003e Build[Build Image] Build --\u003e Image[Container Image] Het image bevat: - De applicatie - Runtime (bijv. Node, Python, Java) - Configuratie defaults --- 3. Applicatie in Kubernetes (Beginner) Deployment Een Deployment beschrijft: - Welke image moet draaien - Hoeveel replicas - Hoe updates verlopen mermaid flowchart TD Deployment --\u003e Pod1 Deployment --\u003e Pod2 Kubernetes zorgt voor: - Starten van pods - Herstarten bij fouten - Rolling updates --- 4. Applicatie Bereikbaar via het Web Service (intern) Een Service: - Geeft een vast adres (DNS/IP) - Verdeelt verkeer over pods mermaid flowchart LR Service --\u003e PodA Service --\u003e PodB Gebruikt binnen het cluster. --- Ingress (extern ‚Äì webtoegang) Een Ingress: - Maakt de applicatie bereikbaar via HTTP/HTTPS - Regelt routing op domeinnaam en pad mermaid flowchart LR Browser --\u003e Ingress Ingress --\u003e Service Voorbeeld: - https://app.example.nl - https://api.example.nl --- 5. Test en Productie Omgevingen (Beginner) Waarom scheiden? - Fouten in test mogen geen impact hebben op productie - Nieuwe versies eerst veilig uitproberen Meest gebruikte aanpak: namespaces mermaid flowchart LR Dev[Namespace: test] Prod[Namespace: productie] Elke omgeving heeft: - Eigen pods - Eigen services - Eigen configuratie --- 6. Deployment Flow met Test ‚Üí Productie mermaid flowchart TD Commit --\u003e Build Build --\u003e DeployTest[Test omgeving] DeployTest --\u003e TestOK{Tests OK?} TestOK --\u003e|Ja| DeployProd[Productie] TestOK --\u003e|Nee| Fix --- 7. Configuratie per Omgeving (Expert) ConfigMaps \u0026 Secrets - ConfigMap: niet-gevoelige configuratie - Secret: wachtwoorden, tokens, certificaten mermaid flowchart LR Config --\u003e Pod Secret --\u003e Pod Per omgeving verschillend: - Database URL - API keys - Feature flags --- 8. Updates en Releases (Expert) Rolling Updates - Pods worden √©√©n voor √©√©n vervangen - Geen downtime Blue/Green of Canary - Nieuwe versie eerst beperkt beschikbaar - Terugrollen is eenvoudig mermaid stateDiagram-v2 v1 --\u003e v2 v2 --\u003e v1 : rollback --- 9. Beveiliging en Toegang (Expert) - HTTPS via Ingress - RBAC voor deployment-rechten - NetworkPolicies tussen applicaties - Secrets nooit in images --- 10. Veelgemaakte Valkuilen - Geen omgevingsscheiding - Handmatig deployen in productie - Configuratie in code - Geen health checks - Geen rollback-strategie --- 11. Samenvatting Beginner - Code ‚Üí container ‚Üí Kubernetes ‚Üí web - Kubernetes regelt starten en herstellen - Ingress maakt de app bereikbaar Expert - Omgevingen zijn strikt gescheiden - Releases zijn gecontroleerd en terug te draaien - Configuratie en security zijn first-class citizens"
  },
  {
    "title": "TO: Git",
    "category": "design",
    "path": "design/git.md",
    "content": "Git \u0026 Kubernetes Inleiding Dit document legt uit hoe je Git gebruikt om applicaties beheerst naar productie te brengen in een Kubernetes-omgeving. We bouwen op van basisprincipes (beginners) naar een volwassen GitOps-aanpak (experts), inclusief Mermaid-diagrammen. Doel: een herhaalbare, auditeerbare en veilige route van code ‚Üí test ‚Üí productie. --- 1. Wat is Git? (Beginner) Git is een versiebeheersysteem: het bewaart de geschiedenis van je bestanden. Git helpt je om: - Wijzigingen te volgen (wie, wat, wanneer, waarom) - Samen te werken (branches, pull requests) - Reproducible releases te maken (tags, releases) - Terug te rollen naar een werkende versie Begrippen (kort) - Repository: map met code + geschiedenis - Commit: opgeslagen wijziging - Branch: parallelle lijn (bijv. feature/x, main) - Pull Request (PR): voorstel om wijzigingen te mergen - Tag: ‚Äúlabel‚Äù op een commit, vaak voor releases (bijv. v1.2.0) --- 2. Van Git naar Kubernetes: twee paden Je kunt Kubernetes op twee manieren ‚Äúvoeden‚Äù vanuit Git: 1. CI/CD push model (klassiek) - Pipeline pusht manifests naar cluster (kubectl apply) 2. GitOps pull model (aanbevolen) - Cluster pullt desired state uit Git en reconcilieert continu mermaid flowchart LR Git[Git Repo] --\u003e|CI/CD push| ClusterA[(Kubernetes)] Git --\u003e|GitOps pull| Controller[GitOps Controller] Controller --\u003e ClusterB[(Kubernetes)] --- 3. Basisflow: Code ‚Üí Image ‚Üí Deploy (Beginner) Stap-voor-stap 1. Developer commit code naar Git 2. Pipeline bouwt een container image 3. Image wordt opgeslagen in een registry 4. Kubernetes krijgt nieuwe desired state (manifests/Helm) mermaid flowchart TD Dev[Developer] --\u003e|git commit| Git[(Git Repo)] Git --\u003e|CI build| Build[Build \u0026 Test] Build --\u003e|docker build| Image[Container Image] Image --\u003e Registry[(Image Registry)] Build --\u003e Deploy[Update Kubernetes manifests] Deploy --\u003e Cluster[(Kubernetes Cluster)] --- 4. Repo-structuur voor Kubernetes (Beginner ‚Üí Intermediate) Veel teams gebruiken 2 repos: A) App repo (code) Bevat: - applicatiecode - Dockerfile - tests - pipeline config B) Config repo (deployments) Bevat: - Kubernetes manifests / Helm / Kustomize overlays - omgevingsconfig (test/prod) - policies (optioneel) mermaid flowchart LR AppRepo[App repo\u003cbr/\u003ecode + Dockerfile] --\u003e Image ConfigRepo[Config repo\u003cbr/\u003emanifests + env overlays] --\u003e Desired[Desired State] Waarom 2 repos? - App teams kunnen code releasen zonder productieconfig te overschrijven - Platform/security kan config-review afdwingen --- 5. Test vs Productie: omgevingen beheren Populaire keuzes - Namespaces: test en prod in hetzelfde cluster - Clusters: apart testcluster en prodcluster (sterker, duurder) Voorbeeld met namespaces: mermaid flowchart LR Git --\u003e TestNS[Namespace: test] Git --\u003e ProdNS[Namespace: prod] Belangrijk - Test en prod hebben andere configuratie (URLs, feature flags, secrets) - Je promoot changes gecontroleerd: eerst test, dan prod --- 6. GitOps (Recommended) ‚Äì Hoe werkt dat? Wat is GitOps? GitOps is een werkwijze waarbij: \u003e Git de enige bron van waarheid is voor wat er in Kubernetes draait. Een GitOps controller (bijv. Argo CD / Flux) draait in het cluster en: - leest de gewenste state uit Git - vergelijkt dit met de echte state - voert reconciliatie uit (apply/rollback) mermaid flowchart TD Git[(Git: desired state)] --\u003e Poll[GitOps Controller\u003cbr/\u003epoll/webhook] Poll --\u003e Diff{Diff?} Diff --\u003e|Ja| Apply[Apply/Sync] Diff --\u003e|Nee| Sleep[Wacht] Apply --\u003e Cluster[(Kubernetes)] Cluster --\u003e Observe[Observe state] Observe --\u003e Diff Waarom is dit sterk? - Audit trail in Git - Rollback = revert commit - Drift-detectie (handmatige wijzigingen vallen op) - Declaratief + reproduceerbaar --- 7. Releasebeheer: ‚Äúbeheerst naar productie‚Äù (Beginner ‚Üí Expert) Simpele promotie (beginner) - PR naar main triggert deploy naar test - Handmatige ‚Äúpromote‚Äù PR triggert deploy naar productie mermaid flowchart TD Feature[feature branch] --\u003e PR1[PR naar main] PR1 --\u003e Test[Deploy naar test] Test --\u003e Gate{Tests OK?} Gate --\u003e|Ja| PR2[Promote PR\u003cbr/\u003enaar prod overlay] PR2 --\u003e Prod[Deploy naar productie] Gate --\u003e|Nee| Fix[Fix + nieuwe commit] Volwassen promotie (expert) - Immutable versioning: image tags zijn versies (bijv. v1.3.7), nooit latest - Environment overlays: Kustomize/Helm values per omgeving - Approval gates: security/ops approvals voor prod - Progressive delivery: canary/blue-green met metriek-gates - Automated rollback bij SLO breach --- 8. Concreet voorbeeld: overlays met Kustomize (Intermediate) Repo-structuur (voorbeeld): text config-repo/ base/ deployment.yaml service.yaml ingress.yaml kustomization.yaml overlays/ test/ kustomization.yaml values.yaml (optioneel) prod/ kustomization.yaml values.yaml (optioneel) Conceptueel: mermaid flowchart LR Base[base manifests] --\u003e TestOverlay[test overlay] Base --\u003e ProdOverlay[prod overlay] TestOverlay --\u003e TestCluster[(K8s test)] ProdOverlay --\u003e ProdCluster[(K8s prod)] Promotie = dezelfde base + andere overlay met nieuwe image tag"
  },
  {
    "title": "FO: Vergunning zoeker",
    "category": "design",
    "path": "design/vergunning_zoeker.md",
    "content": "Functioneel Ontwerp: Vergunning zoeker üéØ Doelstelling Veel oude vergunningen (PDFs, Word-documenten) staan nog op file-shares (S-schijf, SharePoint) in plaats van in het offici√´le Zaaksysteem. Dit maakt ze onvindbaar, juridisch kwetsbaar en niet compliant met de Archiefwet. De Vergunning zoeker is een AI-gedreven flow die deze \"verloren\" vergunningen opspoort, analyseert, registreert in het Zaaksysteem en vervolgens opruimt. --- üë• Gebruikersverhaal \u003e \"Als medewerker Vergunningverlening wil ik dat oude vergunningen automatisch op de juiste plek in het Zaaksysteem komen, zodat ik niet handmatig duizenden mappen hoef door te spitten.\" --- üèóÔ∏è Proces Flow (High Level) mermaid graph TD Start(\"üü¢ Start Proces\") --\u003e Search(\"üïµÔ∏è AI Zoekt Bestanden\") Search --\u003e Classify{{\"Is dit een Vergunning?\"}} Classify -- Nee --\u003e Skip(\"‚è≠Ô∏è Negeer bestand\") Classify -- Ja --\u003e Extract(\"üß† AI Extractie (LLM)\") Extract --\u003e Validate{{\"Validatie (Human-in-Loop?)\"}} Validate -- Afgekeurd --\u003e Manual(\"üë∑ Handmatige Actie\") Validate -- Goedgekeurd --\u003e Register(\"üìù Registreer in Zaaksysteem\") Register -- Succes --\u003e Archive(\"üóëÔ∏è Verwijder van Schijf\") Archive --\u003e Log(\"‚úÖ Audit Log\") --- üß© Componenten \u0026 Werking We gebruiken de Secure Agentic RAG Network architectuur. 1. De Speurder (Ingest Agent + MCP Filesystem) Taak: Scant mappen op de netwerkschijf (SMB). Filter: Zoekt naar bestandsnamen zoals vergunning, beschikking, .pdf. Security: De agent gebruikt de rechten van een \"Service Account\" dat specifiek toegang heeft tot deze mappen. 2. De Analist (Internal AI Agent) Taak: Leest de inhoud van het document (OCR indien nodig). Classificatie: Bepaal Document Type: Watervergunning, Leggerwijziging, Ontheffing. Bepaal Metadata: Huisnummer, Perceel, Datum, Aanvrager. Privacy: Detecteer BSN nummers (via AI Anonymizer logica). 3. De Beslisser (Policy Engine) Check: Is de \"Vertrouwen Score\" van de AI hoog genoeg (\u003e 90%)? Ja: Volledig automatisch verwerken. Nee: Stuur taak naar \"Mens in de Loop\" werklijst in Druppie UI. 4. De Uitvoerder (Action Agent + MCP Zaaksysteem) Actie 1: Roep API van Zaaksysteem (bijv. PowerBrowser/Mozard) aan om een Nieuwe Zaak aan te maken. Actie 2: Upload het document als bijlage. Actie 3: Vul metadatavelden in. Actie 4 (Na bevestiging API): Verwijder het originele bestand van de file-share (Data Clean-up). --- üõ°Ô∏è Waarborgen (Compliance) 1. De \"Prullenbak\" Veiligheid: We verwijderen het bestand niet direct hard (rm), maar verplaatsen het eerst naar een PROCESSED_QUARANTINE map voor 30 dagen. Mocht er iets misgaan, hebben we een backup. 2. Audit Trail: \"Bestand 'Vergunning_Jansen.pdf' is op 21-12-2025 verplaatst naar Zaak Z-2025-001 door Agent Druppie.\" 3. Toegangsrechten: Documenten met BSN nummers worden als \"Vertrouwelijk\" gemarkeerd in het Zaaksysteem. --- ‚úÖ Resultaat Opgeruimde schijven: Minder storage kosten, minder datalek risico. Compleet Dossier: Het Zaaksysteem bevat nu het volledige beeld. Tijdwinst: Geen handmatig overtikken van pdf's. üîó Relatie met Bouwblokken Gebruikt Secure Agentic RAG voor het vinden. Gebruikt Interne AI (Ollama) voor het lezen van gevoelige data. Gebruikt MCP Servers voor connectie met Filesystem en Zaaksysteem."
  },
  {
    "title": "FO: Exoten Detectie",
    "category": "design",
    "path": "design/exoten_detectie.md",
    "content": "Functioneel Ontwerp: Exoten Detectie üéØ Doelstelling De verspreiding van invasieve waterplanten (exoten) bedreigt de waterkwaliteit en doorstroming. Dit ontwerp richt zich puur op het signaleren en verwerken van deze exoten, gebruikmakend van satelliet- en dronedata. De daadwerkelijke vliegbeweging wordt afgehandeld door de Drone Planner. --- üèóÔ∏è Proces Flow (Detectie \u0026 Afhandeling) mermaid graph TD subgraph Trigger [\"üõ∞Ô∏è Stap 1: Signalering (Grof)\"] Sat(Satelliet Data/SuperView) --\u003e ChangeAI(AI: Change Detection) ChangeAI --\u003e |\"Mogelijke Hotspot\"| Planner(Drone Planner) end subgraph Analysis [\"üî¨ Stap 2: Analyse (Fijn)\"] Planner --\u003e |\"Ruwe Drone Foto's\"| Ingest(Ingest Pipeline) Ingest --\u003e |\"Anonimiseren\"| Privacy(AI Anonymizer) Privacy --\u003e |\"Stitching\"| ODM(WebODM) ODM --\u003e DetectAI(AI: Exoten Herkenning) end subgraph Action [\"üöú Stap 3: Actie\"] DetectAI --\u003e |\"Locatie + Foto + Confidence\"| Dashboard(Ecoloog Dashboard) Dashboard --\u003e Beoordeel{{\"Ecoloog Akkoord?\"}} Beoordeel -- Ja --\u003e Werk(Werkorder Systeem) Werk --\u003e Aannemer(Verwijdering) Aannemer --\u003e |\"Gereed Melding\"| Feedback(Update Historie) end --- üß© Componenten \u0026 Werking 1. De Satelliet Verkenner (Change Detection) Bron: Dagelijkse/Wekelijkse satellietbeelden (via MCP). Analyse: Een AI vergelijkt het beeld van \"Vandaag\" met \"Vorige Week\" en historische data. Trigger: Detecteert afwijkingen in vegetatie-index (NDVI) op watergangen. Output: Een lijst met co√∂rdinaten (Hotspots) die nader onderzoek vereisen. 2. De Exoten Analist (AI Recognition) Na de dronevlucht (zie Drone Planner) komen hoge-resolutie beelden beschikbaar. AI Model: Een gespecialiseerd Computer Vision model (bijv. YOLO of EfficientNet) getraind op specifieke soorten (Grote Waternavel, Japanse Duizendknoop). Output: Een GeoJSON feature voor elke detectie: Type: \"Cabomba\" Confidence: 98% Oppervlakte: 15m2 3. Het Werkproces (Afhandeling) De Ecoloog krijgt een taak in zijn werklijst. Hij ziet de satelliet-trigger, de drone-foto en de AI-detectie. Bij akkoord roept de Action Agent het onderhoudssysteem aan. Feedback Loop: Na verwijdering wordt de locatie gemarkeerd als \"Schoon\", maar blijft een \"Risico Locatie\" voor toekomstige satelliet-checks. --- üõ°Ô∏è Privacy \u0026 Compliance Privacy: Beelden worden pas aan de ecoloog getoond NA anonimisering van personen/voertuigen. Doelbinding: Beelden worden alleen gebruikt voor waterbeheer (exoten, schouw), niet voor handhaving op andere gebieden zonder apart besluit."
  },
  {
    "title": "FO: AI Video Workflow",
    "category": "design",
    "path": "design/ai_video_workflow.md",
    "content": "Technisch Ontwerp: AI Film Productie Pipeline üéØ Doelstelling Het automatiseren van het filmproductieproces door middel van Generative AI. Dit ontwerp beschrijft hoe we van een script (tekst) naar een volledige video gaan, gebruikmakend van Headless ComfyUI op Kubernetes voor schaalbare, GPU-intensieve generatie. üèóÔ∏è Architectuur De pipeline bestaat uit drie hoofdfasen die worden georkestreerd door de Director Agent (Orchestrator). De \"Heavy Lifting\" vindt plaats in de K8s Render Farm. Componenten 1. Director Agent (LLM): Vertaalt het verhaal naar technische prompts (Storyboard). 2. Scene Generator (ComfyUI API): Genereert losse clips op basis van prompts (HunyuanVideo). 3. Voice Generator (TTS API): Genereert gesproken Nederlandse tekst (XTTSv2 / Parkiet). 4. Editor (FFmpeg Worker): Voegt clips, overgangen en audio samen. --- üé¨ De Workflow Stap 1: Audio Eerst (Timing) Voordat we beeld maken, genereert de TTS Service (XTTSv2/Parkiet) de volledige voice-over. Doel: De lengte van de audio bepaalt de exacte lengte van de videosnede. Action: Text -\u003e Audio (.wav). Result: We weten nu: \"Scene 1 duurt 4.2 seconden\". Stap 2: Storyboard (Thumbnails) We genereren voor elke sc√®ne √©√©n statisch beeld (Start Image). Dit is goedkoop en snel (seconden). Model: Flux.1 of SDXL (via ComfyUI). Output: scene_01_thumb.png. Stap 3: Animatic \u0026 Approval (Human-in-the-Loop) De Agent maakt een preview (Animatic): de static images gemonteerd op de audio. User Action: De gebruiker ziet het storyboard met geluid. Feedback: \"Scene 2 is te donker\", \"Tekst in Scene 1 loopt niet lekker\". Kostenbesparing: Mislukte idee√´n worden hier gefixt voordat we dure video-GPU minuten verbranden. Stap 4: Video Productie (Hunyuan I2V) Na \"AKKOORD\" start pas de zware renderfarm. Input: De scene_01_thumb.png (als Image-to-Video input) + de duur van Stap 1. Model: HunyuanVideo (Image-to-Video modus). Consistentie: Omdat we een start-image gebruiken, \"morph\" de video exact vanuit het goedgekeurde plaatje. Stap 5: Final Montage De FFmpeg Worker stikt de High-Res videoclips (.mp4) aan elkaar met de reeds goedgekeurde audio (.wav). Stap 6: Levering 1. De eindfilm (final_movie.mp4) wordt beschikbaar gemaakt in de UI. 2. De tijdelijke render-pods schalen automatisch af (Scale-to-Zero). --- üõ†Ô∏è Technische Specificatie (ComfyUI API Payload) Voorbeeld payload voor Stap 4 (Image-to-Video): json { \"client_id\": \"director_agent_007\", \"prompt\": { \"10\": { \"class_type\": \"LoadImage\", \"inputs\": { \"image\": \"scene_01_thumb.png\" // Goedgekeurde Start Image } }, \"3\": { \"class_type\": \"HunyuanVideoSampler\", \"inputs\": { \"seed\": 849302, \"steps\": 30, \"frame_count\": 125, // 5.0 seconden audio 25 fps \"fps\": 25, \"visual_condition\": [\"10\", 0], // Link naar Start Image \"text_condition\": [\"6\", 0] } }, \"6\": { \"class_type\": \"CLIPTextEncode\", \"inputs\": { \"text\": \"Cyberpunk detective walking, rain...\" } } } } ‚úÖ Voordelen Schaalbaar: Het cluster verdeelt de sc√®nes over alle beschikbare GPU's (Parallel Rendering). Automatisering: Geen menselijke interactie nodig; van tekst tot video in √©√©n pijplijn. Gestandaardiseerd: Door Docker containers is de output, in tegenstelling tot lokale machines, altijd identiek."
  },
  {
    "title": "FO: Drone Planner",
    "category": "design",
    "path": "design/drone_planner.md",
    "content": "Functioneel Ontwerp: Drone Route Planner üéØ Doelstelling Het automatiseren van de inspectievluchten zodat een drone effici√´nt en veilig de betrouwbaarheid van watergangen en hotspots uit satellietdata kan inspecteren. Dit component is de \"logistieke schakel\" tussen de Exoten Detectie en de fysieke uitvoering. --- üèóÔ∏è Proces Flow (Planning \u0026 Vlucht) mermaid graph TD subgraph Input [\"üìç Data Input\"] Hotspots(Hotspots uit Satelliet) History(Historische Risico Locaties) Legger(Watergangen Netwerk) NoFly(No-Fly Zones / CTR) end subgraph Calculator [\"üßÆ Route Engine\"] Join(Combineer Locaties) Path(Pad optimalisatie - TSP) Constraint(Check: Boven Water?) Join --\u003e Path --\u003e Constraint end subgraph Execution [\"üöÅ Vlucht Uitvoering\"] Constraint --\u003e Plan(Vluchtplan .waypoint) Plan --\u003e Auth(Luchtvaart Autoriteit API) Auth --\u003e |\"Toestemming\"| Dock(Drone Dock) Dock --\u003e Fly(Vlucht) end --- üß© Componenten \u0026 Werking 1. De Slimme Routeplanner (Algoritme) Taak: Bereken de meest effici√´nte route om X inspectiepunten te bezoeken binnen de batterijduur van de drone. Constraints (Veiligheid): Boven Water: De drone moet 95% van de tijd boven water vliegen. Dit minimaliseert het risico voor grond-objecten en privacy. Batterij: Inclusief \"Return to Home\" marge. Logica: Reistijd vs. Inspectietijd. Soms is het sneller om een stuk \"rechtdoor\" te vliegen (over weiland) als dit mag, dan de meanderende rivier te volgen. De planner weegt deze opties. 2. Integratie met Luchtvaart (Compliance) Voordat een plan wordt \"gecommit\", checkt de planner de No-Fly Zones (vliegvelden, natura2000). Indien vereist, dient de planner het vluchtplan digitaal in bij de luchtvaartautoriteit (UTM - Unmanned Traffic Management). 3. De Mission Upload Het gevalideerde plan (Waypoints, Hoogte, Snelheid, Camera Acties) wordt verstuurd naar het docking station. De drone voert de missie volledig autonoom uit. --- üõ°Ô∏è Privacy by Design Vliegroute: Door primair boven water te vliegen, vermijden we tuinen en openbare wegen. Camera: De camera staat standaard in een hoek die \"vooruit/omlaag\" kijkt (Nadir/Oblique) gericht op het water, waardoor de horizon (en dus ramen/mensen in de verte) geminimaliseerd wordt. üîó Relaties Wordt getriggerd door Exoten Detectie (Hotspots). Levert beelden aan Data Lifecycle (Raw Images)."
  },
  {
    "title": "Overview",
    "category": "scripts",
    "path": "script/overview.md",
    "content": "Scripts \u0026 Automatisering Hier bewaren we herbruikbare scripts en quick-start commando's die gebruikt kunnen worden voor beheer, setup, of demo doeleinden. üöÄ Hoofdmenu Het makkelijkste startpunt is de Master CLI in de root: ./druppie.sh: Interactief menu voor installatie, bootstrap en beheer. üìÇ Scripts per Categorie üèóÔ∏è Infrastructuur install_k8s.sh: Installeert Kubernetes (RKE2 voor Linux/Prod, k3d voor Mac/Dev). uninstall_k8s.sh: Verwijdert de Kubernetes cluster. üì¶ Platform Services setup_dev_env.sh: Base Layer. Installeert Flux (GitOps), Kyverno (Policy), Tekton (CI) en Kong (Gateway). setup_iam.sh: IAM. Installeert Keycloak (Identity Provider). setup_observability.sh: Observability. Installeert de LGTM stack (Loki, Grafana, Tempo, Prometheus). üõ†Ô∏è Applicatie Services setup_data_tools.sh: Data. Installeert Gitea (Git) en MinIO (S3 Lake). setup_databases.sh: Storage. Installeert PostgreSQL (SQL/GIS) en Qdrant (Vector). setup_security_tools.sh: Security. Installeert Trivy (Scanning) en SonarQube (Quality). setup_gis.sh: GIS. Installeert GeoServer (Maps), GeoNode (Portal) en NodeODM (Drone). üß™ Demo \u0026 Simulatie simulate_user_login.py (Concept) trigger_drone_flow.sh (Concept) ü§ñ Automatisering Deze scripts zijn idempotent en kunnen worden aangeroepen door: 1. Engineers: Via druppie.sh of direct. 2. Builder Agent: Om omgevingen te provisionen. 3. Argo Workflows: Als onderdeel van een grotere keten."
  },
  {
    "title": "Druppie CLI",
    "category": "scripts",
    "path": "druppie.sh",
    "content": "!/bin/bash Druppie Master CLI Interface voor alle beheer taken binnen het Druppie Platform. BASE_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\" SCRIPT_DIR=\"$BASE_DIR/script\" COLOR_CYAN='\\033[0;36m' COLOR_NC='\\033[0m' SECRETS_FILE=\"$BASE_DIR/.secrets\" function load_secrets() { if [ ! -f \"$SECRETS_FILE\" ]; then touch \"$SECRETS_FILE\" fi source \"$SECRETS_FILE\" } function get_or_create_secret() { local key=$1 local existing_value=${!key} if [ -z \"$existing_value\" ]; then Generate a random 16-char secret local new_secret=$(openssl rand -hex 8) echo \"$key=$new_secret\" \u003e\u003e \"$SECRETS_FILE\" export $key=$new_secret else export $key=$existing_value fi } function ensure_secrets() { Define required secrets for each installer get_or_create_secret \"DRUPPIE_K8S_TOKEN\" k8s get_or_create_secret \"DRUPPIE_RANCHER_TOKEN\" Rancher get_or_create_secret \"DRUPPIE_GITEA_PASS\" data get_or_create_secret \"DRUPPIE_MINIO_PASS\" data get_or_create_secret \"DRUPPIE_SONAR_PASS\" security get_or_create_secret \"DRUPPIE_KEYCLOAK_PASS\" iam get_or_create_secret \"DRUPPIE_GRAFANA_PASS\" observability get_or_create_secret \"DRUPPIE_POSTGRES_PASS\" database get_or_create_secret \"DRUPPIE_QDRANT_KEY\" database get_or_create_secret \"DRUPPIE_GEOSERVER_PASS\" gis get_or_create_secret \"DRUPPIE_GEOSERVER_PASS\" gis get_or_create_secret \"DRUPPIE_MONITOR_PASS\" security Ensure Domain if [ -z \"${DRUPPIE_DOMAIN}\" ]; then echo \"DRUPPIE_DOMAIN=localhost\" \u003e\u003e \"$SECRETS_FILE\" export DRUPPIE_DOMAIN=\"localhost\" fi Re-export to be safe export DRUPPIE_DOMAIN=\"${DRUPPIE_DOMAIN:-localhost}\" Ensure Cluster Name if [ -z \"${DRUPPIE_CLUSTER_NAME}\" ]; then echo \"DRUPPIE_CLUSTER_NAME=druppie-dev\" \u003e\u003e \"$SECRETS_FILE\" export DRUPPIE_CLUSTER_NAME=\"druppie-dev\" fi export DRUPPIE_CLUSTER_NAME=\"${DRUPPIE_CLUSTER_NAME:-druppie-dev}\" Reload to be sure source \"$SECRETS_FILE\" } function show_banner() { clear echo -e \"${COLOR_CYAN}\" echo \" _____ _ \" echo \" | __ \\ (_) \" echo \" | | | |_ __ _ _ _ __ _ __ _ ___ \" echo \" | | | | '__| | | | '_ \\| '_ \\ |/ _ \\\\\" echo \" | |__| | | | |_| | |_) | |_) | | __/\" echo \" |_____/|_| \\__,_| .__/| .__/|_|\\___|\" echo \" | | | | \" echo \" |_| |_| \" echo -e \"${COLOR_NC}\" echo \" v1.0 - Platform CLI\" echo \"\" } function menu() { show_banner echo \"Beschikbare Acties:\" echo \"-------------------\" echo \" 0) ‚ò∏Ô∏è Install Kubernetes (RKE2/k3d)\" echo \" 1) üöÄ Bootstrap DEV Platform (Helm + Flux CD + Kyverno + Tekton + Kong + Postgres)\" echo \" 2) üíæ Install Data Services (Gitea + MinIO + Qdrant)\" echo \" 3) üõ°Ô∏è Install Security Services (Trivy + SonarQube)\" echo \" 4) üîë Install IAM (Keycloak)\" echo \" 5) üëÅÔ∏è Install Observability (LGTM Stack)\" echo \" 6) üåç Install GIS Services (GeoServer + GEONode + WebODM)\" echo \" 7) ü§† Install Rancher UI (Cert-Manager + Rancher)\" echo \" 8) üíß Build \u0026 Install Druppie\" echo \" 9) üåê Configure Ingress (Expose Services)\" echo \"\" echo \" a) ‚è© Install EVERYTHING (0-9)\" echo \" u) üóëÔ∏è Uninstall Kubernetes\" echo \" h) üìú List Installation History\" echo \" q) Quit\" echo \"\" read -p \"Maak een keuze: \" CHOICE execute_choice \"$CHOICE\" } Global flag to track if we are running in interactive mode INTERACTIVE_MODE=true function handle_wait() { local exit_code=$? Wait if the last command failed OR if we are in interactive mode and just finished a menu action if [ $exit_code -ne 0 ] || [ \"$INTERACTIVE_MODE\" = true ]; then If it failed, show why we are waiting if [ $exit_code -ne 0 ]; then echo \"‚ö†Ô∏è Command failed with exit code $exit_code.\" fi read -p \"Druk op Enter...\" fi } function execute_choice() { local choice=$1 local extra_arg=$2 case $choice in 0) handle_k8s_install handle_wait ;; 1) install_platform handle_wait ;; 2) install_data handle_wait ;; 3) install_security handle_wait ;; 4) install_iam handle_wait ;; 5) install_observability handle_wait ;; 6) install_gis handle_wait ;; 7) install_rancher handle_wait ;; 8) install_druppie_core handle_wait ;; 9) install_ingress handle_wait ;; a) handle_k8s_install || return 1 install_platform || return 1 install_data || return 1 install_security || return 1 install_iam || return 1 install_observability || return 1 install_gis || return 1 install_rancher || return 1 install_druppie || return 1 install_ingress || return 1 handle_wait ;; u) handle_uninstall \"$extra_arg\" handle_wait ;; ua) handle_uninstall \"$extra_arg\" || return 1 execute_choice \"a\" ;; h) show_history handle_wait ;; q) echo \"Bye!\"; exit 0 ;; ) echo \"Ongeldige keuze: $choice\" ;; esac } LOG_DIR=\"$BASE_DIR/.logs\" Function to run a script with logging function run_script_logged() { local label=$1 local script_path=$2 Capture remaining args shift 2 local args=\"$@\" local script_name=$(basename \"$script_path\") local log_file=\"$LOG_DIR/${script_name%.}.log\" Ensure log directory exists mkdir -p \"$LOG_DIR\" Empty the log file \u003e \"$log_file\" Execute with logging (both stdout and stderr to screen and file) Wrap everything in a block to capture header echoes too { set -o pipefail echo \"==================================================\" ech"
  },
  {
    "title": "Install Kubernetes (RKE2/k3d)",
    "category": "scripts",
    "path": "script/install_k8s.sh",
    "content": "!/bin/bash Druppie Kubernetes Installer (RKE2) Supports: Server (Control Plane) and Workstation (Single Node Dev) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_RED='\\033[0;31m' COLOR_NC='\\033[0m' Log File Location (Project Root) LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[DRUPPIE]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | INSTALL | Kubernetes | $1\" \u003e\u003e \"$LOG_FILE\" } function error() { echo -e \"${COLOR_RED}[ERROR]${COLOR_NC} $1\" exit 1 } Check Root (Only required for RKE2/Linux) IS_ROOT=false if [[ $EUID -eq 0 ]]; then IS_ROOT=true fi OS=\"$(uname)\" Selection Menu echo -e \"${COLOR_GREEN}Select Installation Profile:${COLOR_NC}\" echo \"1) Local Dev (k3d - Docker Required - macOS/Linux)\" echo \"2) Workstation (RKE2 - Single Node - Linux Only)\" echo \"3) Server (RKE2 - Control Plane - Linux Only)\" if [ ! -z \"$1\" ]; then PROFILE_OPT=$1 echo \"Selected Profile (Argument): $PROFILE_OPT\" else read -p \"Choice [1-3]: \" PROFILE_OPT fi Validation if [[ \"$PROFILE_OPT\" == \"2\" || \"$PROFILE_OPT\" == \"3\" ]]; then if [[ \"$OS\" == \"Darwin\" ]]; then error \"RKE2 (Options 2/3) is only supported on Linux. Use Option 1 (k3d) for macOS.\" fi if [ \"$IS_ROOT\" = false ]; then error \"RKE2 installation requires root (sudo).\" fi fi if [ \"$PROFILE_OPT\" == \"1\" ]; then log \"Checking Docker...\" if ! command -v docker \u0026\u003e /dev/null; then error \"Docker is not installed or not in PATH.\" fi if ! docker info \u0026\u003e /dev/null; then error \"Docker daemon is not running.\" fi log \"Checking/Installing k3d...\" if ! command -v k3d \u0026\u003e /dev/null; then if [[ \"$OS\" == \"Darwin\" ]]; then log \"Installing k3d via Homebrew...\" brew install k3d else log \"Installing k3d via Script...\" curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash fi else log \"k3d is already installed.\" fi log \"Checking/Installing kubectl...\" if ! command -v kubectl \u0026\u003e /dev/null; then if [[ \"$OS\" == \"Darwin\" ]]; then log \"Installing kubectl via Homebrew...\" brew install kubectl else log \"Installing kubectl...\" curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" chmod +x kubectl sudo mv kubectl /usr/local/bin/ fi else log \"kubectl is already installed.\" fi log \"Checking/Installing Helm...\" if ! command -v helm \u0026\u003e /dev/null; then if [[ \"$OS\" == \"Darwin\" ]]; then log \"Installing Helm via Homebrew...\" brew install helm else log \"Installing Helm...\" curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash fi fi Default to druppie-dev if env var is missing (e.g. running script directly) CLUSTER_NAME=\"${DRUPPIE_CLUSTER_NAME:-druppie-dev}\" log \"Creating/Updating Cluster '$CLUSTER_NAME'...\" Create cluster with Ingress ports mapped - 80:80 (HTTP Ingress) - 443:443 (HTTPS Ingress) k3d cluster create \"$CLUSTER_NAME\" \\ --api-port 6443 \\ -p \"80:80@loadbalancer\" \\ -p \"443:443@loadbalancer\" \\ --k3s-arg \"--disable=traefik@server:0\" \\ --wait log \"Cluster Ready! üöÄ\" log \"Run: kubectl get nodes\" log_history \"k3d ($CLUSTER_NAME)\" exit 0 fi RKE2 Logic (Linux Only) RKE2_CONFIG_DIR=\"/etc/rancher/rke2\" CONFIG_FILE=\"$RKE2_CONFIG_DIR/config.yaml\" mkdir -p $RKE2_CONFIG_DIR if [ \"$PROFILE_OPT\" == \"3\" ]; then log \"Configuring for WORKSTATION...\" Workstation: Minimal resource usage cat \u003c\u003cEOF \u003e $CONFIG_FILE write-kubeconfig-mode: \"0644\" tls-san: - \"druppie.local\" - \"127.0.0.1\" disable: - rke2-ingress-nginx profile: \"cis-1.23\" EOF elif [ \"$PROFILE_OPT\" == \"3\" ]; then log \"Configuring for SERVER (Production)...\" if [ -z \"$CLUSTER_TOKEN\" ]; then if [ ! -z \"$DRUPPIE_K8S_TOKEN\" ]; then CLUSTER_TOKEN=\"$DRUPPIE_K8S_TOKEN\" log \"Using Token from Environment.\" else read -p \"Enter Cluster Token (secret): \" CLUSTER_TOKEN fi fi read -p \"Enter Generic S3 Endpoint (for etcd snapshots) [optional]: \" S3_ENDPOINT cat \u003c\u003cEOF \u003e $CONFIG_FILE write-kubeconfig-mode: \"0644\" token: \"$CLUSTER_TOKEN\" cni: \"canal\" profile: \"cis-1.23\" selinux: true kube-apiserver-arg: - \"audit-log-path=/var/lib/rancher/rke2/server/audit.log\" - \"audit-policy-file=/etc/rancher/rke2/audit-policy.yaml\" EOF cat \u003c\u003cEOF \u003e $RKE2_CONFIG_DIR/audit-policy.yaml apiVersion: audit.k8s.io/v1 kind: Policy rules: - level: Metadata EOF if [ ! -z \"$S3_ENDPOINT\" ]; then echo \"etcd-s3: true\" \u003e\u003e $CONFIG_FILE echo \"etcd-s3-endpoint: $S3_ENDPOINT\" \u003e\u003e $CONFIG_FILE fi fi Install RKE2 log \"Downloading and Installing RKE2...\" curl -sfL https://get.rke2.io | sh - Enable \u0026 Start log \"Starting RKE2 Server...\" systemctl enable rke2-server.service systemctl start rke2-server.service Symlink kubectl for convenience if [ ! -f /usr/local/bin/kubectl ]; then log \"Symlinking RKE2 kubectl to /usr/local/bin/kubectl...\" ln -s /var/lib/rancher/rke2/bin/kubectl /usr/local/bin/kubectl fi Validating log \"Waiting for Node to be Ready...\" export KUBECONFIG=/etc/rancher/rke2/rke2.yaml for i in {1..30}; do if /var/lib/rancher/rke2/bin/kubectl get nodes \u0026\u003e /dev/null; then break fi sleep 2 done /var/lib/ra"
  },
  {
    "title": "Platform Bootstrap (Base)",
    "category": "scripts",
    "path": "script/setup_dev_env.sh",
    "content": "!/bin/bash Druppie Dev Environment Bootstrap Installs the Platform Base Layer (Flux, Kyverno, Tekton, Kong) into the current cluster. set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Platform | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" echo \"üí° Run 'Install Kubernetes' first or check your KUBECONFIG.\" exit 1 fi log \"Connected to $(kubectl config current-context).\" 1.5. Wait for Nodes to be Ready (Crucial for fresh local clusters) function wait_for_nodes() { log \"Waiting for all cluster nodes to be Ready...\" if ! kubectl wait --for=condition=Ready nodes --all --timeout=120s; then echo \"‚ö†Ô∏è Nodes are not ready yet. This might be fine if they are starting up, but could cause issues.\" else log \"All nodes are Ready.\" fi } wait_for_nodes 2. Install Helm (if missing) if ! command -v helm \u0026\u003e /dev/null; then log \"Installing Helm...\" curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash fi Check for Secrets (Crucial for DB in Boot Layer) if [ -z \"$DRUPPIE_POSTGRES_PASS\" ]; then echo \"‚ö†Ô∏è DRUPPIE_POSTGRES_PASS is not set. Defaulting to 'postgres_p@ssw0rd' for Dev.\" DRUPPIE_POSTGRES_PASS=\"postgres_p@ssw0rd\" fi 3. Add Repos log \"Adding Helm Repositories...\" helm repo add fluxcd-community https://fluxcd-community.github.io/helm-charts helm repo add kyverno https://kyverno.github.io/kyverno helm repo add tekton-cd https://cdfoundation.github.io/tekton-helm-chart helm repo add kong https://charts.konghq.com helm repo add bitnami https://charts.bitnami.com/bitnami helm repo up 4. Install Flux CD (GitOps Engine) log \"Installing Flux CD...\" kubectl apply -f https://github.com/fluxcd/flux2/releases/latest/download/install.yaml log \"Waiting for Flux Controllers...\" kubectl wait --for=condition=available deployment/source-controller -n flux-system --timeout=300s kubectl wait --for=condition=available deployment/kustomize-controller -n flux-system --timeout=300s kubectl wait --for=condition=available deployment/helm-controller -n flux-system --timeout=300s kubectl wait --for=condition=available deployment/notification-controller -n flux-system --timeout=300s log_history \"Flux CD Installed\" 5. Install Kyverno (Policy Engine) log \"Installing Kyverno...\" helm upgrade --install kyverno kyverno/kyverno \\ --namespace kyverno --create-namespace \\ --set admissionController.replicas=1 \\ --wait log_history \"Kyverno Installed\" 6. Install Tekton (Build Engine) Tekton is complex via Helm, often easier via kubectl apply for base log \"Installing Tekton Pipelines...\" kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml log_history \"Tekton Pipelines Installed\" Ensure Domain if [ -z \"$DRUPPIE_DOMAIN\" ]; then DRUPPIE_DOMAIN=\"localhost\" fi 7. Install Kong (API Gateway) log \"Installing Kong Gateway (Ingress)...\" helm upgrade --install kong kong/kong \\ --namespace kong --create-namespace \\ --set ingressController.installCRDs=false \\ --set proxy.type=LoadBalancer \\ --set controller.ingressClass.name=kong \\ --set controller.ingressClass.resource.enabled=true \\ --set controller.ingressClass.resource.default=true \\ --set admin.enabled=true \\ --set admin.http.enabled=true \\ --set manager.enabled=true \\ --set env.admin_gui_api_url=\"http://api.${DRUPPIE_DOMAIN}\" \\ --wait log_history \"Kong Gateway Installed\" 10. Install Shared PostgreSQL (Boot Layer DB) log \"Installing Shared PostgreSQL (Boot Layer)...\" helm upgrade --install postgres bitnami/postgresql \\ --namespace databases --create-namespace \\ --set global.postgresql.auth.postgresPassword=${DRUPPIE_POSTGRES_PASS} \\ --set primary.persistence.size=5Gi \\ --set global.storageClass=local-path \\ --wait log_history \"PostgreSQL (Shared) Installed\" echo \"Enable PostGIS manually if needed:\" kubectl exec -it -n databases svc/postgres-postgresql -env=\"PGPASSWORD=${DRUPPIE_POSTGRES_PASS}\" -- psql -U postgres -c 'CREATE EXTENSION IF NOT EXISTS postgis;' log_history \"PostGIS Enabled\" 11. Install Redis (Cache Layer) log \"Installing Redis (Cache Layer)...\" helm upgrade --install redis bitnami/redis \\ --namespace databases --create-namespace \\ --set auth.password=${DRUPPIE_REDIS_PASS} \\ --set architecture=standalone \\ --set master.persistence.size=2Gi \\ --set master.persistence.storageClass=local-path \\ --wait log_history \"Redis (Cache Layer) Installed\" 12. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ Platform Base Layer Installed Successfully!\" echo \"-----------------------------------------------\" echo \" - Flux CD (GitOps)\" echo \" - Kyverno (Policies)\" echo \" - Tekton (CI)\" echo \" - Kong (Ingress)\" echo \" - Postgres (Shared)\" echo \" - Redis (Cache Layer)\" echo \"\" echo \"You are ready to deploy "
  },
  {
    "title": "Data Tools (Gitea/MinIO/Qdrant)",
    "category": "scripts",
    "path": "script/setup_data_tools.sh",
    "content": "!/bin/bash Druppie Data \u0026 Versioning Setup Installs Gitea (Version Control) and MinIO (Data Lake) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | DataTools | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add gitea-charts https://dl.gitea.io/charts/ helm repo add minio https://charts.min.io/ helm repo add qdrant https://qdrant.github.io/qdrant-helm helm repo up 3. Install Gitea (Lightweight Git Server) log \"Installing Gitea...\" helm upgrade --install gitea gitea-charts/gitea \\ --namespace gitea --create-namespace \\ --version 10.6.0 \\ --set gitea.admin.username=druppie_admin \\ --set gitea.admin.password=${DRUPPIE_GITEA_PASS} \\ --set persistence.size=1Gi \\ --set postgresql.enabled=false \\ --set postgresql-ha.enabled=false \\ --set redis.enabled=false \\ --set redis-cluster.enabled=false \\ --set gitea.config.database.DB_TYPE=postgres \\ --set gitea.config.database.HOST=postgres-postgresql.databases.svc.cluster.local:5432 \\ --set gitea.config.database.NAME=postgres \\ --set gitea.config.database.USER=postgres \\ --set gitea.config.database.NAME=postgres \\ --set gitea.config.database.USER=postgres \\ --set gitea.config.database.PASSWD=${DRUPPIE_POSTGRES_PASS} \\ --set gitea.config.server.ROOT_URL=http://gitea.${DRUPPIE_DOMAIN}/ \\ --set gitea.config.server.DOMAIN=gitea.${DRUPPIE_DOMAIN} \\ --set gitea.config.server.SSH_DOMAIN=gitea.${DRUPPIE_DOMAIN} \\ --set gitea.config.server.HTTP_PORT=3000 \\ --set gitea.config.server.StartSSHServer=true \\ --wait log_history \"Gitea Installed\" 4. Install MinIO (S3 Compatible Storage) log \"Installing MinIO...\" helm upgrade --install minio minio/minio \\ --namespace minio --create-namespace \\ --set rootUser=admin \\ --set rootPassword=${DRUPPIE_MINIO_PASS} \\ --set mode=standalone \\ --set replicas=1 \\ --set global.storageClass=local-path \\ --set volumePermissions.enabled=true \\ --set persistence.size=5Gi \\ --set resources.requests.memory=256Mi \\ --set environment.MINIO_BROWSER_REDIRECT_URL=\"http://minio.${DRUPPIE_DOMAIN}\" \\ --wait log_history \"MinIO Installed\" 5. Install Qdrant (Vector DB for AI) log \"Installing Qdrant Vector DB...\" helm upgrade --install qdrant qdrant/qdrant \\ --namespace databases --create-namespace \\ --set replicaCount=1 \\ --set persistence.size=2Gi \\ --set apiKey=${DRUPPIE_QDRANT_KEY} \\ --wait log_history \"Qdrant Installed\" 6. Install pgAdmin4 (Postgres UI) log \"Installing pgAdmin4...\" helm repo add runix https://helm.runix.net helm repo up Create values file for pgAdmin cat \u003c\u003cEOF \u003e /tmp/pgadmin-values.yaml serverDefinitions: enabled: true servers: \"1\": Name: \"Druppie Shared DB\" Group: \"Servers\" Host: \"postgres-postgresql.databases.svc.cluster.local\" Port: 5432 MaintenanceDB: \"postgres\" Username: \"postgres\" SSLMode: \"prefer\" EOF helm upgrade --install pgadmin runix/pgadmin4 \\ --namespace databases --create-namespace \\ --set env.email=admin@druppie.nl \\ --set env.password=${DRUPPIE_POSTGRES_PASS} \\ --set service.type=ClusterIP \\ -f /tmp/pgadmin-values.yaml \\ --wait rm /tmp/pgadmin-values.yaml log_history \"pgAdmin4 Installed\" 6. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ Data Services Installed!\" echo \"--------------------------\" echo \" - Gitea: http://gitea-http.gitea.svc.cluster.local:3000\" echo \" User: druppie_admin\" echo \" Pass: ${DRUPPIE_GITEA_PASS}\" echo \"\" echo \" - MinIO: http://minio.minio.svc.cluster.local:9000\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_MINIO_PASS}\" echo \"\" echo \" - Qdrant: http://qdrant.databases.svc.cluster.local:6333\" echo \" API Key: ${DRUPPIE_QDRANT_KEY}\" echo \"\" echo \"‚ö†Ô∏è Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/gitea-http -n gitea 3000:3000\" echo \" kubectl port-forward svc/minio -n minio 9000:9000\" echo \" kubectl port-forward svc/qdrant -n databases 6333:6333\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "IAM Setup (Keycloak)",
    "category": "scripts",
    "path": "script/setup_iam.sh",
    "content": "!/bin/bash Druppie IAM Setup Installs Keycloak (Identity Provider) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | IAM | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add bitnami https://charts.bitnami.com/bitnami helm repo up 3. Install Keycloak log \"Installing Keycloak...\" helm upgrade --install keycloak bitnami/keycloak \\ --namespace iam --create-namespace \\ --set auth.adminUser=admin \\ --set auth.adminPassword=${DRUPPIE_KEYCLOAK_PASS} \\ --set production=false \\ --set proxy=edge \\ --set service.type=ClusterIP \\ --set postgresql.enabled=false \\ --set externalDatabase.host=postgres-postgresql.databases.svc.cluster.local \\ --set externalDatabase.port=5432 \\ --set externalDatabase.user=postgres \\ --set externalDatabase.database=postgres \\ --set externalDatabase.password=${DRUPPIE_POSTGRES_PASS} \\ --set image.repository=bitnamilegacy/keycloak \\ --set image.tag=26.3.3-debian-12-r0 \\ --wait log_history \"Keycloak Installed\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ IAM Services Installed!\" echo \"-------------------------\" echo \" - Keycloak: http://keycloak.iam.svc.cluster.local:80\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_KEYCLOAK_PASS}\" echo \"\" echo \"‚ö†Ô∏è Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/keycloak -n iam 8080:80\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Observability (LGTM)",
    "category": "scripts",
    "path": "script/setup_observability.sh",
    "content": "!/bin/bash Druppie Observability Setup Installs the LGTM Stack (Loki, Grafana, Tempo, Mimir/Prometheus) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Observability | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add grafana https://grafana.github.io/helm-charts helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo up 3. Install Prometheus (Metrics) log \"Installing Prometheus...\" helm upgrade --install prometheus prometheus-community/prometheus \\ --namespace observability --create-namespace \\ --set alertmanager.enabled=false \\ --set server.persistentVolume.size=5Gi \\ --wait log_history \"Prometheus Installed\" 4. Install Loki (Logs) - Single Binary log \"Installing Loki (Single Binary)...\" helm upgrade --install loki grafana/loki \\ --namespace observability --create-namespace \\ --set deploymentMode=SingleBinary \\ --set loki.auth_enabled=false \\ --set loki.commonConfig.replication_factor=1 \\ --set loki.storage.type=filesystem \\ --set singleBinary.replicas=1 \\ --set read.replicas=0 \\ --set backend.replicas=0 \\ --set write.replicas=0 \\ --set loki.useTestSchema=true \\ --wait log_history \"Loki Installed\" 4b. Install Alloy (Log Collector - Replaces Promtail) log \"Installing Alloy (Log Collector)...\" helm upgrade --install alloy grafana/alloy \\ --namespace observability --create-namespace \\ --set alloy.configMap.content=\" logging { level = \\\"info\\\" format = \\\"logfmt\\\" } loki.write \\\"default\\\" { endpoint { url = \\\"http://loki-gateway.observability.svc.cluster.local/loki/api/v1/push\\\" } } loki.source.kubernetes \\\"pods\\\" { targets = discovery.kubernetes.pods.targets forward_to = [loki.write.default.receiver] } discovery.kubernetes \\\"pods\\\" { role = \\\"pod\\\" } loki.source.kubernetes_events \\\"cluster_events\\\" { job_name = \\\"integrations/kubernetes/eventhandler\\\" log_format = \\\"logfmt\\\" forward_to = [loki.write.default.receiver] } \" \\ --wait log_history \"Alloy Installed\" 5. Install Tempo (Tracing - optional/lightweight) log \"Installing Tempo...\" helm upgrade --install tempo grafana/tempo \\ --namespace observability --create-namespace \\ --set persistence.enabled=false \\ --wait log_history \"Tempo Installed\" 6. Install Grafana (Dashboarding) log \"Installing Grafana...\" Create values file for datasources cat \u003c\u003c'EOF' \u003e /tmp/grafana-values.yaml datasources: datasources.yaml: apiVersion: 1 datasources: - name: Prometheus type: prometheus url: http://prometheus-server.observability.svc.cluster.local access: proxy isDefault: true - name: Loki type: loki url: http://loki-gateway.observability.svc.cluster.local access: proxy jsonData: derivedFields: - datasourceUid: Tempo matcherRegex: \"traceID=(\\\\w+)\" name: TraceID url: \"${__value.raw}\" - name: Tempo type: tempo url: http://tempo.observability.svc.cluster.local:3100 access: proxy EOF helm upgrade --install grafana grafana/grafana \\ --namespace observability --create-namespace \\ --set adminPassword=${DRUPPIE_GRAFANA_PASS} \\ --set service.type=ClusterIP \\ --set \"grafana\\.ini.server.root_url=http://grafana.${DRUPPIE_DOMAIN}/\" \\ --set \"grafana\\.ini.server.serve_from_sub_path=false\" \\ --set persistence.enabled=true \\ --set persistence.size=2Gi \\ -f /tmp/grafana-values.yaml rm /tmp/grafana-values.yaml log \"Waiting for Grafana to be ready...\" kubectl rollout status deployment/grafana -n observability --timeout=300s log \"Waiting for Grafana Health Check (internal port 3000)...\" for i in {1..30}; do if kubectl exec -n observability deploy/grafana -- curl -s -f http://localhost:3000/api/health \u003e/dev/null 2\u003e\u00261; then echo \"Grafana is Healthy!\" break fi echo \"Waiting for Grafana API...\" sleep 5 done log_history \"Grafana Installed\" 7. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ Observability Stack (LGTM) Installed!\" echo \"---------------------------------------\" echo \" - Grafana: http://grafana.observability.svc.cluster.local:80\" echo \" User: admin\" echo \" Pass: ${DRUPPIE_GRAFANA_PASS}\" echo \" Data: Prometheus (Metrics), Loki (Logs), Tempo (Traces)\" echo \"\" echo \"‚ö†Ô∏è Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/grafana -n observability 3000:80\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "GIS Tools (GeoServer)",
    "category": "scripts",
    "path": "script/setup_gis.sh",
    "content": "!/bin/bash Druppie GIS Services Setup Installs GeoServer (Map Server) and WebODM (Drone Mapping) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | GIS | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos 2. Add Repos log \"Adding Helm Repositories...\" Or use Kartoza which is popular for GIS: helm repo add kartoza https://kartoza.github.io/charts helm repo up 3. Create Namespace kubectl create namespace gis --dry-run=client -o yaml | kubectl apply -f - 4. Install GeoServer (Manual Manifest) log \"Installing GeoServer (via Manifest)...\" Cleanup Helm helm uninstall geoserver -n gis \u0026\u003e /dev/null || true kubectl delete deploy geoserver -n gis \u0026\u003e /dev/null || true kubectl delete svc geoserver -n gis \u0026\u003e /dev/null || true cat \u003c\u003cEOF | kubectl apply -f - apiVersion: v1 kind: PersistentVolumeClaim metadata: name: geoserver-data namespace: gis spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: geoserver namespace: gis spec: replicas: 1 selector: matchLabels: app: geoserver template: metadata: labels: app: geoserver spec: initContainers: - name: fix-perms image: busybox command: [\"sh\", \"-c\", \"chown -R 1000:1000 /opt/geoserver/data_dir\"] volumeMounts: - name: geoserver-data mountPath: /opt/geoserver/data_dir containers: - name: geoserver image: kartoza/geoserver:2.26.1 ports: - containerPort: 8080 env: - name: GEOSERVER_ADMIN_USER value: \"admin\" - name: GEOSERVER_ADMIN_PASSWORD value: \"${DRUPPIE_GEOSERVER_PASS}\" - name: GEOSERVER_DATA_DIR value: \"/opt/geoserver/data_dir\" - name: GEOSERVER_CSRF_WHITELIST value: \"geoserver.${DRUPPIE_DOMAIN}\" volumeMounts: - name: geoserver-data mountPath: /opt/geoserver/data_dir resources: requests: memory: \"1Gi\" cpu: \"500m\" limits: memory: \"2Gi\" volumes: - name: geoserver-data persistentVolumeClaim: claimName: geoserver-data --- apiVersion: v1 kind: Service metadata: name: geoserver namespace: gis spec: selector: app: geoserver ports: - port: 8080 targetPort: 8080 type: ClusterIP EOF log \"Waiting for GeoServer...\" kubectl rollout status deployment/geoserver -n gis --timeout=300s log_history \"GeoServer Installed (Manual Manifest)\" Create GEO DBs log \"Ensuring GeoNode Databases exist...\" kubectl exec -n databases svc/postgres-postgresql -- env PGPASSWORD=${DRUPPIE_POSTGRES_PASS} psql -U postgres -c \"CREATE DATABASE geonode;\" || true kubectl exec -n databases svc/postgres-postgresql -- env PGPASSWORD=${DRUPPIE_POSTGRES_PASS} psql -U postgres -c \"CREATE DATABASE geonode_data;\" || true FOR NOW DISABLED NEEDS MORE TESTING OS=\"$(uname)\" if [[ \"$OS\" == \"Darwin\" ]]; then log \"GeoNode Not available on macOS...\" else 5. Install GeoNode (GIS Portal) log \"Installing GeoNode...\" Add Official Repo (Community Maintained) helm repo add geonode https://GeoNodeUserGroup-DE.github.io/geonode-k8s/ helm repo up Install via Helm (Robust community chart) helm upgrade --install geonode charts/geonode \\ --namespace gis \\ --set global.postgresql.host=postgres-postgresql.databases.svc.cluster.local \\ --set global.postgresql.port=5432 \\ --set global.postgresql.user=postgres \\ --set global.postgresql.password=${DRUPPIE_POSTGRES_PASS} \\ --set postgresql.enabled=false \\ --set geonode.database.name=geonode \\ --set geonode.geodatabase.name=geonode_data \\ --set geoserver.url=\"http://geoserver.gis.svc.cluster.local:8080/geoserver/\" \\ --set geonode.siteUrl=\"http://geonode.${DRUPPIE_DOMAIN}/\" \\ --set geonode.adminUser=admin \\ --set geonode.adminPassword=${DRUPPIE_POSTGRES_PASS} \\ --set service.type=ClusterIP \\ --wait log_history \"GeoNode Installed (Helm)\" fi 5. Install WebODM (Lightning/NodeODM) WebODM is complex on K8s (Storage/Postgres/Redis). For this 'Light' script, we deploy a simplified NodeODM (processing node) and references. In a real PROD setup this would be full WebODM stack. log \"Installing NodeODM (Drone Processing Engine)...\" Using raw manifest for simplicity as no official stable Helm chart exists for simple setups cat \u003c\u003cEOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: nodeodm namespace: gis spec: replicas: 1 selector: matchLabels: app: nodeodm template: metadata: labels: app: nodeodm spec: containers: - name: nodeodm image: opendronemap/nodeodm:latest ports: - containerPort: 3000 --- apiVersion: v1 kind: Service metadata: name: nodeodm namespace: gis spec: selector: app: nodeodm ports: - port: 3000 targetPort: 3000 type: ClusterIP EOF log_history \"NodeODM Installed\" 6. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ GIS Services Installed!\" echo \"-------------------------\" echo \" - GeoServer: http://geoserver.gis.svc.cluster.local:8080/geoserver"
  },
  {
    "title": "Security Tools (Trivy)",
    "category": "scripts",
    "path": "script/setup_security_tools.sh",
    "content": "!/bin/bash Druppie Security Services Setup Installs Trivy (Scanning) and SonarQube (Static Analysis) set -e COLOR_GREEN='\\033[0;32m' COLOR_BLUE='\\033[0;34m' COLOR_NC='\\033[0m' LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_BLUE}[SETUP]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | SETUP | Security | $1\" \u003e\u003e \"$LOG_FILE\" } 1. Check Connectivity log \"Checking Kubernetes Connection...\" if ! kubectl cluster-info \u0026\u003e /dev/null; then echo \"‚ùå Cannot connect to Kubernetes.\" exit 1 fi 2. Add Repos log \"Adding Helm Repositories...\" helm repo add aqua https://aquasecurity.github.io/helm-charts/ helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube helm repo up 3. Install Trivy Operator (Continuous Scanning) log \"Installing Trivy Operator...\" helm upgrade --install trivy-operator aqua/trivy-operator \\ --namespace security-system --create-namespace \\ --set compliance.cron=\"0 0 \" \\ --set operator.scanJobConcurrencyLimit=1 \\ --set operator.scanJobTimeout=5m \\ --set operator.vulnerabilityScannerScanOnlyCurrentRevisions=true \\ --set operator.replicas=1 \\ --set targetNamespaces=\"default\" \\ --set excludeNamespaces=\"kube-system\\,security-system\\,cattle-system\\,flux-system\\,cert-manager\\,local-path-storage\" \\ --set operator.backgroundScanning.enabled=false \\ --set vulnerabilityReport.scanAll=false \\ --set trivy.ignoreUnfixed=true \\ --set trivy.resources.requests.cpu=50m \\ --set trivy.resources.requests.memory=128Mi \\ --set trivy.resources.limits.memory=256Mi \\ --wait log_history \"Trivy Operator Installed (Restricted Scope)\" 4. Install SonarQube (Code Quality) - Manual Manifest log \"Installing SonarQube (via Manifest)...\" log \"Creating SonarQube Database...\" Create dedicated database to avoid version conflicts and clean slate kubectl exec -n databases svc/postgres-postgresql -- env PGPASSWORD=${DRUPPIE_POSTGRES_PASS} psql -U postgres -c \"CREATE DATABASE sonarqube;\" || true cat \u003c\u003cEOF | kubectl apply -f - apiVersion: v1 kind: PersistentVolumeClaim metadata: name: sonarqube-data namespace: security-system spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: sonarqube namespace: security-system spec: replicas: 1 selector: matchLabels: app: sonarqube template: metadata: labels: app: sonarqube spec: securityContext: fsGroup: 1000 initContainers: - name: init-sysctl image: busybox command: [\"sysctl\", \"-w\", \"vm.max_map_count=262144\"] securityContext: privileged: true containers: - name: sonarqube image: sonarqube:community ports: - containerPort: 9000 env: - name: SONAR_JDBC_URL value: \"jdbc:postgresql://postgres-postgresql.databases.svc.cluster.local:5432/sonarqube\" - name: SONAR_JDBC_USERNAME value: \"postgres\" - name: SONAR_JDBC_PASSWORD value: \"${DRUPPIE_POSTGRES_PASS}\" resources: requests: memory: \"1Gi\" cpu: \"500m\" limits: memory: \"2Gi\" volumeMounts: - mountPath: /opt/sonarqube/data name: sonarqube-data volumes: - name: sonarqube-data persistentVolumeClaim: claimName: sonarqube-data --- apiVersion: v1 kind: Service metadata: name: sonarqube-sonarqube namespace: security-system spec: selector: app: sonarqube ports: - port: 9000 targetPort: 9000 name: http type: ClusterIP EOF log \"Waiting for SonarQube to start...\" kubectl rollout status deployment/sonarqube -n security-system --timeout=300s log_history \"SonarQube Installed (Manual Manifest)\" 5. Success echo -e \"${COLOR_GREEN}\" echo \"‚úÖ Security Services Installed!\" echo \"------------------------------\" echo \" - Trivy: Background Operator (Check 'trivy-operator' pod)\" echo \" - SonarQube: http://sonarqube-sonarqube.security-system.svc.cluster.local:9000\" echo \" User: admin\" echo \" Pass: admin (Requires change on first login)\" echo \"\" echo \"‚ö†Ô∏è Note: Port-forward to access locally:\" echo \" kubectl port-forward svc/sonarqube-sonarqube -n security-system 9000:9000\" echo -e \"${COLOR_NC}\""
  },
  {
    "title": "Install Druppie Core",
    "category": "scripts",
    "path": "script/install_druppie.sh",
    "content": "!/bin/bash set -e Druppie Core Installer Installs the main application logic (Druppie Core) via Helm Context Checks if [ -z \"$DRUPPIE_DOMAIN\" ]; then echo \"Error: DRUPPIE_DOMAIN is not set. Please source .secrets or run via druppie.sh\" exit 1 fi echo \"Deploying Druppie Core to Kubernetes...\" Path to the Helm chart and Core Source SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\" CHART_PATH=\"$SCRIPT_DIR/../core/deploy/helm\" CORE_DIR=\"$SCRIPT_DIR/../core\" 1. Build Docker Image echo \"Building Druppie Core Docker Image...\" if ! command -v docker \u0026\u003e /dev/null; then echo \"Error: Docker not found. Cannot build image.\" exit 1 fi docker build -t druppie-core:latest \"$CORE_DIR\" 2. Import into k3d (if running locally on k3d) We use the cluster name from env or default K3D_CLUSTER_NAME=\"${DRUPPIE_CLUSTER_NAME:-druppie-dev}\" if command -v k3d \u0026\u003e /dev/null; then if k3d cluster list | grep -q \"$K3D_CLUSTER_NAME\"; then echo \"Importing image into k3d cluster '$K3D_CLUSTER_NAME'...\" k3d image import druppie-core:latest -c \"$K3D_CLUSTER_NAME\" else echo \"k3d installed but cluster '$K3D_CLUSTER_NAME' not found. Skipping import (assuming remote or other setup).\" fi else echo \"k3d not found. Skipping image import.\" fi echo \"Deploying Druppie Core to Kubernetes...\" Install/Upgrade the Helm chart We use 'upgrade --install' to ensure idempotency helm upgrade --install druppie-core \"$CHART_PATH\" \\ --namespace druppie \\ --create-namespace \\ --set ingress.host=\"$DRUPPIE_DOMAIN\" \\ --wait Note: values.yaml defaults to pullPolicy: IfNotPresent, which works with the pre-loaded image. echo \"‚úÖ Druppie Core deployed successfully!\""
  },
  {
    "title": "Uninstall Kubernetes",
    "category": "scripts",
    "path": "script/uninstall_k8s.sh",
    "content": "!/bin/bash Druppie Uninstaller Removes RKE2 or k3d clusters set -e COLOR_RED='\\033[0;31m' COLOR_NC='\\033[0m' Log File Location (Project Root) LOG_FILE=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)/../.druppie_history\" function log() { echo -e \"${COLOR_RED}[UNINSTALL]${COLOR_NC} $1\" } function log_history() { echo \"$(date '+%Y-%m-%d %H:%M:%S') | UNINSTALL | Kubernetes | $1\" \u003e\u003e \"$LOG_FILE\" } echo \"Which Kubernetes distribution do you want to remove?\" echo \"1) k3d (Docker Container)\" echo \"2) RKE2 (Linux Service)\" if [ -n \"$1\" ]; then case $1 in 1|k3d) OPT=\"1\" ;; 2|rke2) OPT=\"2\" ;; ) echo \"Invalid argument: $1\"; exit 1 ;; esac echo \"Selected Option: $1 ($OPT)\" else read -p \"Choice [1-2]: \" OPT fi if [ \"$OPT\" == \"2\" ]; then RKE2 Uninstall if [[ $EUID -ne 0 ]]; then echo \"RKE2 uninstall requires root.\" exit 1 fi log \"Stopping RKE2...\" systemctl stop rke2-server systemctl disable rke2-server log \"Running RKE2 Uninstall Script...\" if [ -f /usr/local/bin/rke2-uninstall.sh ]; then /usr/local/bin/rke2-uninstall.sh else echo \"Uninstall script not found. Was RKE2 installed?\" exit 1 fi log \"RKE2 removed.\" log_history \"RKE2\" elif [ \"$OPT\" == \"1\" ]; then k3d Uninstall CLUSTER_NAME=\"${DRUPPIE_CLUSTER_NAME:-druppie-dev}\" log \"Deleting '$CLUSTER_NAME' cluster...\" if command -v k3d \u0026\u003e /dev/null; then k3d cluster delete \"$CLUSTER_NAME\" log \"Cluster deleted.\" log_history \"k3d ($CLUSTER_NAME)\" if [[ \"$(uname)\" == \"Darwin\" ]]; then macOS: Remove k3d binary brew uninstall k3d log \"k3d removed.\" log_history \"k3d\" else Linux: Remove k3d binary sudo rm -f /usr/local/bin/k3d log \"k3d removed.\" log_history \"k3d\" fi else echo \"k3d binary not found.\" fi else echo \"Invalid choice.\" fi"
  },
  {
    "title": "Overview",
    "category": "tools",
    "path": "tools/overview.md",
    "content": "üõ†Ô∏è Tools Overview Het Druppie Platform biedt een breed scala aan ge√Øntegreerde tools om jouw ontwikkelproces, data-analyse en beheer te ondersteunen. Categorie√´n üîê Identity \u0026 Access - Keycloak: Beheer gebruikers en toegang tot alle applicaties centraal. üìä Observability - Grafana: Monitor de gezondheid van je applicaties en infrastructuur. üíæ Data Services - Gitea: Git hosting voor je broncode en GitOps configuraties. - MinIO: S3-compatible opslag voor bestanden en datasets. - pgAdmin: Beheertool voor de PostgreSQL databases. üåç GIS Services - GeoServer: Serveer kaarten en geodata via web standaarden. - GeoNode: Deel en beheer geospatiale content. - NodeODM: Verwerk dronebeelden tot kaarten. ‚öôÔ∏è System Administration - Rancher: Beheer je Kubernetes clusters. - Kong Manager: Configureer je API Gateway en routes. Klik in het menu op een specifieke tool voor gedetailleerde instructies."
  },
  {
    "title": "Keycloak (IAM)",
    "category": "tools",
    "path": "tools/keycloak.md",
    "content": "üîê Keycloak - Identity \u0026 Access Management Wat is het? Keycloak is de centrale authenticatie- en autorisatieserver van het Druppie Platform. Het beheert gebruikers, groepen en rollen en verzorgt de Single Sign-On (SSO) voor alle andere applicaties. Waarvoor gebruik je het? - Gebruikersbeheer: Aanmaken en beheren van accounts. - Single Sign-On: E√©n keer inloggen voor Gitea, Grafana, Argo, etc. - Rollen \u0026 Rechten: Bepalen wie toegang heeft tot welke applicatie. Inloggen - URL: https://keycloak.localhost (of jouw domein) - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_KEYCLOAK_PASS) Hoe te gebruiken 1. Ga naar de Administration Console. 2. Log in met de admin gegevens. 3. Beheer 'Realms' (standaard is er vaak een bedrijfsnaam of applicatienaam realm). 4. Onder Users kun je nieuwe teamleden toevoegen. 5. Onder Clients zie je de gekoppelde applicaties."
  },
  {
    "title": "Grafana (Obs)",
    "category": "tools",
    "path": "tools/grafana.md",
    "content": "üìä Grafana - Observability Dashboard Wat is het? Grafana is het centrale visualisatieplatform van de Observability stack. Het fungeert als de \"single pane of glass\" waarmee je de status, prestaties en fouten van het hele platform kunt inzien. Het maakt gebruik van de zogenaamde LGTM stack (Loki, Grafana, Tempo, Mimir/Prometheus). Ge√Øntegreerde Tools \u0026 Mogelijkheden üìã Prometheus (Metrics) - \"Is het systeem gezond?\" Prometheus verzamelt cijfermatige data (metrics) zoals CPU-gebruik, geheugengebruik en het aantal requests per seconde. - Gebruik dit voor: Het bouwen van dashboards die trends laten zien (bijv. \"Loopt het geheugen vol?\" of \"Hoeveel bezoekers zijn er nu?\"). ü™µ Loki (Logging) - \"Wat is er gebeurd?\" Loki is een log-aggregatiesysteem dat vaak wordt omschreven als \"Prometheus voor logs\". Het indexeert logs op basis van labels (zoals app naam of namespace) in plaats van de volledige tekst, wat het erg snel en effici√´nt maakt. - Gebruik dit voor: Het doorzoeken van logs van al je containers op √©√©n plek. Gebruik LogQL (Loki Query Language) om foutmeldingen te filteren, bijvoorbeeld: {app=\"gitea\"} |= \"error\". ‚è±Ô∏è Tempo (Tracing) - \"Waar zit de vertraging?\" Tempo is een distributed tracing backend. Het volgt een request terwijl het door verschillende services in je cluster reist. - Gebruik dit voor: Performance optimalisatie en debugging. Als een pagina traag laadt, kun je met Tempo precies zien welke microservice of database query de vertraging veroorzaakt. ü§ñ Alloy (Collector) Alloy (voorheen Grafana Agent) draait op de achtergrond op je cluster. Het verzamelt automatisch alle logs, metrics en traces van je applicaties en stuurt deze naar bovenstaande tools. Inloggen - URL: https://grafana.localhost - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_GRAFANA_PASS) Hoe te gebruiken 1. Dashboards: Ga naar 'Dashboards' om kant-en-klare overzichten van je Kubernetes cluster te zien. 2. Explore (Logs bekijken): - Klik op het kompas-icoon (Explore). - Kies bovenaan Loki als source. - Selecteer bij 'Label filters' bijvoorbeeld app = portal. - Klik op \"Run query\" om live logs te zien. 3. Explore (Traces bekijken): - Als je in de logs een TraceID ziet (vaak automatisch gedetecteerd door onze configuratie), klik erop om direct naar de Tempo trace te springen."
  },
  {
    "title": "Gitea (Git)",
    "category": "tools",
    "path": "tools/gitea.md",
    "content": "üêô Gitea - Git Version Control Wat is het? Gitea is de Git server van het platform. Het is een lichtgewicht alternatief voor GitHub/GitLab en beheert alle broncode en configuraties (GitOps). Waarvoor gebruik je het? - Source Code: Opslaan en versiebeheer van applicatiecode. - GitOps: Opslaan van Kubernetes manifesten die door Flux CD worden uitgerold. - Pull Requests: Samenwerken aan codewijzigingen. Inloggen - URL: https://gitea.localhost - Gebruikersnaam: druppie_admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_GITEA_PASS) Hoe te gebruiken 1. Log in om repositories te bekijken of aan te maken. 2. Clone repositories lokaal: git clone https://gitea.localhost/druppie_admin/mijn-repo.git. 3. Gebruik Access Tokens voor CI/CD integraties."
  },
  {
    "title": "MinIO (S3)",
    "category": "tools",
    "path": "tools/minio.md",
    "content": "üóÑÔ∏è MinIO - Object Storage (S3) Wat is het? MinIO is een High Performance Object Storage die compatibel is met de Amazon S3 API. Het fungeert als de centrale 'Data Lake' voor ongestructureerde data. Waarvoor gebruik je het? - Bestandsopslag: Opslaan van afbeeldingen, video's, documenten en model-artefacten. - Backups: Opslaglocatie voor database backups. - Data Lake: Ruwe data opslag voor AI en analytics. Inloggen - URL: https://minio.localhost - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_MINIO_PASS) Hoe te gebruiken 1. Log in op de Console om 'Buckets' aan te maken. 2. Upload en download bestanden via de browser interface. 3. Maak 'Access Keys' aan onder Identity om applicaties toegang te geven."
  },
  {
    "title": "pgAdmin (DB UI)",
    "category": "tools",
    "path": "tools/pgadmin.md",
    "content": "üêò pgAdmin - PostgreSQL Management Wat is het? pgAdmin is de beheerinterface voor de PostgreSQL databases die in het cluster draaien. Waarvoor gebruik je het? - Database Beheer: Tabellen bekijken, maken en wijzigen. - Queries: SQL queries uitvoeren voor analyse of debugging. - Onderhoud: Backups maken en gebruikers beheren. Inloggen - URL: https://pgadmin.localhost - Gebruikersnaam: admin@druppie.nl (pgAdmin vereist een e-mailadres, 'admin' alleen werkt niet) - Wachtwoord: Zie het .secrets bestand (vaak gelijk aan DRUPPIE_POSTGRES_PASS) Hoe te gebruiken 1. Na inloggen zie je links de server \"Druppie Shared DB\" (of vergelijkbaar). 2. Klik het open en voer het database wachtwoord in (zie .secrets bestand, DRUPPIE_POSTGRES_PASS). 3. Browse door Databases \u003e Schemas \u003e Tables. 4. Gebruik de Query Tool (rechtermuisknop op een database) om SQL te schrijven."
  },
  {
    "title": "GeoServer (GIS)",
    "category": "tools",
    "path": "tools/geoserver.md",
    "content": "üó∫Ô∏è GeoServer - Geospatial Data Server Wat is het? GeoServer is een open source server voor het delen en bewerken van geospati√´le data. Het publiceert data volgens open standaarden zoals WMS, WFS en WCS. Waarvoor gebruik je het? - Kaarten Serveren: Publiceer vectordata (Shapefiles, PostGIS) als kaartlagen. - Styling: Stijl kaarten met SLD of CSS. - Data Delen: Maak GIS data beschikbaar voor webapplicaties en desktop GIS (QGIS). Inloggen - URL: https://geoserver.localhost/geoserver/web/ - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_GEOSERVER_PASS) Hoe te gebruiken 1. Layers: Bekijk gepubliceerde kaartlagen. 2. Stores: Verbind met databases (PostGIS) of bestanden (Shapefiles) om data toe te voegen. 3. Layer Preview: Bekijk snel hoe een laag eruit ziet in OpenLayers."
  },
  {
    "title": "GeoNode (GIS CMS)",
    "category": "tools",
    "path": "tools/geonode.md",
    "content": "üåç GeoNode - Geospatial CMS Wat is het? GeoNode is een Content Management Systeem (CMS) speciaal voor geospati√´le data. Het combineert de kracht van GeoServer met een gebruiksvriendelijke interface voor het uploaden, beheren en delen van data. Waarvoor gebruik je het? - Data Catalogus: Zoeken en vinden van GIS datasets. - Metadata: Beheren van beschrijvingen en tags bij data. - Kaarten Maken: Interactieve kaarten samenstellen vanuit lagen zonder technische kennis. Inloggen - URL: https://geonode.localhost - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (DRUPPIE_POSTGRES_PASS wordt vaak gebruikt als initieel wachtwoord). Hoe te gebruiken 1. Upload Layers: Upload Shapefiles, GeoTIFFs of andere GIS bestanden. 2. Create Maps: Combineer lagen tot een kaart. 3. Share: Deel kaarten en lagen met specifieke gebruikers of publiek."
  },
  {
    "title": "NodeODM (Drone Images)",
    "category": "tools",
    "path": "tools/nodeodm.md",
    "content": "üöÅ NodeODM - Drone Imagery Processing Wat is het? NodeODM is een lichtgewicht API en interface voor OpenDroneMap (ODM). Het verwerkt luchtfoto's (van drones) tot 3D-modellen, orthofoto's en puntenwolken. Waarvoor gebruik je het? - Fotogrammetrie: Omzetten van 2D foto's naar 3D data. - Orthophotos: Maken van hoog-resolutie kaarten van een gebied. - 3D Modellen: Genereren van textured meshes en point clouds. Inloggen - URL: https://nodeodm.localhost - Gebruikersnaam: (Geen, open toegang of API token indien ingesteld) - Wachtwoord: - Hoe te gebruiken 1. New Task: Klik op \"Select Images and GCP\" om foto's te uploaden. 2. Options: Kies de gewenste output (bijv. Orthophoto + DSM). 3. Start: Start de taak en wacht tot de verwerking klaar is. 4. Download: Download de resultaten (.tif, .laz, .obj)."
  },
  {
    "title": "Rancher (K8s UI)",
    "category": "tools",
    "path": "tools/rancher.md",
    "content": "ü§† Rancher - Cluster Management Wat is het? Rancher is een interface voor het beheren van Kubernetes clusters. Het maakt het eenvoudig om workloads, nodes en netwerken te visualiseren en te beheren. Waarvoor gebruik je het? - Cluster Overzicht: Zien welke nodes en pods draaien. - Troubleshooting: Logs en events van pods bekijken. - Workload Management: Deployments schalen, herstarten of aanpassen via een UI. Inloggen - URL: https://rancher.localhost - Gebruikersnaam: admin - Wachtwoord: Zie het .secrets bestand (wordt gegenereerd als DRUPPIE_RANCHER_PASS of staat in logs). Hoe te gebruiken 1. Selecteer het \"local\" cluster. 2. Ga naar Workloads om applicaties te zien. 3. Gebruik de Shell knop om direct een kubectl shell in de browser te openen."
  },
  {
    "title": "Kong Manager (API Gateway)",
    "category": "tools",
    "path": "tools/kong.md",
    "content": "ü¶ç Kong Manager - API Gateway Wat is het? Kong Manager is de grafische interface voor de Kong API Gateway. Kong beheert al het inkomende verkeer naar het platform (Ingress Controller). Waarvoor gebruik je het? - Routes \u0026 Services: Zien welke URL's naar welke interne services leiden. - Plugins: Configureren van plugins zoals Rate Limiting, Authenticatie of Transformaties. - Troubleshooting: Bekijken van de status van de gateway routes. Inloggen - URL: https://kong.localhost - Gebruikersnaam: (Open in OSS versie, of basic auth indien geconfigureerd) - Wachtwoord: Zie het .secrets bestand (DRUPPIE_KONG_PASS) Hoe te gebruiken 1. Services: Bekijk de gedefinieerde backends (bijv. gitea, grafana). 2. Routes: Zie welke hostnames (.localhost) gekoppeld zijn aan welke service. 3. Plugins: Activeer plugins op specifieke routes (bijv. Keycloak authenticatie)."
  },
  {
    "title": "Project Readme",
    "category": "general",
    "path": "README.md",
    "content": "Druppie ‚Äì Spec-Driven AI Architectuur Druppie is een geavanceerd enterprise platform voor Spec-Driven AI en Human-in-the-Loop automatisering. Dit project beschrijft hoe AI-agents, compliance-regels en menselijke interactie samenkomen om software veilig, schaalbaar en consistent te bouwen en te beheren. De focus ligt op het automatiseren van de volledige lifecycle binnen een overheidscontext (Waterschap/Gemeente), met zware nadruk op Security, Privacy (GDPR) en Compliance (BIO/NIS2/AI Act). One-Stop-Shop: Deze repository bevat zowel de architectuurdocumentatie als de Infrastructure-as-Code (IaC) scripts om een platform te implementeren, waarmee de bouwblokken en skills kunnen worden ge√Ømplementeerd. De focus ligt op het experimenteren en gebruiken van AI-agents en compliance-regels in een overheidsomgeving. --- üöÄ Aan de slag met de Architectuur De volledige architectuur is interactief te verkennen. 1. Open index.html in je browser. 2. Gebruik het dashboard om door de verschillende lagen (Bouwblokken, Skills, Runtime) te navigeren. 3. Draai simulaties (Scenarios) om de interactie tussen componenten te visualiseren. üöÄ Snel Starten met het Platform De makkelijkste manier om te beginnen is via de Druppie CLI ./druppie.sh !Druppie CLI Dit interactieve menu geeft toegang tot: 1. ‚ò∏Ô∏è Installatie: Kubernetes (RKE2 voor Prod, k3d voor Dev 'local docker')). 2. üèóÔ∏è Bootstrap: Platform base layer (Flux, Kyverno, Tekton, Kong). 3. üì¶ Services: One-click setup voor Gitea, Keycloak, Prometheus, GeoServer, etc. 4. üöÄ UI: Toegang scherm tot de verschillende UI's van de verschillende services. De password voor de verschillende services is 'druppie' worden opgeslagen in de .secrets file. De installatie logs zijn terug te vinden in de directory .logs. En de applicatie installatie overiew is terug te vinden in de .druppie_history file. !Druppie k3d Deze installatie is een lokaal installatie en draait in een docker container en is toegankelijk via de k3d cluster op https://localhost waarbij je wel even het certificaat moet accepteren. Wil je alles in een keer lokaal installeren? dan gebruik je ./druppie.sh ua k3d --- üìÇ Projectstructuur De repository is opgebouwd uit verschillende lagen: 1. üß± Bouwblokken De lego-stenen van het platform. Definities van tools en componenten: Security: Trivy, SonarQube. Data: MinIO, Gitea, Qdrant (Vector DB). GIS: GeoServer, PostGIS, WebODM, GeoNode. Observability: LGTM Stack (Loki, Grafana, Tempo, Prometheus). 2. üèóÔ∏è Build Plane De \"Agent Factory\". Hier wordt code omgezet in veilige artifacts: Builder Agent: AI die code, tests en docs genereert. Automated Testing: Unit, Integration, E2E in Tekton pipelines. Secure Supply Chain: SBOMs en signatures bij elke build. 3. ‚öôÔ∏è Runtime De landingsplaats (Kubernetes): Hybride Cluster: Draait deels in Azure, deels On-Premise. Policy Engine (Kyverno): Dwingt regels af (bv. \"Geen root containers\"). Agentic RAG: Netwerk van AI agenten die veilig data ontsluiten. 4. üìù Ontwerpen (Designs) Gedetailleerde technische ontwerpen en functionele beschrijvingen: Exoten Detectie: Satelliet + Drone flow. Vergunning zoeker: AI zoekt oude aktes. Automated Rebuild: Self-healing bij security patches. 5. üõ°Ô∏è Compliance De regels en wetten vertaald naar techniek: AI Act \u0026 Register: Verplichte registratie van algoritmes. BIO \u0026 NIS2: Baseline Informatiebeveiliging. Goed Bestuur: Principes van transparantie en controleerbaarheid. --- üí° Kernprincipes 1. Alles is een Spec: Van infrastructuur tot agent-gedrag, alles wordt vastgelegd in leesbare files. 2. Human-in-the-Loop: Kritieke beslissingen (vliegroute drone, verwijderen data) vereisen altijd menselijke goedkeuring. 3. Secure by Design: Security tools (Trivy, Kyverno) staan \"aan\" by default. 4. Traceerbaarheid: Elke actie, van prompt tot deployment, wordt gelogd in de Traceability DB. --- üõ†Ô∏è Scripts \u0026 Tools Bekijk de Script Overview voor een lijst van alle beschikbare beheerscripts. üê≥ Docker (Druppie Core) To run the Druppie Core server (including UI and backend logic) using Docker in a production-like environment: 1. Build the image (execute from the project root): bash docker build -t druppie-core . 2. Run the container: bash docker run -d \\ -p 8080:8080 \\ -v $(pwd)/.druppie:/app/.druppie \\ --name druppie-server \\ druppie-core Port 8080: Access the UI at http://localhost:8080/ui/. Volume: Maps your local .druppie directory to the container, ensuring plans and logs are persisted and accessible locally. Search index De search index is gemaakt met de node generate_search_index.js script en wordt opgeslagen in search_index.json."
  },
  {
    "title": "Het Verhaal Druppie",
    "category": "general",
    "path": "story/story.md",
    "content": "Het Verhaal van Druppie We vertellen hier het verhaal van Druppie, een AI-assistent die is ontwikkeld om te helpen bij het beheer van water door Waterschappen. Introductie !Slide Image \u003c!-- Placeholder, mapping might be off --\u003e De Strategische Verschuiving De kern van de Vaarkaart is de beweging van traditionele automatisering naar een fundamentele digitale transformatie. Van 'Samen Doen' naar 'Samenwerken als Concern': De 21 waterschappen moeten niet langer allemaal hun eigen IT-wiel uitvinden. Het doel is opereren als √©√©n concern om schaalvoordeel te behalen, kosten te drukken en kwaliteit te verhogen. Datagedreven Waterbeheer: De focus verschuift van het beheren van systemen naar het waardevol maken van data. Data wordt gezien als een strategisch asset om wateroverlast, droogte en waterkwaliteit beter te voorspellen en te beheren. Uniformiteit als Basis: Om data uitwisselbaar te maken en samen te kunnen werken, is standaardisatie van processen en techniek noodzakelijk. Dit betekent minder maatwerk per waterschap en meer gezamenlijke standaarden. De Pijlers van de Transformatie De uitvoering van de digitale agenda in de Vaarkaart rust op een aantal concrete thema's: Informatieveiligheid \u0026 Privacy (IBP): Omdat waterbeheer vitale infrastructuur is, is cyberveiligheid topprioriteit. De focus ligt op weerbaarheid tegen hacks en het voldoen aan wetgeving (zoals de BIO en NIS2). De Digitale Werkplek: Het faciliteren van een moderne, plaatsonafhankelijke werkomgeving die samenwerking tussen waterschappen en ketenpartners (zoals Rijkswaterstaat en gemeenten) naadloos maakt. Dataplatforms \u0026 Cloud: De beweging naar de cloud (bijvoorbeeld via het Waterschaps Data Platform) om enorme hoeveelheden sensordata en satellietbeelden te kunnen verwerken. Innovatie \u0026 Nieuwe Technologie: Actieve inzet van Digital Twins (digitale kopie√´n van het watersysteem) om scenario's te simuleren. Gebruik van Artificial Intelligence (AI) en algoritmes voor voorspellend onderhoud en peilbeheer. Mens en Organisatie (De Zachte Kant) De Vaarkaart benadrukt dat digitale transformatie niet alleen over techniek gaat, maar vooral over mensen. Digitaal Veradervermogen: Er is een cultuur nodig waarin men durft te delen, over de grenzen van het eigen waterschap heen kijkt en openstaat voor verandering in werkwijzen. Digitale Vaardigheid: Medewerkers van waterschappen moeten worden opgeleid om met nieuwe digitale tools en data-analyses te kunnen werken. Digitale Innovator: De waterschappen moeten sneller kunnen inspelen op nieuwe technologische ontwikkelingen en veranderende klimaatomstandigheden en hierdoor moeten we durven te experimenteren en innoveren om nieuwe mogelijkheden te ontdekken. We zijn goed op weg !Slide Image \u003c!-- Placeholder, mapping might be off --\u003e Binnen de technologie onderscheiden we verschillende bouwblokken die voortdurend onderling samenwerken en communiceren. Gezamenlijk leveren ze de diensten en digitalisering op. Waar tot nu toe in deze routekaart vooral de kansen van digitalisering zijn belicht, kent het ook significante risico‚Äôs. We zijn en willen een betrouwbaar waterschap blijven dat goed omgaat met de gegevens van haar burgers en bedrijven. Daarom zorgen we er continu voor de digitale weerbaarheid op orde is, zoals tegen hackers en randsomeware. En naarmate we meer digitaliseren zullen algoritmes en kunstmatige intelligentie steeds meer worden toegepast. Dat vraagt naast informatieveiligheid om continue alertheid voor privacy en ethiek. Zodat de kansen van digitalisering verzilverd kunnen worden terwijl de risico‚Äôs tot een minimum beperkt worden.‚Äã Bij het gebruik van algoritmes en kunstmatige intelligentie willen we voorkomen dat er informatie gegeneerd wordt die tegen ethische grenzen aanzitten of er zelfs over heen gaan. Daarom is het een van onze prioriteiten om een ethische AI omgeving te cre√´ren, waarbinnen digitale ontwikkelingen to bloei kunnen komen. Ook aspecten als inclusie, toegankelijkheid voor iedereen, ‚Äòde menselijke maat‚Äô en digital violence zijn onderdeel van de ethische afwegingen. Van visie naar uitvoering !Slide Image \u003c!-- Placeholder, mapping might be off --\u003e Digitale transformatie is niet een gewoon project, maar een verandertraject met impact op de gehele organisatie. Uit de praktijk blijkt dan ook als digitale transformatie wordt aangestuurd als een regulier project dat de implementatie moeizaam gaat of mislukt. Daarom is er gekozen voor een meer natuurlijk proces van Leren, Experimenteren en Verbeteren. Om te zorgen dat we de goede dingen kunnen en gaan doen is het noodzakelijk dat er van boven af wordt gestuurd. De stuurgroep is er om de richting en scope te bepalen wat eerst en wat later, maar ook te zorgen dat de juiste middelen en voorwaarden er zijn om te kunnen leren, experimenteren en verbeteren. Een kleine support groep zorgt ervoor dat de randvoorwaarden voor de teams of medewerkers zijn ingevuld voor dat de proces verandering (Minimal Viable Change) wordt gestart en beg"
  },
  {
    "title": "License (MIT)",
    "category": "general",
    "path": "LICENSE.md",
    "content": "MIT License Copyright (c) 2025 Project Druppie Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  }
]